{"id":"SPEC-001","uuid":"37d447c6-5f01-435d-b7e8-99d689e597f8","title":"Agent Execution System","file_path":"specs/agent_execution_system.md","content":"# Agent Execution System\n\n## Overview\n\nA flexible system for running different coding agents on issues and tracking their execution trajectories. Designed for sudocode's TypeScript/Node.js stack.\n\n## Architecture\n\n### Three-Layer Execution Model\n\n```\nIssue → Execution → Trajectory Entries\n  ↓         ↓            ↓\nTask      Process    Log Events\n```\n\n**1\\. Issue** (existing)\n\n- Already implemented in sudocode\n- Represents a task to be completed\n\n**2\\. Execution** (new)\n\n- Represents a single agent run on an issue\n- Tracks: agent type, status, git context, session info\n- Multiple executions can exist per issue (retries, different agents)\n\n**3\\. Trajectory Entry** (new)\n\n- Individual events/actions during execution\n- Tool uses, thinking, messages, file changes\n- Enables playback and analysis of agent behavior\n\n### Supported Agents\n\nPhase 1: **Claude Code** (via `@anthropic-ai/claude-code`) Phase 2: **Codex** (via `@phasehq/codex`) Future: Aider, Cursor, custom agents\n\n## Data Models\n\n### Execution\n\n```typescript\ninterface Execution {\n  id: string;                    // UUID\n  issueId: string;               // Foreign key to issues\n  agentType: AgentType;          // Which agent ran\n  status: ExecutionStatus;       // Current state\n  \n  // Timestamps\n  startedAt: Date;\n  completedAt?: Date;\n  \n  // Process info\n  exitCode?: number;\n  \n  // Git context (captured before/after)\n  beforeCommit?: string;         // Git SHA before execution\n  afterCommit?: string;          // Git SHA after execution\n  \n  // Session tracking (for resume/fork)\n  sessionId?: string;            // External session ID from agent\n  prompt?: string;               // Initial prompt sent\n  summary?: string;              // Final agent summary\n  \n  // Metadata\n  createdAt: Date;\n  updatedAt: Date;\n}\n\ntype AgentType = 'claude-code' | 'codex';\n\ntype ExecutionStatus = \n  | 'running'\n  | 'completed' \n  | 'failed'\n  | 'stopped';\n```\n\n### Trajectory Entry\n\n```typescript\ninterface TrajectoryEntry {\n  id: number;                    // Auto-increment\n  executionId: string;           // Foreign key to executions\n  index: number;                 // Sequential order within execution\n  timestamp: Date;\n  \n  // Entry type and data (polymorphic)\n  type: EntryType;\n  content: string;               // Display text\n  metadata?: Record<string, any>; // Type-specific data\n}\n\ntype EntryType = \n  | 'tool_use'        // Agent used a tool\n  | 'thinking'        // Agent reasoning/planning\n  | 'assistant_msg'   // Agent message to user\n  | 'user_msg'        // User message to agent\n  | 'user_feedback'   // User approval/denial\n  | 'system_msg'      // System notifications\n  | 'error_msg';      // Errors\n\n// Tool use metadata\ninterface ToolUseMetadata {\n  toolName: string;\n  action: ActionType;\n  status: 'created' | 'running' | 'success' | 'failed';\n}\n\ntype ActionType =\n  | { type: 'file_read', path: string }\n  | { type: 'file_edit', path: string, changes: FileChange[] }\n  | { type: 'file_write', path: string, content: string }\n  | { type: 'command_run', command: string, result?: CommandResult }\n  | { type: 'search', query: string }\n  | { type: 'web_fetch', url: string }\n  | { type: 'task_create', description: string }\n  | { type: 'tool', toolName: string, args: any, result?: any };\n\ninterface FileChange {\n  type: 'edit' | 'write';\n  unifiedDiff?: string;          // For edits\n  content?: string;              // For writes\n  hasLineNumbers: boolean;\n}\n\ninterface CommandResult {\n  exitStatus: { code: number } | { success: boolean };\n  output: string;\n}\n```\n\n## Agent Abstraction\n\n### CodingAgent Interface\n\n```typescript\ninterface CodingAgent {\n  // Spawn initial execution\n  spawn(\n    workDir: string, \n    prompt: string\n  ): Promise<SpawnedProcess>;\n  \n  // Spawn follow-up (resume/fork)\n  spawnFollowUp(\n    workDir: string,\n    prompt: string, \n    sessionId: string\n  ): Promise<SpawnedProcess>;\n  \n  // Normalize agent-specific logs to TrajectoryEntry\n  normalizeLogs(\n    rawLogs: AsyncIterable<string>\n  ): AsyncIterable<TrajectoryEntry>;\n  \n  // Capabilities\n  supportsSessionFork(): boolean;\n  supportsMCP(): boolean;\n  getDefaultMCPConfigPath(): string | null;\n}\n\ninterface SpawnedProcess {\n  process: ChildProcess;\n  exitSignal?: Promise<void>;  // Optional early exit signal\n}\n```\n\n### Claude Code Executor\n\n```typescript\nclass ClaudeCodeExecutor implements CodingAgent {\n  async spawn(workDir: string, prompt: string) {\n    const proc = spawn('npx', [\n      '-y', '@anthropic-ai/claude-code@latest',\n      '-p',\n      '--output-format=stream-json',\n      '--include-partial-messages',\n      '--verbose'\n    ], { \n      cwd: workDir,\n      stdio: ['pipe', 'pipe', 'pipe']\n    });\n    \n    proc.stdin.write(prompt);\n    proc.stdin.end();\n    \n    return { process: proc };\n  }\n  \n  async spawnFollowUp(workDir: string, prompt: string, sessionId: string) {\n    const proc = spawn('npx', [\n      '-y', '@anthropic-ai/claude-code@latest',\n      '-p',\n      '--output-format=stream-json',\n      '--include-partial-messages',\n      '--verbose',\n      '--fork-session',\n      '--resume', sessionId\n    ], { cwd: workDir });\n    \n    proc.stdin.write(prompt);\n    proc.stdin.end();\n    \n    return { process: proc };\n  }\n  \n  async *normalizeLogs(rawLogs: AsyncIterable<string>) {\n    let buffer = '';\n    let sessionIdExtracted = false;\n    let entryIndex = 0;\n    \n    for await (const chunk of rawLogs) {\n      buffer += chunk;\n      \n      // Process complete JSON lines\n      const lines = buffer.split('\\n');\n      buffer = lines.pop() || '';\n      \n      for (const line of lines) {\n        const trimmed = line.trim();\n        if (!trimmed) continue;\n        \n        try {\n          const json = JSON.parse(trimmed);\n          \n          // Extract session ID\n          if (!sessionIdExtracted && json.session_id) {\n            sessionIdExtracted = true;\n            // Emit session ID separately for storage\n          }\n          \n          // Normalize to TrajectoryEntry\n          const entries = this.normalizeClaudeJson(json, entryIndex);\n          for (const entry of entries) {\n            yield entry;\n            entryIndex++;\n          }\n        } catch (e) {\n          // Non-JSON output - treat as system message\n          yield {\n            index: entryIndex++,\n            type: 'system_msg',\n            content: trimmed,\n            timestamp: new Date()\n          };\n        }\n      }\n    }\n  }\n  \n  private normalizeClaudeJson(json: any, startIndex: number): TrajectoryEntry[] {\n    // Parse Claude's JSON format into TrajectoryEntry[]\n    const entries: TrajectoryEntry[] = [];\n    \n    switch (json.type) {\n      case 'system':\n        if (json.subtype !== 'init') {\n          entries.push({\n            index: startIndex,\n            type: 'system_msg',\n            content: `System: ${json.subtype || 'message'}`,\n            timestamp: new Date(),\n            metadata: json\n          });\n        }\n        break;\n        \n      case 'assistant':\n        for (const item of json.message.content) {\n          if (item.type === 'text') {\n            entries.push({\n              index: startIndex + entries.length,\n              type: 'assistant_msg',\n              content: item.text,\n              timestamp: new Date(),\n              metadata: item\n            });\n          } else if (item.type === 'thinking') {\n            entries.push({\n              index: startIndex + entries.length,\n              type: 'thinking',\n              content: item.thinking,\n              timestamp: new Date(),\n              metadata: item\n            });\n          } else if (item.type === 'tool_use') {\n            entries.push({\n              index: startIndex + entries.length,\n              type: 'tool_use',\n              content: this.generateToolContent(item),\n              timestamp: new Date(),\n              metadata: {\n                toolName: item.name,\n                action: this.extractAction(item),\n                status: 'created'\n              }\n            });\n          }\n        }\n        break;\n        \n      case 'user':\n        // Handle tool results and user messages\n        break;\n    }\n    \n    return entries;\n  }\n  \n  supportsSessionFork() { return true; }\n  supportsMCP() { return true; }\n  getDefaultMCPConfigPath() { \n    return `${os.homedir()}/.claude.json`; \n  }\n}\n```\n\n### Codex Executor\n\n```typescript\nclass CodexExecutor implements CodingAgent {\n  async spawn(workDir: string, prompt: string) {\n    // Similar structure, but using Codex CLI\n    const proc = spawn('npx', [\n      '-y', '@phasehq/codex@latest',\n      // Codex-specific flags\n    ], { cwd: workDir });\n    \n    // Codex has different input format\n    proc.stdin.write(JSON.stringify({ prompt }));\n    proc.stdin.end();\n    \n    return { process: proc };\n  }\n  \n  async *normalizeLogs(rawLogs: AsyncIterable<string>) {\n    // Codex-specific log parsing\n    // Different format than Claude\n  }\n  \n  supportsSessionFork() { return true; }\n  supportsMCP() { return true; }\n}\n```\n\n## Database Schema\n\n### Executions Table\n\n[[ISSUE-028]]{ references }\n\n```sql\nCREATE TABLE executions (\n  id TEXT PRIMARY KEY,\n  issue_id TEXT NOT NULL REFERENCES issues(id) ON DELETE CASCADE,\n  agent_type TEXT NOT NULL,  -- 'claude-code' | 'codex' | etc\n  status TEXT NOT NULL,      -- 'running' | 'completed' | 'failed' | 'stopped'\n  \n  started_at INTEGER NOT NULL,\n  completed_at INTEGER,\n  exit_code INTEGER,\n  \n  before_commit TEXT,\n  after_commit TEXT,\n  \n  session_id TEXT,\n  prompt TEXT,\n  summary TEXT,\n  \n  created_at INTEGER NOT NULL DEFAULT (unixepoch()),\n  updated_at INTEGER NOT NULL DEFAULT (unixepoch())\n);\n\nCREATE INDEX idx_executions_issue_id ON executions(issue_id);\nCREATE INDEX idx_executions_status ON executions(status);\nCREATE INDEX idx_executions_session_id ON executions(session_id);\n```\n\n### Trajectory Entries Table\n\n```sql\nCREATE TABLE trajectory_entries (\n  id INTEGER PRIMARY KEY AUTOINCREMENT,\n  execution_id TEXT NOT NULL REFERENCES executions(id) ON DELETE CASCADE,\n  entry_index INTEGER NOT NULL,\n  timestamp INTEGER NOT NULL,\n  \n  type TEXT NOT NULL,  -- 'tool_use' | 'thinking' | 'assistant_msg' | etc\n  content TEXT NOT NULL,\n  metadata TEXT,       -- JSON blob\n  \n  created_at INTEGER NOT NULL DEFAULT (unixepoch())\n);\n\nCREATE INDEX idx_trajectory_entries_execution_id ON trajectory_entries(execution_id);\nCREATE INDEX idx_trajectory_entries_execution_index ON trajectory_entries(execution_id, entry_index);\n```\n\n## API Endpoints\n\n[[ISSUE-031]]{ references }\n\n### Start Execution\n\n```\nPOST /api/issues/:issueId/executions\n{\n  \"agentType\": \"claude-code\",\n  \"prompt\": \"Fix the authentication bug\"\n}\n\nResponse: { \"executionId\": \"exec-123\" }\n```\n\n### Get Execution Status\n\n```\nGET /api/executions/:executionId\n\nResponse: {\n  \"id\": \"exec-123\",\n  \"issueId\": \"issue-456\",\n  \"agentType\": \"claude-code\",\n  \"status\": \"running\",\n  \"startedAt\": \"2025-01-26T10:00:00Z\",\n  ...\n}\n```\n\n### Stream Trajectory (WebSocket)\n\n```\nWS /api/executions/:executionId/trajectory\n\nMessages:\n{\n  \"type\": \"entry\",\n  \"data\": {\n    \"index\": 5,\n    \"type\": \"tool_use\",\n    \"content\": \"`src/auth.ts`\",\n    \"timestamp\": \"2025-01-26T10:01:23Z\",\n    \"metadata\": { ... }\n  }\n}\n\n{\n  \"type\": \"session_id\",\n  \"data\": { \"sessionId\": \"claude-session-abc\" }\n}\n\n{\n  \"type\": \"finished\",\n  \"data\": { \"exitCode\": 0 }\n}\n```\n\n### Stop Execution\n\n```\nPOST /api/executions/:executionId/stop\n\nResponse: { \"status\": \"stopped\" }\n```\n\n### List Executions for Issue\n\n```\nGET /api/issues/:issueId/executions\n\nResponse: {\n  \"executions\": [\n    { \"id\": \"exec-123\", ... },\n    { \"id\": \"exec-124\", ... }\n  ]\n}\n```\n\n## Implementation Phases\n\n### Phase 1: Core Execution (MVP)\n\n[[ISSUE-029]]{ references }**Goal**: Basic process spawning and log storage\n\n**Issues**:\n\n- [[ISSUE-028]] - Database schema and TypeScript types for executions\n- [[ISSUE-029]] - Implement ExecutionManager class for process lifecycle management\n- [[ISSUE-030]] - Implement basic Claude Code process spawning\n- [[ISSUE-031]] - API endpoints for execution management\n- [[ISSUE-032]] - Raw log storage in temp files\n- [[ISSUE-033]] - Integration test for Phase 1 MVP\n\n**Deliverable**: Can start Claude Code on an issue, track if it's running, and know when it finishes.\n\n### Phase 2: Trajectory Normalization\n\n**Goal**: Parse and store structured logs\n\n- Add trajectory\\_entries table\n- ClaudeCodeExecutor with normalization\n- Parse Claude JSON format → TrajectoryEntry\n- Store entries in database\n- API endpoint: get trajectory entries\n\n**Deliverable**: Can view what Claude did step-by-step (tools used, files edited, etc.)\n\n### Phase 3: Real-Time Streaming\n\n**Goal**: Live updates in UI\n\n- WebSocket endpoint for live trajectory\n- Frontend TrajectoryViewer component\n- Display tool uses, thinking, messages\n- Auto-scroll and updates\n\n**Deliverable**: Watch agent execution in real-time\n\n### Phase 4: Session Management\n\n**Goal**: Resume and fork executions\n\n- Extract session IDs during execution\n- Store session\\_id in executions table\n- Implement spawnFollowUp\n- API endpoint: resume execution\n- UI: \"Continue\" button on executions\n\n**Deliverable**: Can send follow-up prompts to same session\n\n### Phase 5: Multiple Agents\n\n**Goal**: Support Codex and others\n\n- CodingAgent abstraction\n- CodexExecutor implementation\n- Agent selection in UI\n- Agent-specific config (MCP, etc.)\n\n**Deliverable**: Can choose between Claude Code and Codex\n\n### Phase 6: Advanced Features\n\n**Goal**: Production-ready\n\n- Git integration (capture commits)\n- Execution history and comparison\n- Trajectory search and filtering\n- Cost tracking (token usage)\n- Approval system for tool execution\n- Export trajectories\n\n## Key Design Decisions\n\n### Why Three Layers (Issue → Execution → Trajectory)?\n\n- **Issue** = What to do (user-defined task)\n- **Execution** = Agent run (can retry, use different agents)\n- **Trajectory** = How it was done (reproducibility, debugging)\n\nThis allows:\n\n1. Multiple attempts on same issue\n1. Comparing different agents\n1. Detailed playback and analysis\n\n### Why Normalize Logs?\n\nDifferent agents have wildly different output formats:\n\n- Claude Code: Structured JSON\n- Codex: Different JSON format\n- Aider: Plain text with markers\n\nNormalization gives us:\n\n1. Unified UI across all agents\n1. Consistent database schema\n1. Easier analysis and search\n\n### Why AsyncIterable for Log Processing?\n\n```typescript\nasync *normalizeLogs(rawLogs: AsyncIterable<string>)\n```\n\nBenefits:\n\n1. Streaming - process logs as they arrive\n1. Memory efficient - don't load all logs at once\n1. Cancellable - can stop mid-stream\n1. Natural async/await syntax\n\n### Why Store Raw + Normalized?\n\nStore both raw logs (temp files) AND normalized entries: [[ISSUE-032]]{ references }\n\n- Raw logs: debugging, replay, re-parsing\n- Normalized: fast queries, UI display\n\nTrade storage for flexibility.\n\n## Testing Strategy\n\n### Unit Tests\n\n- Log normalization logic\n- Action type extraction\n- Session ID parsing\n\n### Integration Tests\n\n[[ISSUE-033]]{ references }\n\n- Full execution lifecycle\n- WebSocket streaming\n- Database persistence\n\n### E2E Tests\n\n- Start execution via API\n- Verify trajectory entries created\n- Check final status\n\n## Open Questions\n\n1. **Where to run executions?**\n  - Option A: Same machine as server (simpler)\n  - Option B: Separate worker processes (scalable)\n  - **Recommendation**: Start with A, migrate to B later\n1. **How to handle long-running executions?**\n  - Timeout after N minutes?\n  - User-configurable timeout?\n  - **Recommendation**: 30min default, configurable per-issue\n1. **Store raw logs where?**\n  - Temp files (deleted after normalization)?\n  - Database blob?\n  - S3/object storage?\n  - **Recommendation**: Temp files initially, add retention later\n1. **How to handle git context?**\n  - Create isolated git worktrees for executions?\n  - Run in-place and capture commits?\n  - **Recommendation**: Start in-place, add worktrees in Phase 6\n\n## Success Metrics\n\n- **MVP (Phase 1)**: Can run Claude Code on an issue\n- **Useful (Phase 3)**: Can watch execution in real-time\n- **Powerful (Phase 4)**: Can have multi-turn conversations\n- **Production (Phase 6)**: Multiple agents, git integration, approval workflows\n\n## References\n\n- Claude Code: [https://docs.anthropic.com/en/docs/claude-code](https://docs.anthropic.com/en/docs/claude-code)\n- Codex: [https://github.com/phasehq/codex](https://github.com/phasehq/codex)\n","priority":0,"archived":1,"archived_at":"2025-10-28T19:03:55.817Z","created_at":"2025-10-27 00:06:59","updated_at":"2025-11-03T03:10:12.596Z","parent_id":null,"parent_uuid":null,"relationships":[{"from":"SPEC-001","from_type":"spec","to":"ISSUE-028","to_type":"issue","type":"references"},{"from":"SPEC-001","from_type":"spec","to":"ISSUE-031","to_type":"issue","type":"references"},{"from":"SPEC-001","from_type":"spec","to":"ISSUE-029","to_type":"issue","type":"references"},{"from":"SPEC-001","from_type":"spec","to":"ISSUE-030","to_type":"issue","type":"references"},{"from":"SPEC-001","from_type":"spec","to":"ISSUE-032","to_type":"issue","type":"references"},{"from":"SPEC-001","from_type":"spec","to":"ISSUE-033","to_type":"issue","type":"references"}],"tags":[]}
{"id":"SPEC-002","uuid":"603f99a9-53d6-448a-b66c-cf6c902894cf","title":"Execution System","file_path":"specs/execution_system.md","content":"Execution System Specification for Sudocode\n\n  Overview\n\n  Design a flexible, simple-first execution system that can spawn Claude Code instances to work on issues and\n  specs, with real-time progress tracking and the ability to upgrade to a pool-based strategy later.\n\n  Architecture Goals\n\n  1. Simple First: Start with straightforward process spawning\n  2. Flexible Design: Easy to upgrade to pool strategy without breaking changes\n  3. Real-time Feedback: Stream progress to frontend via WebSocket\n  4. Context-Aware: Build rich prompts from issue, spec, and codebase data\n  5. Reliable: Handle errors, timeouts, and process crashes gracefully\n\n  System Components\n\n  ┌─────────────────────────────────────────────────────────────┐\n  │                     Execution System                         │\n  ├─────────────────────────────────────────────────────────────┤\n  │                                                              │\n  │  ┌──────────────┐      ┌──────────────┐      ┌──────────┐  │\n  │  │   Context    │      │  Execution   │      │ Progress │  │\n  │  │   Builder    │─────▶│ Orchestrator │─────▶│ Tracker  │  │\n  │  └──────────────┘      └──────┬───────┘      └────┬─────┘  │\n  │                               │                    │         │\n  │                               ▼                    ▼         │\n  │                    ┌──────────────────┐    ┌──────────────┐ │\n  │                    │ Simple Execution │    │  WebSocket   │ │\n  │                    │    Strategy      │    │   Service    │ │\n  │                    └────────┬─────────┘    └──────────────┘ │\n  │                             │                                │\n  │                             ▼                                │\n  │                   ┌──────────────────┐                       │\n  │                   │ Simple Process   │                       │\n  │                   │    Manager       │                       │\n  │                   └────────┬─────────┘                       │\n  │                            │                                 │\n  │                            ▼                                 │\n  │                   ┌──────────────────┐                       │\n  │                   │  Claude Code     │                       │\n  │                   │  CLI Process     │                       │\n  │                   └──────────────────┘                       │\n  │                                                              │\n  └─────────────────────────────────────────────────────────────┘\n\n  Data Flow\n\n  1. User triggers execution (via API/UI)\n     ↓\n  2. ExecutionOrchestrator.executeIssue(issueId)\n     ↓\n  3. ContextBuilder.buildIssueContext(issueId)\n     - Read issue from database\n     - Find related specs via relationships\n     - Find related issues (dependencies, parent)\n     - Read spec content from markdown files\n     - Build comprehensive prompt\n     ↓\n  4. Create ExecutionTask\n     - Task ID, entity type, context, priority\n     ↓\n  5. SimpleExecutionStrategy.executeTask(task)\n     ↓\n  6. SimpleProcessManager.acquireProcess(task)\n     - Spawn new Claude Code CLI process\n     - Return ManagedProcess handle\n     ↓\n  7. Send prompt to Claude via stdin\n     - Use stream-json output format\n     - Parse output line by line\n     ↓\n  8. ProgressTracker emits updates\n     - Phase changes (initializing → executing → finalizing)\n     - Tool use events (reading files, editing, etc.)\n     - Completion status\n     ↓\n  9. WebSocketService broadcasts to frontend\n     - Real-time progress updates\n     - Execution logs\n     - Final results\n     ↓\n  10. Update execution record in database\n      - Status, exit code, duration, etc.\n      ↓\n  11. SimpleProcessManager.releaseProcess(processId)\n      - Terminate Claude process\n      - Clean up resources\n\n  Component Specifications\n\n  1. Context Builder\n\n  Purpose: Build rich, context-aware prompts for Claude Code\n\n  Inspired by: CodeMachine-CLI's context-manager-agent\n  (references/CodeMachine-CLI/prompts/templates/codemachine/agents/04-context-manager-agent.md)\n\n  Interface:\n  interface IContextBuilder {\n    buildIssueContext(issueId: string): Promise<ExecutionContext>;\n    buildSpecContext(specId: string): Promise<ExecutionContext>;\n    buildBatchContext(entityIds: string[]): Promise<Map<string, ExecutionContext>>;\n  }\n\n  interface ExecutionContext {\n    workDir: string;\n    entityType: 'issue' | 'spec';\n    entityId: string;\n\n    // Core data\n    title: string;\n    description: string;\n\n    // Related entities\n    relatedSpecs: Array<{\n      id: string;\n      title: string;\n      content: string;\n      relationship: string;\n    }>;\n\n    relatedIssues: Array<{\n      id: string;\n      title: string;\n      description: string;\n      status: string;\n      relationship: string;\n    }>;\n\n    // Codebase context (optional, for later enhancement)\n    relevantFiles?: string[];\n\n    // Final prompt\n    prompt: string;\n  }\n\n  Prompt Template Structure (inspired by CodeMachine-CLI):\n  # Task: Work on Issue {issueId}\n\n  ## Issue Details\n  **Title**: {issue.title}\n  **Status**: {issue.status}\n  **Priority**: {issue.priority}\n\n  **Description**:\n  {issue.description}\n\n  ## Related Specifications\n\n  {for each related spec}\n  ### {spec.id}: {spec.title}\n  **Relationship**: {relationship.type}\n\n  {spec.content}\n  {end for}\n\n  ## Related Issues\n\n  {for each related issue}\n  ### {issue.id}: {issue.title}\n  **Status**: {issue.status}\n  **Relationship**: {relationship.type}\n\n  {issue.description}\n  {end for}\n\n  ## Instructions\n\n  1. Analyze the issue description and related specifications\n  2. Understand the requirements and acceptance criteria\n  3. Implement the necessary changes to address the issue\n  4. Test your implementation\n  5. Ensure code quality and adherence to project standards\n\n  ## Project Context\n\n  - Working directory: {workDir}\n  - Project: sudocode issue tracking system\n  - Use TypeScript for all implementations\n  - Follow existing code patterns in the codebase\n\n  ## Output Requirements\n\n  - Make necessary code changes\n  - Update tests if needed\n  - Provide a summary of changes made\n\n  Implementation Notes:\n  - Use template strings or a templating library (handlebars, mustache)\n  - Cache spec content to avoid repeated file reads\n  - Handle missing relationships gracefully\n  - Support both issue and spec execution contexts\n\n  ---\n  2. Execution Orchestrator\n\n  Purpose: Main coordinator that ties all components together\n\n  Inspired by:\n  - CodeMachine-CLI's workflow orchestrator (references/CodeMachine-CLI/src/workflows/execution/workflow.ts)\n  - claude-flow's SwarmCoordinator (references/claude-flow/src/swarm/coordinator.ts)\n\n  Interface:\n  class ExecutionOrchestrator {\n    constructor(\n      private strategy: IExecutionStrategy,\n      private contextBuilder: IContextBuilder,\n      private progressTracker: IProgressTracker,\n      private db: Database.Database\n    );\n\n    // Primary methods\n    executeIssue(issueId: string, options?: ExecutionOptions): Promise<ExecutionResult>;\n    executeSpec(specId: string, options?: ExecutionOptions): Promise<ExecutionResult>;\n    executeMultiple(entityIds: string[], options?: ExecutionOptions): Promise<ExecutionResult[]>;\n\n    // Control methods\n    stopExecution(executionId: string): Promise<void>;\n    getExecutionStatus(executionId: string): ExecutionProgress | null;\n\n    // Strategy management\n    switchStrategy(newStrategy: IExecutionStrategy): void;\n  }\n\n  interface ExecutionOptions {\n    workDir?: string;\n    maxDuration?: number;  // milliseconds\n    priority?: number;\n    customPrompt?: string; // Override generated prompt\n  }\n\n  Key Responsibilities:\n  1. Coordinate between context builder, strategy, and progress tracker\n  2. Create and persist execution records in database\n  3. Handle errors and timeouts gracefully\n  4. Provide clean API for frontend/API layer\n\n  Implementation Pattern (from CodeMachine-CLI):\n  async executeIssue(issueId: string, options: ExecutionOptions = {}): Promise<ExecutionResult> {\n    // 1. Build context\n    const context = await this.contextBuilder.buildIssueContext(issueId);\n\n    // 2. Create task\n    const task: ExecutionTask = {\n      id: generateId('task'),\n      type: 'issue',\n      entityId: issueId,\n      context: {\n        ...context,\n        workDir: options.workDir || process.cwd(),\n      },\n      priority: options.priority || 1,\n      dependencies: [], // TODO: Resolve from relationships\n    };\n\n    // 3. Create execution record in DB\n    const execution = createExecution(this.db, {\n      issue_id: issueId,\n      agent_type: 'claude-code',\n      status: 'running',\n    });\n\n    // 4. Start progress tracking\n    this.progressTracker.startTracking(execution.id, task);\n\n    try {\n      // 5. Execute via strategy\n      const result = await this.strategy.executeTask(task);\n\n      // 6. Update database\n      updateExecution(this.db, execution.id, {\n        status: result.success ? 'completed' : 'failed',\n        exit_code: result.success ? 0 : 1,\n        completed_at: Math.floor(Date.now() / 1000),\n        error_message: result.error,\n      });\n\n      // 7. Complete tracking\n      this.progressTracker.completeTracking(execution.id, result);\n\n      return result;\n    } catch (error) {\n      // Handle errors\n      const errorMessage = error instanceof Error ? error.message : 'Unknown error';\n\n      updateExecution(this.db, execution.id, {\n        status: 'failed',\n        completed_at: Math.floor(Date.now() / 1000),\n        error_message: errorMessage,\n      });\n\n      this.progressTracker.completeTracking(execution.id, {\n        ...result,\n        success: false,\n        error: errorMessage,\n      });\n\n      throw error;\n    }\n  }\n\n  ---\n  3. Simple Execution Strategy\n\n  Purpose: Execute tasks by spawning Claude Code processes on-demand\n\n  Inspired by:\n  - CodeMachine-CLI's step execution (references/CodeMachine-CLI/src/workflows/execution/step.ts)\n  - claude-flow's SimpleExecutionStrategy pattern\n\n  Interface:\n  class SimpleExecutionStrategy implements IExecutionStrategy {\n    constructor(\n      private processManager: IProcessManager,\n      private maxConcurrent: number = 3,\n      private defaultTimeout: number = 300_000 // 5 minutes\n    );\n\n    executeTask(task: ExecutionTask): Promise<ExecutionResult>;\n    executeTasks(tasks: ExecutionTask[]): Promise<ExecutionResult[]>;\n    getMetrics(): StrategyMetrics;\n    shutdown(): Promise<void>;\n  }\n\n  Key Implementation Details:\n\n  1. Process Spawning (from CodeMachine-CLI pattern):\n  private async runTask(\n    process: ManagedProcess,\n    task: ExecutionTask\n  ): Promise<ExecutionResult> {\n    const startTime = Date.now();\n\n    return new Promise((resolve, reject) => {\n      let outputBuffer = '';\n      let errorBuffer = '';\n\n      // Set up timeout\n      const timeout = setTimeout(() => {\n        process.process.kill('SIGTERM');\n        reject(new Error('Execution timed out'));\n      }, this.defaultTimeout);\n\n      // Parse stream-json output (from CodeMachine-CLI)\n      process.process.stdout?.on('data', (chunk: Buffer) => {\n        const text = chunk.toString();\n        outputBuffer += text;\n\n        // Parse JSON lines\n        const lines = text.split('\\n');\n        for (const line of lines) {\n          if (!line.trim()) continue;\n\n          try {\n            const json = JSON.parse(line);\n            this.handleStreamJsonLine(json, task);\n          } catch {\n            // Not JSON, treat as regular output\n          }\n        }\n      });\n\n      process.process.stderr?.on('data', (chunk: Buffer) => {\n        errorBuffer += chunk.toString();\n      });\n\n      process.process.on('exit', (code) => {\n        clearTimeout(timeout);\n\n        const duration = Date.now() - startTime;\n        const result: ExecutionResult = {\n          taskId: task.id,\n          executionId: process.id,\n          success: code === 0,\n          output: outputBuffer,\n          error: code !== 0 ? errorBuffer : undefined,\n          duration,\n          metadata: this.extractMetadata(outputBuffer),\n        };\n\n        resolve(result);\n      });\n\n      process.process.on('error', (error) => {\n        clearTimeout(timeout);\n        reject(error);\n      });\n    });\n  }\n\n  2. Stream JSON Parsing (from CodeMachine-CLI claude runner):\n  private handleStreamJsonLine(json: any, task: ExecutionTask): void {\n    // Parse different event types from Claude's stream-json format\n    if (json.type === 'assistant' && json.message?.content) {\n      for (const content of json.message.content) {\n        if (content.type === 'text') {\n          this.emitProgress(task.id, {\n            phase: 'executing',\n            message: content.text.substring(0, 200),\n          });\n        } else if (content.type === 'tool_use') {\n          this.emitProgress(task.id, {\n            phase: 'executing',\n            message: `Using tool: ${content.name}`,\n            metadata: { tool: content.name, args: content.input },\n          });\n        }\n      }\n    } else if (json.type === 'result') {\n      // Final result with usage stats\n      this.emitProgress(task.id, {\n        phase: 'finalizing',\n        message: 'Task completed',\n        metadata: {\n          duration: json.duration_ms,\n          tokensUsed: json.usage?.total_tokens,\n        },\n      });\n    }\n  }\n\n  3. Concurrency Control (simple batching):\n  async executeTasks(tasks: ExecutionTask[]): Promise<ExecutionResult[]> {\n    const results: ExecutionResult[] = [];\n\n    // Execute in batches\n    for (let i = 0; i < tasks.length; i += this.maxConcurrent) {\n      const batch = tasks.slice(i, i + this.maxConcurrent);\n      const batchResults = await Promise.all(\n        batch.map(task => this.executeTask(task))\n      );\n      results.push(...batchResults);\n    }\n\n    return results;\n  }\n\n  ---\n  4. Simple Process Manager\n\n  Purpose: Manage Claude Code CLI process lifecycle\n\n  Inspired by:\n  - claude-flow's process management (references/claude-flow/src/swarm/claude-code-interface.ts)\n  - Your existing ExecutionManager\n\n  Interface:\n  class SimpleProcessManager implements IProcessManager {\n    constructor(\n      private logsDir: string,\n      private claudePath: string = 'claude'\n    );\n\n    acquireProcess(task: ExecutionTask): Promise<ManagedProcess>;\n    releaseProcess(processId: string): Promise<void>;\n    terminateProcess(processId: string): Promise<void>;\n    getProcessMetrics(): ProcessMetrics;\n    shutdown(): Promise<void>;\n  }\n\n  Key Implementation:\n\n  1. Spawn Claude Code (from CodeMachine-CLI pattern):\n  private spawnClaudeProcess(task: ExecutionTask): ChildProcess {\n    const args = [\n      '--print',                          // Non-interactive mode\n      '--output-format', 'stream-json',   // Structured output\n      '--dangerously-skip-permissions',   // Skip permission prompts\n      '--permission-mode', 'bypassPermissions',\n    ];\n\n    const process = spawn(this.claudePath, args, {\n      cwd: task.context.workDir,\n      stdio: ['pipe', 'pipe', 'pipe'],\n      env: {\n        ...process.env,\n        // Add any custom environment variables\n      },\n    });\n\n    // Write prompt to stdin\n    process.stdin?.write(task.context.prompt);\n    process.stdin?.end();\n\n    return process;\n  }\n\n  2. Process Tracking:\n  async acquireProcess(task: ExecutionTask): Promise<ManagedProcess> {\n    const process = this.spawnClaudeProcess(task);\n\n    if (!process.pid) {\n      throw new Error('Failed to spawn Claude process');\n    }\n\n    const managed: ManagedProcess = {\n      id: generateId('process'),\n      process,\n      status: 'busy',\n      spawnedAt: new Date(),\n      lastActivity: new Date(),\n      tasksCompleted: 0,\n      metrics: {\n        totalDuration: 0,\n        successRate: 1.0,\n      },\n    };\n\n    this.activeProcesses.set(managed.id, managed);\n    return managed;\n  }\n\n  3. Graceful Termination:\n  async terminateProcess(processId: string): Promise<void> {\n    const managed = this.activeProcesses.get(processId);\n    if (!managed) return;\n\n    managed.status = 'terminating';\n\n    // Try SIGTERM first\n    managed.process.kill('SIGTERM');\n\n    // Wait for graceful shutdown\n    await new Promise(resolve => setTimeout(resolve, 2000));\n\n    // Force kill if needed\n    if (!managed.process.killed && managed.process.exitCode === null) {\n      managed.process.kill('SIGKILL');\n    }\n\n    this.activeProcesses.delete(processId);\n  }\n\n  ---\n  5. Progress Tracker\n\n  Purpose: Track and emit real-time progress updates\n\n  Inspired by: claude-flow's event emission patterns\n\n  Interface:\n  interface IProgressTracker {\n    startTracking(executionId: string, task: ExecutionTask): void;\n    updateProgress(executionId: string, update: ProgressUpdate): void;\n    completeTracking(executionId: string, result: ExecutionResult): void;\n    getProgress(executionId: string): ExecutionProgress | null;\n    onProgress(callback: (update: ProgressUpdate) => void): void;\n  }\n\n  interface ProgressUpdate {\n    executionId: string;\n    phase: 'initializing' | 'context_building' | 'executing' | 'finalizing';\n    message: string;\n    percentage?: number;\n    metadata?: {\n      tool?: string;\n      args?: any;\n      tokensUsed?: number;\n      filesChanged?: string[];\n    };\n  }\n\n  Implementation:\n  class WebSocketProgressTracker implements IProgressTracker {\n    private progressMap = new Map<string, ExecutionProgress>();\n    private callbacks: Array<(update: ProgressUpdate) => void> = [];\n\n    constructor(private wss: WebSocketService) {}\n\n    startTracking(executionId: string, task: ExecutionTask): void {\n      const progress: ExecutionProgress = {\n        executionId,\n        taskId: task.id,\n        status: 'running',\n        currentPhase: 'initializing',\n        startTime: new Date(),\n        lastUpdate: new Date(),\n      };\n\n      this.progressMap.set(executionId, progress);\n\n      // Emit initial update\n      this.emitUpdate({\n        executionId,\n        phase: 'initializing',\n        message: 'Starting execution...',\n        percentage: 0,\n      });\n    }\n\n    updateProgress(executionId: string, update: ProgressUpdate): void {\n      const progress = this.progressMap.get(executionId);\n      if (!progress) return;\n\n      progress.currentPhase = update.phase;\n      progress.lastUpdate = new Date();\n\n      this.emitUpdate(update);\n    }\n\n    completeTracking(executionId: string, result: ExecutionResult): void {\n      const progress = this.progressMap.get(executionId);\n      if (!progress) return;\n\n      progress.status = result.success ? 'completed' : 'failed';\n\n      this.emitUpdate({\n        executionId,\n        phase: 'finalizing',\n        message: result.success ? 'Execution completed successfully' : `Execution failed: ${result.error}`,\n        percentage: 100,\n        metadata: result.metadata,\n      });\n\n      // Clean up after a delay\n      setTimeout(() => {\n        this.progressMap.delete(executionId);\n      }, 60_000); // Keep for 1 minute\n    }\n\n    private emitUpdate(update: ProgressUpdate): void {\n      // Emit to WebSocket clients\n      this.wss.broadcast('execution:progress', update);\n\n      // Emit to registered callbacks\n      for (const callback of this.callbacks) {\n        callback(update);\n      }\n    }\n\n    onProgress(callback: (update: ProgressUpdate) => void): void {\n      this.callbacks.push(callback);\n    }\n  }\n\n  ---\n  Integration with Existing Code\n\n  1. Update ExecutionManager\n\n  // server/src/execution/manager.ts\n  export class ExecutionManager {\n    private orchestrator: ExecutionOrchestrator;\n\n    constructor(\n      db: Database.Database,\n      wss: WebSocketService,\n      logsDir?: string\n    ) {\n      // Initialize components\n      const contextBuilder = new DefaultContextBuilder(db);\n      const progressTracker = new WebSocketProgressTracker(wss);\n      const processManager = new SimpleProcessManager(logsDir || path.join(os.tmpdir(),\n  'sudocode-executions'));\n      const strategy = new SimpleExecutionStrategy(processManager, 3);\n\n      // Create orchestrator\n      this.orchestrator = new ExecutionOrchestrator(\n        strategy,\n        contextBuilder,\n        progressTracker,\n        db\n      );\n    }\n\n    // Delegate to orchestrator\n    async startExecution(input: StartExecutionInput): Promise<Execution> {\n      return this.orchestrator.executeIssue(input.issue_id, {\n        workDir: input.work_dir,\n        customPrompt: input.prompt,\n      });\n    }\n\n    async stopExecution(executionId: string): Promise<void> {\n      return this.orchestrator.stopExecution(executionId);\n    }\n\n    getExecutionStatus(executionId: string): ExecutionProgress | null {\n      return this.orchestrator.getExecutionStatus(executionId);\n    }\n  }\n\n  2. Add API Endpoints\n\n  // server/src/routes/executions.ts\n  router.post('/executions', async (req, res) => {\n    const { issue_id, work_dir, prompt } = req.body;\n\n    try {\n      const result = await executionManager.startExecution({\n        issue_id,\n        agent_type: 'claude-code',\n        work_dir,\n        prompt,\n      });\n\n      res.json(result);\n    } catch (error) {\n      res.status(500).json({ error: error.message });\n    }\n  });\n\n  router.get('/executions/:id/status', async (req, res) => {\n    const status = executionManager.getExecutionStatus(req.params.id);\n\n    if (!status) {\n      return res.status(404).json({ error: 'Execution not found' });\n    }\n\n    res.json(status);\n  });\n\n  router.post('/executions/:id/stop', async (req, res) => {\n    await executionManager.stopExecution(req.params.id);\n    res.json({ success: true });\n  });\n\n  3. WebSocket Integration\n\n  // server/src/services/websocket.ts\n  export class WebSocketService {\n    broadcast(event: string, data: any): void {\n      this.wss.clients.forEach(client => {\n        if (client.readyState === WebSocket.OPEN) {\n          client.send(JSON.stringify({ event, data }));\n        }\n      });\n    }\n  }\n\n  // Frontend can subscribe to execution progress\n  socket.on('execution:progress', (update: ProgressUpdate) => {\n    console.log(`[${update.executionId}] ${update.phase}: ${update.message}`);\n    // Update UI with progress\n  });\n\n  ---\n  File Structure\n\n  server/src/execution/\n  ├── manager.ts                    # Existing ExecutionManager (updated)\n  ├── spawn-claude-code.ts         # Existing spawn utility\n  ├── orchestrator.ts              # NEW: ExecutionOrchestrator\n  ├── strategies/\n  │   ├── base.ts                  # IExecutionStrategy interface\n  │   ├── simple-strategy.ts       # SimpleExecutionStrategy\n  │   └── pool-strategy.ts         # (Future) PoolExecutionStrategy\n  ├── process-managers/\n  │   ├── base.ts                  # IProcessManager interface\n  │   ├── simple-manager.ts        # SimpleProcessManager\n  │   └── pool-manager.ts          # (Future) PoolProcessManager\n  ├── context/\n  │   ├── builder.ts               # IContextBuilder interface\n  │   ├── default-builder.ts       # DefaultContextBuilder\n  │   └── templates.ts             # Prompt templates\n  ├── progress/\n  │   ├── tracker.ts               # IProgressTracker interface\n  │   └── websocket-tracker.ts    # WebSocketProgressTracker\n  └── types.ts                     # Shared types and interfaces\n\n  ---\n  Implementation Phases\n\n  Phase 1: Core Infrastructure (Week 1)\n  - Define all interfaces in types.ts\n  - Implement DefaultContextBuilder\n  - Implement SimpleProcessManager\n  - Implement SimpleExecutionStrategy\n  - Write unit tests for each component\n\n  Phase 2: Orchestration (Week 2)\n  - Implement ExecutionOrchestrator\n  - Integrate with existing ExecutionManager\n  - Add API endpoints for execution control\n  - Write integration tests\n\n  Phase 3: Progress Tracking (Week 3)\n  - Implement WebSocketProgressTracker\n  - Add WebSocket event handling\n  - Update frontend to display progress\n  - Test end-to-end flow\n\n  Phase 4: Polish & Documentation (Week 4)\n  - Add error handling and recovery\n  - Write comprehensive documentation\n  - Create example usage guides\n  - Performance testing and optimization\n","priority":0,"archived":1,"archived_at":"2025-10-28T08:31:01.555Z","created_at":"2025-10-27 18:30:25","updated_at":"2025-11-03T03:10:12.596Z","parent_id":null,"parent_uuid":null,"relationships":[],"tags":[]}
{"id":"SPEC-003","uuid":"48dd725d-675a-4038-83d2-b5f5e41dd75a","title":"Process Layer - Claude Code Process Management","file_path":"specs/process_layer_claude_code_process_management.md","content":"# Process Layer Specification\n\n## Overview\n\nThe Process Layer (Layer 1) manages the lifecycle of individual Claude Code CLI processes. This is the foundation of the execution system, inspired by claude-flow's simple yet flexible approach.\n\n## Design Goals\n\n1. **Simple First**: Start with basic process spawning using Node.js child_process\n2. **Event-Driven**: Use native event emitters for real-time I/O streaming\n3. **Flexible**: Easy to upgrade from simple spawning to process pooling\n4. **Reliable**: Handle timeouts, crashes, and cleanup gracefully\n5. **Observable**: Expose all process events for upper layers\n\n## Architecture\n\nBased on Execution System spec, this implements the process spawning and management foundation.\n\n```\n┌─────────────────────────────────────────┐\n│        Process Layer (Layer 1)          │\n├─────────────────────────────────────────┤\n│                                         │\n│  ┌──────────────────────────────────┐  │\n│  │   IProcessManager (Interface)    │  │\n│  └────────────┬─────────────────────┘  │\n│               │                         │\n│               ├──────────────────────┐  │\n│               │                      │  │\n│     ┌─────────▼────────┐   ┌────────▼──────────┐\n│     │ SimpleProcess    │   │  PoolProcess      │\n│     │    Manager       │   │   Manager         │\n│     │  (Start Here)    │   │  (Future)         │\n│     └──────────────────┘   └───────────────────┘\n│                                         │\n└─────────────────────────────────────────┘\n```\n\n## Core Types\n\n### ManagedProcess\nRepresents a single Claude Code process instance with its lifecycle state.\n\n```typescript\ninterface ManagedProcess {\n  // Identity\n  id: string;                    // Unique process ID\n  pid: number;                   // OS process ID\n  \n  // Lifecycle\n  status: ProcessStatus;\n  spawnedAt: Date;\n  lastActivity: Date;\n  exitCode: number | null;\n  signal: string | null;\n  \n  // Resources\n  process: ChildProcess;         // Node.js child process handle\n  streams: {\n    stdout: Readable;\n    stderr: Readable;\n    stdin: Writable;\n  };\n  \n  // Metrics\n  metrics: {\n    totalDuration: number;       // milliseconds\n    tasksCompleted: number;\n    successRate: number;\n  };\n}\n\ntype ProcessStatus = \n  | 'spawning'     // Being created\n  | 'idle'         // Ready for work (pool only)\n  | 'busy'         // Executing task\n  | 'terminating'  // Shutting down\n  | 'crashed'      // Exited unexpectedly\n  | 'completed';   // Exited normally\n```\n\n### ProcessConfig\nConfiguration for spawning Claude Code processes.\n\n```typescript\ninterface ProcessConfig {\n  // Claude Code CLI path\n  claudePath: string;            // Default: 'claude'\n  \n  // Working directory\n  workDir: string;\n  \n  // Claude Code CLI arguments\n  args: {\n    print: boolean;              // --print (non-interactive)\n    outputFormat: 'stream-json' | 'json' | 'text';\n    dangerouslySkipPermissions: boolean;\n    permissionMode?: string;\n  };\n  \n  // Environment variables\n  env?: Record<string, string>;\n  \n  // Timeouts\n  timeout?: number;              // Max execution time (ms)\n  idleTimeout?: number;          // Max idle time before cleanup (pool only)\n  \n  // Retry configuration\n  retry?: {\n    maxAttempts: number;\n    backoffMs: number;\n  };\n}\n```\n\n## IProcessManager Interface\n\nThe core abstraction that all process managers implement.\n\n```typescript\ninterface IProcessManager {\n  // Process lifecycle\n  acquireProcess(config: ProcessConfig): Promise<ManagedProcess>;\n  releaseProcess(processId: string): Promise<void>;\n  terminateProcess(processId: string, signal?: NodeJS.Signals): Promise<void>;\n  \n  // Process communication\n  sendInput(processId: string, input: string): Promise<void>;\n  onOutput(processId: string, handler: OutputHandler): void;\n  onError(processId: string, handler: ErrorHandler): void;\n  \n  // Monitoring\n  getProcess(processId: string): ManagedProcess | null;\n  getActiveProcesses(): ManagedProcess[];\n  getMetrics(): ProcessMetrics;\n  \n  // Cleanup\n  shutdown(): Promise<void>;\n}\n\ntype OutputHandler = (data: Buffer, type: 'stdout' | 'stderr') => void;\ntype ErrorHandler = (error: Error) => void;\n\ninterface ProcessMetrics {\n  totalSpawned: number;\n  currentlyActive: number;\n  totalCompleted: number;\n  totalFailed: number;\n  averageDuration: number;\n}\n```\n\n## SimpleProcessManager Implementation\n\nStart with this simple, production-ready implementation based on claude-flow's pattern.\n\n### Key Features\n\n1. **One Process Per Task**: Spawn fresh process for each task\n2. **Event-Based I/O**: Stream stdout/stderr in real-time\n3. **Graceful Termination**: SIGTERM → wait → SIGKILL if needed\n4. **Automatic Cleanup**: Remove completed processes from tracking\n5. **Error Handling**: Capture spawn errors, exit codes, crashes\n\n### Implementation Pattern\n\n```typescript\nclass SimpleProcessManager implements IProcessManager {\n  private activeProcesses = new Map<string, ManagedProcess>();\n  private metrics: ProcessMetrics = {\n    totalSpawned: 0,\n    currentlyActive: 0,\n    totalCompleted: 0,\n    totalFailed: 0,\n    averageDuration: 0,\n  };\n\n  constructor(\n    private defaultConfig: Partial<ProcessConfig> = {}\n  ) {}\n\n  async acquireProcess(config: ProcessConfig): Promise<ManagedProcess> {\n    const mergedConfig = { ...this.defaultConfig, ...config };\n    const process = await this.spawnClaudeProcess(mergedConfig);\n    \n    if (!process.pid) {\n      throw new Error('Failed to spawn Claude Code process');\n    }\n\n    const managed: ManagedProcess = {\n      id: generateId('process'),\n      pid: process.pid,\n      status: 'busy',\n      spawnedAt: new Date(),\n      lastActivity: new Date(),\n      exitCode: null,\n      signal: null,\n      process,\n      streams: {\n        stdout: process.stdout!,\n        stderr: process.stderr!,\n        stdin: process.stdin!,\n      },\n      metrics: {\n        totalDuration: 0,\n        tasksCompleted: 0,\n        successRate: 1.0,\n      },\n    };\n\n    this.setupProcessHandlers(managed, config);\n    this.activeProcesses.set(managed.id, managed);\n    this.metrics.totalSpawned++;\n    this.metrics.currentlyActive++;\n\n    return managed;\n  }\n\n  private async spawnClaudeProcess(config: ProcessConfig): Promise<ChildProcess> {\n    const args = this.buildClaudeArgs(config);\n\n    const process = spawn(config.claudePath, args, {\n      cwd: config.workDir,\n      stdio: ['pipe', 'pipe', 'pipe'],\n      env: {\n        ...process.env,\n        ...config.env,\n      },\n    });\n\n    return process;\n  }\n\n  private buildClaudeArgs(config: ProcessConfig): string[] {\n    const args: string[] = [];\n\n    if (config.args.print) {\n      args.push('--print');\n    }\n\n    if (config.args.outputFormat) {\n      args.push('--output-format', config.args.outputFormat);\n    }\n\n    if (config.args.dangerouslySkipPermissions) {\n      args.push('--dangerously-skip-permissions');\n    }\n\n    if (config.args.permissionMode) {\n      args.push('--permission-mode', config.args.permissionMode);\n    }\n\n    return args;\n  }\n\n  private setupProcessHandlers(managed: ManagedProcess, config: ProcessConfig): void {\n    const { process } = managed;\n    let timeoutHandle: NodeJS.Timeout | null = null;\n\n    // Set timeout if configured\n    if (config.timeout) {\n      timeoutHandle = setTimeout(() => {\n        this.terminateProcess(managed.id, 'SIGTERM');\n      }, config.timeout);\n    }\n\n    // Handle exit\n    process.on('exit', (code, signal) => {\n      if (timeoutHandle) clearTimeout(timeoutHandle);\n\n      managed.exitCode = code;\n      managed.signal = signal;\n      managed.status = code === 0 ? 'completed' : 'crashed';\n\n      const duration = Date.now() - managed.spawnedAt.getTime();\n      managed.metrics.totalDuration = duration;\n\n      // Update global metrics\n      this.metrics.currentlyActive--;\n      if (code === 0) {\n        this.metrics.totalCompleted++;\n      } else {\n        this.metrics.totalFailed++;\n      }\n\n      // Clean up after delay\n      setTimeout(() => {\n        this.activeProcesses.delete(managed.id);\n      }, 5000);\n    });\n\n    // Handle spawn errors\n    process.on('error', (error) => {\n      if (timeoutHandle) clearTimeout(timeoutHandle);\n      \n      managed.status = 'crashed';\n      this.metrics.currentlyActive--;\n      this.metrics.totalFailed++;\n    });\n\n    // Update activity on I/O\n    process.stdout?.on('data', () => {\n      managed.lastActivity = new Date();\n    });\n  }\n\n  async sendInput(processId: string, input: string): Promise<void> {\n    const managed = this.activeProcesses.get(processId);\n    if (!managed) {\n      throw new Error(`Process ${processId} not found`);\n    }\n\n    return new Promise((resolve, reject) => {\n      managed.streams.stdin.write(input, (error) => {\n        if (error) reject(error);\n        else resolve();\n      });\n    });\n  }\n\n  onOutput(processId: string, handler: OutputHandler): void {\n    const managed = this.activeProcesses.get(processId);\n    if (!managed) return;\n\n    managed.streams.stdout.on('data', (data: Buffer) => {\n      handler(data, 'stdout');\n    });\n\n    managed.streams.stderr.on('data', (data: Buffer) => {\n      handler(data, 'stderr');\n    });\n  }\n\n  async terminateProcess(\n    processId: string, \n    signal: NodeJS.Signals = 'SIGTERM'\n  ): Promise<void> {\n    const managed = this.activeProcesses.get(processId);\n    if (!managed) return;\n\n    managed.status = 'terminating';\n\n    // Try graceful shutdown first\n    managed.process.kill(signal);\n\n    // Wait for graceful shutdown\n    await new Promise(resolve => setTimeout(resolve, 2000));\n\n    // Force kill if still running\n    if (!managed.process.killed && managed.exitCode === null) {\n      managed.process.kill('SIGKILL');\n    }\n  }\n\n  async releaseProcess(processId: string): Promise<void> {\n    await this.terminateProcess(processId);\n  }\n\n  getProcess(processId: string): ManagedProcess | null {\n    return this.activeProcesses.get(processId) || null;\n  }\n\n  getActiveProcesses(): ManagedProcess[] {\n    return Array.from(this.activeProcesses.values());\n  }\n\n  getMetrics(): ProcessMetrics {\n    return { ...this.metrics };\n  }\n\n  async shutdown(): Promise<void> {\n    const processes = Array.from(this.activeProcesses.keys());\n    await Promise.all(\n      processes.map(id => this.terminateProcess(id, 'SIGTERM'))\n    );\n  }\n}\n```\n\n## Usage Example\n\n```typescript\n// Initialize manager\nconst processManager = new SimpleProcessManager({\n  claudePath: 'claude',\n  args: {\n    print: true,\n    outputFormat: 'stream-json',\n    dangerouslySkipPermissions: true,\n  },\n});\n\n// Spawn process\nconst process = await processManager.acquireProcess({\n  claudePath: 'claude',\n  workDir: '/path/to/project',\n  args: {\n    print: true,\n    outputFormat: 'stream-json',\n    dangerouslySkipPermissions: true,\n  },\n  timeout: 300000, // 5 minutes\n});\n\n// Send input\nawait processManager.sendInput(process.id, 'Fix the bug in auth.ts\\n');\n\n// Listen to output\nprocessManager.onOutput(process.id, (data, type) => {\n  console.log(`[${type}]`, data.toString());\n});\n\n// Clean up\nawait processManager.releaseProcess(process.id);\n```\n\n## Testing Strategy\n\n### Unit Tests\n\n1. **Process spawning**\n   - Spawns with correct arguments\n   - Sets working directory\n   - Passes environment variables\n\n2. **Lifecycle management**\n   - Tracks process status correctly\n   - Updates metrics on exit\n   - Cleans up resources\n\n3. **I/O handling**\n   - Sends input to stdin\n   - Receives stdout/stderr\n   - Handles stream errors\n\n4. **Termination**\n   - Graceful shutdown (SIGTERM)\n   - Force kill after timeout\n   - Cleans up after termination\n\n### Integration Tests\n\n1. **End-to-end execution**\n   - Spawn → send prompt → receive output → terminate\n   - Multiple concurrent processes\n   - Process crash recovery\n\n2. **Error scenarios**\n   - Invalid claude path\n   - Process spawn failure\n   - Timeout handling\n\n## Future Enhancements\n\n### Path to Pool-Based Strategy\n\nThe interface design makes it easy to add pooling later:\n\n```typescript\nclass PoolProcessManager implements IProcessManager {\n  private pool: ManagedProcess[] = [];\n  private maxPoolSize: number;\n  private minIdleProcesses: number;\n\n  async acquireProcess(config: ProcessConfig): Promise<ManagedProcess> {\n    // Try to get idle process from pool\n    const idle = this.pool.find(p => p.status === 'idle');\n    \n    if (idle) {\n      idle.status = 'busy';\n      return idle;\n    }\n\n    // Create new if under limit\n    if (this.pool.length < this.maxPoolSize) {\n      return this.createAndAddToPool(config);\n    }\n\n    // Wait for available process\n    return this.waitForAvailableProcess(config);\n  }\n\n  async releaseProcess(processId: string): Promise<void> {\n    const process = this.pool.find(p => p.id === processId);\n    if (process) {\n      process.status = 'idle';\n      process.metrics.tasksCompleted++;\n    }\n  }\n\n  // ... pool management logic\n}\n```\n\n### Other Future Features\n\n1. **Process health checks** - Ping processes periodically\n2. **Automatic restarts** - Restart crashed processes in pool\n3. **Resource limits** - Memory/CPU monitoring\n4. **Process affinity** - Pin processes to specific tasks/users\n\n## File Structure\n\n```\nserver/src/execution/process/\n├── types.ts                    # Core types and interfaces\n├── manager.ts                  # IProcessManager interface\n├── simple-manager.ts           # SimpleProcessManager (start here)\n├── pool-manager.ts             # PoolProcessManager (future)\n└── utils.ts                    # Helper functions\n```\n\n## Implementation Checklist\n\n- [ ] Define core types in types.ts\n- [ ] Define IProcessManager interface\n- [ ] Implement SimpleProcessManager\n- [ ] Add process spawning with child_process\n- [ ] Add event handlers for exit, error, I/O\n- [ ] Add graceful termination (SIGTERM → SIGKILL)\n- [ ] Add metrics tracking\n- [ ] Write unit tests for process lifecycle\n- [ ] Write integration tests for end-to-end flow\n- [ ] Document usage examples\n\n## Related Specs\n\n- Execution System (parent spec)\n- Next: Engine Layer (Layer 2) - Multi-agent task execution\n","priority":0,"archived":0,"archived_at":null,"created_at":"2025-10-28 07:34:44","updated_at":"2025-11-03T03:10:12.594Z","parent_id":null,"parent_uuid":null,"relationships":[],"tags":["execution","infrastructure","layer-1","process-management"]}
{"id":"SPEC-004","uuid":"7c8ba15b-95d6-40e1-bf1f-e4305e5ddd80","title":"Engine Layer - Multi-Agent Task Execution","file_path":"specs/engine_layer_multi_agent_task_execution.md","content":"# Engine Layer Specification\n\n## Overview\n\nThe Engine Layer (Layer 2) manages multiple Claude Code agents to execute tasks concurrently. It sits above the Process Layer and provides task queueing, capacity management, and result collection.\n\n## Design Goals\n\n1. **Simple First**: Start with queue-based task distribution\n2. **Capacity Control**: Prevent resource exhaustion with configurable limits\n3. **Fair Scheduling**: FIFO queue with optional priority support\n4. **Observable**: Expose task progress and engine metrics\n5. **Upgradeable**: Easy path to intelligent agent pooling\n\n## Architecture\n\nBased on Execution System spec and [[SPEC-003]] (Process Layer).\n\n```\n┌─────────────────────────────────────────────────┐\n│         Engine Layer (Layer 2)                  │\n├─────────────────────────────────────────────────┤\n│                                                 │\n│  ┌──────────────────────────────────────────┐  │\n│  │      IExecutionEngine (Interface)        │  │\n│  └────────────┬─────────────────────────────┘  │\n│               │                                 │\n│               ├──────────────────────────────┐  │\n│               │                              │  │\n│     ┌─────────▼────────┐         ┌──────────▼─────────┐\n│     │  SimpleEngine    │         │   PoolEngine       │\n│     │  (Start Here)    │         │   (Future)         │\n│     └────────┬─────────┘         └────────────────────┘\n│              │                                  │\n│              ▼                                  │\n│     ┌─────────────────┐                        │\n│     │   Task Queue    │                        │\n│     │   (FIFO/Prio)   │                        │\n│     └────────┬────────┘                        │\n│              │                                  │\n│              ▼                                  │\n│     ┌─────────────────┐                        │\n│     │ Process Manager │◄───────────────────────┘\n│     │  (Layer 1)      │                        │\n│     └─────────────────┘                        │\n│                                                 │\n└─────────────────────────────────────────────────┘\n```\n\n## Core Types\n\n### ExecutionTask\nRepresents a unit of work to be executed by a Claude Code agent.\n\n```typescript\ninterface ExecutionTask {\n  // Identity\n  id: string;\n  type: 'issue' | 'spec' | 'custom';\n  entityId?: string;              // Issue/spec ID if applicable\n  \n  // Execution context\n  prompt: string;                 // What to send to Claude\n  workDir: string;                // Where to execute\n  \n  // Scheduling\n  priority: number;               // 0 = highest\n  dependencies: string[];         // Task IDs that must complete first\n  createdAt: Date;\n  \n  // Configuration\n  config: {\n    timeout?: number;             // Max duration (ms)\n    maxRetries?: number;          // Retry attempts\n    env?: Record<string, string>; // Environment variables\n  };\n  \n  // Metadata\n  metadata?: Record<string, any>; // Custom data\n}\n```\n\n### ExecutionResult\nThe outcome of executing a task.\n\n```typescript\ninterface ExecutionResult {\n  // Identity\n  taskId: string;\n  executionId: string;            // Process ID that ran it\n  \n  // Outcome\n  success: boolean;\n  exitCode: number;\n  \n  // Output\n  output: string;                 // stdout\n  error?: string;                 // stderr or error message\n  \n  // Timing\n  startedAt: Date;\n  completedAt: Date;\n  duration: number;               // milliseconds\n  \n  // Parsed data (from stream-json)\n  metadata?: {\n    toolsUsed?: string[];\n    filesChanged?: string[];\n    tokensUsed?: number;\n    cost?: number;\n  };\n}\n```\n\n### EngineMetrics\nReal-time engine performance statistics.\n\n```typescript\ninterface EngineMetrics {\n  // Capacity\n  maxConcurrent: number;\n  currentlyRunning: number;\n  availableSlots: number;\n  \n  // Queue\n  queuedTasks: number;\n  completedTasks: number;\n  failedTasks: number;\n  \n  // Performance\n  averageDuration: number;        // ms\n  successRate: number;            // 0-1\n  throughput: number;             // tasks/minute\n  \n  // Resources\n  totalProcessesSpawned: number;\n  activeProcesses: number;\n}\n```\n\n## IExecutionEngine Interface\n\nThe core abstraction for task execution engines.\n\n```typescript\ninterface IExecutionEngine {\n  // Task submission\n  submitTask(task: ExecutionTask): Promise<string>; // Returns task ID\n  submitTasks(tasks: ExecutionTask[]): Promise<string[]>;\n  \n  // Task control\n  cancelTask(taskId: string): Promise<void>;\n  getTaskStatus(taskId: string): TaskStatus | null;\n  \n  // Execution\n  waitForTask(taskId: string): Promise<ExecutionResult>;\n  waitForTasks(taskIds: string[]): Promise<ExecutionResult[]>;\n  \n  // Monitoring\n  getMetrics(): EngineMetrics;\n  onTaskComplete(handler: TaskCompleteHandler): void;\n  onTaskFailed(handler: TaskFailedHandler): void;\n  \n  // Lifecycle\n  shutdown(): Promise<void>;\n}\n\ntype TaskStatus = \n  | { state: 'queued'; position: number }\n  | { state: 'running'; processId: string; startedAt: Date }\n  | { state: 'completed'; result: ExecutionResult }\n  | { state: 'failed'; error: string }\n  | { state: 'cancelled'; cancelledAt: Date };\n\ntype TaskCompleteHandler = (result: ExecutionResult) => void;\ntype TaskFailedHandler = (taskId: string, error: Error) => void;\n```\n\n## SimpleExecutionEngine Implementation\n\nQueue-based engine that spawns a process per task, with concurrency limits.\n\n### Key Features\n\n1. **FIFO Queue**: Tasks execute in submission order\n2. **Concurrency Limit**: Max N simultaneous processes\n3. **Automatic Retry**: Optional retry on failure\n4. **Event Emission**: Notify on task completion/failure\n5. **Graceful Shutdown**: Wait for running tasks or force terminate\n\n### Implementation Pattern\n\n```typescript\nclass SimpleExecutionEngine implements IExecutionEngine {\n  private taskQueue: ExecutionTask[] = [];\n  private runningTasks = new Map<string, RunningTask>();\n  private completedResults = new Map<string, ExecutionResult>();\n  private taskResolvers = new Map<string, TaskResolver>();\n  \n  private metrics: EngineMetrics;\n  private completeHandlers: TaskCompleteHandler[] = [];\n  private failedHandlers: TaskFailedHandler[] = [];\n  \n  constructor(\n    private processManager: IProcessManager,\n    private config: EngineConfig = {}\n  ) {\n    this.metrics = {\n      maxConcurrent: config.maxConcurrent || 3,\n      currentlyRunning: 0,\n      availableSlots: config.maxConcurrent || 3,\n      queuedTasks: 0,\n      completedTasks: 0,\n      failedTasks: 0,\n      averageDuration: 0,\n      successRate: 1.0,\n      throughput: 0,\n      totalProcessesSpawned: 0,\n      activeProcesses: 0,\n    };\n  }\n\n  async submitTask(task: ExecutionTask): Promise<string> {\n    // Add to queue\n    this.taskQueue.push(task);\n    this.metrics.queuedTasks++;\n    \n    // Try to start immediately if capacity available\n    this.processQueue();\n    \n    return task.id;\n  }\n\n  async submitTasks(tasks: ExecutionTask[]): Promise<string[]> {\n    const ids: string[] = [];\n    for (const task of tasks) {\n      const id = await this.submitTask(task);\n      ids.push(id);\n    }\n    return ids;\n  }\n\n  private async processQueue(): Promise<void> {\n    // Check if we have capacity\n    while (\n      this.taskQueue.length > 0 &&\n      this.runningTasks.size < this.metrics.maxConcurrent\n    ) {\n      const task = this.taskQueue.shift()!;\n      this.metrics.queuedTasks--;\n      \n      // Check dependencies\n      if (!this.areDependenciesMet(task)) {\n        // Re-queue at end\n        this.taskQueue.push(task);\n        this.metrics.queuedTasks++;\n        break; // Stop processing to avoid infinite loop\n      }\n      \n      // Start execution\n      this.executeTask(task).catch(error => {\n        this.handleTaskFailure(task.id, error);\n      });\n    }\n  }\n\n  private areDependenciesMet(task: ExecutionTask): boolean {\n    for (const depId of task.dependencies) {\n      const result = this.completedResults.get(depId);\n      if (!result || !result.success) {\n        return false;\n      }\n    }\n    return true;\n  }\n\n  private async executeTask(task: ExecutionTask): Promise<void> {\n    const startTime = Date.now();\n    \n    try {\n      // Acquire process\n      const process = await this.processManager.acquireProcess({\n        claudePath: this.config.claudePath || 'claude',\n        workDir: task.workDir,\n        args: {\n          print: true,\n          outputFormat: 'stream-json',\n          dangerouslySkipPermissions: true,\n          permissionMode: 'bypassPermissions',\n        },\n        env: task.config.env,\n        timeout: task.config.timeout,\n      });\n\n      this.metrics.totalProcessesSpawned++;\n      this.metrics.currentlyRunning++;\n      this.metrics.activeProcesses++;\n      this.metrics.availableSlots--;\n\n      // Track running task\n      const running: RunningTask = {\n        task,\n        process,\n        startedAt: new Date(),\n        attempt: 1,\n      };\n      this.runningTasks.set(task.id, running);\n\n      // Send prompt\n      await this.processManager.sendInput(process.id, task.prompt);\n      \n      // Collect output\n      let outputBuffer = '';\n      let errorBuffer = '';\n      \n      this.processManager.onOutput(process.id, (data, type) => {\n        if (type === 'stdout') {\n          outputBuffer += data.toString();\n        } else {\n          errorBuffer += data.toString();\n        }\n      });\n\n      // Wait for completion\n      await this.waitForProcessExit(process);\n\n      const duration = Date.now() - startTime;\n      \n      // Build result\n      const result: ExecutionResult = {\n        taskId: task.id,\n        executionId: process.id,\n        success: process.exitCode === 0,\n        exitCode: process.exitCode || 0,\n        output: outputBuffer,\n        error: process.exitCode !== 0 ? errorBuffer : undefined,\n        startedAt: running.startedAt,\n        completedAt: new Date(),\n        duration,\n        metadata: this.parseMetadata(outputBuffer),\n      };\n\n      // Handle result\n      if (result.success) {\n        this.handleTaskSuccess(task.id, result);\n      } else {\n        // Retry if configured\n        if (\n          task.config.maxRetries &&\n          running.attempt < task.config.maxRetries\n        ) {\n          running.attempt++;\n          this.taskQueue.unshift(task); // Priority re-queue\n          this.metrics.queuedTasks++;\n        } else {\n          this.handleTaskFailure(\n            task.id,\n            new Error(result.error || 'Task failed')\n          );\n        }\n      }\n\n      // Clean up\n      this.runningTasks.delete(task.id);\n      await this.processManager.releaseProcess(process.id);\n      \n      this.metrics.currentlyRunning--;\n      this.metrics.activeProcesses--;\n      this.metrics.availableSlots++;\n\n      // Process next queued task\n      this.processQueue();\n      \n    } catch (error) {\n      this.metrics.currentlyRunning--;\n      this.metrics.activeProcesses--;\n      this.metrics.availableSlots++;\n      this.runningTasks.delete(task.id);\n      \n      throw error;\n    }\n  }\n\n  private async waitForProcessExit(process: ManagedProcess): Promise<void> {\n    return new Promise((resolve) => {\n      const checkInterval = setInterval(() => {\n        if (\n          process.status === 'completed' ||\n          process.status === 'crashed' ||\n          process.status === 'terminated'\n        ) {\n          clearInterval(checkInterval);\n          resolve();\n        }\n      }, 100);\n    });\n  }\n\n  private parseMetadata(output: string): ExecutionResult['metadata'] {\n    // Parse stream-json output for metadata\n    const metadata: ExecutionResult['metadata'] = {\n      toolsUsed: [],\n      filesChanged: [],\n      tokensUsed: 0,\n      cost: 0,\n    };\n\n    const lines = output.split('\\n');\n    for (const line of lines) {\n      if (!line.trim()) continue;\n      \n      try {\n        const json = JSON.parse(line);\n        \n        // Extract tool usage\n        if (json.type === 'assistant' && json.message?.content) {\n          for (const content of json.message.content) {\n            if (content.type === 'tool_use') {\n              metadata.toolsUsed?.push(content.name);\n              \n              // Track file changes\n              if (\n                content.name === 'Write' ||\n                content.name === 'Edit'\n              ) {\n                metadata.filesChanged?.push(content.input.file_path);\n              }\n            }\n          }\n        }\n        \n        // Extract usage stats\n        if (json.type === 'result' && json.usage) {\n          metadata.tokensUsed = json.usage.total_tokens || 0;\n        }\n      } catch {\n        // Not JSON, skip\n      }\n    }\n\n    return metadata;\n  }\n\n  private handleTaskSuccess(taskId: string, result: ExecutionResult): void {\n    this.completedResults.set(taskId, result);\n    this.metrics.completedTasks++;\n    \n    // Update averages\n    this.updateMetrics(result.duration, true);\n    \n    // Resolve promise\n    const resolver = this.taskResolvers.get(taskId);\n    if (resolver) {\n      resolver.resolve(result);\n      this.taskResolvers.delete(taskId);\n    }\n    \n    // Emit event\n    for (const handler of this.completeHandlers) {\n      handler(result);\n    }\n  }\n\n  private handleTaskFailure(taskId: string, error: Error): void {\n    this.metrics.failedTasks++;\n    this.updateMetrics(0, false);\n    \n    // Resolve promise with error\n    const resolver = this.taskResolvers.get(taskId);\n    if (resolver) {\n      resolver.reject(error);\n      this.taskResolvers.delete(taskId);\n    }\n    \n    // Emit event\n    for (const handler of this.failedHandlers) {\n      handler(taskId, error);\n    }\n  }\n\n  private updateMetrics(duration: number, success: boolean): void {\n    const total = this.metrics.completedTasks + this.metrics.failedTasks;\n    \n    // Update average duration\n    this.metrics.averageDuration = \n      (this.metrics.averageDuration * (total - 1) + duration) / total;\n    \n    // Update success rate\n    this.metrics.successRate = this.metrics.completedTasks / total;\n  }\n\n  async waitForTask(taskId: string): Promise<ExecutionResult> {\n    // Check if already completed\n    const existing = this.completedResults.get(taskId);\n    if (existing) return existing;\n    \n    // Wait for completion\n    return new Promise((resolve, reject) => {\n      this.taskResolvers.set(taskId, { resolve, reject });\n    });\n  }\n\n  async waitForTasks(taskIds: string[]): Promise<ExecutionResult[]> {\n    return Promise.all(taskIds.map(id => this.waitForTask(id)));\n  }\n\n  async cancelTask(taskId: string): Promise<void> {\n    // Remove from queue\n    const queueIndex = this.taskQueue.findIndex(t => t.id === taskId);\n    if (queueIndex >= 0) {\n      this.taskQueue.splice(queueIndex, 1);\n      this.metrics.queuedTasks--;\n      return;\n    }\n    \n    // Stop running task\n    const running = this.runningTasks.get(taskId);\n    if (running) {\n      await this.processManager.terminateProcess(running.process.id);\n      this.runningTasks.delete(taskId);\n      this.metrics.currentlyRunning--;\n    }\n  }\n\n  getTaskStatus(taskId: string): TaskStatus | null {\n    // Check completed\n    const result = this.completedResults.get(taskId);\n    if (result) {\n      return { state: 'completed', result };\n    }\n    \n    // Check running\n    const running = this.runningTasks.get(taskId);\n    if (running) {\n      return {\n        state: 'running',\n        processId: running.process.id,\n        startedAt: running.startedAt,\n      };\n    }\n    \n    // Check queued\n    const queuePos = this.taskQueue.findIndex(t => t.id === taskId);\n    if (queuePos >= 0) {\n      return { state: 'queued', position: queuePos };\n    }\n    \n    return null;\n  }\n\n  getMetrics(): EngineMetrics {\n    return { ...this.metrics };\n  }\n\n  onTaskComplete(handler: TaskCompleteHandler): void {\n    this.completeHandlers.push(handler);\n  }\n\n  onTaskFailed(handler: TaskFailedHandler): void {\n    this.failedHandlers.push(handler);\n  }\n\n  async shutdown(): Promise<void> {\n    // Stop accepting new tasks\n    this.taskQueue = [];\n    \n    // Wait for running tasks or force terminate\n    const runningIds = Array.from(this.runningTasks.keys());\n    for (const taskId of runningIds) {\n      await this.cancelTask(taskId);\n    }\n    \n    // Shutdown process manager\n    await this.processManager.shutdown();\n  }\n}\n\ninterface EngineConfig {\n  maxConcurrent?: number;\n  claudePath?: string;\n}\n\ninterface RunningTask {\n  task: ExecutionTask;\n  process: ManagedProcess;\n  startedAt: Date;\n  attempt: number;\n}\n\ninterface TaskResolver {\n  resolve: (result: ExecutionResult) => void;\n  reject: (error: Error) => void;\n}\n```\n\n## Usage Example\n\n```typescript\n// Initialize engine with process manager\nconst processManager = new SimpleProcessManager();\nconst engine = new SimpleExecutionEngine(processManager, {\n  maxConcurrent: 5,\n  claudePath: 'claude',\n});\n\n// Listen to completion events\nengine.onTaskComplete((result) => {\n  console.log(`Task ${result.taskId} completed in ${result.duration}ms`);\n  console.log(`Files changed:`, result.metadata?.filesChanged);\n});\n\n// Submit tasks\nconst task1 = {\n  id: 'task-1',\n  type: 'issue',\n  entityId: 'ISSUE-001',\n  prompt: 'Fix the authentication bug described in ISSUE-001',\n  workDir: '/path/to/project',\n  priority: 0,\n  dependencies: [],\n  createdAt: new Date(),\n  config: {\n    timeout: 300000,\n    maxRetries: 2,\n  },\n};\n\nconst taskId = await engine.submitTask(task1);\n\n// Wait for completion\nconst result = await engine.waitForTask(taskId);\nconsole.log('Success:', result.success);\n\n// Check metrics\nconst metrics = engine.getMetrics();\nconsole.log(`Queue: ${metrics.queuedTasks}, Running: ${metrics.currentlyRunning}`);\n```\n\n## Testing Strategy\n\n### Unit Tests\n\n1. **Task queueing**\n   - Tasks added to queue in order\n   - Queue processes FIFO\n   - Priority ordering (future)\n\n2. **Concurrency control**\n   - Respects maxConcurrent limit\n   - Starts next task when slot available\n   - Tracks running tasks correctly\n\n3. **Dependency resolution**\n   - Waits for dependencies before execution\n   - Handles failed dependencies\n   - Prevents circular dependencies\n\n4. **Retry logic**\n   - Retries failed tasks up to maxRetries\n   - Uses exponential backoff (future)\n   - Stops retrying after limit\n\n### Integration Tests\n\n1. **End-to-end execution**\n   - Submit → queue → execute → complete\n   - Multiple concurrent tasks\n   - Task cancellation during execution\n\n2. **Metrics tracking**\n   - Counts update correctly\n   - Averages calculate properly\n   - Throughput measured accurately\n\n## Future Enhancements\n\n### Path to Pool-Based Strategy\n\n```typescript\nclass PoolExecutionEngine implements IExecutionEngine {\n  private agentPool: AgentPool;\n  \n  async submitTask(task: ExecutionTask): Promise<string> {\n    // Get idle agent from pool or wait\n    const agent = await this.agentPool.acquire();\n    \n    // Reuse existing process\n    await agent.reset(); // Clear previous state\n    await agent.execute(task);\n    \n    // Return to pool\n    this.agentPool.release(agent);\n    \n    return task.id;\n  }\n  \n  // ... intelligent pool management\n}\n```\n\n### Other Future Features\n\n1. **Priority queue** - Higher priority tasks jump queue\n2. **Task batching** - Group similar tasks for efficiency\n3. **Smart scheduling** - Assign tasks based on agent capabilities\n4. **Resource-aware** - Consider memory/CPU before scheduling\n5. **Adaptive concurrency** - Auto-adjust limits based on load\n\n## File Structure\n\n```\nserver/src/execution/engine/\n├── types.ts                    # Core types (ExecutionTask, etc.)\n├── engine.ts                   # IExecutionEngine interface\n├── simple-engine.ts            # SimpleExecutionEngine (start here)\n├── pool-engine.ts              # PoolExecutionEngine (future)\n└── utils.ts                    # Helper functions\n```\n\n## Implementation Checklist\n\n- [ ] Define core types in types.ts\n- [ ] Define IExecutionEngine interface\n- [ ] Implement SimpleExecutionEngine\n- [ ] Add task queue (FIFO)\n- [ ] Add concurrency control\n- [ ] Add dependency resolution\n- [ ] Add retry logic\n- [ ] Add event emission\n- [ ] Integrate with Process Layer\n- [ ] Write unit tests\n- [ ] Write integration tests\n\n## Related Specs\n\n- Execution System (root spec)\n- [[SPEC-003]] - Process Layer (dependency)\n- Next: Task Execution Layer (Layer 3) - Resilience & retry\n","priority":0,"archived":0,"archived_at":null,"created_at":"2025-10-28 07:36:09","updated_at":"2025-11-03T03:10:12.593Z","parent_id":null,"parent_uuid":null,"relationships":[{"from":"SPEC-004","from_type":"spec","to":"SPEC-003","to_type":"spec","type":"references"}],"tags":["concurrency","engine","execution","layer-2","task-queue"]}
{"id":"SPEC-005","uuid":"91c92cf2-110f-4341-88f1-2b90820c769f","title":"Task Execution Layer - Resilience & Retry","file_path":"specs/task_execution_layer_resilience_retry.md","content":"# Task Execution Layer Specification\n\n## Overview\n\nThe Task Execution Layer (Layer 3) adds resilience patterns to task execution. It wraps the Engine Layer with retry logic, circuit breakers, and fault tolerance mechanisms.\n\n## Design Goals\n\n1. **Resilient**: Automatically recover from transient failures\n2. **Smart Retry**: Exponential backoff with jitter\n3. **Circuit Breaker**: Prevent cascading failures\n4. **Fault Isolation**: One agent failure doesn't affect others\n5. **Observable**: Track retry attempts and failure patterns\n\n## Architecture\n\nBased on Execution System spec, [[SPEC-003]] (Process Layer), and [[SPEC-004]] (Engine Layer).\n\n```\n┌──────────────────────────────────────────────────┐\n│      Task Execution Layer (Layer 3)              │\n├──────────────────────────────────────────────────┤\n│                                                  │\n│  ┌────────────────────────────────────────────┐ │\n│  │   IResilientExecutor (Interface)           │ │\n│  └────────────┬───────────────────────────────┘ │\n│               │                                  │\n│     ┌─────────▼────────────┐                    │\n│     │  ResilientExecutor   │                    │\n│     └──────────┬────────────┘                    │\n│                │                                  │\n│         ┌──────┴───────┬──────────┬──────────┐  │\n│         │              │          │          │  │\n│    ┌────▼─────┐  ┌────▼────┐ ┌──▼────┐ ┌───▼──┐│\n│    │  Retry   │  │ Circuit │ │Timeout│ │Error ││\n│    │ Handler  │  │ Breaker │ │Handler│ │Catch ││\n│    └──────────┘  └─────────┘ └───────┘ └──────┘│\n│                                                  │\n│    ┌──────────────────────────────────────────┐ │\n│    │      Execution Engine (Layer 2)          │ │\n│    └──────────────────────────────────────────┘ │\n│                                                  │\n└──────────────────────────────────────────────────┘\n```\n\n## Core Types\n\n### RetryPolicy\nConfiguration for retry behavior.\n\n```typescript\ninterface RetryPolicy {\n  // Retry limits\n  maxAttempts: number;           // Max retry attempts (0 = no retry)\n  \n  // Backoff strategy\n  backoff: {\n    type: 'exponential' | 'linear' | 'fixed';\n    baseDelayMs: number;         // Initial delay\n    maxDelayMs: number;          // Cap on delay\n    jitter: boolean;             // Add randomness to prevent thundering herd\n  };\n  \n  // Retry conditions\n  retryableErrors: string[];     // Error types to retry\n  retryableExitCodes: number[];  // Exit codes to retry\n  \n  // Circuit breaker integration\n  shouldOpenCircuit?: (error: Error, attempts: number) => boolean;\n}\n```\n\n### CircuitBreakerState\nCircuit breaker for preventing cascading failures.\n\n```typescript\ninterface CircuitBreaker {\n  // Identity\n  name: string;                  // Breaker name (e.g., 'issue-executor')\n  \n  // State\n  state: CircuitState;\n  \n  // Configuration\n  config: {\n    failureThreshold: number;    // Failures before opening (e.g., 5)\n    successThreshold: number;    // Successes to close (e.g., 2)\n    timeout: number;             // Half-open retry delay (ms)\n  };\n  \n  // Metrics\n  metrics: {\n    totalRequests: number;\n    failedRequests: number;\n    successfulRequests: number;\n    lastFailureTime?: Date;\n    lastSuccessTime?: Date;\n  };\n}\n\ntype CircuitState = 'closed' | 'open' | 'half-open';\n```\n\n### ExecutionAttempt\nRecord of a single execution attempt.\n\n```typescript\ninterface ExecutionAttempt {\n  attemptNumber: number;\n  startedAt: Date;\n  completedAt?: Date;\n  duration?: number;\n  success: boolean;\n  error?: Error;\n  exitCode?: number;\n  willRetry: boolean;\n  nextRetryAt?: Date;\n}\n```\n\n### ResilientExecutionResult\nEnhanced result with retry information.\n\n```typescript\ninterface ResilientExecutionResult extends ExecutionResult {\n  // Retry information\n  attempts: ExecutionAttempt[];\n  totalAttempts: number;\n  finalAttempt: ExecutionAttempt;\n  \n  // Failure analysis\n  failureReason?: string;\n  circuitBreakerTriggered?: boolean;\n}\n```\n\n## IResilientExecutor Interface\n\nThe core abstraction for resilient task execution.\n\n```typescript\ninterface IResilientExecutor {\n  // Execute with resilience\n  executeTask(\n    task: ExecutionTask,\n    policy?: RetryPolicy\n  ): Promise<ResilientExecutionResult>;\n  \n  executeTasks(\n    tasks: ExecutionTask[],\n    policy?: RetryPolicy\n  ): Promise<ResilientExecutionResult[]>;\n  \n  // Circuit breaker management\n  getCircuitBreaker(name: string): CircuitBreaker | null;\n  resetCircuitBreaker(name: string): void;\n  \n  // Monitoring\n  getRetryMetrics(): RetryMetrics;\n  onRetryAttempt(handler: RetryAttemptHandler): void;\n  onCircuitOpen(handler: CircuitOpenHandler): void;\n}\n\ntype RetryAttemptHandler = (\n  taskId: string,\n  attempt: ExecutionAttempt\n) => void;\n\ntype CircuitOpenHandler = (\n  circuitName: string,\n  breaker: CircuitBreaker\n) => void;\n\ninterface RetryMetrics {\n  totalRetries: number;\n  successfulRetries: number;\n  failedRetries: number;\n  averageAttemptsToSuccess: number;\n  circuitBreakers: Map<string, CircuitBreaker>;\n}\n```\n\n## ResilientExecutor Implementation\n\nWraps the execution engine with retry and circuit breaker logic.\n\n### Key Features\n\n1. **Exponential Backoff**: Delay increases exponentially (2^attempt)\n2. **Jitter**: Random delay component to prevent thundering herd\n3. **Circuit Breaker**: Per-task-type circuit breakers\n4. **Smart Retry**: Only retry transient errors\n5. **Detailed Tracking**: Record all attempts and failures\n\n### Implementation Pattern\n\n```typescript\nclass ResilientExecutor implements IResilientExecutor {\n  private circuitBreakers = new Map<string, CircuitBreaker>();\n  private retryHandlers: RetryAttemptHandler[] = [];\n  private circuitOpenHandlers: CircuitOpenHandler[] = [];\n  \n  private metrics: RetryMetrics = {\n    totalRetries: 0,\n    successfulRetries: 0,\n    failedRetries: 0,\n    averageAttemptsToSuccess: 1.0,\n    circuitBreakers: new Map(),\n  };\n  \n  constructor(\n    private engine: IExecutionEngine,\n    private defaultPolicy: RetryPolicy = DEFAULT_RETRY_POLICY\n  ) {}\n\n  async executeTask(\n    task: ExecutionTask,\n    policy?: RetryPolicy\n  ): Promise<ResilientExecutionResult> {\n    const retryPolicy = policy || this.defaultPolicy;\n    const attempts: ExecutionAttempt[] = [];\n    \n    // Get or create circuit breaker for this task type\n    const circuitBreaker = this.getOrCreateCircuitBreaker(task.type);\n    \n    // Check circuit breaker\n    if (circuitBreaker.state === 'open') {\n      if (!this.shouldAttemptHalfOpen(circuitBreaker)) {\n        throw new Error(\n          `Circuit breaker '${circuitBreaker.name}' is OPEN. ` +\n          `Too many failures. Try again later.`\n        );\n      }\n      circuitBreaker.state = 'half-open';\n    }\n    \n    // Execute with retry\n    for (let attempt = 1; attempt <= retryPolicy.maxAttempts; attempt++) {\n      const attemptRecord: ExecutionAttempt = {\n        attemptNumber: attempt,\n        startedAt: new Date(),\n        success: false,\n        willRetry: false,\n      };\n      \n      try {\n        // Submit to engine\n        const taskId = await this.engine.submitTask(task);\n        \n        // Wait for result\n        const result = await this.engine.waitForTask(taskId);\n        \n        attemptRecord.completedAt = new Date();\n        attemptRecord.duration = \n          attemptRecord.completedAt.getTime() - \n          attemptRecord.startedAt.getTime();\n        attemptRecord.success = result.success;\n        attemptRecord.exitCode = result.exitCode;\n        \n        attempts.push(attemptRecord);\n        \n        if (result.success) {\n          // Success! Record and close circuit\n          this.recordSuccess(circuitBreaker);\n          \n          return {\n            ...result,\n            attempts,\n            totalAttempts: attempt,\n            finalAttempt: attemptRecord,\n          };\n        } else {\n          // Task failed\n          attemptRecord.error = new Error(result.error || 'Task failed');\n          \n          // Check if we should retry\n          const shouldRetry = \n            attempt < retryPolicy.maxAttempts &&\n            this.isRetryable(result, retryPolicy);\n          \n          if (shouldRetry) {\n            // Calculate backoff delay\n            const delay = this.calculateBackoff(\n              attempt,\n              retryPolicy.backoff\n            );\n            \n            attemptRecord.willRetry = true;\n            attemptRecord.nextRetryAt = new Date(Date.now() + delay);\n            \n            // Emit retry event\n            for (const handler of this.retryHandlers) {\n              handler(task.id, attemptRecord);\n            }\n            \n            this.metrics.totalRetries++;\n            \n            // Wait before retry\n            await this.sleep(delay);\n          } else {\n            // No more retries\n            this.recordFailure(circuitBreaker, attemptRecord.error);\n            \n            this.metrics.failedRetries++;\n            \n            return {\n              ...result,\n              attempts,\n              totalAttempts: attempt,\n              finalAttempt: attemptRecord,\n              failureReason: attemptRecord.error.message,\n            };\n          }\n        }\n      } catch (error) {\n        // Engine-level error (spawn failure, etc.)\n        attemptRecord.completedAt = new Date();\n        attemptRecord.duration = \n          attemptRecord.completedAt.getTime() - \n          attemptRecord.startedAt.getTime();\n        attemptRecord.error = error as Error;\n        attemptRecord.success = false;\n        \n        attempts.push(attemptRecord);\n        \n        // Check if we should retry\n        const shouldRetry = \n          attempt < retryPolicy.maxAttempts &&\n          this.isErrorRetryable(error as Error, retryPolicy);\n        \n        if (shouldRetry) {\n          const delay = this.calculateBackoff(attempt, retryPolicy.backoff);\n          attemptRecord.willRetry = true;\n          attemptRecord.nextRetryAt = new Date(Date.now() + delay);\n          \n          for (const handler of this.retryHandlers) {\n            handler(task.id, attemptRecord);\n          }\n          \n          this.metrics.totalRetries++;\n          await this.sleep(delay);\n        } else {\n          this.recordFailure(circuitBreaker, error as Error);\n          this.metrics.failedRetries++;\n          \n          throw error;\n        }\n      }\n    }\n    \n    // Should never reach here, but TypeScript requires it\n    throw new Error('Max retry attempts exceeded');\n  }\n\n  async executeTasks(\n    tasks: ExecutionTask[],\n    policy?: RetryPolicy\n  ): Promise<ResilientExecutionResult[]> {\n    return Promise.all(\n      tasks.map(task => this.executeTask(task, policy))\n    );\n  }\n\n  private getOrCreateCircuitBreaker(taskType: string): CircuitBreaker {\n    let breaker = this.circuitBreakers.get(taskType);\n    \n    if (!breaker) {\n      breaker = {\n        name: taskType,\n        state: 'closed',\n        config: {\n          failureThreshold: 5,\n          successThreshold: 2,\n          timeout: 60000, // 1 minute\n        },\n        metrics: {\n          totalRequests: 0,\n          failedRequests: 0,\n          successfulRequests: 0,\n        },\n      };\n      \n      this.circuitBreakers.set(taskType, breaker);\n      this.metrics.circuitBreakers.set(taskType, breaker);\n    }\n    \n    return breaker;\n  }\n\n  private shouldAttemptHalfOpen(breaker: CircuitBreaker): boolean {\n    if (!breaker.metrics.lastFailureTime) return true;\n    \n    const timeSinceFailure = \n      Date.now() - breaker.metrics.lastFailureTime.getTime();\n    \n    return timeSinceFailure >= breaker.config.timeout;\n  }\n\n  private recordSuccess(breaker: CircuitBreaker): void {\n    breaker.metrics.totalRequests++;\n    breaker.metrics.successfulRequests++;\n    breaker.metrics.lastSuccessTime = new Date();\n    \n    if (breaker.state === 'half-open') {\n      // Count consecutive successes in half-open state\n      const recentSuccesses = this.getRecentSuccessCount(breaker);\n      if (recentSuccesses >= breaker.config.successThreshold) {\n        breaker.state = 'closed';\n        breaker.metrics.failedRequests = 0; // Reset failure count\n      }\n    }\n    \n    this.metrics.successfulRetries++;\n  }\n\n  private recordFailure(breaker: CircuitBreaker, error: Error): void {\n    breaker.metrics.totalRequests++;\n    breaker.metrics.failedRequests++;\n    breaker.metrics.lastFailureTime = new Date();\n    \n    // Check if we should open circuit\n    if (\n      breaker.state === 'closed' &&\n      breaker.metrics.failedRequests >= breaker.config.failureThreshold\n    ) {\n      breaker.state = 'open';\n      \n      // Emit circuit open event\n      for (const handler of this.circuitOpenHandlers) {\n        handler(breaker.name, breaker);\n      }\n    } else if (breaker.state === 'half-open') {\n      // Failed in half-open, back to open\n      breaker.state = 'open';\n    }\n  }\n\n  private getRecentSuccessCount(breaker: CircuitBreaker): number {\n    // In a real implementation, track recent attempts\n    // For now, simplified\n    return breaker.metrics.successfulRequests;\n  }\n\n  private calculateBackoff(\n    attempt: number,\n    config: RetryPolicy['backoff']\n  ): number {\n    let delay: number;\n    \n    switch (config.type) {\n      case 'exponential':\n        delay = config.baseDelayMs * Math.pow(2, attempt - 1);\n        break;\n      case 'linear':\n        delay = config.baseDelayMs * attempt;\n        break;\n      case 'fixed':\n        delay = config.baseDelayMs;\n        break;\n    }\n    \n    // Cap at max delay\n    delay = Math.min(delay, config.maxDelayMs);\n    \n    // Add jitter if configured\n    if (config.jitter) {\n      const jitterAmount = delay * 0.1; // 10% jitter\n      delay += Math.random() * jitterAmount - jitterAmount / 2;\n    }\n    \n    return Math.floor(delay);\n  }\n\n  private isRetryable(\n    result: ExecutionResult,\n    policy: RetryPolicy\n  ): boolean {\n    // Check exit code\n    if (\n      result.exitCode !== undefined &&\n      policy.retryableExitCodes.includes(result.exitCode)\n    ) {\n      return true;\n    }\n    \n    // Check error message\n    if (result.error) {\n      for (const retryableError of policy.retryableErrors) {\n        if (result.error.includes(retryableError)) {\n          return true;\n        }\n      }\n    }\n    \n    return false;\n  }\n\n  private isErrorRetryable(error: Error, policy: RetryPolicy): boolean {\n    for (const retryableError of policy.retryableErrors) {\n      if (error.message.includes(retryableError)) {\n        return true;\n      }\n    }\n    return false;\n  }\n\n  private sleep(ms: number): Promise<void> {\n    return new Promise(resolve => setTimeout(resolve, ms));\n  }\n\n  getCircuitBreaker(name: string): CircuitBreaker | null {\n    return this.circuitBreakers.get(name) || null;\n  }\n\n  resetCircuitBreaker(name: string): void {\n    const breaker = this.circuitBreakers.get(name);\n    if (breaker) {\n      breaker.state = 'closed';\n      breaker.metrics.failedRequests = 0;\n      breaker.metrics.successfulRequests = 0;\n    }\n  }\n\n  getRetryMetrics(): RetryMetrics {\n    return { ...this.metrics };\n  }\n\n  onRetryAttempt(handler: RetryAttemptHandler): void {\n    this.retryHandlers.push(handler);\n  }\n\n  onCircuitOpen(handler: CircuitOpenHandler): void {\n    this.circuitOpenHandlers.push(handler);\n  }\n}\n\n// Default retry policy\nconst DEFAULT_RETRY_POLICY: RetryPolicy = {\n  maxAttempts: 3,\n  backoff: {\n    type: 'exponential',\n    baseDelayMs: 1000,\n    maxDelayMs: 30000,\n    jitter: true,\n  },\n  retryableErrors: [\n    'ECONNREFUSED',\n    'ETIMEDOUT',\n    'ENOTFOUND',\n    'timeout',\n    'network',\n  ],\n  retryableExitCodes: [1, 137], // Generic error, SIGKILL\n};\n```\n\n## Usage Example\n\n```typescript\n// Initialize stack\nconst processManager = new SimpleProcessManager();\nconst engine = new SimpleExecutionEngine(processManager, {\n  maxConcurrent: 5,\n});\n\nconst resilientExecutor = new ResilientExecutor(engine, {\n  maxAttempts: 3,\n  backoff: {\n    type: 'exponential',\n    baseDelayMs: 1000,\n    maxDelayMs: 30000,\n    jitter: true,\n  },\n  retryableErrors: ['timeout', 'ECONNREFUSED'],\n  retryableExitCodes: [1],\n});\n\n// Listen to retry attempts\nresilientExecutor.onRetryAttempt((taskId, attempt) => {\n  console.log(\n    `Task ${taskId} attempt ${attempt.attemptNumber} failed. ` +\n    `Retrying in ${attempt.nextRetryAt}...`\n  );\n});\n\n// Listen to circuit breaker events\nresilientExecutor.onCircuitOpen((name, breaker) => {\n  console.log(\n    `Circuit breaker '${name}' opened after ` +\n    `${breaker.metrics.failedRequests} failures`\n  );\n});\n\n// Execute task with resilience\nconst task = {\n  id: 'task-1',\n  type: 'issue',\n  entityId: 'ISSUE-001',\n  prompt: 'Fix the bug',\n  workDir: '/path/to/project',\n  priority: 0,\n  dependencies: [],\n  createdAt: new Date(),\n  config: {},\n};\n\nconst result = await resilientExecutor.executeTask(task);\n\nconsole.log(`Success: ${result.success}`);\nconsole.log(`Attempts: ${result.totalAttempts}`);\nconsole.log(`Attempts:`, result.attempts);\n```\n\n## Testing Strategy\n\n### Unit Tests\n\n1. **Retry logic**\n   - Retries up to maxAttempts\n   - Calculates backoff correctly\n   - Adds jitter when configured\n   - Stops retrying on non-retryable errors\n\n2. **Circuit breaker**\n   - Opens after failure threshold\n   - Transitions to half-open after timeout\n   - Closes after success threshold\n   - Rejects requests when open\n\n3. **Backoff calculation**\n   - Exponential: 1s, 2s, 4s, 8s, 16s\n   - Linear: 1s, 2s, 3s, 4s, 5s\n   - Fixed: 1s, 1s, 1s, 1s, 1s\n   - Respects maxDelay cap\n\n### Integration Tests\n\n1. **End-to-end resilience**\n   - Task fails → retries → succeeds\n   - Circuit breaker opens → half-open → closes\n   - Multiple task types have separate breakers\n\n2. **Failure scenarios**\n   - Transient errors are retried\n   - Permanent errors fail fast\n   - Circuit breaker prevents cascading failures\n\n## Future Enhancements\n\n1. **Adaptive retry** - Adjust backoff based on load\n2. **Bulkhead pattern** - Isolate task types with separate pools\n3. **Rate limiting** - Prevent overwhelming downstream services\n4. **Retry budgets** - Limit total retry percentage\n5. **Dead letter queue** - Store permanently failed tasks\n\n## File Structure\n\n```\nserver/src/execution/resilience/\n├── types.ts                    # Core types (RetryPolicy, etc.)\n├── executor.ts                 # IResilientExecutor interface\n├── resilient-executor.ts       # ResilientExecutor implementation\n├── circuit-breaker.ts          # Circuit breaker logic\n├── retry.ts                    # Retry and backoff logic\n└── utils.ts                    # Helper functions\n```\n\n## Implementation Checklist\n\n- [ ] Define core types in types.ts\n- [ ] Define IResilientExecutor interface\n- [ ] Implement ResilientExecutor\n- [ ] Add retry logic with exponential backoff\n- [ ] Add jitter to backoff\n- [ ] Implement circuit breaker\n- [ ] Add retryable error detection\n- [ ] Add metrics tracking\n- [ ] Write unit tests for retry logic\n- [ ] Write unit tests for circuit breaker\n- [ ] Write integration tests\n\n## Related Specs\n\n- Execution System (root spec)\n- [[SPEC-003]] - Process Layer (foundation)\n- [[SPEC-004]] - Engine Layer (dependency)\n- Next: Workflow Layer (Layer 4) - Orchestration & state\n","priority":0,"archived":0,"archived_at":null,"created_at":"2025-10-28 07:45:43","updated_at":"2025-11-03T03:10:12.593Z","parent_id":null,"parent_uuid":null,"relationships":[{"from":"SPEC-005","from_type":"spec","to":"SPEC-003","to_type":"spec","type":"references"},{"from":"SPEC-005","from_type":"spec","to":"SPEC-004","to_type":"spec","type":"references"}],"tags":["circuit-breaker","execution","layer-3","resilience","retry"]}
{"id":"SPEC-006","uuid":"3d34e745-31ce-409e-b43b-9459ea4704bc","title":"Workflow Layer - Orchestration & State Management","file_path":"specs/workflow_layer_orchestration_state_management.md","content":"# Workflow Layer Specification\n\n## Overview\n\nThe Workflow Layer (Layer 4) orchestrates complex multi-step executions with state persistence, dependency management, and workflow resumption. It enables building sophisticated agent workflows that can survive crashes and resume from checkpoints.\n\n## Design Goals\n\n1. **Stateful**: Persist workflow state for crash recovery\n2. **Resumable**: Continue from last checkpoint after failure\n3. **Composable**: Build complex workflows from simple steps\n4. **Observable**: Track workflow progress in real-time\n5. **Simple First**: Start with linear workflows, upgrade to DAGs\n\n## Architecture\n\nBased on Execution System spec, [[SPEC-003]] (Process), [[SPEC-004]] (Engine), and [[SPEC-005]] (Resilience).\n\n```\n┌────────────────────────────────────────────────────┐\n│       Workflow Layer (Layer 4)                     │\n├────────────────────────────────────────────────────┤\n│                                                    │\n│  ┌──────────────────────────────────────────────┐ │\n│  │    IWorkflowOrchestrator (Interface)         │ │\n│  └──────────────┬───────────────────────────────┘ │\n│                 │                                  │\n│       ┌─────────▼──────────┐                      │\n│       │ LinearOrchestrator │                      │\n│       │  (Start Here)      │                      │\n│       └─────────┬──────────┘                      │\n│                 │                                  │\n│          ┌──────┴───────┬────────────┐            │\n│          │              │            │            │\n│     ┌────▼────┐   ┌────▼────┐  ┌───▼──────┐     │\n│     │Workflow │   │  Step   │  │  State   │     │\n│     │Executor │   │Executor │  │Persister │     │\n│     └─────────┘   └─────────┘  └──────────┘     │\n│                                                    │\n│    ┌────────────────────────────────────────────┐ │\n│    │   Resilient Executor (Layer 3)             │ │\n│    └────────────────────────────────────────────┘ │\n│                                                    │\n└────────────────────────────────────────────────────┘\n```\n\n## Core Types\n\n### WorkflowDefinition\nDefines a multi-step workflow.\n\n```typescript\ninterface WorkflowDefinition {\n  // Identity\n  id: string;\n  name: string;\n  version: string;\n  \n  // Steps\n  steps: WorkflowStep[];\n  \n  // Configuration\n  config: {\n    checkpointInterval?: number;  // Save state every N steps\n    continueOnStepFailure?: boolean;\n    timeout?: number;             // Overall workflow timeout\n  };\n  \n  // Metadata\n  metadata?: Record<string, any>;\n}\n\ninterface WorkflowStep {\n  // Identity\n  id: string;\n  name: string;\n  \n  // Task configuration\n  taskType: 'issue' | 'spec' | 'custom';\n  promptTemplate: string;         // Template with variables\n  \n  // Dependencies\n  dependsOn: string[];            // Step IDs that must complete first\n  \n  // Execution config\n  retryPolicy?: RetryPolicy;\n  timeout?: number;\n  \n  // Condition\n  condition?: (context: WorkflowContext) => boolean;\n  \n  // Output mapping\n  outputMapping?: Record<string, string>; // Map outputs to context vars\n}\n```\n\n### WorkflowExecution\nRuntime state of a workflow execution.\n\n```typescript\ninterface WorkflowExecution {\n  // Identity\n  id: string;\n  workflowId: string;\n  \n  // State\n  status: WorkflowStatus;\n  currentStep?: string;          // Currently executing step ID\n  \n  // Progress\n  completedSteps: string[];\n  failedSteps: string[];\n  skippedSteps: string[];\n  \n  // Context (variables shared across steps)\n  context: WorkflowContext;\n  \n  // Results\n  stepResults: Map<string, ExecutionResult>;\n  \n  // Timing\n  startedAt: Date;\n  completedAt?: Date;\n  lastCheckpointAt?: Date;\n  \n  // Metadata\n  metadata?: Record<string, any>;\n}\n\ntype WorkflowStatus = \n  | 'pending'\n  | 'running'\n  | 'paused'\n  | 'completed'\n  | 'failed'\n  | 'cancelled';\n\ninterface WorkflowContext {\n  // Global variables\n  variables: Record<string, any>;\n  \n  // Step outputs (accessible by step ID)\n  outputs: Record<string, any>;\n  \n  // Shared state\n  shared: Record<string, any>;\n}\n```\n\n### WorkflowCheckpoint\nSerializable checkpoint for resumption.\n\n```typescript\ninterface WorkflowCheckpoint {\n  executionId: string;\n  workflowId: string;\n  timestamp: Date;\n  \n  // State snapshot\n  execution: WorkflowExecution;\n  \n  // Next step to execute\n  nextStep?: string;\n}\n```\n\n## IWorkflowOrchestrator Interface\n\nThe core abstraction for workflow orchestration.\n\n```typescript\ninterface IWorkflowOrchestrator {\n  // Workflow execution\n  startWorkflow(\n    workflow: WorkflowDefinition,\n    initialContext?: Partial<WorkflowContext>\n  ): Promise<string>; // Returns execution ID\n  \n  resumeWorkflow(\n    checkpointId: string\n  ): Promise<string>; // Returns execution ID\n  \n  // Control\n  pauseWorkflow(executionId: string): Promise<void>;\n  cancelWorkflow(executionId: string): Promise<void>;\n  \n  // Monitoring\n  getExecution(executionId: string): WorkflowExecution | null;\n  getStepStatus(executionId: string, stepId: string): StepStatus | null;\n  \n  // Waiting\n  waitForWorkflow(executionId: string): Promise<WorkflowResult>;\n  \n  // Checkpointing\n  saveCheckpoint(executionId: string): Promise<string>; // Returns checkpoint ID\n  listCheckpoints(workflowId: string): Promise<WorkflowCheckpoint[]>;\n  \n  // Events\n  onStepComplete(handler: StepCompleteHandler): void;\n  onWorkflowComplete(handler: WorkflowCompleteHandler): void;\n  onCheckpoint(handler: CheckpointHandler): void;\n}\n\ninterface StepStatus {\n  stepId: string;\n  status: 'pending' | 'running' | 'completed' | 'failed' | 'skipped';\n  result?: ExecutionResult;\n  attempts: number;\n}\n\ninterface WorkflowResult {\n  executionId: string;\n  success: boolean;\n  completedSteps: number;\n  failedSteps: number;\n  outputs: Record<string, any>;\n  duration: number;\n}\n\ntype StepCompleteHandler = (\n  executionId: string,\n  stepId: string,\n  result: ExecutionResult\n) => void;\n\ntype WorkflowCompleteHandler = (result: WorkflowResult) => void;\n\ntype CheckpointHandler = (checkpoint: WorkflowCheckpoint) => void;\n```\n\n## LinearOrchestrator Implementation\n\nSimple linear workflow execution with checkpointing.\n\n### Key Features\n\n1. **Sequential Execution**: Steps execute in defined order\n2. **Dependency Resolution**: Wait for dependencies before executing\n3. **Context Passing**: Share data between steps via context\n4. **Checkpointing**: Save state after each step for resumption\n5. **Conditional Steps**: Skip steps based on conditions\n\n### Implementation Pattern\n\n```typescript\nclass LinearOrchestrator implements IWorkflowOrchestrator {\n  private executions = new Map<string, WorkflowExecution>();\n  private checkpoints = new Map<string, WorkflowCheckpoint>();\n  \n  private stepCompleteHandlers: StepCompleteHandler[] = [];\n  private workflowCompleteHandlers: WorkflowCompleteHandler[] = [];\n  private checkpointHandlers: CheckpointHandler[] = [];\n  \n  constructor(\n    private executor: IResilientExecutor,\n    private storage?: IWorkflowStorage\n  ) {}\n\n  async startWorkflow(\n    workflow: WorkflowDefinition,\n    initialContext?: Partial<WorkflowContext>\n  ): Promise<string> {\n    const execution: WorkflowExecution = {\n      id: generateId('execution'),\n      workflowId: workflow.id,\n      status: 'pending',\n      completedSteps: [],\n      failedSteps: [],\n      skippedSteps: [],\n      context: {\n        variables: initialContext?.variables || {},\n        outputs: {},\n        shared: {},\n      },\n      stepResults: new Map(),\n      startedAt: new Date(),\n    };\n    \n    this.executions.set(execution.id, execution);\n    \n    // Start execution in background\n    this.executeWorkflow(workflow, execution).catch(error => {\n      execution.status = 'failed';\n      execution.completedAt = new Date();\n    });\n    \n    return execution.id;\n  }\n\n  async resumeWorkflow(checkpointId: string): Promise<string> {\n    const checkpoint = this.checkpoints.get(checkpointId);\n    if (!checkpoint) {\n      throw new Error(`Checkpoint ${checkpointId} not found`);\n    }\n    \n    // Restore execution state\n    const execution = checkpoint.execution;\n    execution.status = 'pending';\n    this.executions.set(execution.id, execution);\n    \n    // Find workflow definition\n    const workflow = await this.loadWorkflowDefinition(execution.workflowId);\n    \n    // Resume from next step\n    this.executeWorkflow(workflow, execution, checkpoint.nextStep).catch(\n      error => {\n        execution.status = 'failed';\n        execution.completedAt = new Date();\n      }\n    );\n    \n    return execution.id;\n  }\n\n  private async executeWorkflow(\n    workflow: WorkflowDefinition,\n    execution: WorkflowExecution,\n    startFromStep?: string\n  ): Promise<void> {\n    execution.status = 'running';\n    \n    // Find starting point\n    let startIndex = 0;\n    if (startFromStep) {\n      startIndex = workflow.steps.findIndex(s => s.id === startFromStep);\n      if (startIndex === -1) {\n        throw new Error(`Step ${startFromStep} not found in workflow`);\n      }\n    }\n    \n    // Execute steps sequentially\n    for (let i = startIndex; i < workflow.steps.length; i++) {\n      const step = workflow.steps[i];\n      \n      // Check if paused or cancelled\n      if (execution.status === 'paused' || execution.status === 'cancelled') {\n        return;\n      }\n      \n      // Check dependencies\n      if (!this.areDependenciesMet(step, execution)) {\n        execution.failedSteps.push(step.id);\n        if (!workflow.config.continueOnStepFailure) {\n          execution.status = 'failed';\n          execution.completedAt = new Date();\n          return;\n        }\n        continue;\n      }\n      \n      // Check condition\n      if (step.condition && !step.condition(execution.context)) {\n        execution.skippedSteps.push(step.id);\n        continue;\n      }\n      \n      // Execute step\n      execution.currentStep = step.id;\n      \n      try {\n        const result = await this.executeStep(step, execution, workflow);\n        \n        execution.stepResults.set(step.id, result);\n        execution.completedSteps.push(step.id);\n        \n        // Update context with step outputs\n        if (step.outputMapping) {\n          for (const [key, path] of Object.entries(step.outputMapping)) {\n            execution.context.outputs[key] = this.extractValue(result, path);\n          }\n        }\n        \n        // Emit step complete event\n        for (const handler of this.stepCompleteHandlers) {\n          handler(execution.id, step.id, result);\n        }\n        \n        // Checkpoint if configured\n        if (\n          workflow.config.checkpointInterval &&\n          execution.completedSteps.length % workflow.config.checkpointInterval === 0\n        ) {\n          await this.saveCheckpoint(execution.id);\n        }\n      } catch (error) {\n        execution.failedSteps.push(step.id);\n        \n        if (!workflow.config.continueOnStepFailure) {\n          execution.status = 'failed';\n          execution.completedAt = new Date();\n          throw error;\n        }\n      }\n    }\n    \n    // Workflow completed\n    execution.status = 'completed';\n    execution.completedAt = new Date();\n    \n    // Emit workflow complete event\n    const result: WorkflowResult = {\n      executionId: execution.id,\n      success: execution.failedSteps.length === 0,\n      completedSteps: execution.completedSteps.length,\n      failedSteps: execution.failedSteps.length,\n      outputs: execution.context.outputs,\n      duration: execution.completedAt.getTime() - execution.startedAt.getTime(),\n    };\n    \n    for (const handler of this.workflowCompleteHandlers) {\n      handler(result);\n    }\n  }\n\n  private areDependenciesMet(\n    step: WorkflowStep,\n    execution: WorkflowExecution\n  ): boolean {\n    for (const depId of step.dependsOn) {\n      if (!execution.completedSteps.includes(depId)) {\n        return false;\n      }\n    }\n    return true;\n  }\n\n  private async executeStep(\n    step: WorkflowStep,\n    execution: WorkflowExecution,\n    workflow: WorkflowDefinition\n  ): Promise<ExecutionResult> {\n    // Render prompt template with context\n    const prompt = this.renderTemplate(step.promptTemplate, execution.context);\n    \n    // Build execution task\n    const task: ExecutionTask = {\n      id: generateId('task'),\n      type: step.taskType,\n      entityId: undefined,\n      prompt,\n      workDir: process.cwd(), // TODO: Make configurable\n      priority: 0,\n      dependencies: [],\n      createdAt: new Date(),\n      config: {\n        timeout: step.timeout,\n      },\n    };\n    \n    // Execute with resilience\n    return await this.executor.executeTask(task, step.retryPolicy);\n  }\n\n  private renderTemplate(\n    template: string,\n    context: WorkflowContext\n  ): string {\n    let rendered = template;\n    \n    // Replace variables: {{variable}}\n    for (const [key, value] of Object.entries(context.variables)) {\n      rendered = rendered.replace(\n        new RegExp(`{{${key}}}`, 'g'),\n        String(value)\n      );\n    }\n    \n    // Replace outputs: {{step.output}}\n    for (const [key, value] of Object.entries(context.outputs)) {\n      rendered = rendered.replace(\n        new RegExp(`{{${key}}}`, 'g'),\n        String(value)\n      );\n    }\n    \n    return rendered;\n  }\n\n  private extractValue(result: ExecutionResult, path: string): any {\n    // Simple path extraction (e.g., \"output\" or \"metadata.filesChanged\")\n    const parts = path.split('.');\n    let value: any = result;\n    \n    for (const part of parts) {\n      value = value[part];\n      if (value === undefined) break;\n    }\n    \n    return value;\n  }\n\n  async saveCheckpoint(executionId: string): Promise<string> {\n    const execution = this.executions.get(executionId);\n    if (!execution) {\n      throw new Error(`Execution ${executionId} not found`);\n    }\n    \n    const checkpoint: WorkflowCheckpoint = {\n      executionId,\n      workflowId: execution.workflowId,\n      timestamp: new Date(),\n      execution: { ...execution },\n      nextStep: execution.currentStep,\n    };\n    \n    const checkpointId = generateId('checkpoint');\n    this.checkpoints.set(checkpointId, checkpoint);\n    \n    execution.lastCheckpointAt = new Date();\n    \n    // Persist to storage if available\n    if (this.storage) {\n      await this.storage.saveCheckpoint(checkpointId, checkpoint);\n    }\n    \n    // Emit checkpoint event\n    for (const handler of this.checkpointHandlers) {\n      handler(checkpoint);\n    }\n    \n    return checkpointId;\n  }\n\n  async pauseWorkflow(executionId: string): Promise<void> {\n    const execution = this.executions.get(executionId);\n    if (execution) {\n      execution.status = 'paused';\n    }\n  }\n\n  async cancelWorkflow(executionId: string): Promise<void> {\n    const execution = this.executions.get(executionId);\n    if (execution) {\n      execution.status = 'cancelled';\n      execution.completedAt = new Date();\n    }\n  }\n\n  getExecution(executionId: string): WorkflowExecution | null {\n    return this.executions.get(executionId) || null;\n  }\n\n  getStepStatus(executionId: string, stepId: string): StepStatus | null {\n    const execution = this.executions.get(executionId);\n    if (!execution) return null;\n    \n    const result = execution.stepResults.get(stepId);\n    \n    let status: StepStatus['status'];\n    if (execution.completedSteps.includes(stepId)) {\n      status = 'completed';\n    } else if (execution.failedSteps.includes(stepId)) {\n      status = 'failed';\n    } else if (execution.skippedSteps.includes(stepId)) {\n      status = 'skipped';\n    } else if (execution.currentStep === stepId) {\n      status = 'running';\n    } else {\n      status = 'pending';\n    }\n    \n    return {\n      stepId,\n      status,\n      result,\n      attempts: 1, // TODO: Track attempts\n    };\n  }\n\n  async waitForWorkflow(executionId: string): Promise<WorkflowResult> {\n    return new Promise((resolve, reject) => {\n      const checkInterval = setInterval(() => {\n        const execution = this.executions.get(executionId);\n        if (!execution) {\n          clearInterval(checkInterval);\n          reject(new Error(`Execution ${executionId} not found`));\n          return;\n        }\n        \n        if (\n          execution.status === 'completed' ||\n          execution.status === 'failed' ||\n          execution.status === 'cancelled'\n        ) {\n          clearInterval(checkInterval);\n          \n          const result: WorkflowResult = {\n            executionId,\n            success: execution.status === 'completed',\n            completedSteps: execution.completedSteps.length,\n            failedSteps: execution.failedSteps.length,\n            outputs: execution.context.outputs,\n            duration: execution.completedAt\n              ? execution.completedAt.getTime() - execution.startedAt.getTime()\n              : 0,\n          };\n          \n          resolve(result);\n        }\n      }, 100);\n    });\n  }\n\n  async listCheckpoints(workflowId: string): Promise<WorkflowCheckpoint[]> {\n    const checkpoints: WorkflowCheckpoint[] = [];\n    \n    for (const checkpoint of this.checkpoints.values()) {\n      if (checkpoint.workflowId === workflowId) {\n        checkpoints.push(checkpoint);\n      }\n    }\n    \n    return checkpoints;\n  }\n\n  onStepComplete(handler: StepCompleteHandler): void {\n    this.stepCompleteHandlers.push(handler);\n  }\n\n  onWorkflowComplete(handler: WorkflowCompleteHandler): void {\n    this.workflowCompleteHandlers.push(handler);\n  }\n\n  onCheckpoint(handler: CheckpointHandler): void {\n    this.checkpointHandlers.push(handler);\n  }\n\n  private async loadWorkflowDefinition(\n    workflowId: string\n  ): Promise<WorkflowDefinition> {\n    // TODO: Load from storage\n    throw new Error('Not implemented');\n  }\n}\n\ninterface IWorkflowStorage {\n  saveCheckpoint(id: string, checkpoint: WorkflowCheckpoint): Promise<void>;\n  loadCheckpoint(id: string): Promise<WorkflowCheckpoint | null>;\n}\n```\n\n## Usage Example\n\n```typescript\n// Define workflow\nconst bugFixWorkflow: WorkflowDefinition = {\n  id: 'bug-fix-workflow',\n  name: 'Bug Fix and Test',\n  version: '1.0',\n  steps: [\n    {\n      id: 'analyze',\n      name: 'Analyze Issue',\n      taskType: 'issue',\n      promptTemplate: 'Analyze the bug in {{issueId}} and suggest a fix',\n      dependsOn: [],\n      outputMapping: {\n        analysis: 'output',\n      },\n    },\n    {\n      id: 'implement',\n      name: 'Implement Fix',\n      taskType: 'issue',\n      promptTemplate: 'Implement the fix for {{issueId}}. Analysis: {{analysis}}',\n      dependsOn: ['analyze'],\n      outputMapping: {\n        filesChanged: 'metadata.filesChanged',\n      },\n    },\n    {\n      id: 'test',\n      name: 'Run Tests',\n      taskType: 'custom',\n      promptTemplate: 'Run tests for files: {{filesChanged}}',\n      dependsOn: ['implement'],\n    },\n  ],\n  config: {\n    checkpointInterval: 1,\n    continueOnStepFailure: false,\n  },\n};\n\n// Execute workflow\nconst orchestrator = new LinearOrchestrator(resilientExecutor);\n\norchestrator.onStepComplete((execId, stepId, result) => {\n  console.log(`Step ${stepId} completed:`, result.success);\n});\n\nconst executionId = await orchestrator.startWorkflow(bugFixWorkflow, {\n  variables: {\n    issueId: 'ISSUE-001',\n  },\n});\n\nconst result = await orchestrator.waitForWorkflow(executionId);\nconsole.log(`Workflow completed: ${result.success}`);\nconsole.log(`Outputs:`, result.outputs);\n```\n\n## Testing Strategy\n\n### Unit Tests\n\n1. **Step execution**\n   - Executes steps in order\n   - Passes context between steps\n   - Handles step failures\n   - Skips conditional steps\n\n2. **Checkpointing**\n   - Saves checkpoint after interval\n   - Resumes from checkpoint correctly\n   - Preserves execution state\n\n3. **Template rendering**\n   - Replaces variables correctly\n   - Handles nested paths\n   - Handles missing variables\n\n### Integration Tests\n\n1. **End-to-end workflows**\n   - Multi-step workflow completes\n   - Checkpoint and resume works\n   - Context data flows correctly\n\n2. **Failure scenarios**\n   - Step failure stops workflow\n   - Resume after crash\n   - Handle partial completion\n\n## Future Enhancements\n\n1. **DAG workflows** - Parallel step execution\n2. **Conditional branches** - If/else logic\n3. **Loops** - Repeat steps until condition\n4. **Sub-workflows** - Compose workflows\n5. **Workflow versioning** - A/B testing\n\n## File Structure\n\n```\nserver/src/execution/workflow/\n├── types.ts                    # Core types (WorkflowDefinition, etc.)\n├── orchestrator.ts             # IWorkflowOrchestrator interface\n├── linear-orchestrator.ts      # LinearOrchestrator (start here)\n├── dag-orchestrator.ts         # DAGOrchestrator (future)\n├── storage.ts                  # Checkpoint persistence\n└── utils.ts                    # Template rendering, etc.\n```\n\n## Implementation Checklist\n\n- [ ] Define core types\n- [ ] Define IWorkflowOrchestrator interface\n- [ ] Implement LinearOrchestrator\n- [ ] Add sequential step execution\n- [ ] Add dependency resolution\n- [ ] Add template rendering\n- [ ] Add checkpointing\n- [ ] Add workflow resumption\n- [ ] Add conditional step execution\n- [ ] Write unit tests\n- [ ] Write integration tests\n\n## Related Specs\n\n- Execution System (root spec)\n- [[SPEC-003]] - Process Layer\n- [[SPEC-004]] - Engine Layer\n- [[SPEC-005]] - Task Execution Layer (dependency)\n- Next: Output Processing Layer (Layer 5)\n","priority":0,"archived":0,"archived_at":null,"created_at":"2025-10-28 07:45:45","updated_at":"2025-11-03T03:10:12.592Z","parent_id":null,"parent_uuid":null,"relationships":[{"from":"SPEC-006","from_type":"spec","to":"SPEC-003","to_type":"spec","type":"references"},{"from":"SPEC-006","from_type":"spec","to":"SPEC-004","to_type":"spec","type":"references"},{"from":"SPEC-006","from_type":"spec","to":"SPEC-005","to_type":"spec","type":"references"},{"from":"SPEC-006","from_type":"spec","to":"SPEC-005","to_type":"spec","type":"depends-on"}],"tags":["execution","layer-4","orchestration","state","workflow"]}
{"id":"SPEC-007","uuid":"cb9b2531-e8ce-4696-a74e-6973649ccdc7","title":"Output Processing Layer - Real-time Parsing","file_path":"specs/output_processing_layer_real_time_parsing.md","content":"# Output Processing Layer Specification\n\n## Overview\n\nThe Output Processing Layer (Layer 5) handles real-time parsing and processing of Claude Code's output. It parses stream-json format, extracts structured data, tracks progress, and provides event-driven updates.\n\n## Design Goals\n\n1. **Real-time**: Parse output as it streams, not after completion\n2. **Structured**: Extract tool calls, file changes, errors from JSON\n3. **Event-driven**: Emit events for progress tracking\n4. **Robust**: Handle malformed JSON gracefully\n5. **Flexible**: Support multiple output formats\n\n## Architecture\n\nBased on Execution System spec and all previous layers.\n\n```\n┌──────────────────────────────────────────────────┐\n│     Output Processing Layer (Layer 5)            │\n├──────────────────────────────────────────────────┤\n│                                                  │\n│  ┌────────────────────────────────────────────┐ │\n│  │   IOutputProcessor (Interface)             │ │\n│  └────────────┬───────────────────────────────┘ │\n│               │                                  │\n│     ┌─────────▼──────────┐                      │\n│     │ StreamJsonProcessor│                      │\n│     │  (Start Here)      │                      │\n│     └─────────┬──────────┘                      │\n│               │                                  │\n│        ┌──────┴──────┬──────────┬──────────┐   │\n│        │             │          │          │   │\n│   ┌────▼────┐  ┌────▼────┐ ┌──▼────┐ ┌───▼──┐│\n│   │  JSON   │  │  Event  │ │ Meta  │ │Error ││\n│   │ Parser  │  │ Emitter │ │Extract│ │Handle││\n│   └─────────┘  └─────────┘ └───────┘ └──────┘│\n│                                                  │\n│    ┌──────────────────────────────────────────┐ │\n│    │      Process Manager (Layer 1)           │ │\n│    └──────────────────────────────────────────┘ │\n│                                                  │\n└──────────────────────────────────────────────────┘\n```\n\n## Core Types\n\n### StreamMessage\nParsed message from Claude Code stream-json output.\n\n```typescript\ninterface StreamMessage {\n  type: MessageType;\n  timestamp: Date;\n  raw: string;                   // Original JSON line\n  data: any;                     // Parsed JSON\n}\n\ntype MessageType = \n  | 'user'                       // User message\n  | 'assistant'                  // Assistant message\n  | 'tool_use'                   // Tool invocation\n  | 'tool_result'                // Tool result\n  | 'result'                     // Final result with usage\n  | 'error'                      // Error message\n  | 'unknown';                   // Unparseable\n```\n\n### ToolCall\nExtracted tool call information.\n\n```typescript\ninterface ToolCall {\n  id: string;\n  name: string;\n  input: Record<string, any>;\n  timestamp: Date;\n}\n\ninterface ToolResult {\n  toolCallId: string;\n  success: boolean;\n  output?: any;\n  error?: string;\n  timestamp: Date;\n}\n```\n\n### ExecutionProgress\nReal-time execution progress.\n\n```typescript\ninterface ExecutionProgress {\n  // Basic info\n  processId: string;\n  startedAt: Date;\n  lastUpdate: Date;\n  \n  // Progress\n  toolCalls: ToolCall[];\n  toolResults: ToolResult[];\n  filesChanged: string[];\n  errors: string[];\n  \n  // Current state\n  currentActivity?: string;      // e.g., \"Reading file auth.ts\"\n  \n  // Usage\n  usage?: {\n    inputTokens: number;\n    outputTokens: number;\n    totalTokens: number;\n    cost?: number;\n  };\n}\n```\n\n### OutputProcessingOptions\nConfiguration for output processing.\n\n```typescript\ninterface OutputProcessingOptions {\n  // Format\n  format: 'stream-json' | 'json' | 'text';\n  \n  // Filtering\n  captureToolCalls?: boolean;\n  captureFileChanges?: boolean;\n  captureErrors?: boolean;\n  \n  // Events\n  emitProgressEvents?: boolean;\n  progressInterval?: number;     // ms between progress events\n  \n  // Buffering\n  maxBufferSize?: number;        // Max lines to buffer\n  lineSeparator?: string;        // Default: '\\n'\n}\n```\n\n## IOutputProcessor Interface\n\nThe core abstraction for output processing.\n\n```typescript\ninterface IOutputProcessor {\n  // Processing\n  processLine(line: string): StreamMessage | null;\n  processBuffer(buffer: string): StreamMessage[];\n  \n  // Progress tracking\n  getProgress(processId: string): ExecutionProgress | null;\n  \n  // Events\n  onToolCall(handler: ToolCallHandler): void;\n  onFileChange(handler: FileChangeHandler): void;\n  onProgress(handler: ProgressHandler): void;\n  onError(handler: ErrorHandler): void;\n  onComplete(handler: CompleteHandler): void;\n  \n  // Extraction\n  extractMetadata(messages: StreamMessage[]): ExecutionMetadata;\n  extractToolCalls(messages: StreamMessage[]): ToolCall[];\n  extractFileChanges(messages: StreamMessage[]): string[];\n}\n\ntype ToolCallHandler = (processId: string, toolCall: ToolCall) => void;\ntype FileChangeHandler = (processId: string, filePath: string) => void;\ntype ProgressHandler = (processId: string, progress: ExecutionProgress) => void;\ntype ErrorHandler = (processId: string, error: string) => void;\ntype CompleteHandler = (processId: string, metadata: ExecutionMetadata) => void;\n\ninterface ExecutionMetadata {\n  toolsUsed: string[];\n  filesChanged: string[];\n  tokensUsed: number;\n  cost: number;\n  duration: number;\n}\n```\n\n## StreamJsonProcessor Implementation\n\nParses Claude Code's stream-json format in real-time.\n\n### Key Features\n\n1. **Line-by-line parsing**: Handle incomplete JSON gracefully\n2. **Event emission**: Notify listeners on key events\n3. **Progress tracking**: Build execution progress in real-time\n4. **Metadata extraction**: Extract structured data from messages\n5. **Error handling**: Gracefully handle malformed JSON\n\n### Implementation Pattern\n\n```typescript\nclass StreamJsonProcessor implements IOutputProcessor {\n  private progressTracking = new Map<string, ExecutionProgress>();\n  \n  private toolCallHandlers: ToolCallHandler[] = [];\n  private fileChangeHandlers: FileChangeHandler[] = [];\n  private progressHandlers: ProgressHandler[] = [];\n  private errorHandlers: ErrorHandler[] = [];\n  private completeHandlers: CompleteHandler[] = [];\n  \n  private currentProcessId?: string;\n  \n  constructor(private options: OutputProcessingOptions = {}) {\n    this.options = {\n      format: 'stream-json',\n      captureToolCalls: true,\n      captureFileChanges: true,\n      captureErrors: true,\n      emitProgressEvents: true,\n      progressInterval: 1000,\n      maxBufferSize: 10000,\n      lineSeparator: '\\n',\n      ...options,\n    };\n  }\n\n  processLine(line: string): StreamMessage | null {\n    if (!line.trim()) return null;\n    \n    try {\n      const data = JSON.parse(line);\n      const message: StreamMessage = {\n        type: this.detectMessageType(data),\n        timestamp: new Date(),\n        raw: line,\n        data,\n      };\n      \n      // Process message\n      this.handleMessage(message);\n      \n      return message;\n    } catch (error) {\n      // Not valid JSON, might be plain text\n      return {\n        type: 'unknown',\n        timestamp: new Date(),\n        raw: line,\n        data: { text: line },\n      };\n    }\n  }\n\n  processBuffer(buffer: string): StreamMessage[] {\n    const lines = buffer.split(this.options.lineSeparator!);\n    const messages: StreamMessage[] = [];\n    \n    for (const line of lines) {\n      const message = this.processLine(line);\n      if (message) {\n        messages.push(message);\n      }\n    }\n    \n    return messages;\n  }\n\n  private detectMessageType(data: any): MessageType {\n    if (data.type === 'user') return 'user';\n    if (data.type === 'assistant') return 'assistant';\n    if (data.type === 'result') return 'result';\n    if (data.type === 'error') return 'error';\n    \n    // Check for tool use/result in message content\n    if (data.message?.content) {\n      const content = Array.isArray(data.message.content)\n        ? data.message.content[0]\n        : data.message.content;\n      \n      if (content.type === 'tool_use') return 'tool_use';\n      if (content.type === 'tool_result') return 'tool_result';\n    }\n    \n    return 'unknown';\n  }\n\n  private handleMessage(message: StreamMessage): void {\n    if (!this.currentProcessId) return;\n    \n    const progress = this.getOrCreateProgress(this.currentProcessId);\n    progress.lastUpdate = new Date();\n    \n    switch (message.type) {\n      case 'assistant':\n        this.handleAssistantMessage(message, progress);\n        break;\n      case 'tool_use':\n        this.handleToolUse(message, progress);\n        break;\n      case 'tool_result':\n        this.handleToolResult(message, progress);\n        break;\n      case 'result':\n        this.handleResult(message, progress);\n        break;\n      case 'error':\n        this.handleError(message, progress);\n        break;\n    }\n    \n    // Emit progress event\n    if (this.options.emitProgressEvents) {\n      this.emitProgress(this.currentProcessId, progress);\n    }\n  }\n\n  private handleAssistantMessage(\n    message: StreamMessage,\n    progress: ExecutionProgress\n  ): void {\n    const { data } = message;\n    \n    if (!data.message?.content) return;\n    \n    const contents = Array.isArray(data.message.content)\n      ? data.message.content\n      : [data.message.content];\n    \n    for (const content of contents) {\n      if (content.type === 'tool_use') {\n        const toolCall: ToolCall = {\n          id: content.id,\n          name: content.name,\n          input: content.input,\n          timestamp: message.timestamp,\n        };\n        \n        progress.toolCalls.push(toolCall);\n        \n        // Update current activity\n        progress.currentActivity = `Using tool: ${toolCall.name}`;\n        \n        // Track file changes\n        if (\n          this.options.captureFileChanges &&\n          (content.name === 'Write' || content.name === 'Edit')\n        ) {\n          const filePath = content.input.file_path;\n          if (filePath && !progress.filesChanged.includes(filePath)) {\n            progress.filesChanged.push(filePath);\n            \n            // Emit file change event\n            for (const handler of this.fileChangeHandlers) {\n              handler(progress.processId, filePath);\n            }\n          }\n        }\n        \n        // Emit tool call event\n        if (this.options.captureToolCalls) {\n          for (const handler of this.toolCallHandlers) {\n            handler(progress.processId, toolCall);\n          }\n        }\n      }\n    }\n  }\n\n  private handleToolUse(\n    message: StreamMessage,\n    progress: ExecutionProgress\n  ): void {\n    // Similar to handleAssistantMessage tool_use handling\n    const { data } = message;\n    \n    const toolCall: ToolCall = {\n      id: data.id || generateId('tool'),\n      name: data.name,\n      input: data.input,\n      timestamp: message.timestamp,\n    };\n    \n    progress.toolCalls.push(toolCall);\n    progress.currentActivity = `Using tool: ${toolCall.name}`;\n  }\n\n  private handleToolResult(\n    message: StreamMessage,\n    progress: ExecutionProgress\n  ): void {\n    const { data } = message;\n    \n    const result: ToolResult = {\n      toolCallId: data.tool_use_id || data.id,\n      success: !data.is_error,\n      output: data.content,\n      error: data.is_error ? data.content : undefined,\n      timestamp: message.timestamp,\n    };\n    \n    progress.toolResults.push(result);\n  }\n\n  private handleResult(\n    message: StreamMessage,\n    progress: ExecutionProgress\n  ): void {\n    const { data } = message;\n    \n    // Extract usage information\n    if (data.usage) {\n      progress.usage = {\n        inputTokens: data.usage.input_tokens || 0,\n        outputTokens: data.usage.output_tokens || 0,\n        totalTokens: data.usage.total_tokens || 0,\n        cost: this.calculateCost(data.usage),\n      };\n    }\n    \n    // Emit complete event\n    const metadata = this.buildMetadata(progress);\n    for (const handler of this.completeHandlers) {\n      handler(progress.processId, metadata);\n    }\n  }\n\n  private handleError(\n    message: StreamMessage,\n    progress: ExecutionProgress\n  ): void {\n    const { data } = message;\n    const error = data.error?.message || data.message || 'Unknown error';\n    \n    if (this.options.captureErrors) {\n      progress.errors.push(error);\n      \n      // Emit error event\n      for (const handler of this.errorHandlers) {\n        handler(progress.processId, error);\n      }\n    }\n  }\n\n  private getOrCreateProgress(processId: string): ExecutionProgress {\n    let progress = this.progressTracking.get(processId);\n    \n    if (!progress) {\n      progress = {\n        processId,\n        startedAt: new Date(),\n        lastUpdate: new Date(),\n        toolCalls: [],\n        toolResults: [],\n        filesChanged: [],\n        errors: [],\n      };\n      this.progressTracking.set(processId, progress);\n    }\n    \n    return progress;\n  }\n\n  private emitProgress(processId: string, progress: ExecutionProgress): void {\n    for (const handler of this.progressHandlers) {\n      handler(processId, progress);\n    }\n  }\n\n  private buildMetadata(progress: ExecutionProgress): ExecutionMetadata {\n    const toolsUsed = Array.from(\n      new Set(progress.toolCalls.map(tc => tc.name))\n    );\n    \n    const duration = progress.lastUpdate.getTime() - progress.startedAt.getTime();\n    \n    return {\n      toolsUsed,\n      filesChanged: progress.filesChanged,\n      tokensUsed: progress.usage?.totalTokens || 0,\n      cost: progress.usage?.cost || 0,\n      duration,\n    };\n  }\n\n  private calculateCost(usage: any): number {\n    // Simplified cost calculation\n    // Claude Sonnet pricing (example)\n    const inputCostPer1M = 3.00;\n    const outputCostPer1M = 15.00;\n    \n    const inputCost = (usage.input_tokens / 1000000) * inputCostPer1M;\n    const outputCost = (usage.output_tokens / 1000000) * outputCostPer1M;\n    \n    return inputCost + outputCost;\n  }\n\n  getProgress(processId: string): ExecutionProgress | null {\n    return this.progressTracking.get(processId) || null;\n  }\n\n  extractMetadata(messages: StreamMessage[]): ExecutionMetadata {\n    const toolCalls = this.extractToolCalls(messages);\n    const filesChanged = this.extractFileChanges(messages);\n    \n    let usage = { inputTokens: 0, outputTokens: 0, totalTokens: 0, cost: 0 };\n    \n    for (const message of messages) {\n      if (message.type === 'result' && message.data.usage) {\n        usage = {\n          inputTokens: message.data.usage.input_tokens || 0,\n          outputTokens: message.data.usage.output_tokens || 0,\n          totalTokens: message.data.usage.total_tokens || 0,\n          cost: this.calculateCost(message.data.usage),\n        };\n      }\n    }\n    \n    const toolsUsed = Array.from(new Set(toolCalls.map(tc => tc.name)));\n    \n    return {\n      toolsUsed,\n      filesChanged,\n      tokensUsed: usage.totalTokens,\n      cost: usage.cost,\n      duration: 0, // Would need start/end times\n    };\n  }\n\n  extractToolCalls(messages: StreamMessage[]): ToolCall[] {\n    const toolCalls: ToolCall[] = [];\n    \n    for (const message of messages) {\n      if (message.type === 'assistant' && message.data.message?.content) {\n        const contents = Array.isArray(message.data.message.content)\n          ? message.data.message.content\n          : [message.data.message.content];\n        \n        for (const content of contents) {\n          if (content.type === 'tool_use') {\n            toolCalls.push({\n              id: content.id,\n              name: content.name,\n              input: content.input,\n              timestamp: message.timestamp,\n            });\n          }\n        }\n      }\n    }\n    \n    return toolCalls;\n  }\n\n  extractFileChanges(messages: StreamMessage[]): string[] {\n    const files = new Set<string>();\n    const toolCalls = this.extractToolCalls(messages);\n    \n    for (const toolCall of toolCalls) {\n      if (toolCall.name === 'Write' || toolCall.name === 'Edit') {\n        const filePath = toolCall.input.file_path;\n        if (filePath) {\n          files.add(filePath);\n        }\n      }\n    }\n    \n    return Array.from(files);\n  }\n\n  // Event registration\n  onToolCall(handler: ToolCallHandler): void {\n    this.toolCallHandlers.push(handler);\n  }\n\n  onFileChange(handler: FileChangeHandler): void {\n    this.fileChangeHandlers.push(handler);\n  }\n\n  onProgress(handler: ProgressHandler): void {\n    this.progressHandlers.push(handler);\n  }\n\n  onError(handler: ErrorHandler): void {\n    this.errorHandlers.push(handler);\n  }\n\n  onComplete(handler: CompleteHandler): void {\n    this.completeHandlers.push(handler);\n  }\n\n  // Set current process for tracking\n  setCurrentProcess(processId: string): void {\n    this.currentProcessId = processId;\n  }\n}\n```\n\n## Usage Example\n\n```typescript\n// Create processor\nconst processor = new StreamJsonProcessor({\n  format: 'stream-json',\n  captureToolCalls: true,\n  captureFileChanges: true,\n  emitProgressEvents: true,\n});\n\n// Set up event listeners\nprocessor.onToolCall((processId, toolCall) => {\n  console.log(`[${processId}] Tool: ${toolCall.name}`, toolCall.input);\n});\n\nprocessor.onFileChange((processId, filePath) => {\n  console.log(`[${processId}] File changed: ${filePath}`);\n});\n\nprocessor.onProgress((processId, progress) => {\n  console.log(`[${processId}] Progress:`, {\n    toolCalls: progress.toolCalls.length,\n    filesChanged: progress.filesChanged.length,\n    activity: progress.currentActivity,\n  });\n});\n\nprocessor.onComplete((processId, metadata) => {\n  console.log(`[${processId}] Complete:`, metadata);\n});\n\n// Integrate with process manager\nconst processManager = new SimpleProcessManager();\nconst process = await processManager.acquireProcess({\n  claudePath: 'claude',\n  workDir: '/path/to/project',\n  args: {\n    print: true,\n    outputFormat: 'stream-json',\n    dangerouslySkipPermissions: true,\n  },\n});\n\nprocessor.setCurrentProcess(process.id);\n\n// Process output as it streams\nprocessManager.onOutput(process.id, (data, type) => {\n  if (type === 'stdout') {\n    const lines = data.toString().split('\\n');\n    for (const line of lines) {\n      processor.processLine(line);\n    }\n  }\n});\n\n// Send input\nawait processManager.sendInput(process.id, 'Fix the bug in auth.ts\\n');\n```\n\n## Testing Strategy\n\n### Unit Tests\n\n1. **JSON parsing**\n   - Parses valid stream-json lines\n   - Handles malformed JSON gracefully\n   - Detects message types correctly\n\n2. **Metadata extraction**\n   - Extracts tool calls from messages\n   - Extracts file changes from Write/Edit tools\n   - Calculates usage and cost correctly\n\n3. **Event emission**\n   - Emits tool call events\n   - Emits file change events\n   - Emits progress events at interval\n\n### Integration Tests\n\n1. **End-to-end processing**\n   - Process real Claude Code output\n   - Track progress accurately\n   - Extract complete metadata\n\n2. **Real-time streaming**\n   - Handle partial lines\n   - Process incomplete JSON\n   - Buffer management\n\n## Future Enhancements\n\n1. **Format adapters** - Support text, JSON formats\n2. **Filtering** - Filter events by type/pattern\n3. **Aggregation** - Aggregate metrics across processes\n4. **Persistence** - Store output for replay\n5. **Compression** - Compress large outputs\n\n## File Structure\n\n```\nserver/src/execution/output/\n├── types.ts                    # Core types (StreamMessage, etc.)\n├── processor.ts                # IOutputProcessor interface\n├── stream-json-processor.ts    # StreamJsonProcessor (start here)\n├── text-processor.ts           # TextProcessor (future)\n└── utils.ts                    # JSON parsing, cost calculation\n```\n\n## Implementation Checklist\n\n- [ ] Define core types\n- [ ] Define IOutputProcessor interface\n- [ ] Implement StreamJsonProcessor\n- [ ] Add line-by-line JSON parsing\n- [ ] Add message type detection\n- [ ] Add tool call extraction\n- [ ] Add file change tracking\n- [ ] Add progress tracking\n- [ ] Add event emission\n- [ ] Add metadata extraction\n- [ ] Write unit tests\n- [ ] Write integration tests\n\n## Related Specs\n\n- Execution System (root spec)\n- [[SPEC-003]] - Process Layer (integrates with)\n- [[SPEC-004]] - Engine Layer\n- [[SPEC-005]] - Task Execution Layer\n- [[SPEC-006]] - Workflow Layer\n","priority":0,"archived":0,"archived_at":null,"created_at":"2025-10-28 07:45:45","updated_at":"2025-11-03T03:10:12.592Z","parent_id":null,"parent_uuid":null,"relationships":[{"from":"SPEC-007","from_type":"spec","to":"SPEC-003","to_type":"spec","type":"references"},{"from":"SPEC-007","from_type":"spec","to":"SPEC-004","to_type":"spec","type":"references"},{"from":"SPEC-007","from_type":"spec","to":"SPEC-005","to_type":"spec","type":"references"},{"from":"SPEC-007","from_type":"spec","to":"SPEC-006","to_type":"spec","type":"references"}],"tags":["execution","layer-5","output-processing","parsing","streaming"]}
{"id":"SPEC-008","uuid":"1ece2c76-6874-4849-9dd4-1555b885ec88","title":"Inline Feedback Visualization for Spec Documents","file_path":"specs/inline_feedback_visualization_for_spec_documents.md","content":"\n# Inline Feedback Visualization for Spec Documents\n\n## Overview\n\nImplement a Google Docs-style feedback visualization system for spec documents that displays feedback inline with the document content or aligned in a side panel. This replaces the current separate column approach with a more integrated, contextual feedback experience.\n\n## Goals\n\n- **Contextual Feedback**: Show feedback aligned with the specific lines/sections it references\n- **Visual Clarity**: Use highlights and indicators to show where feedback exists\n- **Flexible Layout**: Support both general document comments and line-specific feedback\n- **Minimal Dependencies**: Leverage existing Tiptap editor without paid extensions\n- **Responsive Design**: Work across different screen sizes\n\n## Current State\n\nCurrently, `SpecDetailPage` displays feedback in a completely separate `SpecFeedbackPanel` column with no visual connection to the referenced content. Users must manually correlate feedback with document locations using line numbers.\n\n**Key files:**\n- `frontend/src/pages/SpecDetailPage.tsx` - Main spec view page\n- `frontend/src/components/specs/SpecFeedbackPanel.tsx` - Current feedback panel\n- `frontend/src/components/specs/TiptapEditor.tsx` - Rich text editor\n- `frontend/src/components/specs/SpecViewer.tsx` - Markdown source view\n\n## Proposed Design\n\n### Hybrid Approach: Margin Indicators + Aligned Side Panel\n\n```\n┌───────────────────────────────────────┬─────────────────────┐\n│                Spec Content           │ Feedback Panel      │\n│                                       │                     │\n│ # Introduction                        │ 💭 General Comments │\n│ This spec... [💬] ← highlighted       │   \"Overall good\"    │\n│                                       │                     │\n│ ## Architecture                       │ 💬 Line 6          │\n│ System design...                      │   \"Missing details\" │\n│ Implementation [💬] ← highlighted     │   ↑ aligned        │\n│                                       │                     │\n└───────────────────────────────────────┴─────────────────────┘\n```\n\n### Key Features\n\n1. **Inline Indicators**: Show 💬 emoji or icon at feedback locations\n2. **Text Highlighting**: Subtle background color on referenced text\n3. **Aligned Comments**: Side panel comments vertically aligned with their anchors\n4. **General Comments**: Unanchored feedback shown at top of panel\n5. **Interactive**: Click indicator or highlight to focus the comment\n\n## Technical Approach\n\n### Architecture Decision: Free Tiptap Features Only\n\nSince Tiptap's Collaboration and Comments extensions are paid features, we'll use:\n\n- ✅ **Custom Marks** - For text highlighting (free)\n- ✅ **ProseMirror Decorations** - For overlay indicators (free)\n- ✅ **Native DOM APIs** - For position tracking (`getBoundingClientRect`)\n- ✅ **React State** - For coordinating editor and panel\n\n### Component Structure\n\n```typescript\nSpecDetailPage\n├── SpecEditor (with feedback extensions)\n│   ├── TiptapEditor\n│   │   ├── FeedbackMark (highlight text)\n│   │   └── FeedbackDecorations (add indicators)\n│   └── Feedback indicators overlaid\n└── AlignedFeedbackPanel\n    ├── GeneralComments (no anchor)\n    └── AnchoredComments (positioned absolutely)\n```\n\n### Key Components\n\n1. **FeedbackMark** - Custom Tiptap mark extension for highlighting text with feedback\n2. **FeedbackDecorations** - ProseMirror plugin for adding clickable indicators\n3. **useFeedbackPositions** - React hook for tracking vertical positions\n4. **AlignedFeedbackPanel** - Component displaying comments aligned with document\n\n## Implementation Phases\n\n### Phase 1: Basic Infrastructure\n\n**Tasks:**\n- Create `FeedbackMark` Tiptap extension\n- Create `useFeedbackPositions` hook\n- Create `AlignedFeedbackPanel` component\n- Update `SpecDetailPage` layout for side-by-side view\n- Implement basic position tracking with scroll sync\n\n**Files to create:**\n- `frontend/src/components/specs/extensions/FeedbackMark.ts`\n- `frontend/src/hooks/useFeedbackPositions.ts`\n- `frontend/src/components/specs/AlignedFeedbackPanel.tsx`\n\n**Files to modify:**\n- `frontend/src/components/specs/TiptapEditor.tsx`\n- `frontend/src/pages/SpecDetailPage.tsx`\n\n**Deliverable**: Feedback panel shows comments aligned with rough positions\n\n### Phase 2: Decorations & Indicators\n\n**Tasks:**\n- Implement `FeedbackDecorations` extension\n- Add clickable indicators (💬) in document margins\n- Wire up click handlers to focus comments\n- Add hover states for highlights\n- Implement scroll-to-comment functionality\n\n**Files to create:**\n- `frontend/src/components/specs/extensions/FeedbackDecorations.ts`\n\n**Deliverable**: Visual indicators in document, clickable to show comments\n\n### Phase 3: Polish & Edge Cases\n\n**Tasks:**\n- Handle feedback without anchors (general comments)\n- Handle stale anchors (content changed, line moved)\n- Optimize position updates (debouncing, throttling)\n- Add transitions/animations for smooth UX\n- Test with long documents and many comments\n- Mobile responsive behavior (stack instead of side-by-side)\n\n**Deliverable**: Production-ready feature with edge cases handled\n\n### Phase 4: Advanced Features (Optional)\n\n**Tasks:**\n- Filter comments by type in side panel\n- Show/hide resolved comments\n- Keyboard navigation between comments\n- Minimap showing comment distribution\n- Export with comment indicators\n\n## Technical Considerations\n\n### Anchor Resolution\n\nWhen feedback has an anchor, resolve the position using this priority:\n\n1. **Exact text match**: Search for `anchor.text_snippet` in document\n2. **Line number**: Fall back to `anchor.line_number` if text moved\n3. **Section heading**: Use `anchor.section_heading` as last resort\n4. **Mark as stale**: If none match, show in \"Stale Comments\" section\n\n### Performance\n\n- **Debounce position updates**: 100ms delay on scroll/resize\n- **Memoize calculations**: Use `useMemo` for filtered feedback lists\n- **Virtual scrolling**: If >50 comments, consider virtualization\n- **Lazy decorations**: Only create decorations for visible viewport\n\n### View Modes\n\nSupport both Formatted (Tiptap) and Markdown views:\n\n- **Formatted**: Use Tiptap marks and decorations\n- **Markdown**: Show indicators in line number gutter\n\n## Dependencies\n\n**No new dependencies required** - uses existing:\n- `@tiptap/react` (already installed)\n- `@tiptap/core` (already installed)\n- Native browser APIs (`getBoundingClientRect`, `IntersectionObserver`)\n- React hooks (`useState`, `useEffect`, `useRef`)\n\n**Optional lightweight additions** (if needed):\n- `floating-ui` (7kb) - For smarter popover positioning\n- `react-intersection-observer` (3.5kb) - For performance optimization\n\n## Success Metrics\n\n- Feedback is visually connected to document locations\n- Users can quickly identify which content has feedback\n- Position sync is smooth and performant (no jank on scroll)\n- Works in both Formatted and Markdown view modes\n- Mobile experience is usable (stacked or simplified layout)\n","priority":1,"archived":0,"archived_at":null,"created_at":"2025-10-29 10:10:27","updated_at":"2025-11-03T03:10:12.588Z","parent_id":null,"parent_uuid":null,"relationships":[],"tags":["feedback","frontend","tiptap","ui/ux"]}
{"id":"SPEC-009","uuid":"8ef5d62f-6681-4207-a088-230caae2e884","title":"AG-UI Protocol Integration","file_path":"specs/ag_ui_protocol_integration.md","content":"# AG-UI Protocol Integration Specification\n\n## Overview\n\nThis specification details the integration of the AG-UI (Agent-User Interaction) Protocol into the sudocode execution system. AG-UI is a lightweight, event-based protocol that standardizes how AI agents connect to user-facing applications, enabling real-time streaming of agent execution state to frontend applications.\n\nThis spec builds on **SPEC-007 (Output Processing Layer)** which provides the foundation for parsing agent output into structured `StreamMessage` format. The AG-UI integration adds a second transformation layer that converts these generic messages into standardized AG-UI events.\n\n**Transformation Flow:**\n\n```\nRaw Agent Output → [SPEC-007] → StreamMessage → [SPEC-009] → AgUiEvent → SSE → Frontend\n                    OutputProcessor              AgUiAdapter\n```\n\nThe integration consists of three main layers:\n\n1. **AG-UI Adapter Layer**: Transforms `StreamMessage` (from SPEC-007) into standardized AG-UI events\n1. **SSE Transport Layer**: Streams AG-UI events to frontend via Server-Sent Events\n1. **Frontend Integration**: Consumes and displays AG-UI events in real-time\n\n## Design Goals\n\n1. **Standardized**: Use AG-UI's 17 event types for consistent agent communication\n1. **Real-time**: Stream events as they occur, not after completion\n1. **Multi-Agent Ready**: Support any AG-UI compatible agent (Claude Code, Cursor, etc.)\n1. **SSE-based**: Stream events via Server-Sent Events for simplicity and native browser support\n1. **Type-Safe**: Full TypeScript typing with Zod validation\n1. **Observable**: Complete visibility into agent execution lifecycle\n1. **Layered**: Clean separation between parsing (SPEC-007) and protocol transformation (SPEC-009)\n\n## Architecture\n\n```\n┌──────────────────────────────────────────────────────────────┐\n│                 Frontend (React)                             │\n├──────────────────────────────────────────────────────────────┤\n│                                                              │\n│  ┌────────────────────┐     ┌──────────────────────────┐   │\n│  │  useAgUiStream()   │────▶│  ExecutionMonitor        │   │\n│  │  Hook              │     │  Component               │   │\n│  └────────┬───────────┘     └──────────────────────────┘   │\n│           │                                                  │\n│           │ EventSource (SSE)                               │\n│           │                                                  │\n└───────────┼──────────────────────────────────────────────────┘\n            │\n            │ Server-Sent Events\n            ▼\n┌──────────────────────────────────────────────────────────────┐\n│            SSE Transport Layer (Server)                      │\n├──────────────────────────────────────────────────────────────┤\n│                                                              │\n│              ┌─────────────────────┐                        │\n│              │   SseTransport      │                        │\n│              │   (EventStream)     │                        │\n│              └─────────┬───────────┘                        │\n│                        │                                     │\n└────────────────────────┼────────────────────────────────────┘\n                         │\n                         │ AG-UI Events\n                         ▼\n┌──────────────────────────────────────────────────────────────┐\n│            AG-UI Adapter Layer (Server)                      │\n├──────────────────────────────────────────────────────────────┤\n│                                                              │\n│  ┌────────────────────────────────────────────────────────┐ │\n│  │         AgUiEventAdapter                               │ │\n│  │                                                        │ │\n│  │  Transforms StreamMessage → AgUiEvent                 │ │\n│  │                                                        │ │\n│  │  ┌──────────────┐  ┌──────────────┐  ┌─────────────┐ │ │\n│  │  │ Tool Call    │  │ Message      │  │ State       │ │ │\n│  │  │ Mapper       │  │ Mapper       │  │ Mapper      │ │ │\n│  │  └──────────────┘  └──────────────┘  └─────────────┘ │ │\n│  └────────────┬───────────────────────────────────────────┘ │\n│               │                                             │\n└───────────────┼─────────────────────────────────────────────┘\n                │\n                │ StreamMessage (SPEC-007)\n                ▼\n┌──────────────────────────────────────────────────────────────┐\n│     Output Processing Layer (SPEC-007)                       │\n├──────────────────────────────────────────────────────────────┤\n│                                                              │\n│  ┌────────────────────────────────────────────────────────┐ │\n│  │         StreamJsonProcessor                            │ │\n│  │                                                        │ │\n│  │  Parses Raw Output → StreamMessage                    │ │\n│  │                                                        │ │\n│  │  Types: assistant | tool_use | tool_result | error   │ │\n│  └────────────┬───────────────────────────────────────────┘ │\n│               │                                             │\n└───────────────┼─────────────────────────────────────────────┘\n                │\n                │ Raw stdout/stderr\n                ▼\n┌──────────────────────────────────────────────────────────────┐\n│     Process Layer (SPEC-003)                                 │\n├──────────────────────────────────────────────────────────────┤\n│  SimpleProcessManager │ LinearOrchestrator (SPEC-006)       │\n└──────────────────────────────────────────────────────────────┘\n```\n\n**Layer Responsibilities:**\n\n- **SPEC-003 (Process Layer)**: Spawns agent process, captures raw output\n- **SPEC-007 (Output Processing)**: Parses raw output into `StreamMessage` format\n- **SPEC-009 (AG-UI Adapter)**: Transforms `StreamMessage` into AG-UI events\n- **SSE Transport**: Broadcasts AG-UI events to connected clients\n- **Frontend**: Consumes and displays events in real-time\n\n## Part 1: AG-UI Adapter Layer\n\n### Core Types\n\n#### AG-UI Event Types Enum\n\n```typescript\nexport enum AgUiEventType {\n  // Lifecycle Events\n  RUN_STARTED = 'RUN_STARTED',\n  RUN_FINISHED = 'RUN_FINISHED',\n  RUN_ERROR = 'RUN_ERROR',\n  STEP_STARTED = 'STEP_STARTED',\n  STEP_FINISHED = 'STEP_FINISHED',\n\n  // Text Message Events\n  TEXT_MESSAGE_START = 'TEXT_MESSAGE_START',\n  TEXT_MESSAGE_CONTENT = 'TEXT_MESSAGE_CONTENT',\n  TEXT_MESSAGE_END = 'TEXT_MESSAGE_END',\n\n  // Tool Call Events\n  TOOL_CALL_START = 'TOOL_CALL_START',\n  TOOL_CALL_ARGS = 'TOOL_CALL_ARGS',\n  TOOL_CALL_END = 'TOOL_CALL_END',\n  TOOL_CALL_RESULT = 'TOOL_CALL_RESULT',\n\n  // State Management Events\n  STATE_SNAPSHOT = 'STATE_SNAPSHOT',\n  STATE_DELTA = 'STATE_DELTA',\n  MESSAGES_SNAPSHOT = 'MESSAGES_SNAPSHOT',\n\n  // Special Events\n  RAW = 'RAW',\n  CUSTOM = 'CUSTOM',\n}\n```\n\n#### Base Event Schema\n\n```typescript\nimport { z } from 'zod';\n\nexport const BaseEventSchema = z.object({\n  type: z.nativeEnum(AgUiEventType),\n  timestamp: z.number().optional(),\n  rawEvent: z.any().optional(),\n});\n\nexport type BaseEvent = z.infer<typeof BaseEventSchema>;\n```\n\n#### Lifecycle Event Schemas\n\n```typescript\n// RUN_STARTED\nexport const RunStartedEventSchema = BaseEventSchema.extend({\n  type: z.literal(AgUiEventType.RUN_STARTED),\n  runId: z.string(),\n  threadId: z.string().optional(),\n  workflowId: z.string().optional(),\n});\n\nexport type RunStartedEvent = z.infer<typeof RunStartedEventSchema>;\n\n// RUN_FINISHED\nexport const RunFinishedEventSchema = BaseEventSchema.extend({\n  type: z.literal(AgUiEventType.RUN_FINISHED),\n  runId: z.string(),\n  result: z.any().optional(),\n});\n\nexport type RunFinishedEvent = z.infer<typeof RunFinishedEventSchema>;\n\n// RUN_ERROR\nexport const RunErrorEventSchema = BaseEventSchema.extend({\n  type: z.literal(AgUiEventType.RUN_ERROR),\n  runId: z.string(),\n  error: z.object({\n    message: z.string(),\n    code: z.string().optional(),\n    stack: z.string().optional(),\n  }),\n});\n\nexport type RunErrorEvent = z.infer<typeof RunErrorEventSchema>;\n\n// STEP_STARTED\nexport const StepStartedEventSchema = BaseEventSchema.extend({\n  type: z.literal(AgUiEventType.STEP_STARTED),\n  runId: z.string(),\n  stepId: z.string(),\n  stepName: z.string(),\n});\n\nexport type StepStartedEvent = z.infer<typeof StepStartedEventSchema>;\n\n// STEP_FINISHED\nexport const StepFinishedEventSchema = BaseEventSchema.extend({\n  type: z.literal(AgUiEventType.STEP_FINISHED),\n  runId: z.string(),\n  stepId: z.string(),\n  status: z.enum(['success', 'error']),\n  output: z.any().optional(),\n});\n\nexport type StepFinishedEvent = z.infer<typeof StepFinishedEventSchema>;\n```\n\n#### Text Message Event Schemas\n\n```typescript\n// TEXT_MESSAGE_START\nexport const TextMessageStartEventSchema = BaseEventSchema.extend({\n  type: z.literal(AgUiEventType.TEXT_MESSAGE_START),\n  messageId: z.string(),\n  role: z.enum(['assistant', 'user', 'system']),\n});\n\nexport type TextMessageStartEvent = z.infer<typeof TextMessageStartEventSchema>;\n\n// TEXT_MESSAGE_CONTENT\nexport const TextMessageContentEventSchema = BaseEventSchema.extend({\n  type: z.literal(AgUiEventType.TEXT_MESSAGE_CONTENT),\n  messageId: z.string(),\n  delta: z.string(),\n});\n\nexport type TextMessageContentEvent = z.infer<typeof TextMessageContentEventSchema>;\n\n// TEXT_MESSAGE_END\nexport const TextMessageEndEventSchema = BaseEventSchema.extend({\n  type: z.literal(AgUiEventType.TEXT_MESSAGE_END),\n  messageId: z.string(),\n});\n\nexport type TextMessageEndEvent = z.infer<typeof TextMessageEndEventSchema>;\n```\n\n#### Tool Call Event Schemas\n\n```typescript\n// TOOL_CALL_START\nexport const ToolCallStartEventSchema = BaseEventSchema.extend({\n  type: z.literal(AgUiEventType.TOOL_CALL_START),\n  toolCallId: z.string(),\n  toolCallName: z.string(),\n  parentMessageId: z.string().optional(),\n});\n\nexport type ToolCallStartEvent = z.infer<typeof ToolCallStartEventSchema>;\n\n// TOOL_CALL_ARGS\nexport const ToolCallArgsEventSchema = BaseEventSchema.extend({\n  type: z.literal(AgUiEventType.TOOL_CALL_ARGS),\n  toolCallId: z.string(),\n  delta: z.string(), // JSON fragment\n});\n\nexport type ToolCallArgsEvent = z.infer<typeof ToolCallArgsEventSchema>;\n\n// TOOL_CALL_END\nexport const ToolCallEndEventSchema = BaseEventSchema.extend({\n  type: z.literal(AgUiEventType.TOOL_CALL_END),\n  toolCallId: z.string(),\n});\n\nexport type ToolCallEndEvent = z.infer<typeof ToolCallEndEventSchema>;\n\n// TOOL_CALL_RESULT\nexport const ToolCallResultEventSchema = BaseEventSchema.extend({\n  type: z.literal(AgUiEventType.TOOL_CALL_RESULT),\n  messageId: z.string(),\n  toolCallId: z.string(),\n  content: z.string(),\n  role: z.literal('tool').optional(),\n});\n\nexport type ToolCallResultEvent = z.infer<typeof ToolCallResultEventSchema>;\n```\n\n#### State Management Event Schemas\n\n```typescript\n// STATE_SNAPSHOT\nexport const StateSnapshotEventSchema = BaseEventSchema.extend({\n  type: z.literal(AgUiEventType.STATE_SNAPSHOT),\n  runId: z.string(),\n  state: z.record(z.any()),\n});\n\nexport type StateSnapshotEvent = z.infer<typeof StateSnapshotEventSchema>;\n\n// STATE_DELTA (JSON Patch RFC 6902)\nexport const JsonPatchOperationSchema = z.object({\n  op: z.enum(['add', 'remove', 'replace', 'move', 'copy', 'test']),\n  path: z.string(),\n  value: z.any().optional(),\n  from: z.string().optional(),\n});\n\nexport const StateDeltaEventSchema = BaseEventSchema.extend({\n  type: z.literal(AgUiEventType.STATE_DELTA),\n  runId: z.string(),\n  delta: z.array(JsonPatchOperationSchema),\n});\n\nexport type StateDeltaEvent = z.infer<typeof StateDeltaEventSchema>;\n\n// MESSAGES_SNAPSHOT\nexport const MessageSchema = z.object({\n  id: z.string(),\n  role: z.enum(['user', 'assistant', 'system', 'tool']),\n  content: z.string(),\n  timestamp: z.string().optional(),\n});\n\nexport const MessagesSnapshotEventSchema = BaseEventSchema.extend({\n  type: z.literal(AgUiEventType.MESSAGES_SNAPSHOT),\n  runId: z.string(),\n  messages: z.array(MessageSchema),\n});\n\nexport type MessagesSnapshotEvent = z.infer<typeof MessagesSnapshotEventSchema>;\n```\n\n#### Custom and Raw Event Schemas\n\n```typescript\n// RAW\nexport const RawEventSchema = BaseEventSchema.extend({\n  type: z.literal(AgUiEventType.RAW),\n  event: z.any(),\n  source: z.string().optional(),\n});\n\nexport type RawEvent = z.infer<typeof RawEventSchema>;\n\n// CUSTOM\nexport const CustomEventSchema = BaseEventSchema.extend({\n  type: z.literal(AgUiEventType.CUSTOM),\n  name: z.string(),\n  value: z.any(),\n});\n\nexport type CustomEvent = z.infer<typeof CustomEventSchema>;\n```\n\n#### Discriminated Union\n\n```typescript\nexport const AgUiEventSchema = z.discriminatedUnion('type', [\n  RunStartedEventSchema,\n  RunFinishedEventSchema,\n  RunErrorEventSchema,\n  StepStartedEventSchema,\n  StepFinishedEventSchema,\n  TextMessageStartEventSchema,\n  TextMessageContentEventSchema,\n  TextMessageEndEventSchema,\n  ToolCallStartEventSchema,\n  ToolCallArgsEventSchema,\n  ToolCallEndEventSchema,\n  ToolCallResultEventSchema,\n  StateSnapshotEventSchema,\n  StateDeltaEventSchema,\n  MessagesSnapshotEventSchema,\n  RawEventSchema,\n  CustomEventSchema,\n]);\n\nexport type AgUiEvent = z.infer<typeof AgUiEventSchema>;\n```\n\n### AG-UI Event Adapter Implementation\n\nThe `AgUiEventAdapter` is the core component that transforms `StreamMessage` objects (from SPEC-007's `OutputProcessor`) into AG-UI events. It subscribes to the output processor's event stream and maps each message type to the appropriate AG-UI event(s).\n\n**Key Principle**: This adapter is protocol-agnostic at its input (works with any `StreamMessage` source) and protocol-specific at its output (emits AG-UI events).\n\n```typescript\n// server/src/execution/output/ag-ui-adapter.ts\nimport { StreamMessage, ExecutionProgress } from './types.js';\nimport { AgUiEvent, AgUiEventType } from './ag-ui-types.js';\nimport { generateId } from '../utils.js';\n\nexport class AgUiEventAdapter {\n  private listeners: Array<(event: AgUiEvent) => void> = [];\n  private messageBuffers = new Map<string, string[]>();\n  private toolCallBuffers = new Map<string, string>();\n\n  constructor() {}\n\n  /**\n   * Transform a StreamMessage from Claude Code into AG-UI events\n   */\n  transformStreamMessage(\n    message: StreamMessage,\n    processId: string\n  ): AgUiEvent[] {\n    const events: AgUiEvent[] = [];\n\n    switch (message.type) {\n      case 'assistant':\n        events.push(...this.handleAssistantMessage(message, processId));\n        break;\n      case 'tool_use':\n        events.push(...this.handleToolUse(message, processId));\n        break;\n      case 'tool_result':\n        events.push(...this.handleToolResult(message, processId));\n        break;\n      case 'result':\n        events.push(...this.handleResult(message, processId));\n        break;\n      case 'error':\n        events.push(...this.handleError(message, processId));\n        break;\n    }\n\n    // Emit all events\n    events.forEach(event => this.emit(event));\n\n    return events;\n  }\n\n  /**\n   * Handle Claude assistant messages\n   */\n  private handleAssistantMessage(\n    message: StreamMessage,\n    processId: string\n  ): AgUiEvent[] {\n    const events: AgUiEvent[] = [];\n    const contents = Array.isArray(message.data.message?.content)\n      ? message.data.message.content\n      : [message.data.message?.content];\n\n    for (const content of contents) {\n      if (!content) continue;\n\n      if (content.type === 'text') {\n        // Text message: START → CONTENT → END\n        const messageId = generateId('msg');\n\n        events.push({\n          type: AgUiEventType.TEXT_MESSAGE_START,\n          messageId,\n          role: 'assistant',\n          timestamp: Date.now(),\n        });\n\n        events.push({\n          type: AgUiEventType.TEXT_MESSAGE_CONTENT,\n          messageId,\n          delta: content.text,\n          timestamp: Date.now(),\n        });\n\n        events.push({\n          type: AgUiEventType.TEXT_MESSAGE_END,\n          messageId,\n          timestamp: Date.now(),\n        });\n      } else if (content.type === 'tool_use') {\n        // Tool call: START → ARGS → END\n        const toolCallId = content.id || generateId('tool');\n\n        events.push({\n          type: AgUiEventType.TOOL_CALL_START,\n          toolCallId,\n          toolCallName: content.name,\n          timestamp: Date.now(),\n        });\n\n        // Serialize arguments as JSON\n        const argsJson = JSON.stringify(content.input);\n        events.push({\n          type: AgUiEventType.TOOL_CALL_ARGS,\n          toolCallId,\n          delta: argsJson,\n          timestamp: Date.now(),\n        });\n\n        events.push({\n          type: AgUiEventType.TOOL_CALL_END,\n          toolCallId,\n          timestamp: Date.now(),\n        });\n      }\n    }\n\n    return events;\n  }\n\n  /**\n   * Handle tool usage events\n   */\n  private handleToolUse(\n    message: StreamMessage,\n    processId: string\n  ): AgUiEvent[] {\n    const toolCallId = message.data.id || generateId('tool');\n\n    return [\n      {\n        type: AgUiEventType.TOOL_CALL_START,\n        toolCallId,\n        toolCallName: message.data.name,\n        timestamp: Date.now(),\n      },\n      {\n        type: AgUiEventType.TOOL_CALL_ARGS,\n        toolCallId,\n        delta: JSON.stringify(message.data.input),\n        timestamp: Date.now(),\n      },\n      {\n        type: AgUiEventType.TOOL_CALL_END,\n        toolCallId,\n        timestamp: Date.now(),\n      },\n    ];\n  }\n\n  /**\n   * Handle tool result events\n   */\n  private handleToolResult(\n    message: StreamMessage,\n    processId: string\n  ): AgUiEvent[] {\n    const messageId = generateId('msg');\n    const toolCallId = message.data.tool_use_id || message.data.id;\n\n    return [\n      {\n        type: AgUiEventType.TOOL_CALL_RESULT,\n        messageId,\n        toolCallId,\n        content: JSON.stringify(message.data.content),\n        role: 'tool',\n        timestamp: Date.now(),\n      },\n    ];\n  }\n\n  /**\n   * Handle execution result (final usage stats)\n   */\n  private handleResult(\n    message: StreamMessage,\n    processId: string\n  ): AgUiEvent[] {\n    // Could emit a CUSTOM event with usage stats\n    return [\n      {\n        type: AgUiEventType.CUSTOM,\n        name: 'usage_stats',\n        value: {\n          usage: message.data.usage,\n          cost: this.calculateCost(message.data.usage),\n        },\n        timestamp: Date.now(),\n      },\n    ];\n  }\n\n  /**\n   * Handle error events\n   */\n  private handleError(\n    message: StreamMessage,\n    processId: string\n  ): AgUiEvent[] {\n    const error = message.data.error || message.data;\n\n    return [\n      {\n        type: AgUiEventType.RUN_ERROR,\n        runId: processId,\n        error: {\n          message: error.message || error.toString(),\n          code: error.code,\n          stack: error.stack,\n        },\n        timestamp: Date.now(),\n      },\n    ];\n  }\n\n  /**\n   * Emit progress update as STATE_DELTA\n   */\n  emitProgressDelta(progress: ExecutionProgress): void {\n    const event: AgUiEvent = {\n      type: AgUiEventType.STATE_DELTA,\n      runId: progress.processId,\n      delta: [\n        {\n          op: 'replace',\n          path: '/progress',\n          value: {\n            toolCalls: progress.toolCalls.length,\n            filesChanged: progress.filesChanged,\n            currentActivity: progress.currentActivity,\n          },\n        },\n      ],\n      timestamp: Date.now(),\n    };\n\n    this.emit(event);\n  }\n\n  /**\n   * Emit state snapshot\n   */\n  emitStateSnapshot(runId: string, state: Record<string, any>): void {\n    const event: AgUiEvent = {\n      type: AgUiEventType.STATE_SNAPSHOT,\n      runId,\n      state,\n      timestamp: Date.now(),\n    };\n\n    this.emit(event);\n  }\n\n  /**\n   * Register event listener\n   */\n  onEvent(listener: (event: AgUiEvent) => void): void {\n    this.listeners.push(listener);\n  }\n\n  /**\n   * Remove event listener\n   */\n  offEvent(listener: (event: AgUiEvent) => void): void {\n    const index = this.listeners.indexOf(listener);\n    if (index >= 0) {\n      this.listeners.splice(index, 1);\n    }\n  }\n\n  /**\n   * Emit event to all listeners\n   */\n  private emit(event: AgUiEvent): void {\n    this.listeners.forEach(listener => {\n      try {\n        listener(event);\n      } catch (error) {\n        console.error('Error in AG-UI event listener:', error);\n      }\n    });\n  }\n\n  private calculateCost(usage: any): number {\n    // Simplified cost calculation\n    const inputCostPer1M = 3.0;\n    const outputCostPer1M = 15.0;\n\n    const inputCost = (usage.input_tokens / 1000000) * inputCostPer1M;\n    const outputCost = (usage.output_tokens / 1000000) * outputCostPer1M;\n\n    return inputCost + outputCost;\n  }\n}\n```\n\n### Integration with SPEC-007 Output Processor\n\nThe AgUiAdapter integrates with SPEC-007's `StreamJsonProcessor` by subscribing to its output messages. This creates a clean pipeline where SPEC-007 handles parsing and SPEC-009 handles protocol transformation.\n\n**Pattern**: Wire the output processor's message events to the AG-UI adapter's transformation method.\n\n```typescript\n// server/src/execution/output/ag-ui-integration.ts\nimport { StreamJsonProcessor } from './stream-json-processor.js';\nimport { AgUiEventAdapter } from './ag-ui-adapter.js';\n\n/**\n * Wire SPEC-007's output processor to SPEC-009's AG-UI adapter\n */\nexport function createAgUiPipeline(\n  processor: StreamJsonProcessor,\n  adapter: AgUiEventAdapter,\n  processId: string\n): void {\n  // Subscribe to processor's message stream\n  // Note: This requires adding a message event to StreamJsonProcessor\n  processor.onMessage?.((message: StreamMessage) => {\n    adapter.transformStreamMessage(message, processId);\n  });\n\n  // Alternative: If StreamJsonProcessor doesn't have onMessage,\n  // wrap its processLine method\n  const originalProcessLine = processor.processLine.bind(processor);\n  processor.processLine = (line: string) => {\n    const message = originalProcessLine(line);\n    if (message) {\n      adapter.transformStreamMessage(message, processId);\n    }\n    return message;\n  };\n}\n\n/**\n * Factory function to create a complete AG-UI pipeline\n */\nexport function createAgUiSystem(processId: string) {\n  const processor = new StreamJsonProcessor({\n    format: 'stream-json',\n    captureToolCalls: true,\n    captureFileChanges: true,\n    emitProgressEvents: true,\n  });\n\n  const adapter = new AgUiEventAdapter();\n\n  // Wire them together\n  createAgUiPipeline(processor, adapter, processId);\n\n  return { processor, adapter };\n}\n```\n\n**Usage Example:**\n\n```typescript\n// Create the pipeline\nconst { processor, adapter } = createAgUiSystem('process-123');\n\n// Connect adapter to SSE transport\nconst sseTransport = new SseTransport();\nadapter.onEvent(event => {\n  sseTransport.broadcastToRun('process-123', event);\n});\n\n// Feed raw output from process manager\nprocessManager.onOutput('process-123', (data, type) => {\n  if (type === 'stdout') {\n    const lines = data.toString().split('\\n');\n    for (const line of lines) {\n      processor.processLine(line); // → StreamMessage → AgUiEvent → SSE\n    }\n  }\n});\n```\n\n### Integration with LinearOrchestrator\n\n```typescript\n// server/src/execution/workflow/linear-orchestrator.ts (MODIFIED)\nimport { AgUiEventAdapter } from '../output/ag-ui-adapter.js';\nimport { AgUiEventType } from '../output/ag-ui-types.js';\n\nexport class LinearOrchestrator implements IWorkflowOrchestrator {\n  private agUiAdapter: AgUiEventAdapter;\n\n  constructor(\n    private executor: IResilientExecutor,\n    private storage?: IWorkflowStorage,\n    agUiAdapter?: AgUiEventAdapter\n  ) {\n    this.agUiAdapter = agUiAdapter || new AgUiEventAdapter();\n  }\n\n  async startWorkflow(\n    workflow: WorkflowDefinition,\n    initialContext?: Partial<WorkflowContext>\n  ): Promise<string> {\n    const execution = /* ... create execution ... */;\n\n    // Emit RUN_STARTED\n    this.agUiAdapter.onEvent({\n      type: AgUiEventType.RUN_STARTED,\n      runId: execution.id,\n      threadId: workflow.id,\n      workflowId: workflow.id,\n      timestamp: Date.now(),\n    });\n\n    this.executeWorkflow(workflow, execution).catch(error => {\n      // Emit RUN_ERROR\n      this.agUiAdapter.onEvent({\n        type: AgUiEventType.RUN_ERROR,\n        runId: execution.id,\n        error: {\n          message: error.message,\n          stack: error.stack,\n        },\n        timestamp: Date.now(),\n      });\n    });\n\n    return execution.id;\n  }\n\n  private async executeWorkflow(\n    workflow: WorkflowDefinition,\n    execution: WorkflowExecution,\n    startFromStep?: string\n  ): Promise<void> {\n    execution.status = 'running';\n\n    for (let i = startIndex; i < workflow.steps.length; i++) {\n      const step = workflow.steps[i];\n\n      // Emit STEP_STARTED\n      this.agUiAdapter.onEvent({\n        type: AgUiEventType.STEP_STARTED,\n        runId: execution.id,\n        stepId: step.id,\n        stepName: step.name,\n        timestamp: Date.now(),\n      });\n\n      try {\n        const result = await this.executeStep(step, execution, workflow);\n\n        // Emit STEP_FINISHED\n        this.agUiAdapter.onEvent({\n          type: AgUiEventType.STEP_FINISHED,\n          runId: execution.id,\n          stepId: step.id,\n          status: 'success',\n          output: result,\n          timestamp: Date.now(),\n        });\n\n        // ... existing checkpoint logic\n      } catch (error) {\n        // Emit STEP_FINISHED with error\n        this.agUiAdapter.onEvent({\n          type: AgUiEventType.STEP_FINISHED,\n          runId: execution.id,\n          stepId: step.id,\n          status: 'error',\n          timestamp: Date.now(),\n        });\n\n        throw error;\n      }\n    }\n\n    // Emit RUN_FINISHED\n    this.agUiAdapter.onEvent({\n      type: AgUiEventType.RUN_FINISHED,\n      runId: execution.id,\n      result: {\n        completedSteps: execution.completedSteps.length,\n        outputs: execution.context.outputs,\n      },\n      timestamp: Date.now(),\n    });\n  }\n\n  /**\n   * Get AG-UI adapter for transport layer\n   */\n  getAgUiAdapter(): AgUiEventAdapter {\n    return this.agUiAdapter;\n  }\n}\n```\n\n## Part 2: AG-UI Transport Layer\n\n### Server-Sent Events (SSE) Transport\n\n```typescript\n// server/src/execution/transport/sse-transport.ts\nimport { Response } from 'express';\nimport { AgUiEvent } from '../output/ag-ui-types.js';\n\nexport interface SseClient {\n  id: string;\n  response: Response;\n  runId?: string;\n  connectedAt: Date;\n}\n\nexport class SseTransport {\n  private clients = new Map<string, SseClient>();\n  private heartbeatInterval: NodeJS.Timeout | null = null;\n\n  constructor(\n    private heartbeatIntervalMs: number = 30000 // 30 seconds\n  ) {\n    this.startHeartbeat();\n  }\n\n  /**\n   * Handle new SSE connection\n   */\n  handleConnection(\n    clientId: string,\n    res: Response,\n    runId?: string\n  ): void {\n    // Set SSE headers\n    res.writeHead(200, {\n      'Content-Type': 'text/event-stream',\n      'Cache-Control': 'no-cache, no-transform',\n      'Connection': 'keep-alive',\n      'X-Accel-Buffering': 'no', // Disable nginx buffering\n    });\n\n    // Create client\n    const client: SseClient = {\n      id: clientId,\n      response: res,\n      runId,\n      connectedAt: new Date(),\n    };\n\n    this.clients.set(clientId, client);\n\n    // Handle client disconnect\n    res.on('close', () => {\n      this.removeClient(clientId);\n    });\n\n    // Send initial connection event\n    this.sendToClient(clientId, {\n      type: AgUiEventType.CUSTOM,\n      name: 'connection_established',\n      value: { clientId, runId },\n      timestamp: Date.now(),\n    });\n  }\n\n  /**\n   * Send event to specific client\n   */\n  sendToClient(clientId: string, event: AgUiEvent): boolean {\n    const client = this.clients.get(clientId);\n    if (!client) return false;\n\n    try {\n      const data = JSON.stringify(event);\n      client.response.write(`event: ${event.type}\\n`);\n      client.response.write(`data: ${data}\\n\\n`);\n      return true;\n    } catch (error) {\n      console.error(`Error sending event to client ${clientId}:`, error);\n      this.removeClient(clientId);\n      return false;\n    }\n  }\n\n  /**\n   * Broadcast event to all clients\n   */\n  broadcast(event: AgUiEvent): void {\n    this.clients.forEach((client, clientId) => {\n      this.sendToClient(clientId, event);\n    });\n  }\n\n  /**\n   * Broadcast event to clients subscribed to specific run\n   */\n  broadcastToRun(runId: string, event: AgUiEvent): void {\n    this.clients.forEach((client, clientId) => {\n      if (client.runId === runId) {\n        this.sendToClient(clientId, event);\n      }\n    });\n  }\n\n  /**\n   * Remove client\n   */\n  removeClient(clientId: string): void {\n    const client = this.clients.get(clientId);\n    if (client) {\n      try {\n        client.response.end();\n      } catch (error) {\n        // Ignore errors when ending response\n      }\n      this.clients.delete(clientId);\n    }\n  }\n\n  /**\n   * Start heartbeat to keep connections alive\n   */\n  private startHeartbeat(): void {\n    this.heartbeatInterval = setInterval(() => {\n      this.clients.forEach((client, clientId) => {\n        try {\n          client.response.write(': heartbeat\\n\\n');\n        } catch (error) {\n          this.removeClient(clientId);\n        }\n      });\n    }, this.heartbeatIntervalMs);\n  }\n\n  /**\n   * Stop heartbeat\n   */\n  stopHeartbeat(): void {\n    if (this.heartbeatInterval) {\n      clearInterval(this.heartbeatInterval);\n      this.heartbeatInterval = null;\n    }\n  }\n\n  /**\n   * Get active client count\n   */\n  getClientCount(): number {\n    return this.clients.size;\n  }\n\n  /**\n   * Cleanup all clients\n   */\n  shutdown(): void {\n    this.stopHeartbeat();\n    this.clients.forEach((client, clientId) => {\n      this.removeClient(clientId);\n    });\n  }\n}\n```\n\n### Transport Manager\n\nSimplified transport manager that coordinates SSE transport with AG-UI adapter.\n\n```typescript\n// server/src/execution/transport/transport-manager.ts\nimport { AgUiEvent } from '../output/ag-ui-types.js';\nimport { AgUiEventAdapter } from '../output/ag-ui-adapter.js';\nimport { SseTransport } from './sse-transport.js';\n\nexport class TransportManager {\n  private sseTransport: SseTransport;\n\n  constructor() {\n    this.sseTransport = new SseTransport();\n  }\n\n  /**\n   * Connect AG-UI adapter to SSE transport\n   */\n  connectAdapter(adapter: AgUiEventAdapter, runId?: string): void {\n    adapter.onEvent((event: AgUiEvent) => {\n      if (runId) {\n        this.broadcastToRun(runId, event);\n      } else {\n        this.broadcast(event);\n      }\n    });\n  }\n\n  /**\n   * Broadcast event to all clients\n   */\n  broadcast(event: AgUiEvent): void {\n    this.sseTransport.broadcast(event);\n  }\n\n  /**\n   * Broadcast to specific run\n   */\n  broadcastToRun(runId: string, event: AgUiEvent): void {\n    this.sseTransport.broadcastToRun(runId, event);\n  }\n\n  /**\n   * Get SSE transport\n   */\n  getSseTransport(): SseTransport {\n    return this.sseTransport;\n  }\n\n  /**\n   * Cleanup\n   */\n  shutdown(): void {\n    this.sseTransport.shutdown();\n  }\n}\n```\n\n### API Routes\n\n```typescript\n// server/src/routes/executions-stream.ts\nimport { Router, Request, Response } from 'express';\nimport { TransportManager } from '../execution/transport/transport-manager.js';\nimport { generateId } from '../execution/utils.js';\n\nexport function createExecutionStreamRoutes(\n  transportManager: TransportManager\n): Router {\n  const router = Router();\n\n  /**\n   * SSE endpoint for execution streaming\n   * GET /api/executions/:executionId/stream\n   */\n  router.get('/:executionId/stream', (req: Request, res: Response) => {\n    const { executionId } = req.params;\n    const clientId = generateId('client');\n\n    // TODO: Add authentication/authorization\n\n    const sseTransport = transportManager.getSseTransport();\n    sseTransport.handleConnection(clientId, res, executionId);\n  });\n\n  return router;\n}\n```\n\n## Part 3: Frontend Integration\n\n### React Hook for AG-UI Streaming\n\n```typescript\n// frontend/src/hooks/useAgUiStream.ts\nimport { useEffect, useState, useRef, useCallback } from 'react';\nimport { AgUiEvent, AgUiEventType } from '../types/ag-ui';\n\nexport interface AgUiStreamState {\n  status: 'connecting' | 'connected' | 'disconnected' | 'error';\n  events: AgUiEvent[];\n  messages: Array<{\n    id: string;\n    role: string;\n    content: string;\n  }>;\n  toolCalls: Array<{\n    id: string;\n    name: string;\n    args: any;\n    result?: any;\n    status: 'running' | 'completed' | 'error';\n  }>;\n  currentStep?: {\n    id: string;\n    name: string;\n  };\n  progress?: {\n    toolCalls: number;\n    filesChanged: string[];\n    currentActivity?: string;\n  };\n  error?: string;\n}\n\nexport interface UseAgUiStreamOptions {\n  executionId: string;\n  onEvent?: (event: AgUiEvent) => void;\n  onError?: (error: Error) => void;\n}\n\nexport function useAgUiStream(options: UseAgUiStreamOptions) {\n  const { executionId, onEvent, onError } = options;\n\n  const [state, setState] = useState<AgUiStreamState>({\n    status: 'connecting',\n    events: [],\n    messages: [],\n    toolCalls: [],\n  });\n\n  const eventSourceRef = useRef<EventSource | null>(null);\n  const messageBuffers = useRef<Map<string, string[]>>(new Map());\n  const toolCallBuffers = useRef<Map<string, string>>(new Map());\n\n  const handleEvent = useCallback((event: AgUiEvent) => {\n    // Call custom handler\n    onEvent?.(event);\n\n    // Update state based on event type\n    setState(prev => {\n      const newState = { ...prev };\n      newState.events = [...prev.events, event];\n\n      switch (event.type) {\n        case AgUiEventType.TEXT_MESSAGE_START:\n          messageBuffers.current.set(event.messageId, []);\n          break;\n\n        case AgUiEventType.TEXT_MESSAGE_CONTENT:\n          const buffer = messageBuffers.current.get(event.messageId) || [];\n          buffer.push(event.delta);\n          messageBuffers.current.set(event.messageId, buffer);\n          break;\n\n        case AgUiEventType.TEXT_MESSAGE_END:\n          const content = messageBuffers.current.get(event.messageId)?.join('') || '';\n          newState.messages = [\n            ...prev.messages,\n            {\n              id: event.messageId,\n              role: 'assistant',\n              content,\n            },\n          ];\n          messageBuffers.current.delete(event.messageId);\n          break;\n\n        case AgUiEventType.TOOL_CALL_START:\n          newState.toolCalls = [\n            ...prev.toolCalls,\n            {\n              id: event.toolCallId,\n              name: event.toolCallName,\n              args: null,\n              status: 'running',\n            },\n          ];\n          toolCallBuffers.current.set(event.toolCallId, '');\n          break;\n\n        case AgUiEventType.TOOL_CALL_ARGS:\n          const argBuffer = toolCallBuffers.current.get(event.toolCallId) || '';\n          toolCallBuffers.current.set(event.toolCallId, argBuffer + event.delta);\n          break;\n\n        case AgUiEventType.TOOL_CALL_END:\n          const argsJson = toolCallBuffers.current.get(event.toolCallId) || '{}';\n          newState.toolCalls = prev.toolCalls.map(tc =>\n            tc.id === event.toolCallId\n              ? { ...tc, args: JSON.parse(argsJson) }\n              : tc\n          );\n          toolCallBuffers.current.delete(event.toolCallId);\n          break;\n\n        case AgUiEventType.TOOL_CALL_RESULT:\n          newState.toolCalls = prev.toolCalls.map(tc =>\n            tc.id === event.toolCallId\n              ? { ...tc, result: event.content, status: 'completed' }\n              : tc\n          );\n          break;\n\n        case AgUiEventType.STEP_STARTED:\n          newState.currentStep = {\n            id: event.stepId,\n            name: event.stepName,\n          };\n          break;\n\n        case AgUiEventType.STEP_FINISHED:\n          if (prev.currentStep?.id === event.stepId) {\n            newState.currentStep = undefined;\n          }\n          break;\n\n        case AgUiEventType.STATE_DELTA:\n          // Apply JSON Patch to progress\n          event.delta.forEach(patch => {\n            if (patch.path === '/progress') {\n              newState.progress = patch.value;\n            }\n          });\n          break;\n\n        case AgUiEventType.RUN_ERROR:\n          newState.error = event.error.message;\n          break;\n      }\n\n      return newState;\n    });\n  }, [onEvent]);\n\n  useEffect(() => {\n    // Use Server-Sent Events for real-time streaming\n    const eventSource = new EventSource(\n      `/api/executions/${executionId}/stream`\n    );\n\n    eventSourceRef.current = eventSource;\n\n    eventSource.onopen = () => {\n      setState(prev => ({ ...prev, status: 'connected' }));\n    };\n\n    // Listen to all AG-UI event types\n    Object.values(AgUiEventType).forEach(eventType => {\n      eventSource.addEventListener(eventType, (e: MessageEvent) => {\n        try {\n          const event: AgUiEvent = JSON.parse(e.data);\n          handleEvent(event);\n        } catch (error) {\n          console.error('Error parsing AG-UI event:', error);\n        }\n      });\n    });\n\n    eventSource.onerror = (error) => {\n      setState(prev => ({\n        ...prev,\n        status: 'error',\n        error: 'Connection lost',\n      }));\n      onError?.(new Error('EventSource error'));\n      eventSource.close();\n    };\n\n    return () => {\n      eventSource.close();\n    };\n  }, [executionId, handleEvent, onError]);\n\n  return state;\n}\n```\n\n### Execution Monitor Component\n\n```typescript\n// frontend/src/components/executions/ExecutionMonitor.tsx\nimport React from 'react';\nimport { useAgUiStream } from '../../hooks/useAgUiStream';\nimport { MessageStream } from './MessageStream';\nimport { ToolCallViewer } from './ToolCallViewer';\nimport { ProgressIndicator } from './ProgressIndicator';\n\nexport interface ExecutionMonitorProps {\n  executionId: string;\n  onComplete?: () => void;\n}\n\nexport const ExecutionMonitor: React.FC<ExecutionMonitorProps> = ({\n  executionId,\n  onComplete,\n}) => {\n  const stream = useAgUiStream({\n    executionId,\n    onEvent: (event) => {\n      if (event.type === 'RUN_FINISHED' && onComplete) {\n        onComplete();\n      }\n    },\n  });\n\n  return (\n    <div className=\"execution-monitor\">\n      <div className=\"execution-header\">\n        <h2>Execution: {executionId}</h2>\n        <div className=\"status-badge\" data-status={stream.status}>\n          {stream.status}\n        </div>\n      </div>\n\n      {stream.error && (\n        <div className=\"error-banner\">\n          <strong>Error:</strong> {stream.error}\n        </div>\n      )}\n\n      {stream.currentStep && (\n        <div className=\"current-step\">\n          <strong>Current Step:</strong> {stream.currentStep.name}\n        </div>\n      )}\n\n      {stream.progress && (\n        <ProgressIndicator progress={stream.progress} />\n      )}\n\n      <div className=\"execution-content\">\n        <div className=\"messages-section\">\n          <h3>Messages</h3>\n          <MessageStream messages={stream.messages} />\n        </div>\n\n        <div className=\"tool-calls-section\">\n          <h3>Tool Calls ({stream.toolCalls.length})</h3>\n          <ToolCallViewer toolCalls={stream.toolCalls} />\n        </div>\n      </div>\n    </div>\n  );\n};\n```\n\n### Tool Call Viewer Component\n\n```typescript\n// frontend/src/components/executions/ToolCallViewer.tsx\nimport React, { useState } from 'react';\n\nexport interface ToolCall {\n  id: string;\n  name: string;\n  args: any;\n  result?: any;\n  status: 'running' | 'completed' | 'error';\n}\n\nexport interface ToolCallViewerProps {\n  toolCalls: ToolCall[];\n}\n\nexport const ToolCallViewer: React.FC<ToolCallViewerProps> = ({ toolCalls }) => {\n  const [expandedIds, setExpandedIds] = useState<Set<string>>(new Set());\n\n  const toggleExpand = (id: string) => {\n    setExpandedIds(prev => {\n      const next = new Set(prev);\n      if (next.has(id)) {\n        next.delete(id);\n      } else {\n        next.add(id);\n      }\n      return next;\n    });\n  };\n\n  return (\n    <div className=\"tool-call-viewer\">\n      {toolCalls.length === 0 && (\n        <div className=\"empty-state\">No tool calls yet</div>\n      )}\n\n      {toolCalls.map(toolCall => (\n        <div\n          key={toolCall.id}\n          className=\"tool-call-item\"\n          data-status={toolCall.status}\n        >\n          <div\n            className=\"tool-call-header\"\n            onClick={() => toggleExpand(toolCall.id)}\n          >\n            <span className=\"tool-name\">{toolCall.name}</span>\n            <span className=\"tool-status\">{toolCall.status}</span>\n          </div>\n\n          {expandedIds.has(toolCall.id) && (\n            <div className=\"tool-call-details\">\n              {toolCall.args && (\n                <div className=\"tool-args\">\n                  <strong>Arguments:</strong>\n                  <pre>{JSON.stringify(toolCall.args, null, 2)}</pre>\n                </div>\n              )}\n\n              {toolCall.result && (\n                <div className=\"tool-result\">\n                  <strong>Result:</strong>\n                  <pre>{JSON.stringify(toolCall.result, null, 2)}</pre>\n                </div>\n              )}\n            </div>\n          )}\n        </div>\n      ))}\n    </div>\n  );\n};\n```\n\n### Message Stream Component\n\n```typescript\n// frontend/src/components/executions/MessageStream.tsx\nimport React, { useEffect, useRef } from 'react';\n\nexport interface Message {\n  id: string;\n  role: string;\n  content: string;\n}\n\nexport interface MessageStreamProps {\n  messages: Message[];\n  autoScroll?: boolean;\n}\n\nexport const MessageStream: React.FC<MessageStreamProps> = ({\n  messages,\n  autoScroll = true,\n}) => {\n  const containerRef = useRef<HTMLDivElement>(null);\n\n  useEffect(() => {\n    if (autoScroll && containerRef.current) {\n      containerRef.current.scrollTop = containerRef.current.scrollHeight;\n    }\n  }, [messages, autoScroll]);\n\n  return (\n    <div ref={containerRef} className=\"message-stream\">\n      {messages.length === 0 && (\n        <div className=\"empty-state\">No messages yet</div>\n      )}\n\n      {messages.map(message => (\n        <div key={message.id} className=\"message\" data-role={message.role}>\n          <div className=\"message-role\">{message.role}</div>\n          <div className=\"message-content\">\n            <pre>{message.content}</pre>\n          </div>\n        </div>\n      ))}\n    </div>\n  );\n};\n```\n\n### Progress Indicator Component\n\n```typescript\n// frontend/src/components/executions/ProgressIndicator.tsx\nimport React from 'react';\n\nexport interface Progress {\n  toolCalls: number;\n  filesChanged: string[];\n  currentActivity?: string;\n}\n\nexport interface ProgressIndicatorProps {\n  progress: Progress;\n}\n\nexport const ProgressIndicator: React.FC<ProgressIndicatorProps> = ({\n  progress,\n}) => {\n  return (\n    <div className=\"progress-indicator\">\n      {progress.currentActivity && (\n        <div className=\"current-activity\">\n          <span className=\"activity-icon\">⚙️</span>\n          <span className=\"activity-text\">{progress.currentActivity}</span>\n        </div>\n      )}\n\n      <div className=\"progress-stats\">\n        <div className=\"stat\">\n          <strong>Tool Calls:</strong> {progress.toolCalls}\n        </div>\n        <div className=\"stat\">\n          <strong>Files Changed:</strong> {progress.filesChanged.length}\n        </div>\n      </div>\n\n      {progress.filesChanged.length > 0 && (\n        <div className=\"files-changed\">\n          <strong>Modified Files:</strong>\n          <ul>\n            {progress.filesChanged.map((file, index) => (\n              <li key={index}>{file}</li>\n            ))}\n          </ul>\n        </div>\n      )}\n    </div>\n  );\n};\n```\n\n## Testing Strategy\n\n### Unit Tests\n\n```typescript\n// server/src/execution/output/ag-ui-adapter.test.ts\ndescribe('AgUiEventAdapter', () => {\n  it('should transform Claude assistant message to AG-UI events', () => {\n    const adapter = new AgUiEventAdapter();\n    const events: AgUiEvent[] = [];\n\n    adapter.onEvent(event => events.push(event));\n\n    const message: StreamMessage = {\n      type: 'assistant',\n      data: {\n        type: 'assistant',\n        message: {\n          content: [\n            { type: 'text', text: 'Hello world' }\n          ]\n        }\n      },\n      timestamp: new Date(),\n      raw: ''\n    };\n\n    adapter.transformStreamMessage(message, 'process-1');\n\n    expect(events.length).toBe(3);\n    expect(events[0].type).toBe(AgUiEventType.TEXT_MESSAGE_START);\n    expect(events[1].type).toBe(AgUiEventType.TEXT_MESSAGE_CONTENT);\n    expect(events[2].type).toBe(AgUiEventType.TEXT_MESSAGE_END);\n  });\n\n  it('should transform tool use to AG-UI tool call events', () => {\n    const adapter = new AgUiEventAdapter();\n    const events: AgUiEvent[] = [];\n\n    adapter.onEvent(event => events.push(event));\n\n    const message: StreamMessage = {\n      type: 'assistant',\n      data: {\n        type: 'assistant',\n        message: {\n          content: [\n            {\n              type: 'tool_use',\n              id: 'tool-123',\n              name: 'Read',\n              input: { file_path: '/path/to/file.ts' }\n            }\n          ]\n        }\n      },\n      timestamp: new Date(),\n      raw: ''\n    };\n\n    adapter.transformStreamMessage(message, 'process-1');\n\n    expect(events[0].type).toBe(AgUiEventType.TOOL_CALL_START);\n    expect(events[1].type).toBe(AgUiEventType.TOOL_CALL_ARGS);\n    expect(events[2].type).toBe(AgUiEventType.TOOL_CALL_END);\n  });\n});\n```\n\n### Integration Tests\n\n```typescript\n// server/src/execution/transport/sse-transport.test.ts\ndescribe('SseTransport', () => {\n  it('should send events to connected clients', (done) => {\n    const transport = new SseTransport();\n    const mockRes = {\n      writeHead: jest.fn(),\n      write: jest.fn(),\n      on: jest.fn(),\n    };\n\n    transport.handleConnection('client-1', mockRes as any);\n\n    const event: AgUiEvent = {\n      type: AgUiEventType.TEXT_MESSAGE_START,\n      messageId: 'msg-1',\n      role: 'assistant',\n      timestamp: Date.now(),\n    };\n\n    transport.sendToClient('client-1', event);\n\n    expect(mockRes.write).toHaveBeenCalledWith(\n      expect.stringContaining('TEXT_MESSAGE_START')\n    );\n\n    done();\n  });\n});\n```\n\n### E2E Tests\n\n```typescript\n// frontend/src/hooks/useAgUiStream.test.tsx\ndescribe('useAgUiStream', () => {\n  it('should receive and process AG-UI events', async () => {\n    const { result } = renderHook(() =>\n      useAgUiStream({ executionId: 'exec-1' })\n    );\n\n    // Wait for connection\n    await waitFor(() => {\n      expect(result.current.status).toBe('connected');\n    });\n\n    // Simulate events (mock EventSource)\n    // ...\n\n    await waitFor(() => {\n      expect(result.current.messages.length).toBeGreaterThan(0);\n    });\n  });\n});\n```\n\n## File Structure\n\n```\nserver/src/execution/\n├── output/\n│   ├── types.ts                    # SPEC-007: StreamMessage, ExecutionProgress types\n│   ├── processor.ts                # SPEC-007: IOutputProcessor interface\n│   ├── stream-json-processor.ts    # SPEC-007: Parses raw output → StreamMessage\n│   ├── ag-ui-types.ts              # SPEC-009: AG-UI event schemas (300 lines)\n│   ├── ag-ui-adapter.ts            # SPEC-009: StreamMessage → AgUiEvent (400 lines)\n│   └── ag-ui-integration.ts        # SPEC-009: Wire SPEC-007 to SPEC-009 (100 lines)\n├── transport/\n│   ├── sse-transport.ts            # SSE transport (200 lines)\n│   └── transport-manager.ts        # SSE coordinator (100 lines)\n├── workflow/\n│   └── linear-orchestrator.ts      # Modified to emit lifecycle events\n└── routes/\n    └── executions-stream.ts        # SSE endpoint (100 lines)\n\nfrontend/src/\n├── types/\n│   └── ag-ui.ts                    # Frontend AG-UI types (100 lines)\n├── hooks/\n│   └── useAgUiStream.ts            # React hook for SSE streaming (150 lines)\n└── components/executions/\n    ├── ExecutionMonitor.tsx        # Main dashboard (250 lines)\n    ├── ToolCallViewer.tsx          # Tool call display (150 lines)\n    ├── MessageStream.tsx           # Message streaming (150 lines)\n    └── ProgressIndicator.tsx       # Progress display (100 lines)\n\n.sudocode/specs/\n├── output_processing_layer_real_time_parsing.md  # SPEC-007\n└── ag_ui_protocol_integration.md                 # SPEC-009 (this spec)\n```\n\n**Key Files:**\n\n- **SPEC-007 Foundation** (`output/` dir): Parses agent output into `StreamMessage`\n- **SPEC-009 Protocol** (`ag-ui-*.ts`): Transforms `StreamMessage` into AG-UI events\n- **Integration** (`ag-ui-integration.ts`): Wires SPEC-007 → SPEC-009\n- **Transport** (`sse-transport.ts`): Streams AG-UI events to frontend via SSE\n\n## Implementation Checklist\n\n### Backend\n\n- Define AG-UI event types and Zod schemas\n- Implement AG-UI event adapter\n- Integrate adapter with StreamJsonProcessor\n- Integrate adapter with LinearOrchestrator\n- Implement SSE transport\n- Implement WebSocket transport\n- Create transport manager\n- Add SSE API endpoint\n- Add WebSocket endpoint\n- Write unit tests for adapter\n- Write integration tests for transports\n\n### Frontend\n\n- Define AG-UI types for frontend\n- Implement useAgUiStream hook\n- Create ExecutionMonitor component\n- Create ToolCallViewer component\n- Create MessageStream component\n- Create ProgressIndicator component\n- Add styling for components\n- Write unit tests for hook\n- Write E2E tests for components\n\n### Documentation\n\n- Write specification document\n- Add usage examples\n- Create API documentation\n- Update README with AG-UI integration\n\n## Usage Example\n\n### Backend Integration\n\n```typescript\n// server/src/index.ts\nimport { TransportManager } from './execution/transport/transport-manager.js';\nimport { AgUiEventAdapter } from './execution/output/ag-ui-adapter.js';\nimport { LinearOrchestrator } from './execution/workflow/linear-orchestrator.js';\n\n// Create transport manager\nconst transportManager = new TransportManager();\n\n// Create AG-UI adapter\nconst agUiAdapter = new AgUiEventAdapter();\n\n// Connect adapter to transports\ntransportManager.connectAdapter(agUiAdapter);\n\n// Create orchestrator with AG-UI support\nconst orchestrator = new LinearOrchestrator(\n  executor,\n  storage,\n  agUiAdapter\n);\n\n// Start workflow - events automatically stream to frontend\nconst executionId = await orchestrator.startWorkflow(workflow);\n```\n\n### Frontend Integration\n\n```typescript\n// App.tsx\nimport { ExecutionMonitor } from './components/executions/ExecutionMonitor';\n\nfunction App() {\n  const [executionId, setExecutionId] = useState<string | null>(null);\n\n  return (\n    <div>\n      {executionId && (\n        <ExecutionMonitor\n          executionId={executionId}\n          onComplete={() => console.log('Execution completed!')}\n        />\n      )}\n    </div>\n  );\n}\n```\n\n## Related Specs\n\n- [[SPEC-003]] - Process Layer (provides output streaming)\n- [[SPEC-004]] - Engine Layer (task execution)\n- [[SPEC-005]] - Task Execution Layer (resilience)\n- [[SPEC-006]] - Workflow Layer (orchestration, integrates lifecycle events)\n- [[SPEC-007]] - Output Processing Layer (provides StreamJsonProcessor)\n","priority":2,"archived":0,"archived_at":null,"created_at":"2025-10-30 08:17:27","updated_at":"2025-11-03T03:10:12.588Z","parent_id":null,"parent_uuid":null,"relationships":[{"from":"SPEC-009","from_type":"spec","to":"SPEC-003","to_type":"spec","type":"references"},{"from":"SPEC-009","from_type":"spec","to":"SPEC-004","to_type":"spec","type":"references"},{"from":"SPEC-009","from_type":"spec","to":"SPEC-005","to_type":"spec","type":"references"},{"from":"SPEC-009","from_type":"spec","to":"SPEC-006","to_type":"spec","type":"references"},{"from":"SPEC-009","from_type":"spec","to":"SPEC-007","to_type":"spec","type":"references"}],"tags":[]}
{"id":"SPEC-010","uuid":"ba3bb9ff-d3a2-403a-ac5c-8addf7064fb0","title":"Worktree Management Design","file_path":"specs/worktree_management_design.md","content":"# Worktree Management Design\n\n## Overview\n\nThis spec describes the design for managing git worktrees to isolate Claude Code execution sessions in sudocode. The design is informed by analysis of reference implementations:\n\n- **vibe-kanban**: Comprehensive worktree management with robust cleanup and state tracking\n- **CodeMachine-CLI**: No worktree management (not applicable)\n\n## Motivation\n\nCurrently, sudocode runs Claude Code sessions in the main working directory. To support:\n\n1. **Concurrent sessions** - Run multiple Claude Code sessions simultaneously without conflicts\n1. **Issue isolation** - Each issue gets its own isolated git environment\n1. **Branch management** - Automatically manage branches per issue/session\n1. **Cleanup** - Reliable cleanup of session artifacts\n\nWe need to implement git worktree management.\n\n## Architecture\n\n### Layer Structure\n\nBuilding on sudocode's existing execution architecture:\n\n```\n┌─────────────────────────────────────┐\n│   Workflow Layer                     │\n│   - orchestrates multi-step flows   │\n└──────────────┬──────────────────────┘\n               │\n┌──────────────▼──────────────────────┐\n│   Engine Layer                       │\n│   - manages task queue & lifecycle  │\n└──────────────┬──────────────────────┘\n               │\n┌──────────────▼──────────────────────┐\n│   Resilience Layer                   │\n│   - retry & circuit breaker logic   │\n└──────────────┬──────────────────────┘\n               │\n┌──────────────▼──────────────────────┐\n│   Process Layer                      │\n│   - spawns/manages processes        │\n└──────────────┬──────────────────────┘\n               │\n      ┌────────▼────────┐\n      │  Worktree Layer │  ← NEW\n      │  - git isolation│\n      └─────────────────┘\n```\n\n### Core Components\n\n#### 1\\. WorktreeManager\n\n**Location**: `server/src/execution/worktree/manager.ts`\n\n**Responsibilities**:\n\n- Create git worktrees for sessions\n- Ensure worktree existence (recreate if needed)\n- Cleanup worktrees and git metadata\n- Handle race conditions with locking\n- Prune orphaned worktree metadata\n- Read and apply configuration from `.sudocode/config.json`\n\n**Key Methods**:\n\n```typescript\ninterface IWorktreeManager {\n  /**\n   * Create a new worktree for a session\n   * @param repoPath - Path to the main git repository\n   * @param branchName - Branch name for the worktree\n   * @param worktreePath - Where to create the worktree\n   * @param baseBranch - Branch to base the new branch on\n   * @param createBranch - Whether to create the branch\n   */\n  createWorktree(\n    repoPath: string,\n    branchName: string,\n    worktreePath: string,\n    baseBranch: string,\n    createBranch: boolean\n  ): Promise<void>;\n\n  /**\n   * Ensure worktree exists, recreating if necessary\n   * Uses locking to prevent race conditions\n   */\n  ensureWorktreeExists(\n    repoPath: string,\n    branchName: string,\n    worktreePath: string\n  ): Promise<void>;\n\n  /**\n   * Clean up a worktree (filesystem + git metadata)\n   */\n  cleanupWorktree(\n    worktreePath: string,\n    repoPath?: string\n  ): Promise<void>;\n\n  /**\n   * Check if worktree is properly set up\n   */\n  isWorktreeValid(\n    repoPath: string,\n    worktreePath: string\n  ): Promise<boolean>;\n}\n```\n\n**Implementation Notes** (from vibe-kanban):\n\n- Use **git CLI** (not libgit2/nodegit) for reliability\n- Implement **per-path locking** to prevent concurrent creation conflicts\n- **Comprehensive cleanup**: Remove both filesystem and `.git/worktrees/<name>` metadata\n- **Retry logic**: If creation fails due to metadata conflicts, cleanup and retry\n- **Validation**: Check both filesystem existence AND git metadata registration\n- **Configuration**: Load settings from `.sudocode/config.json` on initialization\n\n#### 2\\. Session Model Extension\n\n**Location**: Database schema + models\n\n**New Fields**:\n\n```typescript\ninterface Session {\n  id: string;\n  issueId: string;\n\n  // NEW: Worktree tracking\n  worktreePath: string | null;        // Path to the worktree\n  branchName: string;                  // Git branch for this session\n  targetBranch: string;                // Base/target branch (e.g., 'main')\n  worktreeDeleted: boolean;            // Cleanup flag\n\n  // Existing fields...\n  status: SessionStatus;\n  createdAt: Date;\n  updatedAt: Date;\n}\n```\n\n**Database Migration**:\n\n```sql\n-- Add worktree fields to sessions table\nALTER TABLE sessions ADD COLUMN worktree_path TEXT;\nALTER TABLE sessions ADD COLUMN branch_name TEXT NOT NULL;\nALTER TABLE sessions ADD COLUMN target_branch TEXT NOT NULL;\nALTER TABLE sessions ADD COLUMN worktree_deleted BOOLEAN NOT NULL DEFAULT FALSE;\n\n-- Index for cleanup queries\nCREATE INDEX idx_sessions_worktree_deleted ON sessions(worktree_deleted);\n```\n\n#### 3\\. Git CLI Wrapper\n\n**Location**: `server/src/execution/worktree/git-cli.ts`\n\n**Purpose**: Wrap git commands for worktree operations\n\n```typescript\ninterface IGitCli {\n  /**\n   * Add a new worktree\n   * Equivalent to: git worktree add <path> <branch>\n   */\n  worktreeAdd(\n    repoPath: string,\n    worktreePath: string,\n    branch: string,\n    force?: boolean\n  ): Promise<void>;\n\n  /**\n   * Remove a worktree\n   * Equivalent to: git worktree remove <path> --force\n   */\n  worktreeRemove(\n    repoPath: string,\n    worktreePath: string,\n    force?: boolean\n  ): Promise<void>;\n\n  /**\n   * Prune worktree metadata\n   * Equivalent to: git worktree prune\n   */\n  worktreePrune(repoPath: string): Promise<void>;\n\n  /**\n   * List all worktrees\n   * Equivalent to: git worktree list\n   */\n  worktreeList(repoPath: string): Promise<WorktreeInfo[]>;\n\n  /**\n   * Create a branch\n   * Equivalent to: git branch <name> <base>\n   */\n  createBranch(\n    repoPath: string,\n    branchName: string,\n    baseBranch: string\n  ): Promise<void>;\n}\n```\n\n**Implementation**:\n\n- Use `child_process.exec` or `execa` for git commands\n- Proper error handling and output parsing\n- Shell command construction with proper escaping\n- Support for sparse-checkout if configured\n\n#### 4\\. ProcessConfig Extension\n\n**Location**: `server/src/execution/process/types.ts`\n\n**Extension**:\n\n```typescript\nexport interface ProcessConfig {\n  executablePath: string;\n  args: string[];\n\n  // CHANGED: workDir now optional, calculated from session\n  workDir?: string;\n\n  // NEW: Session reference for worktree lookup\n  sessionId?: string;\n\n  env?: Record<string, string>;\n  timeout?: number;\n  idleTimeout?: number;\n  retry?: {\n    maxAttempts: number;\n    backoffMs: number;\n  };\n}\n```\n\n#### 5\\. Session Lifecycle Integration\n\n**Location**: New service layer\n\n```typescript\ninterface ISessionService {\n  /**\n   * Create a new session with worktree\n   */\n  createSession(params: {\n    issueId: string;\n    baseBranch: string;\n    repoPath: string;\n  }): Promise<Session>;\n\n  /**\n   * Ensure session worktree is ready\n   */\n  ensureSessionReady(sessionId: string): Promise<void>;\n\n  /**\n   * Cleanup session and worktree\n   */\n  cleanupSession(sessionId: string): Promise<void>;\n\n  /**\n   * Get working directory for session\n   */\n  getSessionWorkDir(sessionId: string): Promise<string>;\n}\n```\n\n## Implementation Strategy\n\n### Phase 1: Foundation (Week 1)\n\n- Create worktree manager interface and basic implementation\n- Implement git CLI wrapper\n- Add configuration schema and loading from `.sudocode/config.json`\n- Add database schema for worktree tracking\n- Write unit tests for worktree operations\n\n### Phase 2: Integration (Week 2)\n\n- Integrate worktree manager with process layer\n- Update session lifecycle to create/cleanup worktrees\n- Modify process spawning to use worktree paths\n- Add worktree validation checks\n- Implement configuration-driven behavior (auto-create/delete branches)\n\n### Phase 3: Robustness (Week 3)\n\n- Implement locking mechanism\n- Add retry logic for creation failures\n- Implement comprehensive cleanup (filesystem + metadata)\n- Add orphaned worktree detection and cleanup\n- Implement sparse-checkout support\n\n### Phase 4: Testing & Polish (Week 4)\n\n- Integration tests for concurrent session scenarios\n- Cleanup on startup (handle crashed sessions)\n- Performance testing\n- Configuration validation and documentation\n\n## Key Design Decisions\n\n### 1\\. Worktree Naming Convention\n\n**Pattern**: `<project-name>-<session-id>-<branch-name>`\n\n**Example**: `sudocode-abc123-fix-issue-42`\n\n**Location**: Configurable via `worktreeStoragePath` in config (default: `.sudocode/worktrees/`)\n\n**Benefits**:\n\n- Easy to identify which session owns the worktree\n- Unique per session\n- Human-readable for debugging\n\n### 2\\. Branch Naming Convention\n\n**Pattern**: `<branchPrefix>/<session-id>/<issue-title>`\n\n**Example**: `sudocode/abc123/fix-authentication-bug`\n\n**Configuration**: `branchPrefix` is configurable (default: \"sudocode\")\n\n**Benefits**:\n\n- Clear namespace separation\n- Maps directly to session\n- Compatible with git best practices\n- Customizable prefix for team conventions\n\n### 3\\. Cleanup Strategy\n\n**When to cleanup**:\n\n1. **On session completion** - Normal cleanup path\n1. **On session failure** - Cleanup after errors\n1. **On server startup** - Cleanup orphaned worktrees (if `cleanupOrphanedWorktreesOnStartup` enabled)\n1. **Manual cleanup** - Admin tool for force cleanup\n\n**Cleanup process**:\n\n```typescript\nasync function cleanupWorktree(session: Session) {\n  // 1. Stop any running processes\n  await stopSessionProcesses(session.id);\n\n  // 2. Mark as deleted in DB (prevents race conditions)\n  await markWorktreeDeleted(session.id);\n\n  // 3. Remove git worktree registration\n  await gitCli.worktreeRemove(repoPath, session.worktreePath, true);\n\n  // 4. Force cleanup metadata directory\n  await forceCleanupMetadata(repoPath, session.branchName);\n\n  // 5. Remove filesystem directory\n  await fs.rm(session.worktreePath, { recursive: true, force: true });\n\n  // 6. Prune stale worktree entries\n  await gitCli.worktreePrune(repoPath);\n\n  // 7. Delete branch if configured to auto-delete\n  if (config.autoDeleteBranches) {\n    await gitCli.deleteBranch(repoPath, session.branchName);\n  }\n}\n```\n\n### 4\\. Race Condition Handling\n\n**Problem**: Multiple requests might try to create the same worktree concurrently.\n\n**Solution**: Per-path mutex using async locks\n\n```typescript\nimport { AsyncMutex } from 'async-mutex';\n\nclass WorktreeManager {\n  private locks = new Map<string, AsyncMutex>();\n\n  async ensureWorktreeExists(\n    repoPath: string,\n    branchName: string,\n    worktreePath: string\n  ): Promise<void> {\n    // Get or create lock for this specific path\n    let lock = this.locks.get(worktreePath);\n    if (!lock) {\n      lock = new AsyncMutex();\n      this.locks.set(worktreePath, lock);\n    }\n\n    // Acquire lock before proceeding\n    const release = await lock.acquire();\n    try {\n      // Check if already exists\n      if (await this.isWorktreeValid(repoPath, worktreePath)) {\n        return;\n      }\n\n      // Create worktree\n      await this.createWorktree(repoPath, branchName, worktreePath, baseBranch, false);\n    } finally {\n      release();\n    }\n  }\n}\n```\n\n### 5\\. Error Recovery\n\n**Scenarios to handle**:\n\n1. **Metadata exists but filesystem doesn't**\n\n- Solution: Force cleanup metadata, recreate\n\n1. **Filesystem exists but metadata doesn't**\n\n- Solution: Remove filesystem, recreate\n\n1. **Creation fails with \"already exists\"**\n\n- Solution: Cleanup completely, retry once\n\n1. **Git repository is locked**\n\n- Solution: Wait and retry with exponential backoff\n\n1. **Invalid configuration**\n\n- Solution: Validate config on load, use defaults for invalid values, warn user\n\n## API Design\n\n### REST Endpoints\n\n```typescript\n// Create session with worktree\nPOST /api/sessions\n{\n  \"issueId\": \"ISSUE-001\",\n  \"baseBranch\": \"main\"\n}\nResponse: {\n  \"sessionId\": \"abc123\",\n  \"worktreePath\": \"/tmp/sudocode-worktrees/...\",\n  \"branchName\": \"sudocode/abc123/fix-bug\"\n}\n\n// Get session info\nGET /api/sessions/:sessionId\nResponse: {\n  \"id\": \"abc123\",\n  \"issueId\": \"ISSUE-001\",\n  \"worktreePath\": \"/tmp/sudocode-worktrees/...\",\n  \"branchName\": \"sudocode/abc123/fix-bug\",\n  \"targetBranch\": \"main\",\n  \"status\": \"running\"\n}\n\n// Cleanup session\nDELETE /api/sessions/:sessionId\nResponse: { \"success\": true }\n\n// Admin: List all worktrees\nGET /api/admin/worktrees\nResponse: [\n  {\n    \"sessionId\": \"abc123\",\n    \"path\": \"/tmp/sudocode-worktrees/...\",\n    \"branch\": \"sudocode/abc123/fix-bug\",\n    \"createdAt\": \"2025-10-30T10:00:00Z\",\n    \"deleted\": false\n  }\n]\n\n// Admin: Cleanup orphaned worktrees\nPOST /api/admin/worktrees/cleanup\nResponse: {\n  \"cleaned\": 3,\n  \"failed\": 0\n}\n```\n\n## Testing Strategy\n\n### Unit Tests\n\n```typescript\ndescribe('WorktreeManager', () => {\n  it('should create a new worktree');\n  it('should handle concurrent creation requests');\n  it('should cleanup worktree completely');\n  it('should recover from partial cleanup');\n  it('should validate worktree existence');\n  it('should handle metadata conflicts');\n});\n\ndescribe('GitCli', () => {\n  it('should execute git worktree add');\n  it('should execute git worktree remove');\n  it('should parse git worktree list output');\n  it('should handle git errors gracefully');\n});\n```\n\n### Integration Tests\n\n```typescript\ndescribe('Session Lifecycle', () => {\n  it('should create session with worktree');\n  it('should run Claude Code in worktree');\n  it('should cleanup worktree on completion');\n  it('should handle multiple concurrent sessions');\n  it('should recover orphaned worktrees on startup');\n});\n```\n\n## Reference Implementation Insights\n\n### From vibe-kanban\n\n**Key Learnings**:\n\n1. **Use git CLI, not libgit2** - More reliable for worktree operations\n1. **Lock per path** - Prevents race conditions\n1. **Comprehensive cleanup** - Must remove both filesystem AND metadata\n1. **Retry logic** - Handle metadata conflicts by cleanup + retry\n1. **Database tracking** - `worktree_deleted` flag prevents double cleanup\n1. **Container abstraction** - Higher-level interface over worktree details\n\n**Code References**:\n\n- `crates/services/src/services/worktree_manager.rs` - Core worktree logic\n- `crates/services/src/services/container.rs` - Higher-level abstraction\n- `crates/db/src/models/task_attempt.rs` - Database model\n- Database migrations show evolution of worktree tracking\n\n## Configuration\n\nAll worktree settings will be configurable via `.sudocode/config.json`. This provides flexibility for different team workflows and repository sizes.\n\n### Configuration Schema\n\n```typescript\ninterface WorktreeConfig {\n  // Where to store worktrees\n  // Default: \".sudocode/worktrees\" (relative to project root)\n  // Can be absolute path like \"/tmp/sudocode-worktrees\"\n  worktreeStoragePath: string;\n\n  // Auto-create branches for new sessions\n  // Default: true\n  autoCreateBranches: boolean;\n\n  // Auto-delete branches when session is cleaned up\n  // Default: false (keep branches for history)\n  autoDeleteBranches: boolean;\n\n  // Use sparse-checkout for worktrees (for large repos)\n  // Default: false\n  enableSparseCheckout: boolean;\n\n  // Patterns for sparse-checkout (only if enableSparseCheckout=true)\n  // Example: [\"src/\", \"package.json\", \"tsconfig.json\"]\n  sparseCheckoutPatterns?: string[];\n\n  // Branch naming prefix\n  // Default: \"sudocode\"\n  branchPrefix: string;\n\n  // Cleanup orphaned worktrees on server startup\n  // Default: true\n  cleanupOrphanedWorktreesOnStartup: boolean;\n}\n```\n\n### Example config.json\n\n```json\n{\n  \"worktree\": {\n    \"worktreeStoragePath\": \".sudocode/worktrees\",\n    \"autoCreateBranches\": true,\n    \"autoDeleteBranches\": false,\n    \"enableSparseCheckout\": false,\n    \"branchPrefix\": \"sudocode\",\n    \"cleanupOrphanedWorktreesOnStartup\": true\n  }\n}\n```\n\n### Configuration Details\n\n**Storage Location**:\n\n- **Default**: `.sudocode/worktrees/` (relative to project root)\n- **Alternatives**: Absolute paths like `/tmp/sudocode-worktrees/` or `~/.sudocode/worktrees/`\n- **Benefits**: User-controlled, can optimize for disk I/O or temp cleanup needs\n\n**Concurrent Sessions**:\n\n- **Support**: Multiple sessions per issue allowed\n- **Design assumption**: Typically one session per issue at a time\n- **Benefit**: Worktrees enable safe concurrent sessions if needed (e.g., testing different approaches)\n\n**Branch Lifecycle**:\n\n- **Creation**: Configurable via `autoCreateBranches` (default: true)\n- **Deletion**: Configurable via `autoDeleteBranches` (default: false)\n- **Rationale**: Keep branches by default for git history; users can enable auto-deletion if preferred\n\n**Sparse Checkout**:\n\n- **Configurable**: Enable/disable via `enableSparseCheckout`\n- **Use case**: Large monorepos where full checkout is slow/wasteful\n- **Patterns**: Specify which paths to include in worktree\n\n**Future: Cloud Deployment**:\n\n- Design uses `container_ref` abstraction (like vibe-kanban)\n- Local implementation uses worktree paths\n- Future cloud implementation could use devcontainer IDs\n- Not in scope for initial implementation\n\n## Next Steps\n\n1. **Review this design** with team\n1. **Prototype** worktree manager with basic operations\n1. **Test** race condition handling\n1. **Integrate** with existing execution layers\n1. **Document** usage patterns for future developers\n\n## References\n\n- `/Users/alexngai/GitHub/sudocode/references/vibe-kanban/crates/services/src/services/worktree_manager.rs`\n- `/Users/alexngai/GitHub/sudocode/references/vibe-kanban/crates/services/src/services/container.rs`\n- [Git worktree documentation](https://git-scm.com/docs/git-worktree)\n","priority":2,"archived":0,"archived_at":null,"created_at":"2025-10-30 20:47:36","updated_at":"2025-11-03T03:10:12.586Z","parent_id":null,"parent_uuid":null,"relationships":[],"tags":[]}
{"id":"SPEC-011","uuid":"05ffaeb2-ee36-4155-836e-c49d583f5093","title":"Issue-to-Execution System Specification","file_path":"specs/issue_to_execution_system.md","content":"# Issue-to-Execution System Specification\n\n## Overview\n\nThe Issue-to-Execution System bridges sudocode's issue tracking with the execution infrastructure, enabling users to run AI agents directly on issues. This system transforms issues into executable workflows, manages execution lifecycle, supports iterative feedback loops, and provides real-time progress monitoring.\n\nThis spec integrates:\n- [[SPEC-003]] through [[SPEC-007]] - Execution infrastructure layers\n- [[SPEC-009]] - AG-UI protocol integration for real-time streaming\n- [[SPEC-010]] - Worktree management for execution isolation\n\n## Design Goals\n\n1. **Template-Driven**: Configurable prompt templates shown/edited before dispatch\n2. **Flexible Execution**: Support both isolated worktrees and local git tree\n3. **Configurable**: Execution settings modifiable before agent starts\n4. **Interactive**: Follow-up mechanism matching Claude Code's interaction flow\n5. **Observable**: Real-time progress via AG-UI event streaming\n6. **Resilient**: Auto-save, crash recovery, cleanup management\n\n## Architecture\n\n```\n┌───────────────────────────────────────────────────────────────────────┐\n│                        Frontend (React)                               │\n├───────────────────────────────────────────────────────────────────────┤\n│                                                                       │\n│  IssuePanel                                                          │\n│  ├─ [Run Agent] Button → ExecutionConfigDialog                      │\n│  │   ├─ Template Preview (editable)                                 │\n│  │   ├─ Execution Mode: [Worktree | Local]                         │\n│  │   ├─ Base Branch: [main ▼]                                      │\n│  │   ├─ Model: [claude-sonnet-4 ▼]                                 │\n│  │   └─ [Start Execution]                                          │\n│  │                                                                   │\n│  └─ ExecutionHistory                                                │\n│      └─ List of past executions with status                        │\n│                                                                       │\n│  ExecutionView                                                       │\n│  ├─ ExecutionMonitor (AG-UI streaming)                             │\n│  │   ├─ Real-time tool calls                                       │\n│  │   ├─ File changes                                               │\n│  │   └─ Progress indicators                                        │\n│  │                                                                   │\n│  └─ FollowUpPanel                                                   │\n│      ├─ Feedback textarea                                          │\n│      └─ [Send Follow-up]                                           │\n│                                                                       │\n└───────────────────────────────────────────────────────────────────────┘\n                                │\n                                ▼\n┌───────────────────────────────────────────────────────────────────────┐\n│                         Backend (Server)                              │\n├───────────────────────────────────────────────────────────────────────┤\n│                                                                       │\n│  API Routes                                                          │\n│  ├─ POST   /api/issues/:issueId/executions/prepare                 │\n│  │   → Returns template preview + defaults                          │\n│  │                                                                   │\n│  ├─ POST   /api/issues/:issueId/executions                         │\n│  │   → Creates and starts execution                                │\n│  │                                                                   │\n│  ├─ GET    /api/executions/:executionId                            │\n│  │   → Returns execution state                                      │\n│  │                                                                   │\n│  ├─ GET    /api/executions/:executionId/stream (SSE)               │\n│  │   → Real-time AG-UI events                                      │\n│  │                                                                   │\n│  ├─ POST   /api/executions/:executionId/follow-up                  │\n│  │   → Continues execution with user feedback                      │\n│  │                                                                   │\n│  └─ DELETE /api/executions/:executionId                            │\n│      → Cancels execution + cleanup                                  │\n│                                                                       │\n├───────────────────────────────────────────────────────────────────────┤\n│                                                                       │\n│  ExecutionService                                                    │\n│  ├─ prepareExecution(issueId, config?)                             │\n│  │   ├─ Load issue + related specs/feedback                        │\n│  │   ├─ Render prompt template                                     │\n│  │   └─ Return preview                                             │\n│  │                                                                   │\n│  ├─ createExecution(issueId, config)                               │\n│  │   ├─ Create DB record                                           │\n│  │   ├─ Setup execution environment                                │\n│  │   │   ├─ [Worktree Mode] Create isolated worktree              │\n│  │   │   └─ [Local Mode] Validate working directory               │\n│  │   ├─ Build workflow definition                                  │\n│  │   ├─ Start LinearOrchestrator                                   │\n│  │   └─ Return executionId                                         │\n│  │                                                                   │\n│  ├─ createFollowUp(executionId, feedback)                          │\n│  │   ├─ Load execution state                                       │\n│  │   ├─ Append feedback to context                                │\n│  │   ├─ Create follow-up workflow step                            │\n│  │   └─ Resume orchestrator                                        │\n│  │                                                                   │\n│  └─ cleanupExecution(executionId, mode)                            │\n│      ├─ [Auto] Cleanup on success                                  │\n│      ├─ [Manual] User-triggered cleanup                            │\n│      └─ [OnStartup] Orphaned worktree cleanup                      │\n│                                                                       │\n├───────────────────────────────────────────────────────────────────────┤\n│                                                                       │\n│  PromptTemplateEngine                                                │\n│  ├─ renderTemplate(template, context)                               │\n│  ├─ getDefaultTemplate(taskType)                                    │\n│  └─ validateTemplate(template)                                      │\n│                                                                       │\n│  WorktreeManager (SPEC-010)                                          │\n│  ├─ createWorktree(executionId, baseBranch)                        │\n│  ├─ getWorktreePath(executionId)                                   │\n│  └─ removeWorktree(executionId)                                    │\n│                                                                       │\n│  LinearOrchestrator + AgUiAdapter (SPEC-006, 009)                   │\n│  └─ Executes workflow with real-time event streaming               │\n│                                                                       │\n└───────────────────────────────────────────────────────────────────────┘\n```\n\n## Part 1: Core Types\n\n### Execution Database Entity\n\n```typescript\n/**\n * Execution - Persistent execution record\n *\n * Stored in database to track all agent executions for issues\n */\nexport interface Execution {\n  // Identity\n  id: string;                        // UUID\n  issueId: string;                   // Parent issue\n\n  // Configuration\n  mode: ExecutionMode;               // 'worktree' | 'local'\n  baseBranch: string;                // Base git branch\n  worktreePath?: string;             // Path if using worktree mode\n  prompt: string;                    // Rendered prompt sent to agent\n\n  // State\n  status: ExecutionStatus;\n  workflowExecutionId: string;       // Links to WorkflowExecution\n\n  // Metadata\n  model: string;                     // e.g., 'claude-sonnet-4'\n  config: ExecutionConfig;           // User-configurable settings\n\n  // Lifecycle\n  createdAt: Date;\n  startedAt?: Date;\n  completedAt?: Date;\n  cancelledAt?: Date;\n\n  // Results\n  filesChanged?: string[];\n  error?: string;\n\n  // Relationships\n  parentExecutionId?: string;        // If this is a follow-up\n  followUpExecutionIds?: string[];   // Child follow-ups\n}\n\nexport type ExecutionMode =\n  | 'worktree'  // Isolated git worktree\n  | 'local';    // Local working directory\n\nexport type ExecutionStatus =\n  | 'preparing'   // Template being prepared\n  | 'pending'     // Created, not yet started\n  | 'running'     // Agent executing\n  | 'paused'      // Execution paused (awaiting follow-up)\n  | 'completed'   // Successfully finished\n  | 'failed'      // Execution failed\n  | 'cancelled';  // User cancelled\n```\n\n### ExecutionConfig\n\n```typescript\n/**\n * ExecutionConfig - User-configurable execution settings\n */\nexport interface ExecutionConfig {\n  // Agent settings\n  model?: string;                    // Override default model\n  maxTokens?: number;\n  temperature?: number;\n\n  // Execution behavior\n  timeout?: number;                  // Overall timeout (ms)\n  retryPolicy?: RetryPolicy;         // From SPEC-005\n\n  // Worktree settings (if mode === 'worktree')\n  baseBranch?: string;               // Branch to base worktree on\n  branchName?: string;               // Override auto-generated branch name\n  cleanupMode?: CleanupMode;         // When to cleanup worktree\n\n  // Workflow settings\n  checkpointInterval?: number;       // Steps between checkpoints\n  continueOnStepFailure?: boolean;   // Continue after step failure\n\n  // Output settings\n  captureFileChanges?: boolean;\n  captureToolCalls?: boolean;\n}\n\nexport type CleanupMode =\n  | 'auto'       // Cleanup on successful completion\n  | 'manual'     // User must manually cleanup\n  | 'never';     // Never auto-cleanup (for debugging)\n```\n\n### PromptTemplate\n\n```typescript\n/**\n * PromptTemplate - Configurable template for generating agent prompts\n */\nexport interface PromptTemplate {\n  id: string;\n  name: string;\n  description: string;\n\n  // Template types\n  type: 'issue' | 'spec' | 'custom';\n\n  // Template content with variables\n  template: string;\n\n  // Available variables in template\n  variables: PromptVariable[];\n\n  // Metadata\n  isDefault?: boolean;\n  createdAt: Date;\n  updatedAt: Date;\n}\n\nexport interface PromptVariable {\n  name: string;                      // e.g., 'issueId', 'title', 'description'\n  description: string;\n  type: 'string' | 'number' | 'boolean' | 'array' | 'object';\n  required: boolean;\n  defaultValue?: any;\n}\n\n/**\n * Default issue prompt template\n */\nexport const DEFAULT_ISSUE_TEMPLATE = `Fix issue {{issueId}}: {{title}}\n\n## Description\n{{description}}\n\n{{#if relatedSpecs}}\n## Related Specifications\n{{#each relatedSpecs}}\n- [[{{id}}]]: {{title}}\n{{/each}}\n{{/if}}\n\n{{#if feedback}}\n## Feedback from Previous Attempts\n{{#each feedback}}\n- {{content}} (from {{issueId}})\n{{/each}}\n{{/if}}\n\nPlease implement a solution for this issue. Make sure to:\n1. Read and understand the issue requirements\n2. Check related specifications for context\n3. Write clean, well-tested code\n4. Update documentation if needed\n`;\n```\n\n### ExecutionPrepareResult\n\n```typescript\n/**\n * ExecutionPrepareResult - Preview before starting execution\n */\nexport interface ExecutionPrepareResult {\n  // Rendered preview\n  renderedPrompt: string;\n\n  // Issue context\n  issue: {\n    id: string;\n    title: string;\n    description: string;\n  };\n\n  // Related context\n  relatedSpecs: Array<{ id: string; title: string }>;\n  relatedFeedback: Array<{ issueId: string; content: string }>;\n\n  // Default configuration\n  defaultConfig: ExecutionConfig;\n\n  // Available options\n  availableModels: string[];\n  availableBranches: string[];\n  availableTemplates: PromptTemplate[];\n\n  // Validation\n  warnings?: string[];\n  errors?: string[];\n}\n```\n\n## Part 2: Service Layer\n\n### ExecutionService\n\n```typescript\nexport class ExecutionService {\n  constructor(\n    private db: Database,\n    private worktreeManager: WorktreeManager,\n    private orchestratorFactory: OrchestratorFactory,\n    private transportManager: TransportManager\n  ) {}\n\n  /**\n   * Prepare execution - render template and show preview\n   */\n  async prepareExecution(\n    issueId: string,\n    options?: {\n      templateId?: string;\n      config?: Partial<ExecutionConfig>;\n    }\n  ): Promise<ExecutionPrepareResult> {\n    // 1. Load issue\n    const issue = await this.db.issues.findById(issueId);\n    if (!issue) {\n      throw new Error(`Issue ${issueId} not found`);\n    }\n\n    // 2. Load related specs (via relationships)\n    const relatedSpecs = await this.db.relationships.getRelatedSpecs(issueId);\n\n    // 3. Load feedback from related issues\n    const relatedFeedback = await this.db.feedback.getForIssue(issueId);\n\n    // 4. Get template\n    const template = options?.templateId\n      ? await this.db.templates.findById(options.templateId)\n      : await this.getDefaultTemplate('issue');\n\n    // 5. Build context for template rendering\n    const context = {\n      issueId: issue.id,\n      title: issue.title,\n      description: issue.description,\n      relatedSpecs: relatedSpecs.map(s => ({\n        id: s.id,\n        title: s.title,\n      })),\n      feedback: relatedFeedback.map(f => ({\n        issueId: f.fromIssueId,\n        content: f.content,\n      })),\n    };\n\n    // 6. Render template\n    const renderedPrompt = this.templateEngine.render(\n      template.template,\n      context\n    );\n\n    // 7. Get default config\n    const defaultConfig: ExecutionConfig = {\n      model: 'claude-sonnet-4',\n      baseBranch: 'main',\n      cleanupMode: 'auto',\n      checkpointInterval: 1,\n      continueOnStepFailure: false,\n      captureFileChanges: true,\n      captureToolCalls: true,\n      ...options?.config,\n    };\n\n    // 8. Get available options\n    const availableModels = ['claude-sonnet-4', 'claude-opus-4'];\n    const availableBranches = await this.gitService.listBranches();\n    const availableTemplates = await this.db.templates.findByType('issue');\n\n    // 9. Validate\n    const warnings: string[] = [];\n    const errors: string[] = [];\n\n    if (!renderedPrompt.trim()) {\n      errors.push('Rendered prompt is empty');\n    }\n\n    // Check for uncommitted changes if using local mode\n    if (options?.config?.mode === 'local') {\n      const hasChanges = await this.gitService.hasUncommittedChanges();\n      if (hasChanges) {\n        warnings.push(\n          'Working directory has uncommitted changes. ' +\n          'Consider using worktree mode for isolation.'\n        );\n      }\n    }\n\n    return {\n      renderedPrompt,\n      issue: {\n        id: issue.id,\n        title: issue.title,\n        description: issue.description,\n      },\n      relatedSpecs,\n      relatedFeedback,\n      defaultConfig,\n      availableModels,\n      availableBranches,\n      availableTemplates,\n      warnings,\n      errors,\n    };\n  }\n\n  /**\n   * Create and start execution\n   */\n  async createExecution(\n    issueId: string,\n    config: ExecutionConfig,\n    prompt: string\n  ): Promise<Execution> {\n    // 1. Validate\n    if (!prompt.trim()) {\n      throw new Error('Prompt cannot be empty');\n    }\n\n    const issue = await this.db.issues.findById(issueId);\n    if (!issue) {\n      throw new Error(`Issue ${issueId} not found`);\n    }\n\n    // 2. Determine execution mode\n    const mode = config.mode || 'worktree';\n    let worktreePath: string | undefined;\n    let workDir: string;\n\n    if (mode === 'worktree') {\n      // Create isolated worktree\n      const executionId = generateId('exec');\n      worktreePath = await this.worktreeManager.createWorktree(\n        executionId,\n        config.baseBranch || 'main',\n        config.branchName\n      );\n      workDir = worktreePath;\n    } else {\n      // Use local working directory\n      workDir = process.cwd();\n    }\n\n    // 3. Create execution record\n    const execution: Execution = {\n      id: generateId('exec'),\n      issueId,\n      mode,\n      baseBranch: config.baseBranch || 'main',\n      worktreePath,\n      prompt,\n      status: 'pending',\n      workflowExecutionId: '', // Will be set below\n      model: config.model || 'claude-sonnet-4',\n      config,\n      createdAt: new Date(),\n    };\n\n    await this.db.executions.create(execution);\n\n    // 4. Build workflow definition\n    const workflow: WorkflowDefinition = {\n      id: `issue-${issueId}-workflow`,\n      steps: [\n        {\n          id: 'implement',\n          taskType: 'issue',\n          prompt,\n          dependencies: [],\n          retryPolicy: config.retryPolicy,\n          timeout: config.timeout,\n        },\n      ],\n      initialContext: {\n        issueId,\n        executionId: execution.id,\n        mode,\n      },\n      config: {\n        checkpointInterval: config.checkpointInterval,\n        continueOnStepFailure: config.continueOnStepFailure,\n      },\n      metadata: {\n        workDir,\n      },\n    };\n\n    // 5. Create AG-UI adapter for this execution\n    const agUiAdapter = new AgUiEventAdapter(\n      execution.id,\n      execution.id // threadId = executionId\n    );\n\n    // Connect to SSE transport\n    this.transportManager.connectAdapter(agUiAdapter, execution.id);\n\n    // 6. Create and start orchestrator\n    const orchestrator = this.orchestratorFactory.create(agUiAdapter);\n\n    const workflowExecutionId = await orchestrator.startWorkflow(\n      workflow,\n      workDir,\n      {\n        checkpointInterval: config.checkpointInterval,\n        initialContext: workflow.initialContext,\n      }\n    );\n\n    // 7. Update execution with workflow ID\n    execution.workflowExecutionId = workflowExecutionId;\n    execution.status = 'running';\n    execution.startedAt = new Date();\n    await this.db.executions.update(execution);\n\n    // 8. Setup completion handlers\n    orchestrator.onWorkflowComplete(async (executionId, result) => {\n      await this.handleWorkflowComplete(execution.id, result);\n    });\n\n    orchestrator.onWorkflowFailed(async (executionId, error) => {\n      await this.handleWorkflowFailed(execution.id, error);\n    });\n\n    return execution;\n  }\n\n  /**\n   * Create follow-up execution (continue in same worktree)\n   */\n  async createFollowUp(\n    executionId: string,\n    feedback: string\n  ): Promise<Execution> {\n    // 1. Load parent execution\n    const parentExecution = await this.db.executions.findById(executionId);\n    if (!parentExecution) {\n      throw new Error(`Execution ${executionId} not found`);\n    }\n\n    if (parentExecution.status === 'running') {\n      throw new Error('Cannot create follow-up while execution is running');\n    }\n\n    // 2. Build follow-up prompt\n    const followUpPrompt = `${parentExecution.prompt}\n\n---\n\nUser feedback: ${feedback}\n\nPlease address the feedback above and continue working on the issue.`;\n\n    // 3. Create follow-up execution (same mode, same worktree if applicable)\n    const followUpExecution: Execution = {\n      id: generateId('exec'),\n      issueId: parentExecution.issueId,\n      mode: parentExecution.mode,\n      baseBranch: parentExecution.baseBranch,\n      worktreePath: parentExecution.worktreePath, // Reuse same worktree\n      prompt: followUpPrompt,\n      status: 'pending',\n      workflowExecutionId: '',\n      model: parentExecution.model,\n      config: parentExecution.config,\n      parentExecutionId: parentExecution.id,\n      createdAt: new Date(),\n    };\n\n    await this.db.executions.create(followUpExecution);\n\n    // 4. Update parent to track this follow-up\n    parentExecution.followUpExecutionIds = [\n      ...(parentExecution.followUpExecutionIds || []),\n      followUpExecution.id,\n    ];\n    await this.db.executions.update(parentExecution);\n\n    // 5. Start execution (same as createExecution but reuse worktree)\n    const workDir = parentExecution.worktreePath || process.cwd();\n\n    const workflow: WorkflowDefinition = {\n      id: `issue-${parentExecution.issueId}-follow-up-workflow`,\n      steps: [\n        {\n          id: 'follow-up',\n          taskType: 'issue',\n          prompt: followUpPrompt,\n          dependencies: [],\n        },\n      ],\n      initialContext: {\n        issueId: parentExecution.issueId,\n        executionId: followUpExecution.id,\n        parentExecutionId: parentExecution.id,\n        mode: parentExecution.mode,\n      },\n    };\n\n    const agUiAdapter = new AgUiEventAdapter(\n      followUpExecution.id,\n      followUpExecution.id\n    );\n    this.transportManager.connectAdapter(agUiAdapter, followUpExecution.id);\n\n    const orchestrator = this.orchestratorFactory.create(agUiAdapter);\n    const workflowExecutionId = await orchestrator.startWorkflow(\n      workflow,\n      workDir\n    );\n\n    followUpExecution.workflowExecutionId = workflowExecutionId;\n    followUpExecution.status = 'running';\n    followUpExecution.startedAt = new Date();\n    await this.db.executions.update(followUpExecution);\n\n    return followUpExecution;\n  }\n\n  /**\n   * Cancel execution and cleanup\n   */\n  async cancelExecution(executionId: string): Promise<void> {\n    const execution = await this.db.executions.findById(executionId);\n    if (!execution) {\n      throw new Error(`Execution ${executionId} not found`);\n    }\n\n    // 1. Cancel workflow orchestrator\n    const orchestrator = this.orchestratorFactory.get(\n      execution.workflowExecutionId\n    );\n    if (orchestrator) {\n      await orchestrator.cancelWorkflow(execution.workflowExecutionId);\n    }\n\n    // 2. Update status\n    execution.status = 'cancelled';\n    execution.cancelledAt = new Date();\n    await this.db.executions.update(execution);\n\n    // 3. Cleanup if auto mode\n    if (execution.config.cleanupMode === 'auto' && execution.worktreePath) {\n      await this.cleanupExecution(executionId);\n    }\n  }\n\n  /**\n   * Cleanup execution resources\n   */\n  async cleanupExecution(executionId: string): Promise<void> {\n    const execution = await this.db.executions.findById(executionId);\n    if (!execution) {\n      throw new Error(`Execution ${executionId} not found`);\n    }\n\n    // Only cleanup if using worktree mode\n    if (execution.mode === 'worktree' && execution.worktreePath) {\n      await this.worktreeManager.removeWorktree(executionId);\n    }\n  }\n\n  /**\n   * Get execution by ID\n   */\n  async getExecution(executionId: string): Promise<Execution | null> {\n    return this.db.executions.findById(executionId);\n  }\n\n  /**\n   * List executions for an issue\n   */\n  async listExecutions(issueId: string): Promise<Execution[]> {\n    return this.db.executions.findByIssueId(issueId);\n  }\n\n  /**\n   * Handle workflow completion\n   */\n  private async handleWorkflowComplete(\n    executionId: string,\n    result: WorkflowResult\n  ): Promise<void> {\n    const execution = await this.db.executions.findById(executionId);\n    if (!execution) return;\n\n    execution.status = 'completed';\n    execution.completedAt = new Date();\n    execution.filesChanged = result.outputs.filesChanged || [];\n    await this.db.executions.update(execution);\n\n    // Auto-cleanup if configured\n    if (execution.config.cleanupMode === 'auto' && result.success) {\n      await this.cleanupExecution(executionId);\n    }\n  }\n\n  /**\n   * Handle workflow failure\n   */\n  private async handleWorkflowFailed(\n    executionId: string,\n    error: Error\n  ): Promise<void> {\n    const execution = await this.db.executions.findById(executionId);\n    if (!execution) return;\n\n    execution.status = 'failed';\n    execution.completedAt = new Date();\n    execution.error = error.message;\n    await this.db.executions.update(execution);\n  }\n\n  /**\n   * Get default template for task type\n   */\n  private async getDefaultTemplate(type: string): Promise<PromptTemplate> {\n    const defaultTemplates = await this.db.templates.findByType(type);\n    const defaultTemplate = defaultTemplates.find(t => t.isDefault);\n\n    if (!defaultTemplate) {\n      // Return built-in default\n      return {\n        id: 'default-issue',\n        name: 'Default Issue Template',\n        description: 'Default template for issue execution',\n        type: 'issue',\n        template: DEFAULT_ISSUE_TEMPLATE,\n        variables: [\n          {\n            name: 'issueId',\n            description: 'Issue identifier',\n            type: 'string',\n            required: true,\n          },\n          {\n            name: 'title',\n            description: 'Issue title',\n            type: 'string',\n            required: true,\n          },\n          {\n            name: 'description',\n            description: 'Issue description',\n            type: 'string',\n            required: true,\n          },\n        ],\n        isDefault: true,\n        createdAt: new Date(),\n        updatedAt: new Date(),\n      };\n    }\n\n    return defaultTemplate;\n  }\n}\n```\n\n### PromptTemplateEngine\n\n```typescript\n/**\n * Simple template engine with Handlebars-like syntax\n */\nexport class PromptTemplateEngine {\n  /**\n   * Render template with context variables\n   */\n  render(template: string, context: Record<string, any>): string {\n    let result = template;\n\n    // Replace simple variables: {{variable}}\n    result = result.replace(/\\{\\{([^}#/]+)\\}\\}/g, (match, key) => {\n      const value = this.getValue(context, key.trim());\n      return value !== undefined ? String(value) : match;\n    });\n\n    // Handle conditionals: {{#if variable}}...{{/if}}\n    result = result.replace(\n      /\\{\\{#if ([^}]+)\\}\\}([\\s\\S]*?)\\{\\{\\/if\\}\\}/g,\n      (match, key, content) => {\n        const value = this.getValue(context, key.trim());\n        return value ? content : '';\n      }\n    );\n\n    // Handle loops: {{#each array}}...{{/each}}\n    result = result.replace(\n      /\\{\\{#each ([^}]+)\\}\\}([\\s\\S]*?)\\{\\{\\/each\\}\\}/g,\n      (match, key, itemTemplate) => {\n        const array = this.getValue(context, key.trim());\n        if (!Array.isArray(array)) return '';\n\n        return array\n          .map(item => this.render(itemTemplate, item))\n          .join('');\n      }\n    );\n\n    return result;\n  }\n\n  /**\n   * Get nested value from context\n   */\n  private getValue(context: Record<string, any>, path: string): any {\n    const keys = path.split('.');\n    let value: any = context;\n\n    for (const key of keys) {\n      if (value === null || value === undefined) return undefined;\n      value = value[key];\n    }\n\n    return value;\n  }\n\n  /**\n   * Validate template syntax\n   */\n  validate(template: string): { valid: boolean; errors: string[] } {\n    const errors: string[] = [];\n\n    // Check for balanced tags\n    const ifCount = (template.match(/\\{\\{#if/g) || []).length;\n    const endIfCount = (template.match(/\\{\\{\\/if\\}\\}/g) || []).length;\n    if (ifCount !== endIfCount) {\n      errors.push(`Unbalanced {{#if}} tags (${ifCount} vs ${endIfCount})`);\n    }\n\n    const eachCount = (template.match(/\\{\\{#each/g) || []).length;\n    const endEachCount = (template.match(/\\{\\{\\/each\\}\\}/g) || []).length;\n    if (eachCount !== endEachCount) {\n      errors.push(`Unbalanced {{#each}} tags (${eachCount} vs ${endEachCount})`);\n    }\n\n    return {\n      valid: errors.length === 0,\n      errors,\n    };\n  }\n}\n```\n\n## Part 3: API Routes\n\n```typescript\n// server/src/routes/executions.ts\n\n/**\n * Prepare execution - preview before starting\n * POST /api/issues/:issueId/executions/prepare\n */\nrouter.post(\n  '/issues/:issueId/executions/prepare',\n  async (req: Request, res: Response) => {\n    const { issueId } = req.params;\n    const { templateId, config } = req.body;\n\n    const result = await executionService.prepareExecution(issueId, {\n      templateId,\n      config,\n    });\n\n    res.json(result);\n  }\n);\n\n/**\n * Create and start execution\n * POST /api/issues/:issueId/executions\n */\nrouter.post(\n  '/issues/:issueId/executions',\n  async (req: Request, res: Response) => {\n    const { issueId } = req.params;\n    const { config, prompt } = req.body;\n\n    const execution = await executionService.createExecution(\n      issueId,\n      config,\n      prompt\n    );\n\n    res.json(execution);\n  }\n);\n\n/**\n * Get execution by ID\n * GET /api/executions/:executionId\n */\nrouter.get(\n  '/executions/:executionId',\n  async (req: Request, res: Response) => {\n    const { executionId } = req.params;\n    const execution = await executionService.getExecution(executionId);\n\n    if (!execution) {\n      return res.status(404).json({ error: 'Execution not found' });\n    }\n\n    res.json(execution);\n  }\n);\n\n/**\n * Stream execution events (SSE)\n * GET /api/executions/:executionId/stream\n */\nrouter.get(\n  '/executions/:executionId/stream',\n  async (req: Request, res: Response) => {\n    const { executionId } = req.params;\n    const clientId = generateId('client');\n\n    // Get SSE transport from transport manager\n    const sseTransport = transportManager.getSseTransport();\n    sseTransport.handleConnection(clientId, res, executionId);\n  }\n);\n\n/**\n * Create follow-up execution\n * POST /api/executions/:executionId/follow-up\n */\nrouter.post(\n  '/executions/:executionId/follow-up',\n  async (req: Request, res: Response) => {\n    const { executionId } = req.params;\n    const { feedback } = req.body;\n\n    const followUpExecution = await executionService.createFollowUp(\n      executionId,\n      feedback\n    );\n\n    res.json(followUpExecution);\n  }\n);\n\n/**\n * Cancel execution\n * DELETE /api/executions/:executionId\n */\nrouter.delete(\n  '/executions/:executionId',\n  async (req: Request, res: Response) => {\n    const { executionId } = req.params;\n    await executionService.cancelExecution(executionId);\n    res.json({ message: 'Execution cancelled' });\n  }\n);\n\n/**\n * List executions for issue\n * GET /api/issues/:issueId/executions\n */\nrouter.get(\n  '/issues/:issueId/executions',\n  async (req: Request, res: Response) => {\n    const { issueId } = req.params;\n    const executions = await executionService.listExecutions(issueId);\n    res.json(executions);\n  }\n);\n```\n\n## Part 4: Frontend Components\n\n### ExecutionConfigDialog\n\n```typescript\n// frontend/src/components/executions/ExecutionConfigDialog.tsx\n\nexport interface ExecutionConfigDialogProps {\n  issueId: string;\n  onStart: (config: ExecutionConfig, prompt: string) => void;\n  onCancel: () => void;\n}\n\nexport const ExecutionConfigDialog: React.FC<ExecutionConfigDialogProps> = ({\n  issueId,\n  onStart,\n  onCancel,\n}) => {\n  const [preparing, setPreparing] = useState(true);\n  const [preview, setPreview] = useState<ExecutionPrepareResult | null>(null);\n  const [prompt, setPrompt] = useState('');\n  const [config, setConfig] = useState<ExecutionConfig>({\n    mode: 'worktree',\n    model: 'claude-sonnet-4',\n    baseBranch: 'main',\n    cleanupMode: 'auto',\n  });\n\n  // Load preview on mount\n  useEffect(() => {\n    async function loadPreview() {\n      const response = await fetch(\n        `/api/issues/${issueId}/executions/prepare`,\n        {\n          method: 'POST',\n          headers: { 'Content-Type': 'application/json' },\n          body: JSON.stringify({ config }),\n        }\n      );\n      const result = await response.json();\n      setPreview(result);\n      setPrompt(result.renderedPrompt);\n      setPreparing(false);\n    }\n    loadPreview();\n  }, [issueId]);\n\n  const handleStart = () => {\n    onStart(config, prompt);\n  };\n\n  if (preparing || !preview) {\n    return <div>Loading...</div>;\n  }\n\n  return (\n    <Dialog>\n      <DialogHeader>\n        <DialogTitle>Configure Execution</DialogTitle>\n      </DialogHeader>\n\n      <div className=\"space-y-4\">\n        {/* Warnings */}\n        {preview.warnings && preview.warnings.length > 0 && (\n          <div className=\"bg-yellow-50 p-3 rounded\">\n            {preview.warnings.map((w, i) => (\n              <div key={i} className=\"text-sm text-yellow-800\">\n                ⚠️ {w}\n              </div>\n            ))}\n          </div>\n        )}\n\n        {/* Execution Mode */}\n        <div>\n          <label className=\"block text-sm font-medium mb-2\">\n            Execution Mode\n          </label>\n          <select\n            value={config.mode}\n            onChange={(e) =>\n              setConfig({ ...config, mode: e.target.value as ExecutionMode })\n            }\n            className=\"w-full border rounded p-2\"\n          >\n            <option value=\"worktree\">Isolated Worktree (Recommended)</option>\n            <option value=\"local\">Local Working Directory</option>\n          </select>\n          <p className=\"text-xs text-gray-500 mt-1\">\n            {config.mode === 'worktree'\n              ? 'Creates isolated git worktree for safe execution'\n              : 'Runs in your current working directory'}\n          </p>\n        </div>\n\n        {/* Base Branch (if worktree mode) */}\n        {config.mode === 'worktree' && (\n          <div>\n            <label className=\"block text-sm font-medium mb-2\">\n              Base Branch\n            </label>\n            <select\n              value={config.baseBranch}\n              onChange={(e) =>\n                setConfig({ ...config, baseBranch: e.target.value })\n              }\n              className=\"w-full border rounded p-2\"\n            >\n              {preview.availableBranches.map((branch) => (\n                <option key={branch} value={branch}>\n                  {branch}\n                </option>\n              ))}\n            </select>\n          </div>\n        )}\n\n        {/* Model */}\n        <div>\n          <label className=\"block text-sm font-medium mb-2\">Model</label>\n          <select\n            value={config.model}\n            onChange={(e) => setConfig({ ...config, model: e.target.value })}\n            className=\"w-full border rounded p-2\"\n          >\n            {preview.availableModels.map((model) => (\n              <option key={model} value={model}>\n                {model}\n              </option>\n            ))}\n          </select>\n        </div>\n\n        {/* Cleanup Mode (if worktree) */}\n        {config.mode === 'worktree' && (\n          <div>\n            <label className=\"block text-sm font-medium mb-2\">\n              Worktree Cleanup\n            </label>\n            <select\n              value={config.cleanupMode}\n              onChange={(e) =>\n                setConfig({\n                  ...config,\n                  cleanupMode: e.target.value as CleanupMode,\n                })\n              }\n              className=\"w-full border rounded p-2\"\n            >\n              <option value=\"auto\">Auto (on success)</option>\n              <option value=\"manual\">Manual</option>\n              <option value=\"never\">Never (debugging)</option>\n            </select>\n          </div>\n        )}\n\n        {/* Prompt Preview (Editable) */}\n        <div>\n          <label className=\"block text-sm font-medium mb-2\">\n            Prompt (Editable)\n          </label>\n          <textarea\n            value={prompt}\n            onChange={(e) => setPrompt(e.target.value)}\n            className=\"w-full border rounded p-2 font-mono text-sm\"\n            rows={15}\n          />\n        </div>\n      </div>\n\n      <DialogFooter>\n        <button onClick={onCancel} className=\"btn-secondary\">\n          Cancel\n        </button>\n        <button\n          onClick={handleStart}\n          disabled={preview.errors && preview.errors.length > 0}\n          className=\"btn-primary\"\n        >\n          Start Execution\n        </button>\n      </DialogFooter>\n    </Dialog>\n  );\n};\n```\n\n### ExecutionView\n\n```typescript\n// frontend/src/components/executions/ExecutionView.tsx\n\nexport interface ExecutionViewProps {\n  executionId: string;\n}\n\nexport const ExecutionView: React.FC<ExecutionViewProps> = ({\n  executionId,\n}) => {\n  const [execution, setExecution] = useState<Execution | null>(null);\n  const [showFollowUp, setShowFollowUp] = useState(false);\n\n  const agUiStream = useAgUiStream({\n    executionId,\n    onEvent: {\n      onRunFinished: () => {\n        // Reload execution to get final state\n        loadExecution();\n      },\n    },\n  });\n\n  useEffect(() => {\n    loadExecution();\n  }, [executionId]);\n\n  const loadExecution = async () => {\n    const response = await fetch(`/api/executions/${executionId}`);\n    const data = await response.json();\n    setExecution(data);\n  };\n\n  const handleFollowUp = async (feedback: string) => {\n    await fetch(`/api/executions/${executionId}/follow-up`, {\n      method: 'POST',\n      headers: { 'Content-Type': 'application/json' },\n      body: JSON.stringify({ feedback }),\n    });\n    setShowFollowUp(false);\n  };\n\n  const handleCancel = async () => {\n    await fetch(`/api/executions/${executionId}`, {\n      method: 'DELETE',\n    });\n    loadExecution();\n  };\n\n  if (!execution) {\n    return <div>Loading...</div>;\n  }\n\n  return (\n    <div className=\"execution-view\">\n      {/* Header */}\n      <div className=\"flex items-center justify-between mb-4\">\n        <div>\n          <h2 className=\"text-xl font-semibold\">\n            Execution {execution.id}\n          </h2>\n          <div className=\"flex items-center gap-2 text-sm text-gray-600\">\n            <span>Mode: {execution.mode}</span>\n            <span>•</span>\n            <span>Model: {execution.model}</span>\n            <span>•</span>\n            <span className={`status-${execution.status}`}>\n              {execution.status}\n            </span>\n          </div>\n        </div>\n\n        <div className=\"flex gap-2\">\n          {execution.status === 'running' && (\n            <button onClick={handleCancel} className=\"btn-danger\">\n              Cancel\n            </button>\n          )}\n          {['completed', 'failed'].includes(execution.status) && (\n            <button\n              onClick={() => setShowFollowUp(true)}\n              className=\"btn-primary\"\n            >\n              Follow Up\n            </button>\n          )}\n        </div>\n      </div>\n\n      {/* Execution Monitor (AG-UI streaming) */}\n      <ExecutionMonitor\n        executionId={executionId}\n        onComplete={() => loadExecution()}\n      />\n\n      {/* Follow-up Dialog */}\n      {showFollowUp && (\n        <FollowUpDialog\n          onSubmit={handleFollowUp}\n          onCancel={() => setShowFollowUp(false)}\n        />\n      )}\n    </div>\n  );\n};\n```\n\n### FollowUpDialog\n\n```typescript\n// frontend/src/components/executions/FollowUpDialog.tsx\n\nexport interface FollowUpDialogProps {\n  onSubmit: (feedback: string) => void;\n  onCancel: () => void;\n}\n\nexport const FollowUpDialog: React.FC<FollowUpDialogProps> = ({\n  onSubmit,\n  onCancel,\n}) => {\n  const [feedback, setFeedback] = useState('');\n\n  const handleSubmit = () => {\n    if (feedback.trim()) {\n      onSubmit(feedback);\n    }\n  };\n\n  return (\n    <Dialog>\n      <DialogHeader>\n        <DialogTitle>Provide Follow-up Feedback</DialogTitle>\n      </DialogHeader>\n\n      <div className=\"space-y-4\">\n        <p className=\"text-sm text-gray-600\">\n          Describe what changes you'd like the agent to make, or ask questions\n          about the implementation.\n        </p>\n\n        <textarea\n          value={feedback}\n          onChange={(e) => setFeedback(e.target.value)}\n          placeholder=\"e.g., 'Please add error handling for edge cases' or 'Can you explain why you chose this approach?'\"\n          className=\"w-full border rounded p-3\"\n          rows={6}\n        />\n      </div>\n\n      <DialogFooter>\n        <button onClick={onCancel} className=\"btn-secondary\">\n          Cancel\n        </button>\n        <button\n          onClick={handleSubmit}\n          disabled={!feedback.trim()}\n          className=\"btn-primary\"\n        >\n          Send Follow-up\n        </button>\n      </DialogFooter>\n    </Dialog>\n  );\n};\n```\n\n## Part 5: Database Schema\n\n```sql\n-- Executions table\nCREATE TABLE executions (\n  id TEXT PRIMARY KEY,\n  issue_id TEXT NOT NULL REFERENCES issues(id),\n\n  -- Configuration\n  mode TEXT NOT NULL CHECK(mode IN ('worktree', 'local')),\n  base_branch TEXT NOT NULL,\n  worktree_path TEXT,\n  prompt TEXT NOT NULL,\n\n  -- State\n  status TEXT NOT NULL CHECK(status IN (\n    'preparing', 'pending', 'running', 'paused',\n    'completed', 'failed', 'cancelled'\n  )),\n  workflow_execution_id TEXT NOT NULL,\n\n  -- Metadata\n  model TEXT NOT NULL,\n  config JSONB NOT NULL,\n\n  -- Lifecycle\n  created_at TIMESTAMP NOT NULL DEFAULT NOW(),\n  started_at TIMESTAMP,\n  completed_at TIMESTAMP,\n  cancelled_at TIMESTAMP,\n\n  -- Results\n  files_changed JSONB,\n  error TEXT,\n\n  -- Relationships\n  parent_execution_id TEXT REFERENCES executions(id),\n\n  -- Indexes\n  INDEX idx_executions_issue_id (issue_id),\n  INDEX idx_executions_status (status),\n  INDEX idx_executions_parent (parent_execution_id)\n);\n\n-- Prompt templates table\nCREATE TABLE prompt_templates (\n  id TEXT PRIMARY KEY,\n  name TEXT NOT NULL,\n  description TEXT,\n  type TEXT NOT NULL CHECK(type IN ('issue', 'spec', 'custom')),\n  template TEXT NOT NULL,\n  variables JSONB NOT NULL,\n  is_default BOOLEAN DEFAULT FALSE,\n  created_at TIMESTAMP NOT NULL DEFAULT NOW(),\n  updated_at TIMESTAMP NOT NULL DEFAULT NOW(),\n\n  INDEX idx_templates_type (type),\n  INDEX idx_templates_default (is_default)\n);\n```\n\n## Testing Strategy\n\n### Unit Tests\n\n1. **PromptTemplateEngine**\n   - Variable substitution\n   - Conditional rendering\n   - Loop rendering\n   - Nested paths\n   - Template validation\n\n2. **ExecutionService**\n   - prepareExecution builds correct preview\n   - createExecution with worktree mode\n   - createExecution with local mode\n   - createFollowUp reuses worktree\n   - Cleanup modes work correctly\n\n### Integration Tests\n\n1. **End-to-end execution flow**\n   - Prepare → Create → Stream → Complete\n   - Follow-up workflow\n   - Cancel and cleanup\n\n2. **Worktree isolation**\n   - Multiple concurrent executions don't interfere\n   - Follow-ups work in same worktree\n\n### E2E Tests\n\n1. **Frontend workflow**\n   - Open config dialog → edit prompt → start\n   - Monitor real-time progress\n   - Submit follow-up\n   - View execution history\n\n## Implementation Checklist\n\n### Backend\n\n- [ ] Define Execution entity schema\n- [ ] Create database migrations\n- [ ] Implement PromptTemplateEngine\n- [ ] Implement ExecutionService\n- [ ] Add API routes for executions\n- [ ] Integrate with WorktreeManager\n- [ ] Wire up AG-UI streaming\n- [ ] Add default prompt templates\n- [ ] Write unit tests\n- [ ] Write integration tests\n\n### Frontend\n\n- [ ] Create ExecutionConfigDialog component\n- [ ] Create ExecutionView component\n- [ ] Create FollowUpDialog component\n- [ ] Add \"Run Agent\" button to IssuePanel\n- [ ] Add execution history to IssuePanel\n- [ ] Wire up SSE streaming with useAgUiStream\n- [ ] Add styling and animations\n- [ ] Write component tests\n- [ ] Write E2E tests\n\n### Documentation\n\n- [ ] API documentation\n- [ ] User guide for running executions\n- [ ] Template syntax documentation\n- [ ] Troubleshooting guide\n\n## Usage Example\n\n```typescript\n// 1. User clicks \"Run Agent\" on issue\n// Frontend opens ExecutionConfigDialog\n\n// 2. Dialog prepares execution\nconst preview = await fetch('/api/issues/ISSUE-001/executions/prepare', {\n  method: 'POST',\n  body: JSON.stringify({ config: { mode: 'worktree' } }),\n});\n\n// 3. User edits prompt, configures settings, clicks \"Start\"\nconst execution = await fetch('/api/issues/ISSUE-001/executions', {\n  method: 'POST',\n  body: JSON.stringify({\n    config: {\n      mode: 'worktree',\n      model: 'claude-sonnet-4',\n      baseBranch: 'main',\n      cleanupMode: 'auto',\n    },\n    prompt: editedPrompt,\n  }),\n});\n\n// 4. Frontend connects to SSE stream\nconst eventSource = new EventSource(\n  `/api/executions/${execution.id}/stream`\n);\n\n// 5. Real-time events flow via AG-UI protocol\n// RUN_STARTED → STEP_STARTED → TOOL_CALL_START → ... → RUN_FINISHED\n\n// 6. User provides feedback\nawait fetch(`/api/executions/${execution.id}/follow-up`, {\n  method: 'POST',\n  body: JSON.stringify({\n    feedback: 'Please add error handling for edge cases',\n  }),\n});\n\n// 7. New execution starts in same worktree with appended feedback\n```\n\n## Related Specs\n\n- [[SPEC-003]] - Process Layer (spawns Claude Code processes)\n- [[SPEC-004]] - Engine Layer (task queuing)\n- [[SPEC-005]] - Resilience Layer (retry logic)\n- [[SPEC-006]] - Workflow Layer (LinearOrchestrator)\n- [[SPEC-007]] - Output Processing (parses stream-json)\n- [[SPEC-009]] - AG-UI Integration (real-time events)\n- [[SPEC-010]] - Worktree Management (execution isolation)\n","priority":2,"archived":0,"archived_at":null,"created_at":"2025-10-31 04:41:21","updated_at":"2025-11-03T03:10:12.584Z","parent_id":null,"parent_uuid":null,"relationships":[{"from":"SPEC-011","from_type":"spec","to":"SPEC-003","to_type":"spec","type":"references"},{"from":"SPEC-011","from_type":"spec","to":"SPEC-007","to_type":"spec","type":"references"},{"from":"SPEC-011","from_type":"spec","to":"SPEC-009","to_type":"spec","type":"references"},{"from":"SPEC-011","from_type":"spec","to":"SPEC-010","to_type":"spec","type":"references"},{"from":"SPEC-011","from_type":"spec","to":"SPEC-004","to_type":"spec","type":"references"},{"from":"SPEC-011","from_type":"spec","to":"SPEC-005","to_type":"spec","type":"references"},{"from":"SPEC-011","from_type":"spec","to":"SPEC-006","to_type":"spec","type":"references"}],"tags":[]}
{"id":"SPEC-012","uuid":"a77d2a0d-bae8-4582-a1e0-fb42cad68d35","title":"Issue-to-Execution System","file_path":"specs/issue_to_execution_system_SPEC-012.md","content":"End-to-end system for running AI agents on issues with template-based prompts, configurable execution modes (worktree/local), follow-up interactions, and real-time progress monitoring via AG-UI streaming.\n\n**Key Features:**\n\n- Template-driven prompt generation with preview/edit\n- Isolated worktree execution OR local git tree\n- Configurable execution settings (model, cleanup, retries)\n- Follow-up mechanism like Claude Code interaction flow\n- Real-time progress via AG-UI + SSE\n- Auto/manual cleanup options\n\n**Architecture:**\n\n- ExecutionService orchestrates lifecycle\n- PromptTemplateEngine renders customizable templates\n- WorktreeManager provides execution isolation\n- LinearOrchestrator + AgUiAdapter stream real-time events\n- Frontend components for config, monitoring, follow-ups\n\nIntegrates with SPEC-003 through SPEC-010.\n","priority":0,"archived":1,"archived_at":"2025-10-31T08:15:16.563Z","created_at":"2025-10-31 04:41:30","updated_at":"2025-11-03T03:10:12.591Z","parent_id":null,"parent_uuid":null,"relationships":[],"tags":["ag-ui","execution","integration","issue-management","templates","worktree"]}
{"id":"SPEC-013","uuid":"a1df3333-a59c-424a-bc19-9b5cacdecc46","title":"Merge Conflict Resolution & Multi-Developer Improvements","file_path":"specs/merge_conflict_resolution_multi_developer_improvem.md","content":"Comprehensive improvements to sudocode's JSONL storage system to handle merge conflicts, ID collisions, and reference integrity in multi-developer, multi-branch environments.\n\n## Background\n\nSudocode uses a git-native storage model with JSONL files for specs and issues. While this approach works well for single-developer workflows, several problems emerge in multi-developer scenarios:\n\n1. **ID Collision Risk**: Sequential ID generation can create the same ID on different branches\n2. **Reference Corruption**: Inline `[[ID]]` references become orphaned after collision resolution\n3. **Manual Merge Burden**: No tooling to assist with JSONL merge conflicts\n4. **Limited Collision Resolution**: Only one strategy (renumber incoming), not always optimal\n5. **No Reference Validation**: Broken references go undetected\n\nThis spec addresses all identified issues with a phased improvement plan. See full spec at `specs/merge_conflict_resolution.md` for complete details.\n\n## Problem Analysis\n\n### P1: ID Collision on Concurrent Creation (HIGH)\n- Sequential ID generation causes race conditions across branches\n- Example: Two branches both create ISSUE-042 with different UUIDs\n- Results in merge conflicts requiring manual resolution\n\n### P2: Inline Reference Corruption (HIGH)\n- When IDs are renumbered, `[[ID]]` references in markdown aren't updated\n- Silent corruption - references appear valid but point to wrong entity\n- No validation catches these broken references\n\n### P3: JSONL Merge Conflicts (MEDIUM-HIGH)\n- Large JSONL files (308KB+) with line-by-line conflicts\n- No tooling to assist resolution\n- Manual editing error-prone and time-consuming\n\n### P4: Limited Collision Detection & Resolution (MEDIUM)\n- Only one strategy: always renumber incoming entity\n- Doesn't consider age, reference count, or branch hierarchy\n- No user notification or choice\n\n### P5: Reference Integrity Issues (MEDIUM)\n- References stored in 3 places: SQLite, JSONL, markdown\n- No validation ensures consistency\n- Stale references go undetected\n\n### P6: Lack of Merge Tooling (MEDIUM)\n- Zero automation for conflict resolution\n- No pre-commit validation\n- No post-merge validation\n\n## Proposed Solutions\n\n### Solution 1: Pre-Commit ID Collision Detection\n- New command: `sudocode validate-ids`\n- Git pre-commit hook to catch collisions early\n- Zero runtime overhead (only on commit)\n\n### Solution 2: Reference Validation & Repair\n- New command: `sudocode validate-refs --fix`\n- Scans markdown for broken `[[ID]]` references\n- Automated reference updates after ID renumbering\n- Can suggest replacements for broken references\n\n### Solution 3: Interactive Conflict Resolution\n- New command: `sudocode conflicts detect`\n- New command: `sudocode conflicts resolve --interactive`\n- Guided resolution with metadata display\n- Auto-resolution with configurable strategies\n\n### Solution 4: Custom Git Merge Driver\n- Teach git to merge JSONL files intelligently\n- UUID-aware merging\n- Automatic collision resolution\n- Fallback to manual resolution on conflicts\n\n### Solution 5: Improved Collision Resolution Strategy\n- Multiple strategies: older-wins, more-refs-wins, main-wins, etc.\n- Configurable via `config.json`\n- User choice and control\n\n### Solution 6: Collision Audit Log\n- New table: `collision_log` in database\n- Tracks all collisions and resolutions\n- New command: `sudocode collisions show`\n- Complete audit trail for debugging\n\n## Implementation Phases\n\n### Phase 1: Detection & Validation (Week 1)\n- Pre-commit ID validation\n- Reference validation command\n- Documentation\n\n**Issues**:\n- Implement pre-commit ID validation\n- Implement reference validation command\n- Write multi-developer workflow docs\n\n### Phase 2: Automated Repair (Week 2)\n- Automated reference updates\n- Collision logging\n- Integration tests\n\n**Issues**:\n- Automated reference updates on collision\n- Add collision_log table\n- Implement collision logging\n- Integration tests\n\n### Phase 3: Interactive Resolution (Week 3)\n- Conflict detection and resolution commands\n- Collision resolution strategies\n- Strategy configuration\n\n**Issues**:\n- Implement conflict detection command\n- Implement interactive conflict resolver\n- Implement auto-resolution strategies\n- Add collision strategy to config\n\n### Phase 4: Git Integration (Week 4)\n- Custom git merge driver\n- E2E tests\n- Polish and edge cases\n\n**Issues**:\n- Implement custom git merge driver\n- Document merge driver setup\n- E2E test: Multi-developer workflow\n\n## Configuration\n\nNew config options in `config.json`:\n```json\n{\n  \"collision_resolution\": {\n    \"strategy\": \"older-wins\",\n    \"prompt_on_conflict\": true,\n    \"auto_update_references\": true\n  },\n  \"validation\": {\n    \"pre_commit_check\": true,\n    \"warn_on_broken_refs\": true\n  },\n  \"merge_driver\": {\n    \"enabled\": true,\n    \"fallback_to_manual\": true\n  }\n}\n```\n\n## Success Metrics\n\n- **Collision Detection Rate**: % caught pre-commit\n- **Automatic Merge Success**: % of JSONL merges without manual intervention\n- **Reference Validation**: % of broken references detected and fixed\n- **Developer Satisfaction**: Survey feedback on conflict resolution\n- **Merge Velocity**: Time from PR creation to merge\n\n## Risks & Mitigation\n\n- **Breaking Workflows**: All features opt-in, backward compatible\n- **Performance**: Validation is optional, runs only on changed files\n- **Merge Driver Complexity**: Extensive testing, clear fallback\n- **User Confusion**: Documentation, training, gradual rollout\n\n## Future Enhancements\n\n- Predictive collision avoidance\n- Distributed ID generation\n- Semantic merge with LLM\n- Web-based conflict visualization UI\n- Branch-aware workflows\n","priority":0,"archived":0,"archived_at":null,"created_at":"2025-10-31 07:22:36","updated_at":"2025-11-03T03:10:12.590Z","parent_id":null,"parent_uuid":null,"relationships":[],"tags":["data-integrity","git","infrastructure","multi-developer"]}
{"id":"SPEC-014","uuid":"52d430bc-c5be-4b16-9de9-d0af3ff9726f","title":"Execution Logs Design","file_path":"specs/execution_logs_design.md","content":"# Execution Logs Design\n\n## Overview\n\nExecution logs provide full history replay and debugging capabilities for agent executions. The design is inspired by vibe-kanban's approach but adapted for sudocode's durable file storage model.\n\n## Architecture\n\n### Storage Layers\n\n```\n┌─────────────────────────────────────────────────────────┐\n│                    Execution Logs                        │\n├─────────────────────────────────────────────────────────┤\n│                                                          │\n│  Layer 1: Real-time Streaming (AG-UI Protocol)          │\n│  ├─ SSE/WebSocket to frontend                           │\n│  ├─ Tool calls, file changes, progress                  │\n│  └─ Ephemeral - not persisted                           │\n│                                                          │\n│  Layer 2: Database Cache (execution_logs table)         │\n│  ├─ JSONL format in SQLite                              │\n│  ├─ Append-only for efficiency                          │\n│  ├─ One record per execution                            │\n│  └─ Fast local access                                   │\n│                                                          │\n│  Layer 3: Durable File Storage (executions.jsonl)       │\n│  ├─ Newline-delimited JSON file                         │\n│  ├─ Version controlled with git                         │\n│  ├─ Includes execution metadata + full logs             │\n│  └─ Similar to issues.jsonl and specs.jsonl             │\n│                                                          │\n└─────────────────────────────────────────────────────────┘\n```\n\n## Database Schema\n\n### execution_logs Table\n\n```sql\nCREATE TABLE execution_logs (\n    execution_id TEXT PRIMARY KEY,\n    logs TEXT NOT NULL DEFAULT '',          -- JSONL format\n    byte_size INTEGER NOT NULL DEFAULT 0,\n    created_at INTEGER NOT NULL DEFAULT (unixepoch()),\n    updated_at INTEGER NOT NULL DEFAULT (unixepoch()),\n    FOREIGN KEY (execution_id) REFERENCES executions(id) ON DELETE CASCADE\n);\n\n-- Indexes\nCREATE INDEX idx_execution_logs_updated_at ON execution_logs(updated_at);\nCREATE INDEX idx_execution_logs_byte_size ON execution_logs(byte_size);\n```\n\n### Relationship\n\n```\nexecutions (1) ←→ (0..1) execution_logs\n```\n\n- One execution can have zero or one log record\n- Logs are optional - only created when detailed logging is enabled\n- Foreign key ensures cascade delete when execution is removed\n\n## Log Message Format\n\n### JSONL Structure\n\nEach line in the `logs` field is a JSON object:\n\n```jsonl\n{\"type\":\"stdout\",\"data\":\"Starting execution...\\n\",\"timestamp\":1730361234567}\n{\"type\":\"ag_ui_event\",\"data\":{\"event\":\"tool_call\",\"payload\":{...}},\"timestamp\":1730361235789}\n{\"type\":\"tool_call\",\"data\":{\"tool\":\"Read\",\"input\":{...},\"output\":{...}},\"timestamp\":1730361236012}\n{\"type\":\"stderr\",\"data\":\"Warning: deprecated API\\n\",\"timestamp\":1730361237345}\n{\"type\":\"user_input\",\"data\":\"Please add error handling\",\"timestamp\":1730361240000}\n{\"type\":\"finished\",\"data\":{\"exitCode\":0},\"timestamp\":1730361250123}\n```\n\n### Message Types\n\n| Type | Description | Data Format |\n|------|-------------|-------------|\n| `stdout` | Standard output | String |\n| `stderr` | Standard error | String |\n| `tool_call` | Tool invocation | `{tool, input, output?, error?}` |\n| `ag_ui_event` | AG-UI protocol event | `{event, payload}` |\n| `user_input` | User feedback/follow-up | String |\n| `system` | System messages | String |\n| `finished` | Completion marker | `{exitCode?, error?}` |\n\n## Append-Only Operations\n\n### Efficient Incremental Updates\n\n```sql\n-- Append a new log line\nUPDATE execution_logs\nSET logs = logs || $new_line,\n    byte_size = byte_size + $line_byte_size,\n    updated_at = unixepoch()\nWHERE execution_id = $execution_id;\n```\n\nBenefits:\n- No need to load entire log into memory\n- Efficient for streaming scenarios\n- Works well with SQLite's page-based storage\n\n## Integration Points\n\n### 1. During Execution (Real-time)\n\n```typescript\n// As execution runs, append log messages\nawait executionLogsService.appendLog(executionId, {\n  type: \"tool_call\",\n  data: { tool: \"Read\", input: { file_path: \"...\" } },\n  timestamp: Date.now()\n});\n```\n\n### 2. After Execution (Sync to File)\n\n```typescript\n// Sync execution and logs to executions.jsonl\nawait syncExecutionToDisk(executionId);\n\n// Format in executions.jsonl:\n{\n  \"execution\": {\n    \"id\": \"exec-123\",\n    \"issueId\": \"ISSUE-001\",\n    \"status\": \"completed\",\n    ...\n  },\n  \"logs\": [\n    {\"type\":\"stdout\",\"data\":\"...\",\"timestamp\":...},\n    ...\n  ]\n}\n```\n\n### 3. Import/Export\n\n```typescript\n// Export executions from cache.db to executions.jsonl\nsudocode export --executions\n\n// Import executions from executions.jsonl to cache.db\nsudocode import --executions\n```\n\n## Use Cases\n\n### 1. Debugging Failed Executions\n\n```typescript\n// Load full execution history\nconst execution = await db.executions.findById('exec-123');\nconst logs = await db.executionLogs.findById('exec-123');\nconst messages = ExecutionLogsUtil.parseJsonl(logs.logs);\n\n// Filter for errors\nconst errors = messages.filter(m => m.type === 'stderr');\n```\n\n### 2. Replay Execution in UI\n\n```typescript\n// Stream historical logs to frontend\nconst messages = ExecutionLogsUtil.parseJsonl(logs.logs);\nfor (const msg of messages) {\n  // Send to UI with original timing\n  await delay(msg.timestamp - prevTimestamp);\n  socket.send(JSON.stringify(msg));\n}\n```\n\n### 3. Generate Execution Report\n\n```typescript\n// Summarize execution activity\nconst logs = ExecutionLogsUtil.parseJsonl(logs.logs);\nconst toolCalls = ExecutionLogsUtil.filterByType(logs, 'tool_call');\nconst filesChanged = toolCalls\n  .filter(t => t.data.tool === 'Write' || t.data.tool === 'Edit')\n  .length;\n```\n\n## Storage Management\n\n### Size Limits\n\n- Default: Store last 10MB of logs per execution\n- Configurable via execution config\n- Old logs can be truncated or archived to file storage\n\n### Cleanup Strategy\n\n```typescript\n// After successful sync to executions.jsonl\nif (config.cleanupLogsAfterSync) {\n  await db.executionLogs.delete(executionId);\n}\n\n// Or compress to summary\nconst summary = summarizeLogs(logs);\nawait db.executions.update(executionId, { summary });\nawait db.executionLogs.delete(executionId);\n```\n\n## Comparison with Vibe-Kanban\n\n| Aspect | Vibe-Kanban | Sudocode |\n|--------|-------------|----------|\n| **Storage Format** | JSONL in SQLite | JSONL in SQLite + file |\n| **Message Types** | Stdout, Stderr, JsonPatch, SessionId | Extended set including tool_call, ag_ui_event |\n| **Append Method** | SQL concatenation | SQL concatenation |\n| **Durable Storage** | SQLite only | SQLite + executions.jsonl |\n| **One-to-One** | execution_process ↔ logs | execution ↔ logs |\n\n## Future Enhancements\n\n1. **Compression**: Gzip logs in database to save space\n2. **Streaming API**: `/api/executions/:id/logs/stream` endpoint\n3. **Search**: Full-text search across logs\n4. **Retention Policy**: Auto-archive old logs to file storage\n5. **Log Levels**: Add severity levels (debug, info, warn, error)\n\n## Implementation Checklist\n\n- [x] Schema definition (`execution_logs` table)\n- [x] TypeScript types (`execution-logs.ts`)\n- [x] Design documentation\n- [ ] Database service layer (`ExecutionLogsService`)\n- [ ] Integration with `ExecutionService`\n- [ ] SSE streaming endpoint\n- [ ] Sync to `executions.jsonl`\n- [ ] Import/export CLI commands\n- [ ] Frontend log viewer component\n","priority":2,"archived":0,"archived_at":null,"created_at":"2025-10-31 09:58:18","updated_at":"2025-11-03T03:10:12.582Z","parent_id":null,"parent_uuid":null,"relationships":[],"tags":[]}
{"id":"SPEC-015","uuid":"9e5b7f07-5fc0-424b-858b-349df045dee0","title":"Git Synchronization Architecture for Multi-Remote and Multi-Worktree","file_path":"specs/git_synchronization_architecture_for_multi_remote_.md","content":"Comprehensive architecture for managing sudocode state across two collaboration scenarios:\n\n**Tier 1: Multi-Remote Synchronization** - Multiple developers on separate machines pushing/pulling to shared remote, with focus on minimizing conflicts through CRDT-inspired structures, ID lock files, and custom merge drivers.\n\n**Tier 2: Local Multi-Worktree Management** - Single developer managing multiple git worktrees locally, with main worktree as leader and centralized coordination for consistency.\n\n## Key Innovations\n\n### Multi-Remote (Tier 1)\n- **CRDT-Inspired Entity Schema**: LWW fields, vector clocks, lamport timestamps for deterministic merging\n- **ID Lock File**: `.sudocode/id-lock.json` with custom merge driver for tracking ID allocations\n- **Custom JSONL Merge Driver**: UUID-based merging with automatic collision resolution\n- **ID Range Reservation**: Developers can reserve ID ranges to prevent collisions\n- **Lamport Clock Resolution**: Deterministic collision resolution without coordination\n\n### Multi-Worktree (Tier 2)\n- **Coordination File**: `.git/sudocode-coordination.json` shared across all worktrees\n- **Main as Leader**: Main worktree is authoritative for ID allocation\n- **Pessimistic Locking**: Claim issues to prevent concurrent work\n- **Fast Sync**: Local filesystem sync without network roundtrips\n- **Guided Merge**: Automated merge-to-main workflow with conflict detection\n\n## Architecture Highlights\n\n**Enhanced Entity Structure**:\n```typescript\n{\n  id: \"ISSUE-043\",           // Display ID\n  uuid: \"aaa-111\",           // True identity\n  version: 5,                // Edit counter\n  lamport_clock: 17,         // Total ordering\n  vector_clock: {...},       // Causality tracking\n  title: LWWField<string>,   // CRDT field\n  content: LWWField<string>, // CRDT field\n}\n```\n\n**ID Lock File** for collision tracking\n**Custom Merge Drivers** for JSONL and lock files\n**Worktree Coordination** for local management\n\n## Implementation Plan\n\n5-week phased rollout:\n1. Enhanced entity schema with CRDT metadata\n2. ID lock file and merge driver\n3. JSONL merge driver with collision resolution\n4. Worktree coordination system\n5. Multi-remote validation and auto-resolution\n\nSee full spec at `specs/git_synchronization_architecture.md` for complete details.\n","priority":0,"archived":0,"archived_at":null,"created_at":"2025-11-01 04:52:31","updated_at":"2025-11-03T03:10:12.589Z","parent_id":null,"parent_uuid":null,"relationships":[],"tags":["crdt","distributed-systems","git","infrastructure","synchronization","worktree"]}
{"id":"SPEC-016","uuid":"def61b37-9524-4c17-8857-a35885619d2a","title":"Durable Execution Event Storage","file_path":"specs/durable_execution_event_storage.md","content":"# Durable Execution Event Storage\n\n## Overview\n\nEnhance the execution event system to persist both raw agent output AND AG-UI protocol events to the database, enabling complete durable storage that survives server restarts and allows historical access to execution data.\n\n## Problem Statement\n\nCurrently, execution events are only stored in an in-memory `EventBuffer` which has several limitations:\n\n1. **Ephemeral**: Events are lost on server restart\n2. **Limited History**: Buffer is pruned after 1 hour of inactivity\n3. **Race Conditions**: Clients connecting late may miss events if buffer is cleared\n4. **Memory Constraints**: Unbounded growth for long-running executions\n5. **No Persistence**: Cannot view execution details after server restart\n6. **Incomplete Data**: AG-UI events lose some original agent message context\n\n## Goals\n\n1. **Durability**: Execution events survive server restarts\n2. **Completeness**: Store both raw agent messages and AG-UI events\n3. **Historical Access**: View execution details days/weeks after completion\n4. **Efficient Storage**: Indexed, queryable database storage\n5. **Performance**: Maintain fast event delivery to active clients\n6. **Backwards Compatible**: Work with existing EventBuffer for active executions\n\n## Storage Strategy: Two-Track Approach\n\n### Track 1: Raw Agent Output (Complete)\nStore original agent messages as-is for debugging and regeneration:\n- Full Claude stream-json messages\n- Preserves all metadata (message IDs, model, stop reasons)\n- Appendable (newline-delimited JSON)\n- Useful for debugging and audit trails\n\n### Track 2: AG-UI Events (Structured)\nStore transformed AG-UI events for fast replay:\n- Pre-processed events ready for frontend\n- Indexed by sequence and type\n- Queryable by event type, time range\n- Optimized for SSE streaming\n\n## Architecture\n\n**Dual-Write with Dual-Track Storage**:\n```\n┌───────────────────────────────────────────────────────────┐\n│              ClaudeCodeOutputProcessor                     │\n│                                                            │\n│  Raw Line ──┬──> Parse ──> OutputMessage                  │\n│             │                    │                         │\n│             │                    ▼                         │\n│             │            AG-UI Transformation             │\n│             │                    │                         │\n└─────────────┼────────────────────┼─────────────────────────┘\n              │                    │\n              │                    │\n              ▼                    ▼\n      ┌──────────────┐    ┌──────────────┐\n      │ Raw Logs     │    │ AG-UI Events │\n      │ (append)     │    │ (structured) │\n      └──────────────┘    └──────────────┘\n              │                    │\n              └────────┬───────────┘\n                       ▼\n            ┌────────────────────┐\n            │  execution_logs    │\n            │   (database)       │\n            └────────────────────┘\n                       │\n                       ▼\n               ┌──────────────┐\n               │ EventBuffer  │\n               │ (in-memory)  │\n               └──────────────┘\n                       │\n                       ▼\n                 SSE Clients\n```\n\n## Database Schema\n\n### Updated `execution_logs` Table\n\n**Current Schema**:\n```sql\nCREATE TABLE IF NOT EXISTS execution_logs (\n    execution_id TEXT PRIMARY KEY,\n    logs TEXT NOT NULL DEFAULT '',\n    byte_size INTEGER NOT NULL DEFAULT 0,\n    created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,\n    updated_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,\n    FOREIGN KEY (execution_id) REFERENCES executions(id) ON DELETE CASCADE\n);\n```\n\n**Updated Schema**:\n```sql\nCREATE TABLE IF NOT EXISTS execution_logs (\n    execution_id TEXT PRIMARY KEY,\n    \n    -- Raw agent output (append-only, newline-delimited JSON)\n    raw_logs TEXT NOT NULL DEFAULT '',\n    raw_logs_byte_size INTEGER NOT NULL DEFAULT 0,\n    raw_logs_line_count INTEGER NOT NULL DEFAULT 0,\n    \n    -- AG-UI events (JSON array of structured events)\n    ag_ui_events TEXT NOT NULL DEFAULT '[]',\n    ag_ui_events_count INTEGER NOT NULL DEFAULT 0,\n    \n    -- Metadata\n    last_sequence_number INTEGER NOT NULL DEFAULT -1,\n    created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,\n    updated_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,\n    \n    FOREIGN KEY (execution_id) REFERENCES executions(id) ON DELETE CASCADE\n);\n```\n\n**Design Decisions**:\n- **Single table**: All execution logs/events in one place\n- **`raw_logs`**: Newline-delimited JSON, append-only, preserves everything\n- **`ag_ui_events`**: JSON array of AG-UI events with sequence numbers\n- **Counts**: Track line/event counts for fast metadata queries\n- **`last_sequence_number`**: Track latest sequence for appending\n- **One row per execution**: Simple PRIMARY KEY, no pagination needed for typical executions\n\n### Indexes\n\n```sql\nCREATE INDEX IF NOT EXISTS idx_execution_logs_updated_at \n    ON execution_logs(updated_at);\nCREATE INDEX IF NOT EXISTS idx_execution_logs_byte_size \n    ON execution_logs(raw_logs_byte_size);\nCREATE INDEX IF NOT EXISTS idx_execution_logs_event_count \n    ON execution_logs(ag_ui_events_count);\n```\n\n## Data Format Examples\n\n### Raw Logs Format\nNewline-delimited JSON (NDJSON), one Claude message per line:\n```\n{\"type\":\"assistant\",\"message\":{\"id\":\"msg_1\",\"content\":[{\"type\":\"text\",\"text\":\"Let me help\"}]}}\n{\"type\":\"assistant\",\"message\":{\"id\":\"msg_2\",\"content\":[{\"type\":\"tool_use\",\"id\":\"tool_1\",\"name\":\"Read\",\"input\":{...}}]}}\n{\"type\":\"tool_result\",\"result\":{\"tool_use_id\":\"tool_1\",\"content\":[{\"type\":\"text\",\"text\":\"...\"}]}}\n```\n\n### AG-UI Events Format\nJSON array with sequence numbers:\n```json\n[\n  {\"sequence\": 0, \"event\": {\"type\": \"RUN_STARTED\", \"runId\": \"...\", \"timestamp\": 123}},\n  {\"sequence\": 1, \"event\": {\"type\": \"TOOL_CALL_START\", \"toolCallId\": \"tool_1\", \"timestamp\": 124}},\n  {\"sequence\": 2, \"event\": {\"type\": \"TOOL_CALL_ARGS\", \"toolCallId\": \"tool_1\", \"delta\": \"...\", \"timestamp\": 125}}\n]\n```\n\n## Component Design\n\n### 1. ExecutionLogsStore Service\n\n**File**: `server/src/services/execution-logs-store.ts`\n\n**Responsibilities**:\n- Append raw agent output lines\n- Append AG-UI events with sequence numbers\n- Query logs and events\n- Provide statistics\n\n**Key Methods**:\n```typescript\nclass ExecutionLogsStore {\n  // Initialize logs for new execution\n  initializeLogs(executionId: string): void\n  \n  // Append raw agent output\n  appendRawLog(executionId: string, line: string): void\n  appendRawLogs(executionId: string, lines: string[]): void\n  \n  // Append AG-UI events\n  appendEvent(executionId: string, event: AgUiEvent): number  // Returns sequence number\n  appendEvents(executionId: string, events: AgUiEvent[]): number[]\n  \n  // Read operations\n  getRawLogs(executionId: string): string[]\n  getAgUiEvents(executionId: string, fromSequence?: number): BufferedEvent[]\n  getLogMetadata(executionId: string): LogMetadata\n  \n  // Cleanup\n  deleteLogs(executionId: string): void\n  pruneOldLogs(olderThanMs: number): number\n  \n  // Statistics\n  getStats(): StorageStats\n}\n```\n\n**Performance Considerations**:\n- Use SQLite transactions for batch appends\n- Parse JSON only when needed\n- Keep metadata (counts, sizes) updated incrementally\n- Consider JSONB extension for event queries (future)\n\n### 2. Dual Persistence in ExecutionService\n\n**File**: `server/src/services/execution-service.ts`\n\n**Changes**:\n```typescript\n// In createExecution(), capture both raw output and AG-UI events\n\nlet lineBuffer = '';\nengine = new SimpleExecutionEngine(processManager, {\n  maxConcurrent: 1,\n  onOutput: (data, type) => {\n    if (type === 'stdout') {\n      lineBuffer += data.toString();\n      let newlineIndex;\n      while ((newlineIndex = lineBuffer.indexOf('\\n')) !== -1) {\n        const line = lineBuffer.slice(0, newlineIndex);\n        lineBuffer = lineBuffer.slice(newlineIndex + 1);\n        \n        if (line.trim()) {\n          // 1. Store raw line immediately\n          logsStore.appendRawLog(execution.id, line).catch(err => {\n            console.error('Failed to store raw log:', err);\n          });\n          \n          // 2. Process through AG-UI pipeline\n          agUiSystem.processor.processLine(line).catch((err) => {\n            console.error('[ExecutionService] Error processing output line:', err);\n          });\n        }\n      }\n    }\n  },\n});\n\n// Connect processor to adapter - adapter will persist AG-UI events\nagUiSystem.adapter.onEvent((event) => {\n  logsStore.appendEvent(execution.id, event).catch(err => {\n    console.error('Failed to store AG-UI event:', err);\n  });\n});\n```\n\n### 3. TransportManager Integration\n\n**File**: `server/src/execution/transport/transport-manager.ts`\n\n**Changes**:\n```typescript\nclass TransportManager {\n  private logsStore: ExecutionLogsStore | null;\n  \n  constructor(config?: { enablePersistence?: boolean }) {\n    if (config?.enablePersistence) {\n      this.logsStore = new ExecutionLogsStore(getDatabase());\n    }\n  }\n  \n  broadcastToRun(runId: string, event: AgUiEvent): void {\n    // 1. Add to in-memory buffer (fast, for active clients)\n    this.eventBuffer.addEvent(runId, event);\n    \n    // 2. Events are persisted by ExecutionService listener (see above)\n    \n    // 3. Broadcast to connected clients\n    this.sseTransport.broadcastToRun(runId, event);\n  }\n  \n  getBufferedEvents(runId: string, fromSequence?: number): BufferedEvent[] {\n    // Try database first (durable), fallback to memory\n    if (this.logsStore) {\n      try {\n        const dbEvents = this.logsStore.getAgUiEvents(runId, fromSequence);\n        if (dbEvents.length > 0) {\n          console.log('[TransportManager] Loaded events from database', {\n            runId, eventCount: dbEvents.length, fromSequence\n          });\n          return dbEvents;\n        }\n      } catch (err) {\n        console.warn('[TransportManager] Database load failed, using buffer:', err);\n      }\n    }\n    return this.eventBuffer.getEvents(runId, fromSequence);\n  }\n}\n```\n\n### 4. SSE Endpoint\n\n**File**: `server/src/routes/executions-stream.ts`\n\n**No changes needed** - existing code already uses `transportManager.getBufferedEvents()`\n\n### 5. Cleanup Service\n\n**File**: `server/src/services/execution-logs-cleanup.ts`\n\n```typescript\nexport class ExecutionLogsCleanup {\n  private store: ExecutionLogsStore;\n  \n  start(intervalMs: number, retentionMs: number): void {\n    setInterval(() => this.runCleanup(retentionMs), intervalMs);\n    this.runCleanup(retentionMs); // Run immediately\n  }\n  \n  private runCleanup(retentionMs: number): void {\n    const pruned = this.store.pruneOldLogs(retentionMs);\n    const stats = this.store.getStats();\n    console.log('[ExecutionLogsCleanup] Cleanup completed', {\n      prunedExecutions: pruned,\n      totalExecutions: stats.totalExecutions,\n      avgEventsPerExecution: stats.avgEventsPerExecution.toFixed(2),\n    });\n  }\n}\n```\n\n**Cleanup Strategy**:\n- Delete all logs for completed executions older than retention period\n- Optionally keep only raw logs (smaller) or only AG-UI events (structured)\n- Configurable per-execution retention in future\n\n## Migration Plan\n\n### Phase 1: Schema Update\n1. Update `EXECUTION_LOGS_TABLE` in `types/src/schema.ts`\n2. Create migration function in `server/src/services/db.ts`\n3. Handle existing data (if any - likely none since table unused)\n\n### Phase 2: Storage Service\n1. Implement `ExecutionLogsStore` service\n2. Add methods for raw logs and AG-UI events\n3. Write comprehensive unit tests\n\n### Phase 3: Integration\n1. Update `ExecutionService` to capture raw output\n2. Add event listener to persist AG-UI events\n3. Update `TransportManager` to read from database\n4. Initialize `logsStore` in server startup\n\n### Phase 4: Cleanup\n1. Implement `ExecutionLogsCleanup` service\n2. Start cleanup job on server init\n3. Add graceful shutdown handling\n\n### Phase 5: Testing\n1. Unit tests for `ExecutionLogsStore`\n2. Integration tests for end-to-end persistence\n3. Test server restart scenarios\n4. Test cleanup and pruning logic\n5. Verify both raw logs and AG-UI events are persisted\n\n## Storage Size Analysis\n\n**Typical Execution**:\n- 100 Claude messages × 500 bytes = 50 KB raw logs\n- 500 AG-UI events × 200 bytes = 100 KB events\n- **Total: ~150 KB per execution**\n\n**1000 Executions**: ~150 MB (manageable)\n**With 30-day retention**: Depends on execution frequency\n\n**Optimization Options**:\n1. Compress old logs (gzip can achieve 5-10x compression on JSON)\n2. Prune detailed events, keep summaries\n3. Move to separate archive table after N days\n4. Use SQLite's JSON features for selective queries\n\n## Configuration\n\n```typescript\ninterface ServerConfig {\n  executionLogs: {\n    enablePersistence: boolean;      // Default: true\n    storeRawLogs: boolean;           // Default: true\n    storeAgUiEvents: boolean;        // Default: true\n    cleanupIntervalMs: number;       // Default: 3600000 (1 hour)\n    retentionMs: number;             // Default: 2592000000 (30 days)\n    compressOldLogs: boolean;        // Default: false (future)\n  }\n}\n```\n\n## Success Criteria\n\n1. ✅ Both raw logs and AG-UI events persist across server restarts\n2. ✅ Frontend can load execution history from any point in time\n3. ✅ Can regenerate AG-UI events from raw logs if needed\n4. ✅ No performance degradation for active executions\n5. ✅ Database queries complete in < 100ms for typical executions\n6. ✅ Storage grows predictably with configurable cleanup\n7. ✅ All tests pass including new persistence tests\n\n## Benefits of Two-Track Storage\n\n✅ **Completeness**: Raw logs preserve everything for debugging\n✅ **Performance**: AG-UI events ready for instant replay\n✅ **Flexibility**: Can regenerate different event formats from raw logs\n✅ **Audit Trail**: Complete record of agent interactions\n✅ **Simple Schema**: Single table, one row per execution\n✅ **Efficient**: Text storage is cheap, JSON is queryable\n\n## Trade-offs\n\n**Pros**:\n- Complete data retention\n- Fast event replay\n- Debugging capabilities\n- Future-proof (can regenerate events)\n\n**Cons**:\n- ~2x storage (raw + events)\n- Slightly more complex append logic\n- Need to parse JSON on read\n\n**Mitigation**:\n- Prune old executions aggressively\n- Compress archived logs\n- Store only critical events after N days\n\n## Non-Goals\n\n- Real-time log streaming (use SSE for active executions)\n- Full-text search on logs (can be added later)\n- Multi-server log synchronization (single server for now)\n- Log compression (future optimization)\n\n## Future Enhancements\n\n1. **Selective Storage**: Option to store only raw OR only events\n2. **Compression**: Gzip old logs for 5-10x space savings\n3. **Archive Table**: Move old logs to separate table\n4. **Log Export**: Download execution logs as JSON/text\n5. **Log Replay**: Regenerate AG-UI events from raw logs\n6. **Filtering API**: REST endpoint to query logs/events\n7. **JSONB**: Use SQLite JSON functions for event queries\n\n## Related Components\n\n- [[SPEC-007]]: Output Processing Layer (generates events)\n- [[SPEC-009]]: AG-UI Protocol (event format)\n- Event Buffer (`server/src/execution/transport/event-buffer.ts`)\n- Transport Manager (`server/src/execution/transport/transport-manager.ts`)\n- Database Schema (`types/src/schema.ts`)\n\n## References\n\n- AG-UI Protocol: https://github.com/anthropics/anthropic-quickstarts/tree/main/computer-use-demo/ui\n- Claude Stream JSON Format: Claude Code CLI output format\n- NDJSON: http://ndjson.org/\n- SQLite JSON: https://www.sqlite.org/json1.html","priority":1,"archived":0,"archived_at":null,"created_at":"2025-11-03 10:03:41","updated_at":"2025-11-03 10:22:11","parent_id":null,"parent_uuid":null,"relationships":[],"tags":["ag-ui","database","events","execution","persistence"]}
{"id":"SPEC-017","uuid":"193cbc9e-9a6f-4db4-b93b-1e7f2e414d66","title":"CopilotKit UI Migration Specification","file_path":"specs/copilotkit_ui_migration_specification.md","content":"# CopilotKit UI Migration Specification\n\n## Overview\nThis specification outlines the migration from custom AG-UI React components to CopilotKit's pre-built UI library. CopilotKit, created by the AG-UI protocol authors, provides production-ready React components that natively consume AG-UI events, allowing us to reduce ~85% of our custom UI code while gaining additional features.\n\n## Background\n\n### Current Implementation\n- **Custom Components**: `ExecutionMonitor`, `AgentTrajectory`, `MessageStream` (~1,500 LOC)\n- **Custom Hook**: `useAgUiStream` for AG-UI event consumption (~650 LOC)\n- **Manual SSE**: Direct EventSource connection management\n- **Custom State Management**: Manual tracking of messages, tool calls, execution state\n\n### Problems with Current Approach\n1. **High Maintenance Burden**: Custom UI code requires ongoing maintenance\n2. **Missing Features**: Lack of built-in threading, error handling, accessibility\n3. **Code Duplication**: Reimplementing patterns that CopilotKit provides\n4. **Limited Resources**: Team time better spent on core features\n\n## Goals\n\n### Primary Goals\n1. **Reduce UI Code by 85%+**: Replace custom components with CopilotKit\n2. **Improve UX**: Leverage CopilotKit's polished, battle-tested UI\n3. **Maintain Compatibility**: Keep AG-UI protocol integration intact\n4. **Zero Downtime**: Migrate incrementally without breaking existing features\n\n### Secondary Goals\n1. **Better Accessibility**: WCAG-compliant components out of the box\n2. **Responsive Design**: Mobile-friendly execution monitoring\n3. **Extensibility**: Easier to add new features using CopilotKit patterns\n4. **Developer Experience**: Reduce onboarding time for new developers\n\n## Architecture\n\n### Component Mapping\n\n| Current Component | CopilotKit Replacement | Lines Saved |\n|-------------------|------------------------|-------------|\n| `ExecutionMonitor` | `CopilotSidebar` or `CopilotChat` | ~350 |\n| `AgentTrajectory` | `useCopilotChatHeadless_c` + built-in rendering | ~280 |\n| `MessageStream` | Built-in message rendering | ~125 |\n| `useAgUiStream` | `useCoAgent` + `useCoAgentStateRender` | ~650 |\n| Tool call rendering | `useCopilotAction` with `render` | ~200 |\n| **Total** | | **~1,605 LOC** |\n\n### New Architecture\n\n```\n┌─────────────────────────────────────────┐\n│         CopilotKit Provider             │\n│  (Handles AG-UI connection & state)     │\n└──────────────┬──────────────────────────┘\n               │\n       ┌───────┴────────┐\n       │                │\n   ┌───▼────┐      ┌────▼────┐\n   │ UI     │      │ Headless│\n   │ Layer  │      │ Hooks   │\n   └────────┘      └─────────┘\n       │                │\n   ┌───▼────────────────▼───┐\n   │   Your Application     │\n   │   - Execution Pages    │\n   │   - Issue Management   │\n   └────────────────────────┘\n```\n\n### Runtime Connection\n\n```\nFrontend (React)              Backend (Node.js)\n┌──────────────┐             ┌──────────────┐\n│ CopilotKit   │             │ AG-UI Events │\n│   Provider   │─────HTTP────▶ SSE Stream   │\n└──────────────┘             └──────────────┘\n       │                            │\n       │ AG-UI Protocol             │\n       ▼                            ▼\n┌──────────────┐             ┌──────────────┐\n│ CopilotChat  │             │ Execution    │\n│ Component    │             │ Monitor      │\n└──────────────┘             └──────────────┘\n```\n\n## Implementation Plan\n\n### Phase 1: Setup & Proof of Concept (1-2 days)\n\n#### 1.1 Install Dependencies\n```bash\nnpm install @copilotkit/react-ui @copilotkit/react-core @copilotkit/runtime\n```\n\n**Dependencies Added:**\n- `@copilotkit/react-ui`: Pre-built UI components\n- `@copilotkit/react-core`: Headless hooks and core functionality\n- `@copilotkit/runtime`: Runtime for AG-UI integration\n\n#### 1.2 Create Runtime Endpoint\nCreate `/api/copilotkit/route.ts` to bridge CopilotKit with existing AG-UI streams.\n\n**Key Components:**\n- `CopilotRuntime`: Manages agent connections\n- `HttpAgent`: Connects to existing AG-UI SSE endpoints\n- Route handler for POST requests\n\n#### 1.3 Create Proof-of-Concept Page\nCreate `ExecutionPageCopilotKit.tsx` to demonstrate CopilotKit working alongside existing implementation.\n\n**Success Criteria:**\n- CopilotKit connects to existing AG-UI stream\n- Messages display in CopilotKit UI\n- Tool calls render properly\n- No regressions in existing execution page\n\n### Phase 2: Component Migration (2-3 days)\n\n#### 2.1 Migrate ExecutionMonitor\nReplace `<ExecutionMonitor>` with `<CopilotSidebar>`.\n\n**Before:**\n```tsx\n<ExecutionMonitor \n  executionId={id} \n  onComplete={handleComplete}\n  onError={handleError}\n/>\n```\n\n**After:**\n```tsx\n<CopilotSidebar\n  labels={{\n    title: \"Execution Monitor\",\n    initial: \"Monitoring execution...\"\n  }}\n  defaultOpen={true}\n/>\n```\n\n**Changes Required:**\n- Update `ExecutionView.tsx`\n- Add CopilotKit provider wrapper\n- Map callbacks to CopilotKit events\n- Update tests\n\n#### 2.2 Migrate Tool Call Rendering\nReplace custom tool call UI with `useCopilotAction`.\n\n**For Each Tool Type:**\n- `Read` → Custom render component\n- `Write` → Custom render component\n- `Edit` → Custom render component\n- `Bash` → Custom render component\n- Issue/Spec operations → Custom render components\n\n**Example:**\n```tsx\nuseCopilotAction({\n  name: \"read_file\",\n  available: \"disabled\", // Render only\n  render: ({ status, args, result }) => (\n    <ToolCallCard\n      name=\"Read\"\n      status={status}\n      args={args}\n      result={result}\n    />\n  )\n});\n```\n\n#### 2.3 Migrate State Management\nReplace `useAgUiStream` with `useCoAgent`.\n\n**Migration Steps:**\n1. Create agent state interface\n2. Replace hook calls\n3. Update state access patterns\n4. Migrate event handlers\n\n### Phase 3: Cleanup & Optimization (1 day)\n\n#### 3.1 Remove Deprecated Components\n- Delete `ExecutionMonitor.tsx`\n- Delete `AgentTrajectory.tsx`\n- Delete `MessageStream.tsx`\n- Delete `useAgUiStream.ts`\n\n#### 3.2 Update Tests\n- Migrate component tests to CopilotKit patterns\n- Add integration tests for runtime endpoint\n- Update E2E tests\n\n#### 3.3 Documentation\n- Update component documentation\n- Add CopilotKit setup guide\n- Create migration guide for future features\n\n### Phase 4: Polish & Launch (1 day)\n\n#### 4.1 Styling & Customization\n- Apply custom theme to CopilotKit components\n- Add custom markdown renderers if needed\n- Adjust layout and spacing\n\n#### 4.2 Performance Optimization\n- Lazy load CopilotKit components\n- Optimize bundle size\n- Add loading states\n\n#### 4.3 Launch\n- Deploy to staging\n- User acceptance testing\n- Deploy to production\n\n## Technical Specifications\n\n### API Surface Changes\n\n#### New Exports\n```typescript\n// src/components/copilotkit/ExecutionCopilot.tsx\nexport function ExecutionCopilot({ executionId }: Props)\n\n// src/components/copilotkit/ToolRenderers.tsx\nexport function useToolRenderers()\nexport function ReadFileRenderer({ args, status, result }: Props)\nexport function WriteFileRenderer({ args, status, result }: Props)\n// ... more renderers\n```\n\n#### Deprecated Exports (Mark for Phase 3 removal)\n```typescript\n// src/components/executions/ExecutionMonitor.tsx (deprecated)\n// src/components/executions/AgentTrajectory.tsx (deprecated)\n// src/components/executions/MessageStream.tsx (deprecated)\n// src/hooks/useAgUiStream.ts (deprecated)\n```\n\n### Configuration\n\n#### Environment Variables\n```bash\n# .env\nCOPILOTKIT_PUBLIC_API_KEY=optional_for_cloud_features\nNEXT_PUBLIC_COPILOTKIT_ENDPOINT=/api/copilotkit\n```\n\n#### CopilotKit Config\n```typescript\n// src/config/copilotkit.ts\nexport const copilotKitConfig = {\n  runtimeUrl: process.env.NEXT_PUBLIC_COPILOTKIT_ENDPOINT,\n  agents: {\n    execution: \"execution_agent\",\n    planning: \"planning_agent\",\n  },\n  theme: {\n    primaryColor: \"#your-brand-color\",\n    borderRadius: \"8px\",\n  },\n};\n```\n\n### Data Flow\n\n#### AG-UI Event Flow\n```\nBackend (Python/Node)\n  │\n  ├─ Emit AG-UI Events\n  │   ├─ TEXT_MESSAGE_START\n  │   ├─ TEXT_MESSAGE_CONTENT\n  │   ├─ TEXT_MESSAGE_END\n  │   ├─ TOOL_CALL_START\n  │   ├─ TOOL_CALL_ARGS\n  │   ├─ TOOL_CALL_END\n  │   └─ TOOL_CALL_RESULT\n  │\n  ▼\nSSE Stream (/api/executions/:id/stream)\n  │\n  ▼\nCopilotKit Runtime (/api/copilotkit)\n  │\n  ├─ Parse AG-UI events\n  ├─ Maintain conversation state\n  └─ Stream to frontend\n  │\n  ▼\nFrontend (React)\n  │\n  ├─ CopilotKit Provider\n  │   ├─ useCoAgent (state management)\n  │   ├─ useCopilotAction (tool rendering)\n  │   └─ useCoAgentStateRender (custom UI)\n  │\n  ▼\nUI Components\n  ├─ CopilotSidebar (execution monitor)\n  ├─ Custom tool renderers\n  └─ Status indicators\n```\n\n## Testing Strategy\n\n### Unit Tests\n- **Tool Renderers**: Test each `useCopilotAction` render function\n- **State Hooks**: Test `useCoAgent` state management\n- **Runtime Endpoint**: Test AG-UI event parsing\n\n### Integration Tests\n- **End-to-End Flow**: Create execution → monitor → complete\n- **Error Handling**: Network errors, AG-UI errors\n- **Real-time Updates**: Verify SSE connection and updates\n\n### Migration Tests\n- **Side-by-Side Comparison**: Run old and new UI in parallel\n- **Feature Parity**: Verify all existing features work\n- **Performance**: Compare bundle size and render performance\n\n## Risks & Mitigations\n\n### Risk 1: CopilotKit Incompatibility\n**Probability**: Low  \n**Impact**: High  \n**Mitigation**: \n- CopilotKit created AG-UI protocol (perfect compatibility)\n- Proof-of-concept in Phase 1 validates compatibility\n- Fallback: Continue with current implementation\n\n### Risk 2: Missing Features\n**Probability**: Medium  \n**Impact**: Medium  \n**Mitigation**:\n- Headless hooks provide full control if needed\n- Custom renderers for specialized requirements\n- Community support for feature requests\n\n### Risk 3: Learning Curve\n**Probability**: Low  \n**Impact**: Low  \n**Mitigation**:\n- Comprehensive documentation available\n- Incremental migration reduces complexity\n- POC phase allows team learning\n\n### Risk 4: Bundle Size Increase\n**Probability**: Medium  \n**Impact**: Low  \n**Mitigation**:\n- Tree-shaking removes unused components\n- Lazy loading for execution pages\n- Monitor bundle size throughout migration\n\n## Success Metrics\n\n### Quantitative Metrics\n- **Code Reduction**: Achieve ≥80% reduction in UI code\n- **Bundle Size**: Maintain or reduce current bundle size\n- **Performance**: Page load time ≤ current implementation\n- **Test Coverage**: Maintain ≥90% test coverage\n\n### Qualitative Metrics\n- **Developer Velocity**: Reduce time to add new features by 50%\n- **Bug Reports**: No increase in UI-related bugs\n- **User Satisfaction**: Equal or better UX feedback\n- **Code Maintainability**: Improved code readability scores\n\n## Timeline\n\n| Phase | Duration | Dependencies |\n|-------|----------|--------------|\n| Phase 1: POC | 1-2 days | None |\n| Phase 2: Migration | 2-3 days | Phase 1 complete |\n| Phase 3: Cleanup | 1 day | Phase 2 complete |\n| Phase 4: Polish | 1 day | Phase 3 complete |\n| **Total** | **5-7 days** | |\n\n**Milestone Dates** (assuming start date):\n- Day 0: Spec approved, begin implementation\n- Day 2: POC complete, decision point\n- Day 5: Migration complete\n- Day 6: Cleanup and tests complete\n- Day 7: Production deployment\n\n## Decision Points\n\n### Day 2: POC Review\n**Decision**: Continue with migration or revert?  \n**Criteria**:\n- ✅ CopilotKit successfully displays AG-UI events\n- ✅ Tool calls render correctly\n- ✅ Performance acceptable\n- ✅ Team comfortable with CopilotKit patterns\n\n**If NO → Abort migration, keep current implementation**  \n**If YES → Proceed to Phase 2**\n\n### Day 5: Feature Parity Check\n**Decision**: Deploy to staging or continue development?  \n**Criteria**:\n- ✅ All existing features working\n- ✅ Tests passing\n- ✅ No performance regressions\n\n## Rollback Plan\n\n### If Issues Found in Production\n1. **Immediate**: Feature flag to show old UI\n2. **Short-term**: Revert to previous deployment\n3. **Long-term**: Fix issues and redeploy\n\n### Rollback Triggers\n- Critical bugs affecting > 10% of users\n- Performance degradation > 20%\n- Data loss or corruption\n- Security vulnerabilities\n\n## Maintenance Plan\n\n### Post-Migration\n1. **Monitor**: Track error rates and performance\n2. **Optimize**: Profile and optimize as needed\n3. **Document**: Update all documentation\n4. **Train**: Team knowledge sharing session\n\n### Long-term\n1. **Updates**: Keep CopilotKit updated quarterly\n2. **Feedback**: Gather user feedback on new UI\n3. **Iterate**: Continuous improvement based on feedback\n4. **Contribute**: Contribute improvements back to CopilotKit\n\n## Approval\n\n### Stakeholders\n- [ ] Engineering Lead - Technical approval\n- [ ] Product Manager - Feature parity approval  \n- [ ] Designer - UX/UI approval\n- [ ] QA Lead - Testing strategy approval\n\n### Sign-off Required From\n- [ ] **Technical Owner**: Confirms architecture soundness\n- [ ] **Product Owner**: Confirms feature requirements met\n- [ ] **Security Team**: Confirms no security concerns\n\n---\n\n## Appendix\n\n### A. CopilotKit Component Reference\n- `CopilotKit`: Root provider component\n- `CopilotChat`: Full-featured chat interface\n- `CopilotSidebar`: Collapsible sidebar chat\n- `CopilotPopup`: Floating popup chat\n- `useCoAgent`: Shared state management hook\n- `useCopilotAction`: Define tools with custom rendering\n- `useCoAgentStateRender`: Custom UI for agent state\n\n### B. AG-UI Event Types Supported\n- ✅ `TEXT_MESSAGE_START`, `TEXT_MESSAGE_CONTENT`, `TEXT_MESSAGE_END`\n- ✅ `TOOL_CALL_START`, `TOOL_CALL_ARGS`, `TOOL_CALL_END`, `TOOL_CALL_RESULT`\n- ✅ `RUN_STARTED`, `RUN_FINISHED`, `RUN_ERROR`\n- ✅ `STEP_STARTED`, `STEP_FINISHED`\n- ✅ `STATE_SNAPSHOT`, `STATE_DELTA`\n- ✅ `CUSTOM` events\n\n### C. Resources\n- **CopilotKit Docs**: https://docs.copilotkit.ai\n- **AG-UI Protocol**: https://www.copilotkit.ai/ag-ui\n- **GitHub Repository**: https://github.com/CopilotKit/CopilotKit\n- **Example Apps**: https://github.com/CopilotKit/CopilotKit/tree/main/examples\n\n### D. Questions & Answers\n\n**Q: Will this break our existing AG-UI backend?**  \nA: No. CopilotKit consumes AG-UI events without requiring backend changes.\n\n**Q: Can we customize the UI?**  \nA: Yes. Deep customization via CSS, custom components, and headless hooks.\n\n**Q: What about our custom tool renderers?**  \nA: Preserved via `useCopilotAction` with custom render functions.\n\n**Q: Is CopilotKit free?**  \nA: Yes, open-source under MIT license. Optional paid cloud features available.\n\n**Q: What if CopilotKit doesn't meet our needs?**  \nA: Fallback to headless hooks for full control, or keep current implementation.","priority":0,"archived":0,"archived_at":null,"created_at":"2025-11-03 18:21:32","updated_at":"2025-11-03 18:21:32","parent_id":null,"parent_uuid":null,"relationships":[],"tags":["architecture","copilotkit","migration","ui"]}
