{"id":"SPEC-001","uuid":"37d447c6-5f01-435d-b7e8-99d689e597f8","title":"Agent Execution System","file_path":"specs/agent_execution_system.md","content":"# Agent Execution System\n\n## Overview\n\nA flexible system for running different coding agents on issues and tracking their execution trajectories. Designed for sudocode's TypeScript/Node.js stack.\n\n## Architecture\n\n### Three-Layer Execution Model\n\n```\nIssue → Execution → Trajectory Entries\n  ↓         ↓            ↓\nTask      Process    Log Events\n```\n\n**1\\. Issue** (existing)\n\n- Already implemented in sudocode\n- Represents a task to be completed\n\n**2\\. Execution** (new)\n\n- Represents a single agent run on an issue\n- Tracks: agent type, status, git context, session info\n- Multiple executions can exist per issue (retries, different agents)\n\n**3\\. Trajectory Entry** (new)\n\n- Individual events/actions during execution\n- Tool uses, thinking, messages, file changes\n- Enables playback and analysis of agent behavior\n\n### Supported Agents\n\nPhase 1: **Claude Code** (via `@anthropic-ai/claude-code`) Phase 2: **Codex** (via `@phasehq/codex`) Future: Aider, Cursor, custom agents\n\n## Data Models\n\n### Execution\n\n```typescript\ninterface Execution {\n  id: string;                    // UUID\n  issueId: string;               // Foreign key to issues\n  agentType: AgentType;          // Which agent ran\n  status: ExecutionStatus;       // Current state\n  \n  // Timestamps\n  startedAt: Date;\n  completedAt?: Date;\n  \n  // Process info\n  exitCode?: number;\n  \n  // Git context (captured before/after)\n  beforeCommit?: string;         // Git SHA before execution\n  afterCommit?: string;          // Git SHA after execution\n  \n  // Session tracking (for resume/fork)\n  sessionId?: string;            // External session ID from agent\n  prompt?: string;               // Initial prompt sent\n  summary?: string;              // Final agent summary\n  \n  // Metadata\n  createdAt: Date;\n  updatedAt: Date;\n}\n\ntype AgentType = 'claude-code' | 'codex';\n\ntype ExecutionStatus = \n  | 'running'\n  | 'completed' \n  | 'failed'\n  | 'stopped';\n```\n\n### Trajectory Entry\n\n```typescript\ninterface TrajectoryEntry {\n  id: number;                    // Auto-increment\n  executionId: string;           // Foreign key to executions\n  index: number;                 // Sequential order within execution\n  timestamp: Date;\n  \n  // Entry type and data (polymorphic)\n  type: EntryType;\n  content: string;               // Display text\n  metadata?: Record<string, any>; // Type-specific data\n}\n\ntype EntryType = \n  | 'tool_use'        // Agent used a tool\n  | 'thinking'        // Agent reasoning/planning\n  | 'assistant_msg'   // Agent message to user\n  | 'user_msg'        // User message to agent\n  | 'user_feedback'   // User approval/denial\n  | 'system_msg'      // System notifications\n  | 'error_msg';      // Errors\n\n// Tool use metadata\ninterface ToolUseMetadata {\n  toolName: string;\n  action: ActionType;\n  status: 'created' | 'running' | 'success' | 'failed';\n}\n\ntype ActionType =\n  | { type: 'file_read', path: string }\n  | { type: 'file_edit', path: string, changes: FileChange[] }\n  | { type: 'file_write', path: string, content: string }\n  | { type: 'command_run', command: string, result?: CommandResult }\n  | { type: 'search', query: string }\n  | { type: 'web_fetch', url: string }\n  | { type: 'task_create', description: string }\n  | { type: 'tool', toolName: string, args: any, result?: any };\n\ninterface FileChange {\n  type: 'edit' | 'write';\n  unifiedDiff?: string;          // For edits\n  content?: string;              // For writes\n  hasLineNumbers: boolean;\n}\n\ninterface CommandResult {\n  exitStatus: { code: number } | { success: boolean };\n  output: string;\n}\n```\n\n## Agent Abstraction\n\n### CodingAgent Interface\n\n```typescript\ninterface CodingAgent {\n  // Spawn initial execution\n  spawn(\n    workDir: string, \n    prompt: string\n  ): Promise<SpawnedProcess>;\n  \n  // Spawn follow-up (resume/fork)\n  spawnFollowUp(\n    workDir: string,\n    prompt: string, \n    sessionId: string\n  ): Promise<SpawnedProcess>;\n  \n  // Normalize agent-specific logs to TrajectoryEntry\n  normalizeLogs(\n    rawLogs: AsyncIterable<string>\n  ): AsyncIterable<TrajectoryEntry>;\n  \n  // Capabilities\n  supportsSessionFork(): boolean;\n  supportsMCP(): boolean;\n  getDefaultMCPConfigPath(): string | null;\n}\n\ninterface SpawnedProcess {\n  process: ChildProcess;\n  exitSignal?: Promise<void>;  // Optional early exit signal\n}\n```\n\n### Claude Code Executor\n\n```typescript\nclass ClaudeCodeExecutor implements CodingAgent {\n  async spawn(workDir: string, prompt: string) {\n    const proc = spawn('npx', [\n      '-y', '@anthropic-ai/claude-code@latest',\n      '-p',\n      '--output-format=stream-json',\n      '--include-partial-messages',\n      '--verbose'\n    ], { \n      cwd: workDir,\n      stdio: ['pipe', 'pipe', 'pipe']\n    });\n    \n    proc.stdin.write(prompt);\n    proc.stdin.end();\n    \n    return { process: proc };\n  }\n  \n  async spawnFollowUp(workDir: string, prompt: string, sessionId: string) {\n    const proc = spawn('npx', [\n      '-y', '@anthropic-ai/claude-code@latest',\n      '-p',\n      '--output-format=stream-json',\n      '--include-partial-messages',\n      '--verbose',\n      '--fork-session',\n      '--resume', sessionId\n    ], { cwd: workDir });\n    \n    proc.stdin.write(prompt);\n    proc.stdin.end();\n    \n    return { process: proc };\n  }\n  \n  async *normalizeLogs(rawLogs: AsyncIterable<string>) {\n    let buffer = '';\n    let sessionIdExtracted = false;\n    let entryIndex = 0;\n    \n    for await (const chunk of rawLogs) {\n      buffer += chunk;\n      \n      // Process complete JSON lines\n      const lines = buffer.split('\\n');\n      buffer = lines.pop() || '';\n      \n      for (const line of lines) {\n        const trimmed = line.trim();\n        if (!trimmed) continue;\n        \n        try {\n          const json = JSON.parse(trimmed);\n          \n          // Extract session ID\n          if (!sessionIdExtracted && json.session_id) {\n            sessionIdExtracted = true;\n            // Emit session ID separately for storage\n          }\n          \n          // Normalize to TrajectoryEntry\n          const entries = this.normalizeClaudeJson(json, entryIndex);\n          for (const entry of entries) {\n            yield entry;\n            entryIndex++;\n          }\n        } catch (e) {\n          // Non-JSON output - treat as system message\n          yield {\n            index: entryIndex++,\n            type: 'system_msg',\n            content: trimmed,\n            timestamp: new Date()\n          };\n        }\n      }\n    }\n  }\n  \n  private normalizeClaudeJson(json: any, startIndex: number): TrajectoryEntry[] {\n    // Parse Claude's JSON format into TrajectoryEntry[]\n    const entries: TrajectoryEntry[] = [];\n    \n    switch (json.type) {\n      case 'system':\n        if (json.subtype !== 'init') {\n          entries.push({\n            index: startIndex,\n            type: 'system_msg',\n            content: `System: ${json.subtype || 'message'}`,\n            timestamp: new Date(),\n            metadata: json\n          });\n        }\n        break;\n        \n      case 'assistant':\n        for (const item of json.message.content) {\n          if (item.type === 'text') {\n            entries.push({\n              index: startIndex + entries.length,\n              type: 'assistant_msg',\n              content: item.text,\n              timestamp: new Date(),\n              metadata: item\n            });\n          } else if (item.type === 'thinking') {\n            entries.push({\n              index: startIndex + entries.length,\n              type: 'thinking',\n              content: item.thinking,\n              timestamp: new Date(),\n              metadata: item\n            });\n          } else if (item.type === 'tool_use') {\n            entries.push({\n              index: startIndex + entries.length,\n              type: 'tool_use',\n              content: this.generateToolContent(item),\n              timestamp: new Date(),\n              metadata: {\n                toolName: item.name,\n                action: this.extractAction(item),\n                status: 'created'\n              }\n            });\n          }\n        }\n        break;\n        \n      case 'user':\n        // Handle tool results and user messages\n        break;\n    }\n    \n    return entries;\n  }\n  \n  supportsSessionFork() { return true; }\n  supportsMCP() { return true; }\n  getDefaultMCPConfigPath() { \n    return `${os.homedir()}/.claude.json`; \n  }\n}\n```\n\n### Codex Executor\n\n```typescript\nclass CodexExecutor implements CodingAgent {\n  async spawn(workDir: string, prompt: string) {\n    // Similar structure, but using Codex CLI\n    const proc = spawn('npx', [\n      '-y', '@phasehq/codex@latest',\n      // Codex-specific flags\n    ], { cwd: workDir });\n    \n    // Codex has different input format\n    proc.stdin.write(JSON.stringify({ prompt }));\n    proc.stdin.end();\n    \n    return { process: proc };\n  }\n  \n  async *normalizeLogs(rawLogs: AsyncIterable<string>) {\n    // Codex-specific log parsing\n    // Different format than Claude\n  }\n  \n  supportsSessionFork() { return true; }\n  supportsMCP() { return true; }\n}\n```\n\n## Database Schema\n\n### Executions Table\n\n[[ISSUE-028]]{ references }\n\n```sql\nCREATE TABLE executions (\n  id TEXT PRIMARY KEY,\n  issue_id TEXT NOT NULL REFERENCES issues(id) ON DELETE CASCADE,\n  agent_type TEXT NOT NULL,  -- 'claude-code' | 'codex' | etc\n  status TEXT NOT NULL,      -- 'running' | 'completed' | 'failed' | 'stopped'\n  \n  started_at INTEGER NOT NULL,\n  completed_at INTEGER,\n  exit_code INTEGER,\n  \n  before_commit TEXT,\n  after_commit TEXT,\n  \n  session_id TEXT,\n  prompt TEXT,\n  summary TEXT,\n  \n  created_at INTEGER NOT NULL DEFAULT (unixepoch()),\n  updated_at INTEGER NOT NULL DEFAULT (unixepoch())\n);\n\nCREATE INDEX idx_executions_issue_id ON executions(issue_id);\nCREATE INDEX idx_executions_status ON executions(status);\nCREATE INDEX idx_executions_session_id ON executions(session_id);\n```\n\n### Trajectory Entries Table\n\n```sql\nCREATE TABLE trajectory_entries (\n  id INTEGER PRIMARY KEY AUTOINCREMENT,\n  execution_id TEXT NOT NULL REFERENCES executions(id) ON DELETE CASCADE,\n  entry_index INTEGER NOT NULL,\n  timestamp INTEGER NOT NULL,\n  \n  type TEXT NOT NULL,  -- 'tool_use' | 'thinking' | 'assistant_msg' | etc\n  content TEXT NOT NULL,\n  metadata TEXT,       -- JSON blob\n  \n  created_at INTEGER NOT NULL DEFAULT (unixepoch())\n);\n\nCREATE INDEX idx_trajectory_entries_execution_id ON trajectory_entries(execution_id);\nCREATE INDEX idx_trajectory_entries_execution_index ON trajectory_entries(execution_id, entry_index);\n```\n\n## API Endpoints\n\n[[ISSUE-031]]{ references }\n\n### Start Execution\n\n```\nPOST /api/issues/:issueId/executions\n{\n  \"agentType\": \"claude-code\",\n  \"prompt\": \"Fix the authentication bug\"\n}\n\nResponse: { \"executionId\": \"exec-123\" }\n```\n\n### Get Execution Status\n\n```\nGET /api/executions/:executionId\n\nResponse: {\n  \"id\": \"exec-123\",\n  \"issueId\": \"issue-456\",\n  \"agentType\": \"claude-code\",\n  \"status\": \"running\",\n  \"startedAt\": \"2025-01-26T10:00:00Z\",\n  ...\n}\n```\n\n### Stream Trajectory (WebSocket)\n\n```\nWS /api/executions/:executionId/trajectory\n\nMessages:\n{\n  \"type\": \"entry\",\n  \"data\": {\n    \"index\": 5,\n    \"type\": \"tool_use\",\n    \"content\": \"`src/auth.ts`\",\n    \"timestamp\": \"2025-01-26T10:01:23Z\",\n    \"metadata\": { ... }\n  }\n}\n\n{\n  \"type\": \"session_id\",\n  \"data\": { \"sessionId\": \"claude-session-abc\" }\n}\n\n{\n  \"type\": \"finished\",\n  \"data\": { \"exitCode\": 0 }\n}\n```\n\n### Stop Execution\n\n```\nPOST /api/executions/:executionId/stop\n\nResponse: { \"status\": \"stopped\" }\n```\n\n### List Executions for Issue\n\n```\nGET /api/issues/:issueId/executions\n\nResponse: {\n  \"executions\": [\n    { \"id\": \"exec-123\", ... },\n    { \"id\": \"exec-124\", ... }\n  ]\n}\n```\n\n## Implementation Phases\n\n### Phase 1: Core Execution (MVP)\n\n[[ISSUE-029]]{ references }**Goal**: Basic process spawning and log storage\n\n**Issues**:\n\n- [[ISSUE-028]] - Database schema and TypeScript types for executions\n- [[ISSUE-029]] - Implement ExecutionManager class for process lifecycle management\n- [[ISSUE-030]] - Implement basic Claude Code process spawning\n- [[ISSUE-031]] - API endpoints for execution management\n- [[ISSUE-032]] - Raw log storage in temp files\n- [[ISSUE-033]] - Integration test for Phase 1 MVP\n\n**Deliverable**: Can start Claude Code on an issue, track if it's running, and know when it finishes.\n\n### Phase 2: Trajectory Normalization\n\n**Goal**: Parse and store structured logs\n\n- Add trajectory\\_entries table\n- ClaudeCodeExecutor with normalization\n- Parse Claude JSON format → TrajectoryEntry\n- Store entries in database\n- API endpoint: get trajectory entries\n\n**Deliverable**: Can view what Claude did step-by-step (tools used, files edited, etc.)\n\n### Phase 3: Real-Time Streaming\n\n**Goal**: Live updates in UI\n\n- WebSocket endpoint for live trajectory\n- Frontend TrajectoryViewer component\n- Display tool uses, thinking, messages\n- Auto-scroll and updates\n\n**Deliverable**: Watch agent execution in real-time\n\n### Phase 4: Session Management\n\n**Goal**: Resume and fork executions\n\n- Extract session IDs during execution\n- Store session\\_id in executions table\n- Implement spawnFollowUp\n- API endpoint: resume execution\n- UI: \"Continue\" button on executions\n\n**Deliverable**: Can send follow-up prompts to same session\n\n### Phase 5: Multiple Agents\n\n**Goal**: Support Codex and others\n\n- CodingAgent abstraction\n- CodexExecutor implementation\n- Agent selection in UI\n- Agent-specific config (MCP, etc.)\n\n**Deliverable**: Can choose between Claude Code and Codex\n\n### Phase 6: Advanced Features\n\n**Goal**: Production-ready\n\n- Git integration (capture commits)\n- Execution history and comparison\n- Trajectory search and filtering\n- Cost tracking (token usage)\n- Approval system for tool execution\n- Export trajectories\n\n## Key Design Decisions\n\n### Why Three Layers (Issue → Execution → Trajectory)?\n\n- **Issue** = What to do (user-defined task)\n- **Execution** = Agent run (can retry, use different agents)\n- **Trajectory** = How it was done (reproducibility, debugging)\n\nThis allows:\n\n1. Multiple attempts on same issue\n1. Comparing different agents\n1. Detailed playback and analysis\n\n### Why Normalize Logs?\n\nDifferent agents have wildly different output formats:\n\n- Claude Code: Structured JSON\n- Codex: Different JSON format\n- Aider: Plain text with markers\n\nNormalization gives us:\n\n1. Unified UI across all agents\n1. Consistent database schema\n1. Easier analysis and search\n\n### Why AsyncIterable for Log Processing?\n\n```typescript\nasync *normalizeLogs(rawLogs: AsyncIterable<string>)\n```\n\nBenefits:\n\n1. Streaming - process logs as they arrive\n1. Memory efficient - don't load all logs at once\n1. Cancellable - can stop mid-stream\n1. Natural async/await syntax\n\n### Why Store Raw + Normalized?\n\nStore both raw logs (temp files) AND normalized entries: [[ISSUE-032]]{ references }\n\n- Raw logs: debugging, replay, re-parsing\n- Normalized: fast queries, UI display\n\nTrade storage for flexibility.\n\n## Testing Strategy\n\n### Unit Tests\n\n- Log normalization logic\n- Action type extraction\n- Session ID parsing\n\n### Integration Tests\n\n[[ISSUE-033]]{ references }\n\n- Full execution lifecycle\n- WebSocket streaming\n- Database persistence\n\n### E2E Tests\n\n- Start execution via API\n- Verify trajectory entries created\n- Check final status\n\n## Open Questions\n\n1. **Where to run executions?**\n  - Option A: Same machine as server (simpler)\n  - Option B: Separate worker processes (scalable)\n  - **Recommendation**: Start with A, migrate to B later\n1. **How to handle long-running executions?**\n  - Timeout after N minutes?\n  - User-configurable timeout?\n  - **Recommendation**: 30min default, configurable per-issue\n1. **Store raw logs where?**\n  - Temp files (deleted after normalization)?\n  - Database blob?\n  - S3/object storage?\n  - **Recommendation**: Temp files initially, add retention later\n1. **How to handle git context?**\n  - Create isolated git worktrees for executions?\n  - Run in-place and capture commits?\n  - **Recommendation**: Start in-place, add worktrees in Phase 6\n\n## Success Metrics\n\n- **MVP (Phase 1)**: Can run Claude Code on an issue\n- **Useful (Phase 3)**: Can watch execution in real-time\n- **Powerful (Phase 4)**: Can have multi-turn conversations\n- **Production (Phase 6)**: Multiple agents, git integration, approval workflows\n\n## References\n\n- Claude Code: [https://docs.anthropic.com/en/docs/claude-code](https://docs.anthropic.com/en/docs/claude-code)\n- Codex: [https://github.com/phasehq/codex](https://github.com/phasehq/codex)\n","priority":0,"archived":1,"archived_at":"2025-10-28T19:03:55.817Z","created_at":"2025-10-27 00:06:59","updated_at":"2025-11-03T03:10:12.596Z","parent_id":null,"parent_uuid":null,"relationships":[],"tags":[]}
{"id":"SPEC-002","uuid":"603f99a9-53d6-448a-b66c-cf6c902894cf","title":"Execution System","file_path":"specs/execution_system.md","content":"Execution System Specification for Sudocode\n\n  Overview\n\n  Design a flexible, simple-first execution system that can spawn Claude Code instances to work on issues and\n  specs, with real-time progress tracking and the ability to upgrade to a pool-based strategy later.\n\n  Architecture Goals\n\n  1. Simple First: Start with straightforward process spawning\n  2. Flexible Design: Easy to upgrade to pool strategy without breaking changes\n  3. Real-time Feedback: Stream progress to frontend via WebSocket\n  4. Context-Aware: Build rich prompts from issue, spec, and codebase data\n  5. Reliable: Handle errors, timeouts, and process crashes gracefully\n\n  System Components\n\n  ┌─────────────────────────────────────────────────────────────┐\n  │                     Execution System                         │\n  ├─────────────────────────────────────────────────────────────┤\n  │                                                              │\n  │  ┌──────────────┐      ┌──────────────┐      ┌──────────┐  │\n  │  │   Context    │      │  Execution   │      │ Progress │  │\n  │  │   Builder    │─────▶│ Orchestrator │─────▶│ Tracker  │  │\n  │  └──────────────┘      └──────┬───────┘      └────┬─────┘  │\n  │                               │                    │         │\n  │                               ▼                    ▼         │\n  │                    ┌──────────────────┐    ┌──────────────┐ │\n  │                    │ Simple Execution │    │  WebSocket   │ │\n  │                    │    Strategy      │    │   Service    │ │\n  │                    └────────┬─────────┘    └──────────────┘ │\n  │                             │                                │\n  │                             ▼                                │\n  │                   ┌──────────────────┐                       │\n  │                   │ Simple Process   │                       │\n  │                   │    Manager       │                       │\n  │                   └────────┬─────────┘                       │\n  │                            │                                 │\n  │                            ▼                                 │\n  │                   ┌──────────────────┐                       │\n  │                   │  Claude Code     │                       │\n  │                   │  CLI Process     │                       │\n  │                   └──────────────────┘                       │\n  │                                                              │\n  └─────────────────────────────────────────────────────────────┘\n\n  Data Flow\n\n  1. User triggers execution (via API/UI)\n     ↓\n  2. ExecutionOrchestrator.executeIssue(issueId)\n     ↓\n  3. ContextBuilder.buildIssueContext(issueId)\n     - Read issue from database\n     - Find related specs via relationships\n     - Find related issues (dependencies, parent)\n     - Read spec content from markdown files\n     - Build comprehensive prompt\n     ↓\n  4. Create ExecutionTask\n     - Task ID, entity type, context, priority\n     ↓\n  5. SimpleExecutionStrategy.executeTask(task)\n     ↓\n  6. SimpleProcessManager.acquireProcess(task)\n     - Spawn new Claude Code CLI process\n     - Return ManagedProcess handle\n     ↓\n  7. Send prompt to Claude via stdin\n     - Use stream-json output format\n     - Parse output line by line\n     ↓\n  8. ProgressTracker emits updates\n     - Phase changes (initializing → executing → finalizing)\n     - Tool use events (reading files, editing, etc.)\n     - Completion status\n     ↓\n  9. WebSocketService broadcasts to frontend\n     - Real-time progress updates\n     - Execution logs\n     - Final results\n     ↓\n  10. Update execution record in database\n      - Status, exit code, duration, etc.\n      ↓\n  11. SimpleProcessManager.releaseProcess(processId)\n      - Terminate Claude process\n      - Clean up resources\n\n  Component Specifications\n\n  1. Context Builder\n\n  Purpose: Build rich, context-aware prompts for Claude Code\n\n  Inspired by: CodeMachine-CLI's context-manager-agent\n  (references/CodeMachine-CLI/prompts/templates/codemachine/agents/04-context-manager-agent.md)\n\n  Interface:\n  interface IContextBuilder {\n    buildIssueContext(issueId: string): Promise<ExecutionContext>;\n    buildSpecContext(specId: string): Promise<ExecutionContext>;\n    buildBatchContext(entityIds: string[]): Promise<Map<string, ExecutionContext>>;\n  }\n\n  interface ExecutionContext {\n    workDir: string;\n    entityType: 'issue' | 'spec';\n    entityId: string;\n\n    // Core data\n    title: string;\n    description: string;\n\n    // Related entities\n    relatedSpecs: Array<{\n      id: string;\n      title: string;\n      content: string;\n      relationship: string;\n    }>;\n\n    relatedIssues: Array<{\n      id: string;\n      title: string;\n      description: string;\n      status: string;\n      relationship: string;\n    }>;\n\n    // Codebase context (optional, for later enhancement)\n    relevantFiles?: string[];\n\n    // Final prompt\n    prompt: string;\n  }\n\n  Prompt Template Structure (inspired by CodeMachine-CLI):\n  # Task: Work on Issue {issueId}\n\n  ## Issue Details\n  **Title**: {issue.title}\n  **Status**: {issue.status}\n  **Priority**: {issue.priority}\n\n  **Description**:\n  {issue.description}\n\n  ## Related Specifications\n\n  {for each related spec}\n  ### {spec.id}: {spec.title}\n  **Relationship**: {relationship.type}\n\n  {spec.content}\n  {end for}\n\n  ## Related Issues\n\n  {for each related issue}\n  ### {issue.id}: {issue.title}\n  **Status**: {issue.status}\n  **Relationship**: {relationship.type}\n\n  {issue.description}\n  {end for}\n\n  ## Instructions\n\n  1. Analyze the issue description and related specifications\n  2. Understand the requirements and acceptance criteria\n  3. Implement the necessary changes to address the issue\n  4. Test your implementation\n  5. Ensure code quality and adherence to project standards\n\n  ## Project Context\n\n  - Working directory: {workDir}\n  - Project: sudocode issue tracking system\n  - Use TypeScript for all implementations\n  - Follow existing code patterns in the codebase\n\n  ## Output Requirements\n\n  - Make necessary code changes\n  - Update tests if needed\n  - Provide a summary of changes made\n\n  Implementation Notes:\n  - Use template strings or a templating library (handlebars, mustache)\n  - Cache spec content to avoid repeated file reads\n  - Handle missing relationships gracefully\n  - Support both issue and spec execution contexts\n\n  ---\n  2. Execution Orchestrator\n\n  Purpose: Main coordinator that ties all components together\n\n  Inspired by:\n  - CodeMachine-CLI's workflow orchestrator (references/CodeMachine-CLI/src/workflows/execution/workflow.ts)\n  - claude-flow's SwarmCoordinator (references/claude-flow/src/swarm/coordinator.ts)\n\n  Interface:\n  class ExecutionOrchestrator {\n    constructor(\n      private strategy: IExecutionStrategy,\n      private contextBuilder: IContextBuilder,\n      private progressTracker: IProgressTracker,\n      private db: Database.Database\n    );\n\n    // Primary methods\n    executeIssue(issueId: string, options?: ExecutionOptions): Promise<ExecutionResult>;\n    executeSpec(specId: string, options?: ExecutionOptions): Promise<ExecutionResult>;\n    executeMultiple(entityIds: string[], options?: ExecutionOptions): Promise<ExecutionResult[]>;\n\n    // Control methods\n    stopExecution(executionId: string): Promise<void>;\n    getExecutionStatus(executionId: string): ExecutionProgress | null;\n\n    // Strategy management\n    switchStrategy(newStrategy: IExecutionStrategy): void;\n  }\n\n  interface ExecutionOptions {\n    workDir?: string;\n    maxDuration?: number;  // milliseconds\n    priority?: number;\n    customPrompt?: string; // Override generated prompt\n  }\n\n  Key Responsibilities:\n  1. Coordinate between context builder, strategy, and progress tracker\n  2. Create and persist execution records in database\n  3. Handle errors and timeouts gracefully\n  4. Provide clean API for frontend/API layer\n\n  Implementation Pattern (from CodeMachine-CLI):\n  async executeIssue(issueId: string, options: ExecutionOptions = {}): Promise<ExecutionResult> {\n    // 1. Build context\n    const context = await this.contextBuilder.buildIssueContext(issueId);\n\n    // 2. Create task\n    const task: ExecutionTask = {\n      id: generateId('task'),\n      type: 'issue',\n      entityId: issueId,\n      context: {\n        ...context,\n        workDir: options.workDir || process.cwd(),\n      },\n      priority: options.priority || 1,\n      dependencies: [], // TODO: Resolve from relationships\n    };\n\n    // 3. Create execution record in DB\n    const execution = createExecution(this.db, {\n      issue_id: issueId,\n      agent_type: 'claude-code',\n      status: 'running',\n    });\n\n    // 4. Start progress tracking\n    this.progressTracker.startTracking(execution.id, task);\n\n    try {\n      // 5. Execute via strategy\n      const result = await this.strategy.executeTask(task);\n\n      // 6. Update database\n      updateExecution(this.db, execution.id, {\n        status: result.success ? 'completed' : 'failed',\n        exit_code: result.success ? 0 : 1,\n        completed_at: Math.floor(Date.now() / 1000),\n        error_message: result.error,\n      });\n\n      // 7. Complete tracking\n      this.progressTracker.completeTracking(execution.id, result);\n\n      return result;\n    } catch (error) {\n      // Handle errors\n      const errorMessage = error instanceof Error ? error.message : 'Unknown error';\n\n      updateExecution(this.db, execution.id, {\n        status: 'failed',\n        completed_at: Math.floor(Date.now() / 1000),\n        error_message: errorMessage,\n      });\n\n      this.progressTracker.completeTracking(execution.id, {\n        ...result,\n        success: false,\n        error: errorMessage,\n      });\n\n      throw error;\n    }\n  }\n\n  ---\n  3. Simple Execution Strategy\n\n  Purpose: Execute tasks by spawning Claude Code processes on-demand\n\n  Inspired by:\n  - CodeMachine-CLI's step execution (references/CodeMachine-CLI/src/workflows/execution/step.ts)\n  - claude-flow's SimpleExecutionStrategy pattern\n\n  Interface:\n  class SimpleExecutionStrategy implements IExecutionStrategy {\n    constructor(\n      private processManager: IProcessManager,\n      private maxConcurrent: number = 3,\n      private defaultTimeout: number = 300_000 // 5 minutes\n    );\n\n    executeTask(task: ExecutionTask): Promise<ExecutionResult>;\n    executeTasks(tasks: ExecutionTask[]): Promise<ExecutionResult[]>;\n    getMetrics(): StrategyMetrics;\n    shutdown(): Promise<void>;\n  }\n\n  Key Implementation Details:\n\n  1. Process Spawning (from CodeMachine-CLI pattern):\n  private async runTask(\n    process: ManagedProcess,\n    task: ExecutionTask\n  ): Promise<ExecutionResult> {\n    const startTime = Date.now();\n\n    return new Promise((resolve, reject) => {\n      let outputBuffer = '';\n      let errorBuffer = '';\n\n      // Set up timeout\n      const timeout = setTimeout(() => {\n        process.process.kill('SIGTERM');\n        reject(new Error('Execution timed out'));\n      }, this.defaultTimeout);\n\n      // Parse stream-json output (from CodeMachine-CLI)\n      process.process.stdout?.on('data', (chunk: Buffer) => {\n        const text = chunk.toString();\n        outputBuffer += text;\n\n        // Parse JSON lines\n        const lines = text.split('\\n');\n        for (const line of lines) {\n          if (!line.trim()) continue;\n\n          try {\n            const json = JSON.parse(line);\n            this.handleStreamJsonLine(json, task);\n          } catch {\n            // Not JSON, treat as regular output\n          }\n        }\n      });\n\n      process.process.stderr?.on('data', (chunk: Buffer) => {\n        errorBuffer += chunk.toString();\n      });\n\n      process.process.on('exit', (code) => {\n        clearTimeout(timeout);\n\n        const duration = Date.now() - startTime;\n        const result: ExecutionResult = {\n          taskId: task.id,\n          executionId: process.id,\n          success: code === 0,\n          output: outputBuffer,\n          error: code !== 0 ? errorBuffer : undefined,\n          duration,\n          metadata: this.extractMetadata(outputBuffer),\n        };\n\n        resolve(result);\n      });\n\n      process.process.on('error', (error) => {\n        clearTimeout(timeout);\n        reject(error);\n      });\n    });\n  }\n\n  2. Stream JSON Parsing (from CodeMachine-CLI claude runner):\n  private handleStreamJsonLine(json: any, task: ExecutionTask): void {\n    // Parse different event types from Claude's stream-json format\n    if (json.type === 'assistant' && json.message?.content) {\n      for (const content of json.message.content) {\n        if (content.type === 'text') {\n          this.emitProgress(task.id, {\n            phase: 'executing',\n            message: content.text.substring(0, 200),\n          });\n        } else if (content.type === 'tool_use') {\n          this.emitProgress(task.id, {\n            phase: 'executing',\n            message: `Using tool: ${content.name}`,\n            metadata: { tool: content.name, args: content.input },\n          });\n        }\n      }\n    } else if (json.type === 'result') {\n      // Final result with usage stats\n      this.emitProgress(task.id, {\n        phase: 'finalizing',\n        message: 'Task completed',\n        metadata: {\n          duration: json.duration_ms,\n          tokensUsed: json.usage?.total_tokens,\n        },\n      });\n    }\n  }\n\n  3. Concurrency Control (simple batching):\n  async executeTasks(tasks: ExecutionTask[]): Promise<ExecutionResult[]> {\n    const results: ExecutionResult[] = [];\n\n    // Execute in batches\n    for (let i = 0; i < tasks.length; i += this.maxConcurrent) {\n      const batch = tasks.slice(i, i + this.maxConcurrent);\n      const batchResults = await Promise.all(\n        batch.map(task => this.executeTask(task))\n      );\n      results.push(...batchResults);\n    }\n\n    return results;\n  }\n\n  ---\n  4. Simple Process Manager\n\n  Purpose: Manage Claude Code CLI process lifecycle\n\n  Inspired by:\n  - claude-flow's process management (references/claude-flow/src/swarm/claude-code-interface.ts)\n  - Your existing ExecutionManager\n\n  Interface:\n  class SimpleProcessManager implements IProcessManager {\n    constructor(\n      private logsDir: string,\n      private claudePath: string = 'claude'\n    );\n\n    acquireProcess(task: ExecutionTask): Promise<ManagedProcess>;\n    releaseProcess(processId: string): Promise<void>;\n    terminateProcess(processId: string): Promise<void>;\n    getProcessMetrics(): ProcessMetrics;\n    shutdown(): Promise<void>;\n  }\n\n  Key Implementation:\n\n  1. Spawn Claude Code (from CodeMachine-CLI pattern):\n  private spawnClaudeProcess(task: ExecutionTask): ChildProcess {\n    const args = [\n      '--print',                          // Non-interactive mode\n      '--output-format', 'stream-json',   // Structured output\n      '--dangerously-skip-permissions',   // Skip permission prompts\n      '--permission-mode', 'bypassPermissions',\n    ];\n\n    const process = spawn(this.claudePath, args, {\n      cwd: task.context.workDir,\n      stdio: ['pipe', 'pipe', 'pipe'],\n      env: {\n        ...process.env,\n        // Add any custom environment variables\n      },\n    });\n\n    // Write prompt to stdin\n    process.stdin?.write(task.context.prompt);\n    process.stdin?.end();\n\n    return process;\n  }\n\n  2. Process Tracking:\n  async acquireProcess(task: ExecutionTask): Promise<ManagedProcess> {\n    const process = this.spawnClaudeProcess(task);\n\n    if (!process.pid) {\n      throw new Error('Failed to spawn Claude process');\n    }\n\n    const managed: ManagedProcess = {\n      id: generateId('process'),\n      process,\n      status: 'busy',\n      spawnedAt: new Date(),\n      lastActivity: new Date(),\n      tasksCompleted: 0,\n      metrics: {\n        totalDuration: 0,\n        successRate: 1.0,\n      },\n    };\n\n    this.activeProcesses.set(managed.id, managed);\n    return managed;\n  }\n\n  3. Graceful Termination:\n  async terminateProcess(processId: string): Promise<void> {\n    const managed = this.activeProcesses.get(processId);\n    if (!managed) return;\n\n    managed.status = 'terminating';\n\n    // Try SIGTERM first\n    managed.process.kill('SIGTERM');\n\n    // Wait for graceful shutdown\n    await new Promise(resolve => setTimeout(resolve, 2000));\n\n    // Force kill if needed\n    if (!managed.process.killed && managed.process.exitCode === null) {\n      managed.process.kill('SIGKILL');\n    }\n\n    this.activeProcesses.delete(processId);\n  }\n\n  ---\n  5. Progress Tracker\n\n  Purpose: Track and emit real-time progress updates\n\n  Inspired by: claude-flow's event emission patterns\n\n  Interface:\n  interface IProgressTracker {\n    startTracking(executionId: string, task: ExecutionTask): void;\n    updateProgress(executionId: string, update: ProgressUpdate): void;\n    completeTracking(executionId: string, result: ExecutionResult): void;\n    getProgress(executionId: string): ExecutionProgress | null;\n    onProgress(callback: (update: ProgressUpdate) => void): void;\n  }\n\n  interface ProgressUpdate {\n    executionId: string;\n    phase: 'initializing' | 'context_building' | 'executing' | 'finalizing';\n    message: string;\n    percentage?: number;\n    metadata?: {\n      tool?: string;\n      args?: any;\n      tokensUsed?: number;\n      filesChanged?: string[];\n    };\n  }\n\n  Implementation:\n  class WebSocketProgressTracker implements IProgressTracker {\n    private progressMap = new Map<string, ExecutionProgress>();\n    private callbacks: Array<(update: ProgressUpdate) => void> = [];\n\n    constructor(private wss: WebSocketService) {}\n\n    startTracking(executionId: string, task: ExecutionTask): void {\n      const progress: ExecutionProgress = {\n        executionId,\n        taskId: task.id,\n        status: 'running',\n        currentPhase: 'initializing',\n        startTime: new Date(),\n        lastUpdate: new Date(),\n      };\n\n      this.progressMap.set(executionId, progress);\n\n      // Emit initial update\n      this.emitUpdate({\n        executionId,\n        phase: 'initializing',\n        message: 'Starting execution...',\n        percentage: 0,\n      });\n    }\n\n    updateProgress(executionId: string, update: ProgressUpdate): void {\n      const progress = this.progressMap.get(executionId);\n      if (!progress) return;\n\n      progress.currentPhase = update.phase;\n      progress.lastUpdate = new Date();\n\n      this.emitUpdate(update);\n    }\n\n    completeTracking(executionId: string, result: ExecutionResult): void {\n      const progress = this.progressMap.get(executionId);\n      if (!progress) return;\n\n      progress.status = result.success ? 'completed' : 'failed';\n\n      this.emitUpdate({\n        executionId,\n        phase: 'finalizing',\n        message: result.success ? 'Execution completed successfully' : `Execution failed: ${result.error}`,\n        percentage: 100,\n        metadata: result.metadata,\n      });\n\n      // Clean up after a delay\n      setTimeout(() => {\n        this.progressMap.delete(executionId);\n      }, 60_000); // Keep for 1 minute\n    }\n\n    private emitUpdate(update: ProgressUpdate): void {\n      // Emit to WebSocket clients\n      this.wss.broadcast('execution:progress', update);\n\n      // Emit to registered callbacks\n      for (const callback of this.callbacks) {\n        callback(update);\n      }\n    }\n\n    onProgress(callback: (update: ProgressUpdate) => void): void {\n      this.callbacks.push(callback);\n    }\n  }\n\n  ---\n  Integration with Existing Code\n\n  1. Update ExecutionManager\n\n  // server/src/execution/manager.ts\n  export class ExecutionManager {\n    private orchestrator: ExecutionOrchestrator;\n\n    constructor(\n      db: Database.Database,\n      wss: WebSocketService,\n      logsDir?: string\n    ) {\n      // Initialize components\n      const contextBuilder = new DefaultContextBuilder(db);\n      const progressTracker = new WebSocketProgressTracker(wss);\n      const processManager = new SimpleProcessManager(logsDir || path.join(os.tmpdir(),\n  'sudocode-executions'));\n      const strategy = new SimpleExecutionStrategy(processManager, 3);\n\n      // Create orchestrator\n      this.orchestrator = new ExecutionOrchestrator(\n        strategy,\n        contextBuilder,\n        progressTracker,\n        db\n      );\n    }\n\n    // Delegate to orchestrator\n    async startExecution(input: StartExecutionInput): Promise<Execution> {\n      return this.orchestrator.executeIssue(input.issue_id, {\n        workDir: input.work_dir,\n        customPrompt: input.prompt,\n      });\n    }\n\n    async stopExecution(executionId: string): Promise<void> {\n      return this.orchestrator.stopExecution(executionId);\n    }\n\n    getExecutionStatus(executionId: string): ExecutionProgress | null {\n      return this.orchestrator.getExecutionStatus(executionId);\n    }\n  }\n\n  2. Add API Endpoints\n\n  // server/src/routes/executions.ts\n  router.post('/executions', async (req, res) => {\n    const { issue_id, work_dir, prompt } = req.body;\n\n    try {\n      const result = await executionManager.startExecution({\n        issue_id,\n        agent_type: 'claude-code',\n        work_dir,\n        prompt,\n      });\n\n      res.json(result);\n    } catch (error) {\n      res.status(500).json({ error: error.message });\n    }\n  });\n\n  router.get('/executions/:id/status', async (req, res) => {\n    const status = executionManager.getExecutionStatus(req.params.id);\n\n    if (!status) {\n      return res.status(404).json({ error: 'Execution not found' });\n    }\n\n    res.json(status);\n  });\n\n  router.post('/executions/:id/stop', async (req, res) => {\n    await executionManager.stopExecution(req.params.id);\n    res.json({ success: true });\n  });\n\n  3. WebSocket Integration\n\n  // server/src/services/websocket.ts\n  export class WebSocketService {\n    broadcast(event: string, data: any): void {\n      this.wss.clients.forEach(client => {\n        if (client.readyState === WebSocket.OPEN) {\n          client.send(JSON.stringify({ event, data }));\n        }\n      });\n    }\n  }\n\n  // Frontend can subscribe to execution progress\n  socket.on('execution:progress', (update: ProgressUpdate) => {\n    console.log(`[${update.executionId}] ${update.phase}: ${update.message}`);\n    // Update UI with progress\n  });\n\n  ---\n  File Structure\n\n  server/src/execution/\n  ├── manager.ts                    # Existing ExecutionManager (updated)\n  ├── spawn-claude-code.ts         # Existing spawn utility\n  ├── orchestrator.ts              # NEW: ExecutionOrchestrator\n  ├── strategies/\n  │   ├── base.ts                  # IExecutionStrategy interface\n  │   ├── simple-strategy.ts       # SimpleExecutionStrategy\n  │   └── pool-strategy.ts         # (Future) PoolExecutionStrategy\n  ├── process-managers/\n  │   ├── base.ts                  # IProcessManager interface\n  │   ├── simple-manager.ts        # SimpleProcessManager\n  │   └── pool-manager.ts          # (Future) PoolProcessManager\n  ├── context/\n  │   ├── builder.ts               # IContextBuilder interface\n  │   ├── default-builder.ts       # DefaultContextBuilder\n  │   └── templates.ts             # Prompt templates\n  ├── progress/\n  │   ├── tracker.ts               # IProgressTracker interface\n  │   └── websocket-tracker.ts    # WebSocketProgressTracker\n  └── types.ts                     # Shared types and interfaces\n\n  ---\n  Implementation Phases\n\n  Phase 1: Core Infrastructure (Week 1)\n  - Define all interfaces in types.ts\n  - Implement DefaultContextBuilder\n  - Implement SimpleProcessManager\n  - Implement SimpleExecutionStrategy\n  - Write unit tests for each component\n\n  Phase 2: Orchestration (Week 2)\n  - Implement ExecutionOrchestrator\n  - Integrate with existing ExecutionManager\n  - Add API endpoints for execution control\n  - Write integration tests\n\n  Phase 3: Progress Tracking (Week 3)\n  - Implement WebSocketProgressTracker\n  - Add WebSocket event handling\n  - Update frontend to display progress\n  - Test end-to-end flow\n\n  Phase 4: Polish & Documentation (Week 4)\n  - Add error handling and recovery\n  - Write comprehensive documentation\n  - Create example usage guides\n  - Performance testing and optimization\n","priority":0,"archived":1,"archived_at":"2025-10-28T08:31:01.555Z","created_at":"2025-10-27 18:30:25","updated_at":"2025-11-03T03:10:12.596Z","parent_id":null,"parent_uuid":null,"relationships":[],"tags":[]}
{"id":"SPEC-003","uuid":"48dd725d-675a-4038-83d2-b5f5e41dd75a","title":"Process Layer - Claude Code Process Management","file_path":"specs/process_layer_claude_code_process_management.md","content":"# Process Layer Specification\n\n## Overview\n\nThe Process Layer (Layer 1) manages the lifecycle of individual Claude Code CLI processes. This is the foundation of the execution system, inspired by claude-flow's simple yet flexible approach.\n\n## Design Goals\n\n1. **Simple First**: Start with basic process spawning using Node.js child_process\n2. **Event-Driven**: Use native event emitters for real-time I/O streaming\n3. **Flexible**: Easy to upgrade from simple spawning to process pooling\n4. **Reliable**: Handle timeouts, crashes, and cleanup gracefully\n5. **Observable**: Expose all process events for upper layers\n\n## Architecture\n\nBased on Execution System spec, this implements the process spawning and management foundation.\n\n```\n┌─────────────────────────────────────────┐\n│        Process Layer (Layer 1)          │\n├─────────────────────────────────────────┤\n│                                         │\n│  ┌──────────────────────────────────┐  │\n│  │   IProcessManager (Interface)    │  │\n│  └────────────┬─────────────────────┘  │\n│               │                         │\n│               ├──────────────────────┐  │\n│               │                      │  │\n│     ┌─────────▼────────┐   ┌────────▼──────────┐\n│     │ SimpleProcess    │   │  PoolProcess      │\n│     │    Manager       │   │   Manager         │\n│     │  (Start Here)    │   │  (Future)         │\n│     └──────────────────┘   └───────────────────┘\n│                                         │\n└─────────────────────────────────────────┘\n```\n\n## Core Types\n\n### ManagedProcess\nRepresents a single Claude Code process instance with its lifecycle state.\n\n```typescript\ninterface ManagedProcess {\n  // Identity\n  id: string;                    // Unique process ID\n  pid: number;                   // OS process ID\n  \n  // Lifecycle\n  status: ProcessStatus;\n  spawnedAt: Date;\n  lastActivity: Date;\n  exitCode: number | null;\n  signal: string | null;\n  \n  // Resources\n  process: ChildProcess;         // Node.js child process handle\n  streams: {\n    stdout: Readable;\n    stderr: Readable;\n    stdin: Writable;\n  };\n  \n  // Metrics\n  metrics: {\n    totalDuration: number;       // milliseconds\n    tasksCompleted: number;\n    successRate: number;\n  };\n}\n\ntype ProcessStatus = \n  | 'spawning'     // Being created\n  | 'idle'         // Ready for work (pool only)\n  | 'busy'         // Executing task\n  | 'terminating'  // Shutting down\n  | 'crashed'      // Exited unexpectedly\n  | 'completed';   // Exited normally\n```\n\n### ProcessConfig\nConfiguration for spawning Claude Code processes.\n\n```typescript\ninterface ProcessConfig {\n  // Claude Code CLI path\n  claudePath: string;            // Default: 'claude'\n  \n  // Working directory\n  workDir: string;\n  \n  // Claude Code CLI arguments\n  args: {\n    print: boolean;              // --print (non-interactive)\n    outputFormat: 'stream-json' | 'json' | 'text';\n    dangerouslySkipPermissions: boolean;\n    permissionMode?: string;\n  };\n  \n  // Environment variables\n  env?: Record<string, string>;\n  \n  // Timeouts\n  timeout?: number;              // Max execution time (ms)\n  idleTimeout?: number;          // Max idle time before cleanup (pool only)\n  \n  // Retry configuration\n  retry?: {\n    maxAttempts: number;\n    backoffMs: number;\n  };\n}\n```\n\n## IProcessManager Interface\n\nThe core abstraction that all process managers implement.\n\n```typescript\ninterface IProcessManager {\n  // Process lifecycle\n  acquireProcess(config: ProcessConfig): Promise<ManagedProcess>;\n  releaseProcess(processId: string): Promise<void>;\n  terminateProcess(processId: string, signal?: NodeJS.Signals): Promise<void>;\n  \n  // Process communication\n  sendInput(processId: string, input: string): Promise<void>;\n  onOutput(processId: string, handler: OutputHandler): void;\n  onError(processId: string, handler: ErrorHandler): void;\n  \n  // Monitoring\n  getProcess(processId: string): ManagedProcess | null;\n  getActiveProcesses(): ManagedProcess[];\n  getMetrics(): ProcessMetrics;\n  \n  // Cleanup\n  shutdown(): Promise<void>;\n}\n\ntype OutputHandler = (data: Buffer, type: 'stdout' | 'stderr') => void;\ntype ErrorHandler = (error: Error) => void;\n\ninterface ProcessMetrics {\n  totalSpawned: number;\n  currentlyActive: number;\n  totalCompleted: number;\n  totalFailed: number;\n  averageDuration: number;\n}\n```\n\n## SimpleProcessManager Implementation\n\nStart with this simple, production-ready implementation based on claude-flow's pattern.\n\n### Key Features\n\n1. **One Process Per Task**: Spawn fresh process for each task\n2. **Event-Based I/O**: Stream stdout/stderr in real-time\n3. **Graceful Termination**: SIGTERM → wait → SIGKILL if needed\n4. **Automatic Cleanup**: Remove completed processes from tracking\n5. **Error Handling**: Capture spawn errors, exit codes, crashes\n\n### Implementation Pattern\n\n```typescript\nclass SimpleProcessManager implements IProcessManager {\n  private activeProcesses = new Map<string, ManagedProcess>();\n  private metrics: ProcessMetrics = {\n    totalSpawned: 0,\n    currentlyActive: 0,\n    totalCompleted: 0,\n    totalFailed: 0,\n    averageDuration: 0,\n  };\n\n  constructor(\n    private defaultConfig: Partial<ProcessConfig> = {}\n  ) {}\n\n  async acquireProcess(config: ProcessConfig): Promise<ManagedProcess> {\n    const mergedConfig = { ...this.defaultConfig, ...config };\n    const process = await this.spawnClaudeProcess(mergedConfig);\n    \n    if (!process.pid) {\n      throw new Error('Failed to spawn Claude Code process');\n    }\n\n    const managed: ManagedProcess = {\n      id: generateId('process'),\n      pid: process.pid,\n      status: 'busy',\n      spawnedAt: new Date(),\n      lastActivity: new Date(),\n      exitCode: null,\n      signal: null,\n      process,\n      streams: {\n        stdout: process.stdout!,\n        stderr: process.stderr!,\n        stdin: process.stdin!,\n      },\n      metrics: {\n        totalDuration: 0,\n        tasksCompleted: 0,\n        successRate: 1.0,\n      },\n    };\n\n    this.setupProcessHandlers(managed, config);\n    this.activeProcesses.set(managed.id, managed);\n    this.metrics.totalSpawned++;\n    this.metrics.currentlyActive++;\n\n    return managed;\n  }\n\n  private async spawnClaudeProcess(config: ProcessConfig): Promise<ChildProcess> {\n    const args = this.buildClaudeArgs(config);\n\n    const process = spawn(config.claudePath, args, {\n      cwd: config.workDir,\n      stdio: ['pipe', 'pipe', 'pipe'],\n      env: {\n        ...process.env,\n        ...config.env,\n      },\n    });\n\n    return process;\n  }\n\n  private buildClaudeArgs(config: ProcessConfig): string[] {\n    const args: string[] = [];\n\n    if (config.args.print) {\n      args.push('--print');\n    }\n\n    if (config.args.outputFormat) {\n      args.push('--output-format', config.args.outputFormat);\n    }\n\n    if (config.args.dangerouslySkipPermissions) {\n      args.push('--dangerously-skip-permissions');\n    }\n\n    if (config.args.permissionMode) {\n      args.push('--permission-mode', config.args.permissionMode);\n    }\n\n    return args;\n  }\n\n  private setupProcessHandlers(managed: ManagedProcess, config: ProcessConfig): void {\n    const { process } = managed;\n    let timeoutHandle: NodeJS.Timeout | null = null;\n\n    // Set timeout if configured\n    if (config.timeout) {\n      timeoutHandle = setTimeout(() => {\n        this.terminateProcess(managed.id, 'SIGTERM');\n      }, config.timeout);\n    }\n\n    // Handle exit\n    process.on('exit', (code, signal) => {\n      if (timeoutHandle) clearTimeout(timeoutHandle);\n\n      managed.exitCode = code;\n      managed.signal = signal;\n      managed.status = code === 0 ? 'completed' : 'crashed';\n\n      const duration = Date.now() - managed.spawnedAt.getTime();\n      managed.metrics.totalDuration = duration;\n\n      // Update global metrics\n      this.metrics.currentlyActive--;\n      if (code === 0) {\n        this.metrics.totalCompleted++;\n      } else {\n        this.metrics.totalFailed++;\n      }\n\n      // Clean up after delay\n      setTimeout(() => {\n        this.activeProcesses.delete(managed.id);\n      }, 5000);\n    });\n\n    // Handle spawn errors\n    process.on('error', (error) => {\n      if (timeoutHandle) clearTimeout(timeoutHandle);\n      \n      managed.status = 'crashed';\n      this.metrics.currentlyActive--;\n      this.metrics.totalFailed++;\n    });\n\n    // Update activity on I/O\n    process.stdout?.on('data', () => {\n      managed.lastActivity = new Date();\n    });\n  }\n\n  async sendInput(processId: string, input: string): Promise<void> {\n    const managed = this.activeProcesses.get(processId);\n    if (!managed) {\n      throw new Error(`Process ${processId} not found`);\n    }\n\n    return new Promise((resolve, reject) => {\n      managed.streams.stdin.write(input, (error) => {\n        if (error) reject(error);\n        else resolve();\n      });\n    });\n  }\n\n  onOutput(processId: string, handler: OutputHandler): void {\n    const managed = this.activeProcesses.get(processId);\n    if (!managed) return;\n\n    managed.streams.stdout.on('data', (data: Buffer) => {\n      handler(data, 'stdout');\n    });\n\n    managed.streams.stderr.on('data', (data: Buffer) => {\n      handler(data, 'stderr');\n    });\n  }\n\n  async terminateProcess(\n    processId: string, \n    signal: NodeJS.Signals = 'SIGTERM'\n  ): Promise<void> {\n    const managed = this.activeProcesses.get(processId);\n    if (!managed) return;\n\n    managed.status = 'terminating';\n\n    // Try graceful shutdown first\n    managed.process.kill(signal);\n\n    // Wait for graceful shutdown\n    await new Promise(resolve => setTimeout(resolve, 2000));\n\n    // Force kill if still running\n    if (!managed.process.killed && managed.exitCode === null) {\n      managed.process.kill('SIGKILL');\n    }\n  }\n\n  async releaseProcess(processId: string): Promise<void> {\n    await this.terminateProcess(processId);\n  }\n\n  getProcess(processId: string): ManagedProcess | null {\n    return this.activeProcesses.get(processId) || null;\n  }\n\n  getActiveProcesses(): ManagedProcess[] {\n    return Array.from(this.activeProcesses.values());\n  }\n\n  getMetrics(): ProcessMetrics {\n    return { ...this.metrics };\n  }\n\n  async shutdown(): Promise<void> {\n    const processes = Array.from(this.activeProcesses.keys());\n    await Promise.all(\n      processes.map(id => this.terminateProcess(id, 'SIGTERM'))\n    );\n  }\n}\n```\n\n## Usage Example\n\n```typescript\n// Initialize manager\nconst processManager = new SimpleProcessManager({\n  claudePath: 'claude',\n  args: {\n    print: true,\n    outputFormat: 'stream-json',\n    dangerouslySkipPermissions: true,\n  },\n});\n\n// Spawn process\nconst process = await processManager.acquireProcess({\n  claudePath: 'claude',\n  workDir: '/path/to/project',\n  args: {\n    print: true,\n    outputFormat: 'stream-json',\n    dangerouslySkipPermissions: true,\n  },\n  timeout: 300000, // 5 minutes\n});\n\n// Send input\nawait processManager.sendInput(process.id, 'Fix the bug in auth.ts\\n');\n\n// Listen to output\nprocessManager.onOutput(process.id, (data, type) => {\n  console.log(`[${type}]`, data.toString());\n});\n\n// Clean up\nawait processManager.releaseProcess(process.id);\n```\n\n## Testing Strategy\n\n### Unit Tests\n\n1. **Process spawning**\n   - Spawns with correct arguments\n   - Sets working directory\n   - Passes environment variables\n\n2. **Lifecycle management**\n   - Tracks process status correctly\n   - Updates metrics on exit\n   - Cleans up resources\n\n3. **I/O handling**\n   - Sends input to stdin\n   - Receives stdout/stderr\n   - Handles stream errors\n\n4. **Termination**\n   - Graceful shutdown (SIGTERM)\n   - Force kill after timeout\n   - Cleans up after termination\n\n### Integration Tests\n\n1. **End-to-end execution**\n   - Spawn → send prompt → receive output → terminate\n   - Multiple concurrent processes\n   - Process crash recovery\n\n2. **Error scenarios**\n   - Invalid claude path\n   - Process spawn failure\n   - Timeout handling\n\n## Future Enhancements\n\n### Path to Pool-Based Strategy\n\nThe interface design makes it easy to add pooling later:\n\n```typescript\nclass PoolProcessManager implements IProcessManager {\n  private pool: ManagedProcess[] = [];\n  private maxPoolSize: number;\n  private minIdleProcesses: number;\n\n  async acquireProcess(config: ProcessConfig): Promise<ManagedProcess> {\n    // Try to get idle process from pool\n    const idle = this.pool.find(p => p.status === 'idle');\n    \n    if (idle) {\n      idle.status = 'busy';\n      return idle;\n    }\n\n    // Create new if under limit\n    if (this.pool.length < this.maxPoolSize) {\n      return this.createAndAddToPool(config);\n    }\n\n    // Wait for available process\n    return this.waitForAvailableProcess(config);\n  }\n\n  async releaseProcess(processId: string): Promise<void> {\n    const process = this.pool.find(p => p.id === processId);\n    if (process) {\n      process.status = 'idle';\n      process.metrics.tasksCompleted++;\n    }\n  }\n\n  // ... pool management logic\n}\n```\n\n### Other Future Features\n\n1. **Process health checks** - Ping processes periodically\n2. **Automatic restarts** - Restart crashed processes in pool\n3. **Resource limits** - Memory/CPU monitoring\n4. **Process affinity** - Pin processes to specific tasks/users\n\n## File Structure\n\n```\nserver/src/execution/process/\n├── types.ts                    # Core types and interfaces\n├── manager.ts                  # IProcessManager interface\n├── simple-manager.ts           # SimpleProcessManager (start here)\n├── pool-manager.ts             # PoolProcessManager (future)\n└── utils.ts                    # Helper functions\n```\n\n## Implementation Checklist\n\n- [ ] Define core types in types.ts\n- [ ] Define IProcessManager interface\n- [ ] Implement SimpleProcessManager\n- [ ] Add process spawning with child_process\n- [ ] Add event handlers for exit, error, I/O\n- [ ] Add graceful termination (SIGTERM → SIGKILL)\n- [ ] Add metrics tracking\n- [ ] Write unit tests for process lifecycle\n- [ ] Write integration tests for end-to-end flow\n- [ ] Document usage examples\n\n## Related Specs\n\n- Execution System (parent spec)\n- Next: Engine Layer (Layer 2) - Multi-agent task execution\n","priority":0,"archived":1,"archived_at":"2025-11-05T05:38:42.773Z","created_at":"2025-10-28 07:34:44","updated_at":"2025-11-05 05:38:42","parent_id":null,"parent_uuid":null,"relationships":[],"tags":["execution","infrastructure","layer-1","process-management"]}
{"id":"SPEC-004","uuid":"7c8ba15b-95d6-40e1-bf1f-e4305e5ddd80","title":"Engine Layer - Multi-Agent Task Execution","file_path":"specs/engine_layer_multi_agent_task_execution.md","content":"# Engine Layer Specification\n\n## Overview\n\nThe Engine Layer (Layer 2) manages multiple Claude Code agents to execute tasks concurrently. It sits above the Process Layer and provides task queueing, capacity management, and result collection.\n\n## Design Goals\n\n1. **Simple First**: Start with queue-based task distribution\n2. **Capacity Control**: Prevent resource exhaustion with configurable limits\n3. **Fair Scheduling**: FIFO queue with optional priority support\n4. **Observable**: Expose task progress and engine metrics\n5. **Upgradeable**: Easy path to intelligent agent pooling\n\n## Architecture\n\nBased on Execution System spec and [[SPEC-003]] (Process Layer).\n\n```\n┌─────────────────────────────────────────────────┐\n│         Engine Layer (Layer 2)                  │\n├─────────────────────────────────────────────────┤\n│                                                 │\n│  ┌──────────────────────────────────────────┐  │\n│  │      IExecutionEngine (Interface)        │  │\n│  └────────────┬─────────────────────────────┘  │\n│               │                                 │\n│               ├──────────────────────────────┐  │\n│               │                              │  │\n│     ┌─────────▼────────┐         ┌──────────▼─────────┐\n│     │  SimpleEngine    │         │   PoolEngine       │\n│     │  (Start Here)    │         │   (Future)         │\n│     └────────┬─────────┘         └────────────────────┘\n│              │                                  │\n│              ▼                                  │\n│     ┌─────────────────┐                        │\n│     │   Task Queue    │                        │\n│     │   (FIFO/Prio)   │                        │\n│     └────────┬────────┘                        │\n│              │                                  │\n│              ▼                                  │\n│     ┌─────────────────┐                        │\n│     │ Process Manager │◄───────────────────────┘\n│     │  (Layer 1)      │                        │\n│     └─────────────────┘                        │\n│                                                 │\n└─────────────────────────────────────────────────┘\n```\n\n## Core Types\n\n### ExecutionTask\nRepresents a unit of work to be executed by a Claude Code agent.\n\n```typescript\ninterface ExecutionTask {\n  // Identity\n  id: string;\n  type: 'issue' | 'spec' | 'custom';\n  entityId?: string;              // Issue/spec ID if applicable\n  \n  // Execution context\n  prompt: string;                 // What to send to Claude\n  workDir: string;                // Where to execute\n  \n  // Scheduling\n  priority: number;               // 0 = highest\n  dependencies: string[];         // Task IDs that must complete first\n  createdAt: Date;\n  \n  // Configuration\n  config: {\n    timeout?: number;             // Max duration (ms)\n    maxRetries?: number;          // Retry attempts\n    env?: Record<string, string>; // Environment variables\n  };\n  \n  // Metadata\n  metadata?: Record<string, any>; // Custom data\n}\n```\n\n### ExecutionResult\nThe outcome of executing a task.\n\n```typescript\ninterface ExecutionResult {\n  // Identity\n  taskId: string;\n  executionId: string;            // Process ID that ran it\n  \n  // Outcome\n  success: boolean;\n  exitCode: number;\n  \n  // Output\n  output: string;                 // stdout\n  error?: string;                 // stderr or error message\n  \n  // Timing\n  startedAt: Date;\n  completedAt: Date;\n  duration: number;               // milliseconds\n  \n  // Parsed data (from stream-json)\n  metadata?: {\n    toolsUsed?: string[];\n    filesChanged?: string[];\n    tokensUsed?: number;\n    cost?: number;\n  };\n}\n```\n\n### EngineMetrics\nReal-time engine performance statistics.\n\n```typescript\ninterface EngineMetrics {\n  // Capacity\n  maxConcurrent: number;\n  currentlyRunning: number;\n  availableSlots: number;\n  \n  // Queue\n  queuedTasks: number;\n  completedTasks: number;\n  failedTasks: number;\n  \n  // Performance\n  averageDuration: number;        // ms\n  successRate: number;            // 0-1\n  throughput: number;             // tasks/minute\n  \n  // Resources\n  totalProcessesSpawned: number;\n  activeProcesses: number;\n}\n```\n\n## IExecutionEngine Interface\n\nThe core abstraction for task execution engines.\n\n```typescript\ninterface IExecutionEngine {\n  // Task submission\n  submitTask(task: ExecutionTask): Promise<string>; // Returns task ID\n  submitTasks(tasks: ExecutionTask[]): Promise<string[]>;\n  \n  // Task control\n  cancelTask(taskId: string): Promise<void>;\n  getTaskStatus(taskId: string): TaskStatus | null;\n  \n  // Execution\n  waitForTask(taskId: string): Promise<ExecutionResult>;\n  waitForTasks(taskIds: string[]): Promise<ExecutionResult[]>;\n  \n  // Monitoring\n  getMetrics(): EngineMetrics;\n  onTaskComplete(handler: TaskCompleteHandler): void;\n  onTaskFailed(handler: TaskFailedHandler): void;\n  \n  // Lifecycle\n  shutdown(): Promise<void>;\n}\n\ntype TaskStatus = \n  | { state: 'queued'; position: number }\n  | { state: 'running'; processId: string; startedAt: Date }\n  | { state: 'completed'; result: ExecutionResult }\n  | { state: 'failed'; error: string }\n  | { state: 'cancelled'; cancelledAt: Date };\n\ntype TaskCompleteHandler = (result: ExecutionResult) => void;\ntype TaskFailedHandler = (taskId: string, error: Error) => void;\n```\n\n## SimpleExecutionEngine Implementation\n\nQueue-based engine that spawns a process per task, with concurrency limits.\n\n### Key Features\n\n1. **FIFO Queue**: Tasks execute in submission order\n2. **Concurrency Limit**: Max N simultaneous processes\n3. **Automatic Retry**: Optional retry on failure\n4. **Event Emission**: Notify on task completion/failure\n5. **Graceful Shutdown**: Wait for running tasks or force terminate\n\n### Implementation Pattern\n\n```typescript\nclass SimpleExecutionEngine implements IExecutionEngine {\n  private taskQueue: ExecutionTask[] = [];\n  private runningTasks = new Map<string, RunningTask>();\n  private completedResults = new Map<string, ExecutionResult>();\n  private taskResolvers = new Map<string, TaskResolver>();\n  \n  private metrics: EngineMetrics;\n  private completeHandlers: TaskCompleteHandler[] = [];\n  private failedHandlers: TaskFailedHandler[] = [];\n  \n  constructor(\n    private processManager: IProcessManager,\n    private config: EngineConfig = {}\n  ) {\n    this.metrics = {\n      maxConcurrent: config.maxConcurrent || 3,\n      currentlyRunning: 0,\n      availableSlots: config.maxConcurrent || 3,\n      queuedTasks: 0,\n      completedTasks: 0,\n      failedTasks: 0,\n      averageDuration: 0,\n      successRate: 1.0,\n      throughput: 0,\n      totalProcessesSpawned: 0,\n      activeProcesses: 0,\n    };\n  }\n\n  async submitTask(task: ExecutionTask): Promise<string> {\n    // Add to queue\n    this.taskQueue.push(task);\n    this.metrics.queuedTasks++;\n    \n    // Try to start immediately if capacity available\n    this.processQueue();\n    \n    return task.id;\n  }\n\n  async submitTasks(tasks: ExecutionTask[]): Promise<string[]> {\n    const ids: string[] = [];\n    for (const task of tasks) {\n      const id = await this.submitTask(task);\n      ids.push(id);\n    }\n    return ids;\n  }\n\n  private async processQueue(): Promise<void> {\n    // Check if we have capacity\n    while (\n      this.taskQueue.length > 0 &&\n      this.runningTasks.size < this.metrics.maxConcurrent\n    ) {\n      const task = this.taskQueue.shift()!;\n      this.metrics.queuedTasks--;\n      \n      // Check dependencies\n      if (!this.areDependenciesMet(task)) {\n        // Re-queue at end\n        this.taskQueue.push(task);\n        this.metrics.queuedTasks++;\n        break; // Stop processing to avoid infinite loop\n      }\n      \n      // Start execution\n      this.executeTask(task).catch(error => {\n        this.handleTaskFailure(task.id, error);\n      });\n    }\n  }\n\n  private areDependenciesMet(task: ExecutionTask): boolean {\n    for (const depId of task.dependencies) {\n      const result = this.completedResults.get(depId);\n      if (!result || !result.success) {\n        return false;\n      }\n    }\n    return true;\n  }\n\n  private async executeTask(task: ExecutionTask): Promise<void> {\n    const startTime = Date.now();\n    \n    try {\n      // Acquire process\n      const process = await this.processManager.acquireProcess({\n        claudePath: this.config.claudePath || 'claude',\n        workDir: task.workDir,\n        args: {\n          print: true,\n          outputFormat: 'stream-json',\n          dangerouslySkipPermissions: true,\n          permissionMode: 'bypassPermissions',\n        },\n        env: task.config.env,\n        timeout: task.config.timeout,\n      });\n\n      this.metrics.totalProcessesSpawned++;\n      this.metrics.currentlyRunning++;\n      this.metrics.activeProcesses++;\n      this.metrics.availableSlots--;\n\n      // Track running task\n      const running: RunningTask = {\n        task,\n        process,\n        startedAt: new Date(),\n        attempt: 1,\n      };\n      this.runningTasks.set(task.id, running);\n\n      // Send prompt\n      await this.processManager.sendInput(process.id, task.prompt);\n      \n      // Collect output\n      let outputBuffer = '';\n      let errorBuffer = '';\n      \n      this.processManager.onOutput(process.id, (data, type) => {\n        if (type === 'stdout') {\n          outputBuffer += data.toString();\n        } else {\n          errorBuffer += data.toString();\n        }\n      });\n\n      // Wait for completion\n      await this.waitForProcessExit(process);\n\n      const duration = Date.now() - startTime;\n      \n      // Build result\n      const result: ExecutionResult = {\n        taskId: task.id,\n        executionId: process.id,\n        success: process.exitCode === 0,\n        exitCode: process.exitCode || 0,\n        output: outputBuffer,\n        error: process.exitCode !== 0 ? errorBuffer : undefined,\n        startedAt: running.startedAt,\n        completedAt: new Date(),\n        duration,\n        metadata: this.parseMetadata(outputBuffer),\n      };\n\n      // Handle result\n      if (result.success) {\n        this.handleTaskSuccess(task.id, result);\n      } else {\n        // Retry if configured\n        if (\n          task.config.maxRetries &&\n          running.attempt < task.config.maxRetries\n        ) {\n          running.attempt++;\n          this.taskQueue.unshift(task); // Priority re-queue\n          this.metrics.queuedTasks++;\n        } else {\n          this.handleTaskFailure(\n            task.id,\n            new Error(result.error || 'Task failed')\n          );\n        }\n      }\n\n      // Clean up\n      this.runningTasks.delete(task.id);\n      await this.processManager.releaseProcess(process.id);\n      \n      this.metrics.currentlyRunning--;\n      this.metrics.activeProcesses--;\n      this.metrics.availableSlots++;\n\n      // Process next queued task\n      this.processQueue();\n      \n    } catch (error) {\n      this.metrics.currentlyRunning--;\n      this.metrics.activeProcesses--;\n      this.metrics.availableSlots++;\n      this.runningTasks.delete(task.id);\n      \n      throw error;\n    }\n  }\n\n  private async waitForProcessExit(process: ManagedProcess): Promise<void> {\n    return new Promise((resolve) => {\n      const checkInterval = setInterval(() => {\n        if (\n          process.status === 'completed' ||\n          process.status === 'crashed' ||\n          process.status === 'terminated'\n        ) {\n          clearInterval(checkInterval);\n          resolve();\n        }\n      }, 100);\n    });\n  }\n\n  private parseMetadata(output: string): ExecutionResult['metadata'] {\n    // Parse stream-json output for metadata\n    const metadata: ExecutionResult['metadata'] = {\n      toolsUsed: [],\n      filesChanged: [],\n      tokensUsed: 0,\n      cost: 0,\n    };\n\n    const lines = output.split('\\n');\n    for (const line of lines) {\n      if (!line.trim()) continue;\n      \n      try {\n        const json = JSON.parse(line);\n        \n        // Extract tool usage\n        if (json.type === 'assistant' && json.message?.content) {\n          for (const content of json.message.content) {\n            if (content.type === 'tool_use') {\n              metadata.toolsUsed?.push(content.name);\n              \n              // Track file changes\n              if (\n                content.name === 'Write' ||\n                content.name === 'Edit'\n              ) {\n                metadata.filesChanged?.push(content.input.file_path);\n              }\n            }\n          }\n        }\n        \n        // Extract usage stats\n        if (json.type === 'result' && json.usage) {\n          metadata.tokensUsed = json.usage.total_tokens || 0;\n        }\n      } catch {\n        // Not JSON, skip\n      }\n    }\n\n    return metadata;\n  }\n\n  private handleTaskSuccess(taskId: string, result: ExecutionResult): void {\n    this.completedResults.set(taskId, result);\n    this.metrics.completedTasks++;\n    \n    // Update averages\n    this.updateMetrics(result.duration, true);\n    \n    // Resolve promise\n    const resolver = this.taskResolvers.get(taskId);\n    if (resolver) {\n      resolver.resolve(result);\n      this.taskResolvers.delete(taskId);\n    }\n    \n    // Emit event\n    for (const handler of this.completeHandlers) {\n      handler(result);\n    }\n  }\n\n  private handleTaskFailure(taskId: string, error: Error): void {\n    this.metrics.failedTasks++;\n    this.updateMetrics(0, false);\n    \n    // Resolve promise with error\n    const resolver = this.taskResolvers.get(taskId);\n    if (resolver) {\n      resolver.reject(error);\n      this.taskResolvers.delete(taskId);\n    }\n    \n    // Emit event\n    for (const handler of this.failedHandlers) {\n      handler(taskId, error);\n    }\n  }\n\n  private updateMetrics(duration: number, success: boolean): void {\n    const total = this.metrics.completedTasks + this.metrics.failedTasks;\n    \n    // Update average duration\n    this.metrics.averageDuration = \n      (this.metrics.averageDuration * (total - 1) + duration) / total;\n    \n    // Update success rate\n    this.metrics.successRate = this.metrics.completedTasks / total;\n  }\n\n  async waitForTask(taskId: string): Promise<ExecutionResult> {\n    // Check if already completed\n    const existing = this.completedResults.get(taskId);\n    if (existing) return existing;\n    \n    // Wait for completion\n    return new Promise((resolve, reject) => {\n      this.taskResolvers.set(taskId, { resolve, reject });\n    });\n  }\n\n  async waitForTasks(taskIds: string[]): Promise<ExecutionResult[]> {\n    return Promise.all(taskIds.map(id => this.waitForTask(id)));\n  }\n\n  async cancelTask(taskId: string): Promise<void> {\n    // Remove from queue\n    const queueIndex = this.taskQueue.findIndex(t => t.id === taskId);\n    if (queueIndex >= 0) {\n      this.taskQueue.splice(queueIndex, 1);\n      this.metrics.queuedTasks--;\n      return;\n    }\n    \n    // Stop running task\n    const running = this.runningTasks.get(taskId);\n    if (running) {\n      await this.processManager.terminateProcess(running.process.id);\n      this.runningTasks.delete(taskId);\n      this.metrics.currentlyRunning--;\n    }\n  }\n\n  getTaskStatus(taskId: string): TaskStatus | null {\n    // Check completed\n    const result = this.completedResults.get(taskId);\n    if (result) {\n      return { state: 'completed', result };\n    }\n    \n    // Check running\n    const running = this.runningTasks.get(taskId);\n    if (running) {\n      return {\n        state: 'running',\n        processId: running.process.id,\n        startedAt: running.startedAt,\n      };\n    }\n    \n    // Check queued\n    const queuePos = this.taskQueue.findIndex(t => t.id === taskId);\n    if (queuePos >= 0) {\n      return { state: 'queued', position: queuePos };\n    }\n    \n    return null;\n  }\n\n  getMetrics(): EngineMetrics {\n    return { ...this.metrics };\n  }\n\n  onTaskComplete(handler: TaskCompleteHandler): void {\n    this.completeHandlers.push(handler);\n  }\n\n  onTaskFailed(handler: TaskFailedHandler): void {\n    this.failedHandlers.push(handler);\n  }\n\n  async shutdown(): Promise<void> {\n    // Stop accepting new tasks\n    this.taskQueue = [];\n    \n    // Wait for running tasks or force terminate\n    const runningIds = Array.from(this.runningTasks.keys());\n    for (const taskId of runningIds) {\n      await this.cancelTask(taskId);\n    }\n    \n    // Shutdown process manager\n    await this.processManager.shutdown();\n  }\n}\n\ninterface EngineConfig {\n  maxConcurrent?: number;\n  claudePath?: string;\n}\n\ninterface RunningTask {\n  task: ExecutionTask;\n  process: ManagedProcess;\n  startedAt: Date;\n  attempt: number;\n}\n\ninterface TaskResolver {\n  resolve: (result: ExecutionResult) => void;\n  reject: (error: Error) => void;\n}\n```\n\n## Usage Example\n\n```typescript\n// Initialize engine with process manager\nconst processManager = new SimpleProcessManager();\nconst engine = new SimpleExecutionEngine(processManager, {\n  maxConcurrent: 5,\n  claudePath: 'claude',\n});\n\n// Listen to completion events\nengine.onTaskComplete((result) => {\n  console.log(`Task ${result.taskId} completed in ${result.duration}ms`);\n  console.log(`Files changed:`, result.metadata?.filesChanged);\n});\n\n// Submit tasks\nconst task1 = {\n  id: 'task-1',\n  type: 'issue',\n  entityId: 'ISSUE-001',\n  prompt: 'Fix the authentication bug described in ISSUE-001',\n  workDir: '/path/to/project',\n  priority: 0,\n  dependencies: [],\n  createdAt: new Date(),\n  config: {\n    timeout: 300000,\n    maxRetries: 2,\n  },\n};\n\nconst taskId = await engine.submitTask(task1);\n\n// Wait for completion\nconst result = await engine.waitForTask(taskId);\nconsole.log('Success:', result.success);\n\n// Check metrics\nconst metrics = engine.getMetrics();\nconsole.log(`Queue: ${metrics.queuedTasks}, Running: ${metrics.currentlyRunning}`);\n```\n\n## Testing Strategy\n\n### Unit Tests\n\n1. **Task queueing**\n   - Tasks added to queue in order\n   - Queue processes FIFO\n   - Priority ordering (future)\n\n2. **Concurrency control**\n   - Respects maxConcurrent limit\n   - Starts next task when slot available\n   - Tracks running tasks correctly\n\n3. **Dependency resolution**\n   - Waits for dependencies before execution\n   - Handles failed dependencies\n   - Prevents circular dependencies\n\n4. **Retry logic**\n   - Retries failed tasks up to maxRetries\n   - Uses exponential backoff (future)\n   - Stops retrying after limit\n\n### Integration Tests\n\n1. **End-to-end execution**\n   - Submit → queue → execute → complete\n   - Multiple concurrent tasks\n   - Task cancellation during execution\n\n2. **Metrics tracking**\n   - Counts update correctly\n   - Averages calculate properly\n   - Throughput measured accurately\n\n## Future Enhancements\n\n### Path to Pool-Based Strategy\n\n```typescript\nclass PoolExecutionEngine implements IExecutionEngine {\n  private agentPool: AgentPool;\n  \n  async submitTask(task: ExecutionTask): Promise<string> {\n    // Get idle agent from pool or wait\n    const agent = await this.agentPool.acquire();\n    \n    // Reuse existing process\n    await agent.reset(); // Clear previous state\n    await agent.execute(task);\n    \n    // Return to pool\n    this.agentPool.release(agent);\n    \n    return task.id;\n  }\n  \n  // ... intelligent pool management\n}\n```\n\n### Other Future Features\n\n1. **Priority queue** - Higher priority tasks jump queue\n2. **Task batching** - Group similar tasks for efficiency\n3. **Smart scheduling** - Assign tasks based on agent capabilities\n4. **Resource-aware** - Consider memory/CPU before scheduling\n5. **Adaptive concurrency** - Auto-adjust limits based on load\n\n## File Structure\n\n```\nserver/src/execution/engine/\n├── types.ts                    # Core types (ExecutionTask, etc.)\n├── engine.ts                   # IExecutionEngine interface\n├── simple-engine.ts            # SimpleExecutionEngine (start here)\n├── pool-engine.ts              # PoolExecutionEngine (future)\n└── utils.ts                    # Helper functions\n```\n\n## Implementation Checklist\n\n- [ ] Define core types in types.ts\n- [ ] Define IExecutionEngine interface\n- [ ] Implement SimpleExecutionEngine\n- [ ] Add task queue (FIFO)\n- [ ] Add concurrency control\n- [ ] Add dependency resolution\n- [ ] Add retry logic\n- [ ] Add event emission\n- [ ] Integrate with Process Layer\n- [ ] Write unit tests\n- [ ] Write integration tests\n\n## Related Specs\n\n- Execution System (root spec)\n- [[SPEC-003]] - Process Layer (dependency)\n- Next: Task Execution Layer (Layer 3) - Resilience & retry\n","priority":0,"archived":1,"archived_at":"2025-11-05T05:38:47.341Z","created_at":"2025-10-28 07:36:09","updated_at":"2025-11-05 05:38:47","parent_id":null,"parent_uuid":null,"relationships":[{"from":"SPEC-004","from_type":"spec","to":"SPEC-003","to_type":"spec","type":"references"}],"tags":["concurrency","engine","execution","layer-2","task-queue"]}
{"id":"SPEC-005","uuid":"91c92cf2-110f-4341-88f1-2b90820c769f","title":"Task Execution Layer - Resilience & Retry","file_path":"specs/task_execution_layer_resilience_retry.md","content":"# Task Execution Layer Specification\n\n## Overview\n\nThe Task Execution Layer (Layer 3) adds resilience patterns to task execution. It wraps the Engine Layer with retry logic, circuit breakers, and fault tolerance mechanisms.\n\n## Design Goals\n\n1. **Resilient**: Automatically recover from transient failures\n2. **Smart Retry**: Exponential backoff with jitter\n3. **Circuit Breaker**: Prevent cascading failures\n4. **Fault Isolation**: One agent failure doesn't affect others\n5. **Observable**: Track retry attempts and failure patterns\n\n## Architecture\n\nBased on Execution System spec, [[SPEC-003]] (Process Layer), and [[SPEC-004]] (Engine Layer).\n\n```\n┌──────────────────────────────────────────────────┐\n│      Task Execution Layer (Layer 3)              │\n├──────────────────────────────────────────────────┤\n│                                                  │\n│  ┌────────────────────────────────────────────┐ │\n│  │   IResilientExecutor (Interface)           │ │\n│  └────────────┬───────────────────────────────┘ │\n│               │                                  │\n│     ┌─────────▼────────────┐                    │\n│     │  ResilientExecutor   │                    │\n│     └──────────┬────────────┘                    │\n│                │                                  │\n│         ┌──────┴───────┬──────────┬──────────┐  │\n│         │              │          │          │  │\n│    ┌────▼─────┐  ┌────▼────┐ ┌──▼────┐ ┌───▼──┐│\n│    │  Retry   │  │ Circuit │ │Timeout│ │Error ││\n│    │ Handler  │  │ Breaker │ │Handler│ │Catch ││\n│    └──────────┘  └─────────┘ └───────┘ └──────┘│\n│                                                  │\n│    ┌──────────────────────────────────────────┐ │\n│    │      Execution Engine (Layer 2)          │ │\n│    └──────────────────────────────────────────┘ │\n│                                                  │\n└──────────────────────────────────────────────────┘\n```\n\n## Core Types\n\n### RetryPolicy\nConfiguration for retry behavior.\n\n```typescript\ninterface RetryPolicy {\n  // Retry limits\n  maxAttempts: number;           // Max retry attempts (0 = no retry)\n  \n  // Backoff strategy\n  backoff: {\n    type: 'exponential' | 'linear' | 'fixed';\n    baseDelayMs: number;         // Initial delay\n    maxDelayMs: number;          // Cap on delay\n    jitter: boolean;             // Add randomness to prevent thundering herd\n  };\n  \n  // Retry conditions\n  retryableErrors: string[];     // Error types to retry\n  retryableExitCodes: number[];  // Exit codes to retry\n  \n  // Circuit breaker integration\n  shouldOpenCircuit?: (error: Error, attempts: number) => boolean;\n}\n```\n\n### CircuitBreakerState\nCircuit breaker for preventing cascading failures.\n\n```typescript\ninterface CircuitBreaker {\n  // Identity\n  name: string;                  // Breaker name (e.g., 'issue-executor')\n  \n  // State\n  state: CircuitState;\n  \n  // Configuration\n  config: {\n    failureThreshold: number;    // Failures before opening (e.g., 5)\n    successThreshold: number;    // Successes to close (e.g., 2)\n    timeout: number;             // Half-open retry delay (ms)\n  };\n  \n  // Metrics\n  metrics: {\n    totalRequests: number;\n    failedRequests: number;\n    successfulRequests: number;\n    lastFailureTime?: Date;\n    lastSuccessTime?: Date;\n  };\n}\n\ntype CircuitState = 'closed' | 'open' | 'half-open';\n```\n\n### ExecutionAttempt\nRecord of a single execution attempt.\n\n```typescript\ninterface ExecutionAttempt {\n  attemptNumber: number;\n  startedAt: Date;\n  completedAt?: Date;\n  duration?: number;\n  success: boolean;\n  error?: Error;\n  exitCode?: number;\n  willRetry: boolean;\n  nextRetryAt?: Date;\n}\n```\n\n### ResilientExecutionResult\nEnhanced result with retry information.\n\n```typescript\ninterface ResilientExecutionResult extends ExecutionResult {\n  // Retry information\n  attempts: ExecutionAttempt[];\n  totalAttempts: number;\n  finalAttempt: ExecutionAttempt;\n  \n  // Failure analysis\n  failureReason?: string;\n  circuitBreakerTriggered?: boolean;\n}\n```\n\n## IResilientExecutor Interface\n\nThe core abstraction for resilient task execution.\n\n```typescript\ninterface IResilientExecutor {\n  // Execute with resilience\n  executeTask(\n    task: ExecutionTask,\n    policy?: RetryPolicy\n  ): Promise<ResilientExecutionResult>;\n  \n  executeTasks(\n    tasks: ExecutionTask[],\n    policy?: RetryPolicy\n  ): Promise<ResilientExecutionResult[]>;\n  \n  // Circuit breaker management\n  getCircuitBreaker(name: string): CircuitBreaker | null;\n  resetCircuitBreaker(name: string): void;\n  \n  // Monitoring\n  getRetryMetrics(): RetryMetrics;\n  onRetryAttempt(handler: RetryAttemptHandler): void;\n  onCircuitOpen(handler: CircuitOpenHandler): void;\n}\n\ntype RetryAttemptHandler = (\n  taskId: string,\n  attempt: ExecutionAttempt\n) => void;\n\ntype CircuitOpenHandler = (\n  circuitName: string,\n  breaker: CircuitBreaker\n) => void;\n\ninterface RetryMetrics {\n  totalRetries: number;\n  successfulRetries: number;\n  failedRetries: number;\n  averageAttemptsToSuccess: number;\n  circuitBreakers: Map<string, CircuitBreaker>;\n}\n```\n\n## ResilientExecutor Implementation\n\nWraps the execution engine with retry and circuit breaker logic.\n\n### Key Features\n\n1. **Exponential Backoff**: Delay increases exponentially (2^attempt)\n2. **Jitter**: Random delay component to prevent thundering herd\n3. **Circuit Breaker**: Per-task-type circuit breakers\n4. **Smart Retry**: Only retry transient errors\n5. **Detailed Tracking**: Record all attempts and failures\n\n### Implementation Pattern\n\n```typescript\nclass ResilientExecutor implements IResilientExecutor {\n  private circuitBreakers = new Map<string, CircuitBreaker>();\n  private retryHandlers: RetryAttemptHandler[] = [];\n  private circuitOpenHandlers: CircuitOpenHandler[] = [];\n  \n  private metrics: RetryMetrics = {\n    totalRetries: 0,\n    successfulRetries: 0,\n    failedRetries: 0,\n    averageAttemptsToSuccess: 1.0,\n    circuitBreakers: new Map(),\n  };\n  \n  constructor(\n    private engine: IExecutionEngine,\n    private defaultPolicy: RetryPolicy = DEFAULT_RETRY_POLICY\n  ) {}\n\n  async executeTask(\n    task: ExecutionTask,\n    policy?: RetryPolicy\n  ): Promise<ResilientExecutionResult> {\n    const retryPolicy = policy || this.defaultPolicy;\n    const attempts: ExecutionAttempt[] = [];\n    \n    // Get or create circuit breaker for this task type\n    const circuitBreaker = this.getOrCreateCircuitBreaker(task.type);\n    \n    // Check circuit breaker\n    if (circuitBreaker.state === 'open') {\n      if (!this.shouldAttemptHalfOpen(circuitBreaker)) {\n        throw new Error(\n          `Circuit breaker '${circuitBreaker.name}' is OPEN. ` +\n          `Too many failures. Try again later.`\n        );\n      }\n      circuitBreaker.state = 'half-open';\n    }\n    \n    // Execute with retry\n    for (let attempt = 1; attempt <= retryPolicy.maxAttempts; attempt++) {\n      const attemptRecord: ExecutionAttempt = {\n        attemptNumber: attempt,\n        startedAt: new Date(),\n        success: false,\n        willRetry: false,\n      };\n      \n      try {\n        // Submit to engine\n        const taskId = await this.engine.submitTask(task);\n        \n        // Wait for result\n        const result = await this.engine.waitForTask(taskId);\n        \n        attemptRecord.completedAt = new Date();\n        attemptRecord.duration = \n          attemptRecord.completedAt.getTime() - \n          attemptRecord.startedAt.getTime();\n        attemptRecord.success = result.success;\n        attemptRecord.exitCode = result.exitCode;\n        \n        attempts.push(attemptRecord);\n        \n        if (result.success) {\n          // Success! Record and close circuit\n          this.recordSuccess(circuitBreaker);\n          \n          return {\n            ...result,\n            attempts,\n            totalAttempts: attempt,\n            finalAttempt: attemptRecord,\n          };\n        } else {\n          // Task failed\n          attemptRecord.error = new Error(result.error || 'Task failed');\n          \n          // Check if we should retry\n          const shouldRetry = \n            attempt < retryPolicy.maxAttempts &&\n            this.isRetryable(result, retryPolicy);\n          \n          if (shouldRetry) {\n            // Calculate backoff delay\n            const delay = this.calculateBackoff(\n              attempt,\n              retryPolicy.backoff\n            );\n            \n            attemptRecord.willRetry = true;\n            attemptRecord.nextRetryAt = new Date(Date.now() + delay);\n            \n            // Emit retry event\n            for (const handler of this.retryHandlers) {\n              handler(task.id, attemptRecord);\n            }\n            \n            this.metrics.totalRetries++;\n            \n            // Wait before retry\n            await this.sleep(delay);\n          } else {\n            // No more retries\n            this.recordFailure(circuitBreaker, attemptRecord.error);\n            \n            this.metrics.failedRetries++;\n            \n            return {\n              ...result,\n              attempts,\n              totalAttempts: attempt,\n              finalAttempt: attemptRecord,\n              failureReason: attemptRecord.error.message,\n            };\n          }\n        }\n      } catch (error) {\n        // Engine-level error (spawn failure, etc.)\n        attemptRecord.completedAt = new Date();\n        attemptRecord.duration = \n          attemptRecord.completedAt.getTime() - \n          attemptRecord.startedAt.getTime();\n        attemptRecord.error = error as Error;\n        attemptRecord.success = false;\n        \n        attempts.push(attemptRecord);\n        \n        // Check if we should retry\n        const shouldRetry = \n          attempt < retryPolicy.maxAttempts &&\n          this.isErrorRetryable(error as Error, retryPolicy);\n        \n        if (shouldRetry) {\n          const delay = this.calculateBackoff(attempt, retryPolicy.backoff);\n          attemptRecord.willRetry = true;\n          attemptRecord.nextRetryAt = new Date(Date.now() + delay);\n          \n          for (const handler of this.retryHandlers) {\n            handler(task.id, attemptRecord);\n          }\n          \n          this.metrics.totalRetries++;\n          await this.sleep(delay);\n        } else {\n          this.recordFailure(circuitBreaker, error as Error);\n          this.metrics.failedRetries++;\n          \n          throw error;\n        }\n      }\n    }\n    \n    // Should never reach here, but TypeScript requires it\n    throw new Error('Max retry attempts exceeded');\n  }\n\n  async executeTasks(\n    tasks: ExecutionTask[],\n    policy?: RetryPolicy\n  ): Promise<ResilientExecutionResult[]> {\n    return Promise.all(\n      tasks.map(task => this.executeTask(task, policy))\n    );\n  }\n\n  private getOrCreateCircuitBreaker(taskType: string): CircuitBreaker {\n    let breaker = this.circuitBreakers.get(taskType);\n    \n    if (!breaker) {\n      breaker = {\n        name: taskType,\n        state: 'closed',\n        config: {\n          failureThreshold: 5,\n          successThreshold: 2,\n          timeout: 60000, // 1 minute\n        },\n        metrics: {\n          totalRequests: 0,\n          failedRequests: 0,\n          successfulRequests: 0,\n        },\n      };\n      \n      this.circuitBreakers.set(taskType, breaker);\n      this.metrics.circuitBreakers.set(taskType, breaker);\n    }\n    \n    return breaker;\n  }\n\n  private shouldAttemptHalfOpen(breaker: CircuitBreaker): boolean {\n    if (!breaker.metrics.lastFailureTime) return true;\n    \n    const timeSinceFailure = \n      Date.now() - breaker.metrics.lastFailureTime.getTime();\n    \n    return timeSinceFailure >= breaker.config.timeout;\n  }\n\n  private recordSuccess(breaker: CircuitBreaker): void {\n    breaker.metrics.totalRequests++;\n    breaker.metrics.successfulRequests++;\n    breaker.metrics.lastSuccessTime = new Date();\n    \n    if (breaker.state === 'half-open') {\n      // Count consecutive successes in half-open state\n      const recentSuccesses = this.getRecentSuccessCount(breaker);\n      if (recentSuccesses >= breaker.config.successThreshold) {\n        breaker.state = 'closed';\n        breaker.metrics.failedRequests = 0; // Reset failure count\n      }\n    }\n    \n    this.metrics.successfulRetries++;\n  }\n\n  private recordFailure(breaker: CircuitBreaker, error: Error): void {\n    breaker.metrics.totalRequests++;\n    breaker.metrics.failedRequests++;\n    breaker.metrics.lastFailureTime = new Date();\n    \n    // Check if we should open circuit\n    if (\n      breaker.state === 'closed' &&\n      breaker.metrics.failedRequests >= breaker.config.failureThreshold\n    ) {\n      breaker.state = 'open';\n      \n      // Emit circuit open event\n      for (const handler of this.circuitOpenHandlers) {\n        handler(breaker.name, breaker);\n      }\n    } else if (breaker.state === 'half-open') {\n      // Failed in half-open, back to open\n      breaker.state = 'open';\n    }\n  }\n\n  private getRecentSuccessCount(breaker: CircuitBreaker): number {\n    // In a real implementation, track recent attempts\n    // For now, simplified\n    return breaker.metrics.successfulRequests;\n  }\n\n  private calculateBackoff(\n    attempt: number,\n    config: RetryPolicy['backoff']\n  ): number {\n    let delay: number;\n    \n    switch (config.type) {\n      case 'exponential':\n        delay = config.baseDelayMs * Math.pow(2, attempt - 1);\n        break;\n      case 'linear':\n        delay = config.baseDelayMs * attempt;\n        break;\n      case 'fixed':\n        delay = config.baseDelayMs;\n        break;\n    }\n    \n    // Cap at max delay\n    delay = Math.min(delay, config.maxDelayMs);\n    \n    // Add jitter if configured\n    if (config.jitter) {\n      const jitterAmount = delay * 0.1; // 10% jitter\n      delay += Math.random() * jitterAmount - jitterAmount / 2;\n    }\n    \n    return Math.floor(delay);\n  }\n\n  private isRetryable(\n    result: ExecutionResult,\n    policy: RetryPolicy\n  ): boolean {\n    // Check exit code\n    if (\n      result.exitCode !== undefined &&\n      policy.retryableExitCodes.includes(result.exitCode)\n    ) {\n      return true;\n    }\n    \n    // Check error message\n    if (result.error) {\n      for (const retryableError of policy.retryableErrors) {\n        if (result.error.includes(retryableError)) {\n          return true;\n        }\n      }\n    }\n    \n    return false;\n  }\n\n  private isErrorRetryable(error: Error, policy: RetryPolicy): boolean {\n    for (const retryableError of policy.retryableErrors) {\n      if (error.message.includes(retryableError)) {\n        return true;\n      }\n    }\n    return false;\n  }\n\n  private sleep(ms: number): Promise<void> {\n    return new Promise(resolve => setTimeout(resolve, ms));\n  }\n\n  getCircuitBreaker(name: string): CircuitBreaker | null {\n    return this.circuitBreakers.get(name) || null;\n  }\n\n  resetCircuitBreaker(name: string): void {\n    const breaker = this.circuitBreakers.get(name);\n    if (breaker) {\n      breaker.state = 'closed';\n      breaker.metrics.failedRequests = 0;\n      breaker.metrics.successfulRequests = 0;\n    }\n  }\n\n  getRetryMetrics(): RetryMetrics {\n    return { ...this.metrics };\n  }\n\n  onRetryAttempt(handler: RetryAttemptHandler): void {\n    this.retryHandlers.push(handler);\n  }\n\n  onCircuitOpen(handler: CircuitOpenHandler): void {\n    this.circuitOpenHandlers.push(handler);\n  }\n}\n\n// Default retry policy\nconst DEFAULT_RETRY_POLICY: RetryPolicy = {\n  maxAttempts: 3,\n  backoff: {\n    type: 'exponential',\n    baseDelayMs: 1000,\n    maxDelayMs: 30000,\n    jitter: true,\n  },\n  retryableErrors: [\n    'ECONNREFUSED',\n    'ETIMEDOUT',\n    'ENOTFOUND',\n    'timeout',\n    'network',\n  ],\n  retryableExitCodes: [1, 137], // Generic error, SIGKILL\n};\n```\n\n## Usage Example\n\n```typescript\n// Initialize stack\nconst processManager = new SimpleProcessManager();\nconst engine = new SimpleExecutionEngine(processManager, {\n  maxConcurrent: 5,\n});\n\nconst resilientExecutor = new ResilientExecutor(engine, {\n  maxAttempts: 3,\n  backoff: {\n    type: 'exponential',\n    baseDelayMs: 1000,\n    maxDelayMs: 30000,\n    jitter: true,\n  },\n  retryableErrors: ['timeout', 'ECONNREFUSED'],\n  retryableExitCodes: [1],\n});\n\n// Listen to retry attempts\nresilientExecutor.onRetryAttempt((taskId, attempt) => {\n  console.log(\n    `Task ${taskId} attempt ${attempt.attemptNumber} failed. ` +\n    `Retrying in ${attempt.nextRetryAt}...`\n  );\n});\n\n// Listen to circuit breaker events\nresilientExecutor.onCircuitOpen((name, breaker) => {\n  console.log(\n    `Circuit breaker '${name}' opened after ` +\n    `${breaker.metrics.failedRequests} failures`\n  );\n});\n\n// Execute task with resilience\nconst task = {\n  id: 'task-1',\n  type: 'issue',\n  entityId: 'ISSUE-001',\n  prompt: 'Fix the bug',\n  workDir: '/path/to/project',\n  priority: 0,\n  dependencies: [],\n  createdAt: new Date(),\n  config: {},\n};\n\nconst result = await resilientExecutor.executeTask(task);\n\nconsole.log(`Success: ${result.success}`);\nconsole.log(`Attempts: ${result.totalAttempts}`);\nconsole.log(`Attempts:`, result.attempts);\n```\n\n## Testing Strategy\n\n### Unit Tests\n\n1. **Retry logic**\n   - Retries up to maxAttempts\n   - Calculates backoff correctly\n   - Adds jitter when configured\n   - Stops retrying on non-retryable errors\n\n2. **Circuit breaker**\n   - Opens after failure threshold\n   - Transitions to half-open after timeout\n   - Closes after success threshold\n   - Rejects requests when open\n\n3. **Backoff calculation**\n   - Exponential: 1s, 2s, 4s, 8s, 16s\n   - Linear: 1s, 2s, 3s, 4s, 5s\n   - Fixed: 1s, 1s, 1s, 1s, 1s\n   - Respects maxDelay cap\n\n### Integration Tests\n\n1. **End-to-end resilience**\n   - Task fails → retries → succeeds\n   - Circuit breaker opens → half-open → closes\n   - Multiple task types have separate breakers\n\n2. **Failure scenarios**\n   - Transient errors are retried\n   - Permanent errors fail fast\n   - Circuit breaker prevents cascading failures\n\n## Future Enhancements\n\n1. **Adaptive retry** - Adjust backoff based on load\n2. **Bulkhead pattern** - Isolate task types with separate pools\n3. **Rate limiting** - Prevent overwhelming downstream services\n4. **Retry budgets** - Limit total retry percentage\n5. **Dead letter queue** - Store permanently failed tasks\n\n## File Structure\n\n```\nserver/src/execution/resilience/\n├── types.ts                    # Core types (RetryPolicy, etc.)\n├── executor.ts                 # IResilientExecutor interface\n├── resilient-executor.ts       # ResilientExecutor implementation\n├── circuit-breaker.ts          # Circuit breaker logic\n├── retry.ts                    # Retry and backoff logic\n└── utils.ts                    # Helper functions\n```\n\n## Implementation Checklist\n\n- [ ] Define core types in types.ts\n- [ ] Define IResilientExecutor interface\n- [ ] Implement ResilientExecutor\n- [ ] Add retry logic with exponential backoff\n- [ ] Add jitter to backoff\n- [ ] Implement circuit breaker\n- [ ] Add retryable error detection\n- [ ] Add metrics tracking\n- [ ] Write unit tests for retry logic\n- [ ] Write unit tests for circuit breaker\n- [ ] Write integration tests\n\n## Related Specs\n\n- Execution System (root spec)\n- [[SPEC-003]] - Process Layer (foundation)\n- [[SPEC-004]] - Engine Layer (dependency)\n- Next: Workflow Layer (Layer 4) - Orchestration & state\n","priority":0,"archived":1,"archived_at":"2025-11-05T05:39:07.062Z","created_at":"2025-10-28 07:45:43","updated_at":"2025-11-05 05:39:07","parent_id":null,"parent_uuid":null,"relationships":[{"from":"SPEC-005","from_type":"spec","to":"SPEC-003","to_type":"spec","type":"references"},{"from":"SPEC-005","from_type":"spec","to":"SPEC-004","to_type":"spec","type":"references"}],"tags":["circuit-breaker","execution","layer-3","resilience","retry"]}
{"id":"SPEC-006","uuid":"3d34e745-31ce-409e-b43b-9459ea4704bc","title":"Workflow Layer - Orchestration & State Management","file_path":"specs/workflow_layer_orchestration_state_management.md","content":"# Workflow Layer Specification\n\n## Overview\n\nThe Workflow Layer (Layer 4) orchestrates complex multi-step executions with state persistence, dependency management, and workflow resumption. It enables building sophisticated agent workflows that can survive crashes and resume from checkpoints.\n\n## Design Goals\n\n1. **Stateful**: Persist workflow state for crash recovery\n2. **Resumable**: Continue from last checkpoint after failure\n3. **Composable**: Build complex workflows from simple steps\n4. **Observable**: Track workflow progress in real-time\n5. **Simple First**: Start with linear workflows, upgrade to DAGs\n\n## Architecture\n\nBased on Execution System spec, [[SPEC-003]] (Process), [[SPEC-004]] (Engine), and [[SPEC-005]] (Resilience).\n\n```\n┌────────────────────────────────────────────────────┐\n│       Workflow Layer (Layer 4)                     │\n├────────────────────────────────────────────────────┤\n│                                                    │\n│  ┌──────────────────────────────────────────────┐ │\n│  │    IWorkflowOrchestrator (Interface)         │ │\n│  └──────────────┬───────────────────────────────┘ │\n│                 │                                  │\n│       ┌─────────▼──────────┐                      │\n│       │ LinearOrchestrator │                      │\n│       │  (Start Here)      │                      │\n│       └─────────┬──────────┘                      │\n│                 │                                  │\n│          ┌──────┴───────┬────────────┐            │\n│          │              │            │            │\n│     ┌────▼────┐   ┌────▼────┐  ┌───▼──────┐     │\n│     │Workflow │   │  Step   │  │  State   │     │\n│     │Executor │   │Executor │  │Persister │     │\n│     └─────────┘   └─────────┘  └──────────┘     │\n│                                                    │\n│    ┌────────────────────────────────────────────┐ │\n│    │   Resilient Executor (Layer 3)             │ │\n│    └────────────────────────────────────────────┘ │\n│                                                    │\n└────────────────────────────────────────────────────┘\n```\n\n## Core Types\n\n### WorkflowDefinition\nDefines a multi-step workflow.\n\n```typescript\ninterface WorkflowDefinition {\n  // Identity\n  id: string;\n  name: string;\n  version: string;\n  \n  // Steps\n  steps: WorkflowStep[];\n  \n  // Configuration\n  config: {\n    checkpointInterval?: number;  // Save state every N steps\n    continueOnStepFailure?: boolean;\n    timeout?: number;             // Overall workflow timeout\n  };\n  \n  // Metadata\n  metadata?: Record<string, any>;\n}\n\ninterface WorkflowStep {\n  // Identity\n  id: string;\n  name: string;\n  \n  // Task configuration\n  taskType: 'issue' | 'spec' | 'custom';\n  promptTemplate: string;         // Template with variables\n  \n  // Dependencies\n  dependsOn: string[];            // Step IDs that must complete first\n  \n  // Execution config\n  retryPolicy?: RetryPolicy;\n  timeout?: number;\n  \n  // Condition\n  condition?: (context: WorkflowContext) => boolean;\n  \n  // Output mapping\n  outputMapping?: Record<string, string>; // Map outputs to context vars\n}\n```\n\n### WorkflowExecution\nRuntime state of a workflow execution.\n\n```typescript\ninterface WorkflowExecution {\n  // Identity\n  id: string;\n  workflowId: string;\n  \n  // State\n  status: WorkflowStatus;\n  currentStep?: string;          // Currently executing step ID\n  \n  // Progress\n  completedSteps: string[];\n  failedSteps: string[];\n  skippedSteps: string[];\n  \n  // Context (variables shared across steps)\n  context: WorkflowContext;\n  \n  // Results\n  stepResults: Map<string, ExecutionResult>;\n  \n  // Timing\n  startedAt: Date;\n  completedAt?: Date;\n  lastCheckpointAt?: Date;\n  \n  // Metadata\n  metadata?: Record<string, any>;\n}\n\ntype WorkflowStatus = \n  | 'pending'\n  | 'running'\n  | 'paused'\n  | 'completed'\n  | 'failed'\n  | 'cancelled';\n\ninterface WorkflowContext {\n  // Global variables\n  variables: Record<string, any>;\n  \n  // Step outputs (accessible by step ID)\n  outputs: Record<string, any>;\n  \n  // Shared state\n  shared: Record<string, any>;\n}\n```\n\n### WorkflowCheckpoint\nSerializable checkpoint for resumption.\n\n```typescript\ninterface WorkflowCheckpoint {\n  executionId: string;\n  workflowId: string;\n  timestamp: Date;\n  \n  // State snapshot\n  execution: WorkflowExecution;\n  \n  // Next step to execute\n  nextStep?: string;\n}\n```\n\n## IWorkflowOrchestrator Interface\n\nThe core abstraction for workflow orchestration.\n\n```typescript\ninterface IWorkflowOrchestrator {\n  // Workflow execution\n  startWorkflow(\n    workflow: WorkflowDefinition,\n    initialContext?: Partial<WorkflowContext>\n  ): Promise<string>; // Returns execution ID\n  \n  resumeWorkflow(\n    checkpointId: string\n  ): Promise<string>; // Returns execution ID\n  \n  // Control\n  pauseWorkflow(executionId: string): Promise<void>;\n  cancelWorkflow(executionId: string): Promise<void>;\n  \n  // Monitoring\n  getExecution(executionId: string): WorkflowExecution | null;\n  getStepStatus(executionId: string, stepId: string): StepStatus | null;\n  \n  // Waiting\n  waitForWorkflow(executionId: string): Promise<WorkflowResult>;\n  \n  // Checkpointing\n  saveCheckpoint(executionId: string): Promise<string>; // Returns checkpoint ID\n  listCheckpoints(workflowId: string): Promise<WorkflowCheckpoint[]>;\n  \n  // Events\n  onStepComplete(handler: StepCompleteHandler): void;\n  onWorkflowComplete(handler: WorkflowCompleteHandler): void;\n  onCheckpoint(handler: CheckpointHandler): void;\n}\n\ninterface StepStatus {\n  stepId: string;\n  status: 'pending' | 'running' | 'completed' | 'failed' | 'skipped';\n  result?: ExecutionResult;\n  attempts: number;\n}\n\ninterface WorkflowResult {\n  executionId: string;\n  success: boolean;\n  completedSteps: number;\n  failedSteps: number;\n  outputs: Record<string, any>;\n  duration: number;\n}\n\ntype StepCompleteHandler = (\n  executionId: string,\n  stepId: string,\n  result: ExecutionResult\n) => void;\n\ntype WorkflowCompleteHandler = (result: WorkflowResult) => void;\n\ntype CheckpointHandler = (checkpoint: WorkflowCheckpoint) => void;\n```\n\n## LinearOrchestrator Implementation\n\nSimple linear workflow execution with checkpointing.\n\n### Key Features\n\n1. **Sequential Execution**: Steps execute in defined order\n2. **Dependency Resolution**: Wait for dependencies before executing\n3. **Context Passing**: Share data between steps via context\n4. **Checkpointing**: Save state after each step for resumption\n5. **Conditional Steps**: Skip steps based on conditions\n\n### Implementation Pattern\n\n```typescript\nclass LinearOrchestrator implements IWorkflowOrchestrator {\n  private executions = new Map<string, WorkflowExecution>();\n  private checkpoints = new Map<string, WorkflowCheckpoint>();\n  \n  private stepCompleteHandlers: StepCompleteHandler[] = [];\n  private workflowCompleteHandlers: WorkflowCompleteHandler[] = [];\n  private checkpointHandlers: CheckpointHandler[] = [];\n  \n  constructor(\n    private executor: IResilientExecutor,\n    private storage?: IWorkflowStorage\n  ) {}\n\n  async startWorkflow(\n    workflow: WorkflowDefinition,\n    initialContext?: Partial<WorkflowContext>\n  ): Promise<string> {\n    const execution: WorkflowExecution = {\n      id: generateId('execution'),\n      workflowId: workflow.id,\n      status: 'pending',\n      completedSteps: [],\n      failedSteps: [],\n      skippedSteps: [],\n      context: {\n        variables: initialContext?.variables || {},\n        outputs: {},\n        shared: {},\n      },\n      stepResults: new Map(),\n      startedAt: new Date(),\n    };\n    \n    this.executions.set(execution.id, execution);\n    \n    // Start execution in background\n    this.executeWorkflow(workflow, execution).catch(error => {\n      execution.status = 'failed';\n      execution.completedAt = new Date();\n    });\n    \n    return execution.id;\n  }\n\n  async resumeWorkflow(checkpointId: string): Promise<string> {\n    const checkpoint = this.checkpoints.get(checkpointId);\n    if (!checkpoint) {\n      throw new Error(`Checkpoint ${checkpointId} not found`);\n    }\n    \n    // Restore execution state\n    const execution = checkpoint.execution;\n    execution.status = 'pending';\n    this.executions.set(execution.id, execution);\n    \n    // Find workflow definition\n    const workflow = await this.loadWorkflowDefinition(execution.workflowId);\n    \n    // Resume from next step\n    this.executeWorkflow(workflow, execution, checkpoint.nextStep).catch(\n      error => {\n        execution.status = 'failed';\n        execution.completedAt = new Date();\n      }\n    );\n    \n    return execution.id;\n  }\n\n  private async executeWorkflow(\n    workflow: WorkflowDefinition,\n    execution: WorkflowExecution,\n    startFromStep?: string\n  ): Promise<void> {\n    execution.status = 'running';\n    \n    // Find starting point\n    let startIndex = 0;\n    if (startFromStep) {\n      startIndex = workflow.steps.findIndex(s => s.id === startFromStep);\n      if (startIndex === -1) {\n        throw new Error(`Step ${startFromStep} not found in workflow`);\n      }\n    }\n    \n    // Execute steps sequentially\n    for (let i = startIndex; i < workflow.steps.length; i++) {\n      const step = workflow.steps[i];\n      \n      // Check if paused or cancelled\n      if (execution.status === 'paused' || execution.status === 'cancelled') {\n        return;\n      }\n      \n      // Check dependencies\n      if (!this.areDependenciesMet(step, execution)) {\n        execution.failedSteps.push(step.id);\n        if (!workflow.config.continueOnStepFailure) {\n          execution.status = 'failed';\n          execution.completedAt = new Date();\n          return;\n        }\n        continue;\n      }\n      \n      // Check condition\n      if (step.condition && !step.condition(execution.context)) {\n        execution.skippedSteps.push(step.id);\n        continue;\n      }\n      \n      // Execute step\n      execution.currentStep = step.id;\n      \n      try {\n        const result = await this.executeStep(step, execution, workflow);\n        \n        execution.stepResults.set(step.id, result);\n        execution.completedSteps.push(step.id);\n        \n        // Update context with step outputs\n        if (step.outputMapping) {\n          for (const [key, path] of Object.entries(step.outputMapping)) {\n            execution.context.outputs[key] = this.extractValue(result, path);\n          }\n        }\n        \n        // Emit step complete event\n        for (const handler of this.stepCompleteHandlers) {\n          handler(execution.id, step.id, result);\n        }\n        \n        // Checkpoint if configured\n        if (\n          workflow.config.checkpointInterval &&\n          execution.completedSteps.length % workflow.config.checkpointInterval === 0\n        ) {\n          await this.saveCheckpoint(execution.id);\n        }\n      } catch (error) {\n        execution.failedSteps.push(step.id);\n        \n        if (!workflow.config.continueOnStepFailure) {\n          execution.status = 'failed';\n          execution.completedAt = new Date();\n          throw error;\n        }\n      }\n    }\n    \n    // Workflow completed\n    execution.status = 'completed';\n    execution.completedAt = new Date();\n    \n    // Emit workflow complete event\n    const result: WorkflowResult = {\n      executionId: execution.id,\n      success: execution.failedSteps.length === 0,\n      completedSteps: execution.completedSteps.length,\n      failedSteps: execution.failedSteps.length,\n      outputs: execution.context.outputs,\n      duration: execution.completedAt.getTime() - execution.startedAt.getTime(),\n    };\n    \n    for (const handler of this.workflowCompleteHandlers) {\n      handler(result);\n    }\n  }\n\n  private areDependenciesMet(\n    step: WorkflowStep,\n    execution: WorkflowExecution\n  ): boolean {\n    for (const depId of step.dependsOn) {\n      if (!execution.completedSteps.includes(depId)) {\n        return false;\n      }\n    }\n    return true;\n  }\n\n  private async executeStep(\n    step: WorkflowStep,\n    execution: WorkflowExecution,\n    workflow: WorkflowDefinition\n  ): Promise<ExecutionResult> {\n    // Render prompt template with context\n    const prompt = this.renderTemplate(step.promptTemplate, execution.context);\n    \n    // Build execution task\n    const task: ExecutionTask = {\n      id: generateId('task'),\n      type: step.taskType,\n      entityId: undefined,\n      prompt,\n      workDir: process.cwd(), // TODO: Make configurable\n      priority: 0,\n      dependencies: [],\n      createdAt: new Date(),\n      config: {\n        timeout: step.timeout,\n      },\n    };\n    \n    // Execute with resilience\n    return await this.executor.executeTask(task, step.retryPolicy);\n  }\n\n  private renderTemplate(\n    template: string,\n    context: WorkflowContext\n  ): string {\n    let rendered = template;\n    \n    // Replace variables: {{variable}}\n    for (const [key, value] of Object.entries(context.variables)) {\n      rendered = rendered.replace(\n        new RegExp(`{{${key}}}`, 'g'),\n        String(value)\n      );\n    }\n    \n    // Replace outputs: {{step.output}}\n    for (const [key, value] of Object.entries(context.outputs)) {\n      rendered = rendered.replace(\n        new RegExp(`{{${key}}}`, 'g'),\n        String(value)\n      );\n    }\n    \n    return rendered;\n  }\n\n  private extractValue(result: ExecutionResult, path: string): any {\n    // Simple path extraction (e.g., \"output\" or \"metadata.filesChanged\")\n    const parts = path.split('.');\n    let value: any = result;\n    \n    for (const part of parts) {\n      value = value[part];\n      if (value === undefined) break;\n    }\n    \n    return value;\n  }\n\n  async saveCheckpoint(executionId: string): Promise<string> {\n    const execution = this.executions.get(executionId);\n    if (!execution) {\n      throw new Error(`Execution ${executionId} not found`);\n    }\n    \n    const checkpoint: WorkflowCheckpoint = {\n      executionId,\n      workflowId: execution.workflowId,\n      timestamp: new Date(),\n      execution: { ...execution },\n      nextStep: execution.currentStep,\n    };\n    \n    const checkpointId = generateId('checkpoint');\n    this.checkpoints.set(checkpointId, checkpoint);\n    \n    execution.lastCheckpointAt = new Date();\n    \n    // Persist to storage if available\n    if (this.storage) {\n      await this.storage.saveCheckpoint(checkpointId, checkpoint);\n    }\n    \n    // Emit checkpoint event\n    for (const handler of this.checkpointHandlers) {\n      handler(checkpoint);\n    }\n    \n    return checkpointId;\n  }\n\n  async pauseWorkflow(executionId: string): Promise<void> {\n    const execution = this.executions.get(executionId);\n    if (execution) {\n      execution.status = 'paused';\n    }\n  }\n\n  async cancelWorkflow(executionId: string): Promise<void> {\n    const execution = this.executions.get(executionId);\n    if (execution) {\n      execution.status = 'cancelled';\n      execution.completedAt = new Date();\n    }\n  }\n\n  getExecution(executionId: string): WorkflowExecution | null {\n    return this.executions.get(executionId) || null;\n  }\n\n  getStepStatus(executionId: string, stepId: string): StepStatus | null {\n    const execution = this.executions.get(executionId);\n    if (!execution) return null;\n    \n    const result = execution.stepResults.get(stepId);\n    \n    let status: StepStatus['status'];\n    if (execution.completedSteps.includes(stepId)) {\n      status = 'completed';\n    } else if (execution.failedSteps.includes(stepId)) {\n      status = 'failed';\n    } else if (execution.skippedSteps.includes(stepId)) {\n      status = 'skipped';\n    } else if (execution.currentStep === stepId) {\n      status = 'running';\n    } else {\n      status = 'pending';\n    }\n    \n    return {\n      stepId,\n      status,\n      result,\n      attempts: 1, // TODO: Track attempts\n    };\n  }\n\n  async waitForWorkflow(executionId: string): Promise<WorkflowResult> {\n    return new Promise((resolve, reject) => {\n      const checkInterval = setInterval(() => {\n        const execution = this.executions.get(executionId);\n        if (!execution) {\n          clearInterval(checkInterval);\n          reject(new Error(`Execution ${executionId} not found`));\n          return;\n        }\n        \n        if (\n          execution.status === 'completed' ||\n          execution.status === 'failed' ||\n          execution.status === 'cancelled'\n        ) {\n          clearInterval(checkInterval);\n          \n          const result: WorkflowResult = {\n            executionId,\n            success: execution.status === 'completed',\n            completedSteps: execution.completedSteps.length,\n            failedSteps: execution.failedSteps.length,\n            outputs: execution.context.outputs,\n            duration: execution.completedAt\n              ? execution.completedAt.getTime() - execution.startedAt.getTime()\n              : 0,\n          };\n          \n          resolve(result);\n        }\n      }, 100);\n    });\n  }\n\n  async listCheckpoints(workflowId: string): Promise<WorkflowCheckpoint[]> {\n    const checkpoints: WorkflowCheckpoint[] = [];\n    \n    for (const checkpoint of this.checkpoints.values()) {\n      if (checkpoint.workflowId === workflowId) {\n        checkpoints.push(checkpoint);\n      }\n    }\n    \n    return checkpoints;\n  }\n\n  onStepComplete(handler: StepCompleteHandler): void {\n    this.stepCompleteHandlers.push(handler);\n  }\n\n  onWorkflowComplete(handler: WorkflowCompleteHandler): void {\n    this.workflowCompleteHandlers.push(handler);\n  }\n\n  onCheckpoint(handler: CheckpointHandler): void {\n    this.checkpointHandlers.push(handler);\n  }\n\n  private async loadWorkflowDefinition(\n    workflowId: string\n  ): Promise<WorkflowDefinition> {\n    // TODO: Load from storage\n    throw new Error('Not implemented');\n  }\n}\n\ninterface IWorkflowStorage {\n  saveCheckpoint(id: string, checkpoint: WorkflowCheckpoint): Promise<void>;\n  loadCheckpoint(id: string): Promise<WorkflowCheckpoint | null>;\n}\n```\n\n## Usage Example\n\n```typescript\n// Define workflow\nconst bugFixWorkflow: WorkflowDefinition = {\n  id: 'bug-fix-workflow',\n  name: 'Bug Fix and Test',\n  version: '1.0',\n  steps: [\n    {\n      id: 'analyze',\n      name: 'Analyze Issue',\n      taskType: 'issue',\n      promptTemplate: 'Analyze the bug in {{issueId}} and suggest a fix',\n      dependsOn: [],\n      outputMapping: {\n        analysis: 'output',\n      },\n    },\n    {\n      id: 'implement',\n      name: 'Implement Fix',\n      taskType: 'issue',\n      promptTemplate: 'Implement the fix for {{issueId}}. Analysis: {{analysis}}',\n      dependsOn: ['analyze'],\n      outputMapping: {\n        filesChanged: 'metadata.filesChanged',\n      },\n    },\n    {\n      id: 'test',\n      name: 'Run Tests',\n      taskType: 'custom',\n      promptTemplate: 'Run tests for files: {{filesChanged}}',\n      dependsOn: ['implement'],\n    },\n  ],\n  config: {\n    checkpointInterval: 1,\n    continueOnStepFailure: false,\n  },\n};\n\n// Execute workflow\nconst orchestrator = new LinearOrchestrator(resilientExecutor);\n\norchestrator.onStepComplete((execId, stepId, result) => {\n  console.log(`Step ${stepId} completed:`, result.success);\n});\n\nconst executionId = await orchestrator.startWorkflow(bugFixWorkflow, {\n  variables: {\n    issueId: 'ISSUE-001',\n  },\n});\n\nconst result = await orchestrator.waitForWorkflow(executionId);\nconsole.log(`Workflow completed: ${result.success}`);\nconsole.log(`Outputs:`, result.outputs);\n```\n\n## Testing Strategy\n\n### Unit Tests\n\n1. **Step execution**\n   - Executes steps in order\n   - Passes context between steps\n   - Handles step failures\n   - Skips conditional steps\n\n2. **Checkpointing**\n   - Saves checkpoint after interval\n   - Resumes from checkpoint correctly\n   - Preserves execution state\n\n3. **Template rendering**\n   - Replaces variables correctly\n   - Handles nested paths\n   - Handles missing variables\n\n### Integration Tests\n\n1. **End-to-end workflows**\n   - Multi-step workflow completes\n   - Checkpoint and resume works\n   - Context data flows correctly\n\n2. **Failure scenarios**\n   - Step failure stops workflow\n   - Resume after crash\n   - Handle partial completion\n\n## Future Enhancements\n\n1. **DAG workflows** - Parallel step execution\n2. **Conditional branches** - If/else logic\n3. **Loops** - Repeat steps until condition\n4. **Sub-workflows** - Compose workflows\n5. **Workflow versioning** - A/B testing\n\n## File Structure\n\n```\nserver/src/execution/workflow/\n├── types.ts                    # Core types (WorkflowDefinition, etc.)\n├── orchestrator.ts             # IWorkflowOrchestrator interface\n├── linear-orchestrator.ts      # LinearOrchestrator (start here)\n├── dag-orchestrator.ts         # DAGOrchestrator (future)\n├── storage.ts                  # Checkpoint persistence\n└── utils.ts                    # Template rendering, etc.\n```\n\n## Implementation Checklist\n\n- [ ] Define core types\n- [ ] Define IWorkflowOrchestrator interface\n- [ ] Implement LinearOrchestrator\n- [ ] Add sequential step execution\n- [ ] Add dependency resolution\n- [ ] Add template rendering\n- [ ] Add checkpointing\n- [ ] Add workflow resumption\n- [ ] Add conditional step execution\n- [ ] Write unit tests\n- [ ] Write integration tests\n\n## Related Specs\n\n- Execution System (root spec)\n- [[SPEC-003]] - Process Layer\n- [[SPEC-004]] - Engine Layer\n- [[SPEC-005]] - Task Execution Layer (dependency)\n- Next: Output Processing Layer (Layer 5)\n","priority":0,"archived":1,"archived_at":"2025-11-05T05:39:12.948Z","created_at":"2025-10-28 07:45:45","updated_at":"2025-11-05 05:39:12","parent_id":null,"parent_uuid":null,"relationships":[{"from":"SPEC-006","from_type":"spec","to":"SPEC-003","to_type":"spec","type":"references"},{"from":"SPEC-006","from_type":"spec","to":"SPEC-004","to_type":"spec","type":"references"}],"tags":["execution","layer-4","orchestration","state","workflow"]}
{"id":"SPEC-007","uuid":"cb9b2531-e8ce-4696-a74e-6973649ccdc7","title":"Output Processing Layer - Real-time Parsing","file_path":"specs/output_processing_layer_real_time_parsing.md","content":"# Output Processing Layer Specification\n\n## Overview\n\nThe Output Processing Layer (Layer 5) handles real-time parsing and processing of Claude Code's output. It parses stream-json format, extracts structured data, tracks progress, and provides event-driven updates.\n\n## Design Goals\n\n1. **Real-time**: Parse output as it streams, not after completion\n1. **Structured**: Extract tool calls, file changes, errors from JSON\n1. **Event-driven**: Emit events for progress tracking\n1. **Robust**: Handle malformed JSON gracefully\n1. **Flexible**: Support multiple output formats\n\n## Architecture\n\nBased on Execution System spec and all previous layers.\n\n```\n┌──────────────────────────────────────────────────┐\n│     Output Processing Layer (Layer 5)            │\n├──────────────────────────────────────────────────┤\n│                                                  │\n│  ┌────────────────────────────────────────────┐ │\n│  │   IOutputProcessor (Interface)             │ │\n│  └────────────┬───────────────────────────────┘ │\n│               │                                  │\n│     ┌─────────▼──────────┐                      │\n│     │ StreamJsonProcessor│                      │\n│     │  (Start Here)      │                      │\n│     └─────────┬──────────┘                      │\n│               │                                  │\n│        ┌──────┴──────┬──────────┬──────────┐   │\n│        │             │          │          │   │\n│   ┌────▼────┐  ┌────▼────┐ ┌──▼────┐ ┌───▼──┐│\n│   │  JSON   │  │  Event  │ │ Meta  │ │Error ││\n│   │ Parser  │  │ Emitter │ │Extract│ │Handle││\n│   └─────────┘  └─────────┘ └───────┘ └──────┘│\n│                                                  │\n│    ┌──────────────────────────────────────────┐ │\n│    │      Process Manager (Layer 1)           │ │\n│    └──────────────────────────────────────────┘ │\n│                                                  │\n└──────────────────────────────────────────────────┘\n```\n\n## Core Types\n\n### StreamMessage\n\nParsed message from Claude Code stream-json output.\n\n```typescript\ninterface StreamMessage {\n  type: MessageType;\n  timestamp: Date;\n  raw: string;                   // Original JSON line\n  data: any;                     // Parsed JSON\n}\n\ntype MessageType = \n  | 'user'                       // User message\n  | 'assistant'                  // Assistant message\n  | 'tool_use'                   // Tool invocation\n  | 'tool_result'                // Tool result\n  | 'result'                     // Final result with usage\n  | 'error'                      // Error message\n  | 'unknown';                   // Unparseable\n```\n\n### ToolCall\n\nExtracted tool call information.\n\n```typescript\ninterface ToolCall {\n  id: string;\n  name: string;\n  input: Record<string, any>;\n  timestamp: Date;\n}\n\ninterface ToolResult {\n  toolCallId: string;\n  success: boolean;\n  output?: any;\n  error?: string;\n  timestamp: Date;\n}\n```\n\n### ExecutionProgress\n\nReal-time execution progress.\n\n```typescript\ninterface ExecutionProgress {\n  // Basic info\n  processId: string;\n  startedAt: Date;\n  lastUpdate: Date;\n  \n  // Progress\n  toolCalls: ToolCall[];\n  toolResults: ToolResult[];\n  filesChanged: string[];\n  errors: string[];\n  \n  // Current state\n  currentActivity?: string;      // e.g., \"Reading file auth.ts\"\n  \n  // Usage\n  usage?: {\n    inputTokens: number;\n    outputTokens: number;\n    totalTokens: number;\n    cost?: number;\n  };\n}\n```\n\n### OutputProcessingOptions\n\nConfiguration for output processing.\n\n```typescript\ninterface OutputProcessingOptions {\n  // Format\n  format: 'stream-json' | 'json' | 'text';\n  \n  // Filtering\n  captureToolCalls?: boolean;\n  captureFileChanges?: boolean;\n  captureErrors?: boolean;\n  \n  // Events\n  emitProgressEvents?: boolean;\n  progressInterval?: number;     // ms between progress events\n  \n  // Buffering\n  maxBufferSize?: number;        // Max lines to buffer\n  lineSeparator?: string;        // Default: '\\n'\n}\n```\n\n## IOutputProcessor Interface\n\nThe core abstraction for output processing.\n\n```typescript\ninterface IOutputProcessor {\n  // Processing\n  processLine(line: string): StreamMessage | null;\n  processBuffer(buffer: string): StreamMessage[];\n  \n  // Progress tracking\n  getProgress(processId: string): ExecutionProgress | null;\n  \n  // Events\n  onToolCall(handler: ToolCallHandler): void;\n  onFileChange(handler: FileChangeHandler): void;\n  onProgress(handler: ProgressHandler): void;\n  onError(handler: ErrorHandler): void;\n  onComplete(handler: CompleteHandler): void;\n  \n  // Extraction\n  extractMetadata(messages: StreamMessage[]): ExecutionMetadata;\n  extractToolCalls(messages: StreamMessage[]): ToolCall[];\n  extractFileChanges(messages: StreamMessage[]): string[];\n}\n\ntype ToolCallHandler = (processId: string, toolCall: ToolCall) => void;\ntype FileChangeHandler = (processId: string, filePath: string) => void;\ntype ProgressHandler = (processId: string, progress: ExecutionProgress) => void;\ntype ErrorHandler = (processId: string, error: string) => void;\ntype CompleteHandler = (processId: string, metadata: ExecutionMetadata) => void;\n\ninterface ExecutionMetadata {\n  toolsUsed: string[];\n  filesChanged: string[];\n  tokensUsed: number;\n  cost: number;\n  duration: number;\n}\n```\n\n## StreamJsonProcessor Implementation\n\nParses Claude Code's stream-json format in real-time.\n\n### Key Features\n\n1. **Line-by-line parsing**: Handle incomplete JSON gracefully\n1. **Event emission**: Notify listeners on key events\n1. **Progress tracking**: Build execution progress in real-time\n1. **Metadata extraction**: Extract structured data from messages\n1. **Error handling**: Gracefully handle malformed JSON\n\n### Implementation Pattern\n\n```typescript\nclass StreamJsonProcessor implements IOutputProcessor {\n  private progressTracking = new Map<string, ExecutionProgress>();\n  \n  private toolCallHandlers: ToolCallHandler[] = [];\n  private fileChangeHandlers: FileChangeHandler[] = [];\n  private progressHandlers: ProgressHandler[] = [];\n  private errorHandlers: ErrorHandler[] = [];\n  private completeHandlers: CompleteHandler[] = [];\n  \n  private currentProcessId?: string;\n  \n  constructor(private options: OutputProcessingOptions = {}) {\n    this.options = {\n      format: 'stream-json',\n      captureToolCalls: true,\n      captureFileChanges: true,\n      captureErrors: true,\n      emitProgressEvents: true,\n      progressInterval: 1000,\n      maxBufferSize: 10000,\n      lineSeparator: '\\n',\n      ...options,\n    };\n  }\n\n  processLine(line: string): StreamMessage | null {\n    if (!line.trim()) return null;\n    \n    try {\n      const data = JSON.parse(line);\n      const message: StreamMessage = {\n        type: this.detectMessageType(data),\n        timestamp: new Date(),\n        raw: line,\n        data,\n      };\n      \n      // Process message\n      this.handleMessage(message);\n      \n      return message;\n    } catch (error) {\n      // Not valid JSON, might be plain text\n      return {\n        type: 'unknown',\n        timestamp: new Date(),\n        raw: line,\n        data: { text: line },\n      };\n    }\n  }\n\n  processBuffer(buffer: string): StreamMessage[] {\n    const lines = buffer.split(this.options.lineSeparator!);\n    const messages: StreamMessage[] = [];\n    \n    for (const line of lines) {\n      const message = this.processLine(line);\n      if (message) {\n        messages.push(message);\n      }\n    }\n    \n    return messages;\n  }\n\n  private detectMessageType(data: any): MessageType {\n    if (data.type === 'user') return 'user';\n    if (data.type === 'assistant') return 'assistant';\n    if (data.type === 'result') return 'result';\n    if (data.type === 'error') return 'error';\n    \n    // Check for tool use/result in message content\n    if (data.message?.content) {\n      const content = Array.isArray(data.message.content)\n        ? data.message.content[0]\n        : data.message.content;\n      \n      if (content.type === 'tool_use') return 'tool_use';\n      if (content.type === 'tool_result') return 'tool_result';\n    }\n    \n    return 'unknown';\n  }\n\n  private handleMessage(message: StreamMessage): void {\n    if (!this.currentProcessId) return;\n    \n    const progress = this.getOrCreateProgress(this.currentProcessId);\n    progress.lastUpdate = new Date();\n    \n    switch (message.type) {\n      case 'assistant':\n        this.handleAssistantMessage(message, progress);\n        break;\n      case 'tool_use':\n        this.handleToolUse(message, progress);\n        break;\n      case 'tool_result':\n        this.handleToolResult(message, progress);\n        break;\n      case 'result':\n        this.handleResult(message, progress);\n        break;\n      case 'error':\n        this.handleError(message, progress);\n        break;\n    }\n    \n    // Emit progress event\n    if (this.options.emitProgressEvents) {\n      this.emitProgress(this.currentProcessId, progress);\n    }\n  }\n\n  private handleAssistantMessage(\n    message: StreamMessage,\n    progress: ExecutionProgress\n  ): void {\n    const { data } = message;\n    \n    if (!data.message?.content) return;\n    \n    const contents = Array.isArray(data.message.content)\n      ? data.message.content\n      : [data.message.content];\n    \n    for (const content of contents) {\n      if (content.type === 'tool_use') {\n        const toolCall: ToolCall = {\n          id: content.id,\n          name: content.name,\n          input: content.input,\n          timestamp: message.timestamp,\n        };\n        \n        progress.toolCalls.push(toolCall);\n        \n        // Update current activity\n        progress.currentActivity = `Using tool: ${toolCall.name}`;\n        \n        // Track file changes\n        if (\n          this.options.captureFileChanges &&\n          (content.name === 'Write' || content.name === 'Edit')\n        ) {\n          const filePath = content.input.file_path;\n          if (filePath && !progress.filesChanged.includes(filePath)) {\n            progress.filesChanged.push(filePath);\n            \n            // Emit file change event\n            for (const handler of this.fileChangeHandlers) {\n              handler(progress.processId, filePath);\n            }\n          }\n        }\n        \n        // Emit tool call event\n        if (this.options.captureToolCalls) {\n          for (const handler of this.toolCallHandlers) {\n            handler(progress.processId, toolCall);\n          }\n        }\n      }\n    }\n  }\n\n  private handleToolUse(\n    message: StreamMessage,\n    progress: ExecutionProgress\n  ): void {\n    // Similar to handleAssistantMessage tool_use handling\n    const { data } = message;\n    \n    const toolCall: ToolCall = {\n      id: data.id || generateId('tool'),\n      name: data.name,\n      input: data.input,\n      timestamp: message.timestamp,\n    };\n    \n    progress.toolCalls.push(toolCall);\n    progress.currentActivity = `Using tool: ${toolCall.name}`;\n  }\n\n  private handleToolResult(\n    message: StreamMessage,\n    progress: ExecutionProgress\n  ): void {\n    const { data } = message;\n    \n    const result: ToolResult = {\n      toolCallId: data.tool_use_id || data.id,\n      success: !data.is_error,\n      output: data.content,\n      error: data.is_error ? data.content : undefined,\n      timestamp: message.timestamp,\n    };\n    \n    progress.toolResults.push(result);\n  }\n\n  private handleResult(\n    message: StreamMessage,\n    progress: ExecutionProgress\n  ): void {\n    const { data } = message;\n    \n    // Extract usage information\n    if (data.usage) {\n      progress.usage = {\n        inputTokens: data.usage.input_tokens || 0,\n        outputTokens: data.usage.output_tokens || 0,\n        totalTokens: data.usage.total_tokens || 0,\n        cost: this.calculateCost(data.usage),\n      };\n    }\n    \n    // Emit complete event\n    const metadata = this.buildMetadata(progress);\n    for (const handler of this.completeHandlers) {\n      handler(progress.processId, metadata);\n    }\n  }\n\n  private handleError(\n    message: StreamMessage,\n    progress: ExecutionProgress\n  ): void {\n    const { data } = message;\n    const error = data.error?.message || data.message || 'Unknown error';\n    \n    if (this.options.captureErrors) {\n      progress.errors.push(error);\n      \n      // Emit error event\n      for (const handler of this.errorHandlers) {\n        handler(progress.processId, error);\n      }\n    }\n  }\n\n  private getOrCreateProgress(processId: string): ExecutionProgress {\n    let progress = this.progressTracking.get(processId);\n    \n    if (!progress) {\n      progress = {\n        processId,\n        startedAt: new Date(),\n        lastUpdate: new Date(),\n        toolCalls: [],\n        toolResults: [],\n        filesChanged: [],\n        errors: [],\n      };\n      this.progressTracking.set(processId, progress);\n    }\n    \n    return progress;\n  }\n\n  private emitProgress(processId: string, progress: ExecutionProgress): void {\n    for (const handler of this.progressHandlers) {\n      handler(processId, progress);\n    }\n  }\n\n  private buildMetadata(progress: ExecutionProgress): ExecutionMetadata {\n    const toolsUsed = Array.from(\n      new Set(progress.toolCalls.map(tc => tc.name))\n    );\n    \n    const duration = progress.lastUpdate.getTime() - progress.startedAt.getTime();\n    \n    return {\n      toolsUsed,\n      filesChanged: progress.filesChanged,\n      tokensUsed: progress.usage?.totalTokens || 0,\n      cost: progress.usage?.cost || 0,\n      duration,\n    };\n  }\n\n  private calculateCost(usage: any): number {\n    // Simplified cost calculation\n    // Claude Sonnet pricing (example)\n    const inputCostPer1M = 3.00;\n    const outputCostPer1M = 15.00;\n    \n    const inputCost = (usage.input_tokens / 1000000) * inputCostPer1M;\n    const outputCost = (usage.output_tokens / 1000000) * outputCostPer1M;\n    \n    return inputCost + outputCost;\n  }\n\n  getProgress(processId: string): ExecutionProgress | null {\n    return this.progressTracking.get(processId) || null;\n  }\n\n  extractMetadata(messages: StreamMessage[]): ExecutionMetadata {\n    const toolCalls = this.extractToolCalls(messages);\n    const filesChanged = this.extractFileChanges(messages);\n    \n    let usage = { inputTokens: 0, outputTokens: 0, totalTokens: 0, cost: 0 };\n    \n    for (const message of messages) {\n      if (message.type === 'result' && message.data.usage) {\n        usage = {\n          inputTokens: message.data.usage.input_tokens || 0,\n          outputTokens: message.data.usage.output_tokens || 0,\n          totalTokens: message.data.usage.total_tokens || 0,\n          cost: this.calculateCost(message.data.usage),\n        };\n      }\n    }\n    \n    const toolsUsed = Array.from(new Set(toolCalls.map(tc => tc.name)));\n    \n    return {\n      toolsUsed,\n      filesChanged,\n      tokensUsed: usage.totalTokens,\n      cost: usage.cost,\n      duration: 0, // Would need start/end times\n    };\n  }\n\n  extractToolCalls(messages: StreamMessage[]): ToolCall[] {\n    const toolCalls: ToolCall[] = [];\n    \n    for (const message of messages) {\n      if (message.type === 'assistant' && message.data.message?.content) {\n        const contents = Array.isArray(message.data.message.content)\n          ? message.data.message.content\n          : [message.data.message.content];\n        \n        for (const content of contents) {\n          if (content.type === 'tool_use') {\n            toolCalls.push({\n              id: content.id,\n              name: content.name,\n              input: content.input,\n              timestamp: message.timestamp,\n            });\n          }\n        }\n      }\n    }\n    \n    return toolCalls;\n  }\n\n  extractFileChanges(messages: StreamMessage[]): string[] {\n    const files = new Set<string>();\n    const toolCalls = this.extractToolCalls(messages);\n    \n    for (const toolCall of toolCalls) {\n      if (toolCall.name === 'Write' || toolCall.name === 'Edit') {\n        const filePath = toolCall.input.file_path;\n        if (filePath) {\n          files.add(filePath);\n        }\n      }\n    }\n    \n    return Array.from(files);\n  }\n\n  // Event registration\n  onToolCall(handler: ToolCallHandler): void {\n    this.toolCallHandlers.push(handler);\n  }\n\n  onFileChange(handler: FileChangeHandler): void {\n    this.fileChangeHandlers.push(handler);\n  }\n\n  onProgress(handler: ProgressHandler): void {\n    this.progressHandlers.push(handler);\n  }\n\n  onError(handler: ErrorHandler): void {\n    this.errorHandlers.push(handler);\n  }\n\n  onComplete(handler: CompleteHandler): void {\n    this.completeHandlers.push(handler);\n  }\n\n  // Set current process for tracking\n  setCurrentProcess(processId: string): void {\n    this.currentProcessId = processId;\n  }\n}\n```\n\n## Usage Example\n\n```typescript\n// Create processor\nconst processor = new StreamJsonProcessor({\n  format: 'stream-json',\n  captureToolCalls: true,\n  captureFileChanges: true,\n  emitProgressEvents: true,\n});\n\n// Set up event listeners\nprocessor.onToolCall((processId, toolCall) => {\n  console.log(`[${processId}] Tool: ${toolCall.name}`, toolCall.input);\n});\n\nprocessor.onFileChange((processId, filePath) => {\n  console.log(`[${processId}] File changed: ${filePath}`);\n});\n\nprocessor.onProgress((processId, progress) => {\n  console.log(`[${processId}] Progress:`, {\n    toolCalls: progress.toolCalls.length,\n    filesChanged: progress.filesChanged.length,\n    activity: progress.currentActivity,\n  });\n});\n\nprocessor.onComplete((processId, metadata) => {\n  console.log(`[${processId}] Complete:`, metadata);\n});\n\n// Integrate with process manager\nconst processManager = new SimpleProcessManager();\nconst process = await processManager.acquireProcess({\n  claudePath: 'claude',\n  workDir: '/path/to/project',\n  args: {\n    print: true,\n    outputFormat: 'stream-json',\n    dangerouslySkipPermissions: true,\n  },\n});\n\nprocessor.setCurrentProcess(process.id);\n\n// Process output as it streams\nprocessManager.onOutput(process.id, (data, type) => {\n  if (type === 'stdout') {\n    const lines = data.toString().split('\\n');\n    for (const line of lines) {\n      processor.processLine(line);\n    }\n  }\n});\n\n// Send input\nawait processManager.sendInput(process.id, 'Fix the bug in auth.ts\\n');\n```\n\n## Testing Strategy\n\n### Unit Tests\n\n1. **JSON parsing**\n\n- Parses valid stream-json lines\n- Handles malformed JSON gracefully\n- Detects message types correctly\n\n1. **Metadata extraction**\n\n- Extracts tool calls from messages\n- Extracts file changes from Write/Edit tools\n- Calculates usage and cost correctly\n\n1. **Event emission**\n\n- Emits tool call events\n- Emits file change events\n- Emits progress events at interval\n\n### Integration Tests\n\n1. **End-to-end processing**\n\n- Process real Claude Code output\n- Track progress accurately\n- Extract complete metadata\n\n1. **Real-time streaming**\n\n- Handle partial lines\n- Process incomplete JSON\n- Buffer management\n\n## Future Enhancements\n\n1. **Format adapters** - Support text, JSON formats\n1. **Filtering** - Filter events by type/pattern\n1. **Aggregation** - Aggregate metrics across processes\n1. **Persistence** - Store output for replay\n1. **Compression** - Compress large outputs\n\n## File Structure\n\n```\nserver/src/execution/output/\n├── types.ts                    # Core types (StreamMessage, etc.)\n├── processor.ts                # IOutputProcessor interface\n├── stream-json-processor.ts    # StreamJsonProcessor (start here)\n├── text-processor.ts           # TextProcessor (future)\n└── utils.ts                    # JSON parsing, cost calculation\n```\n\n## Implementation Checklist\n\n- Define core types\n- Define IOutputProcessor interface\n- Implement StreamJsonProcessor\n- Add line-by-line JSON parsing\n- Add message type detection\n- Add tool call extraction\n- Add file change tracking\n- Add progress tracking\n- Add event emission\n- Add metadata extraction\n- Write unit tests\n- Write integration tests\n\n## Related Specs\n\n- Execution System (root spec)\n- [[SPEC-003]] - Process Layer (integrates with)\n- [[SPEC-004]] - Engine Layer\n- [[SPEC-005]] - Task Execution Layer\n- [[SPEC-006]] - Workflow Layer","priority":0,"archived":1,"archived_at":"2025-11-05T05:38:59.391Z","created_at":"2025-10-28 07:45:45","updated_at":"2025-11-05 08:55:52","parent_id":null,"parent_uuid":null,"relationships":[{"from":"SPEC-007","from_type":"spec","to":"SPEC-003","to_type":"spec","type":"references"},{"from":"SPEC-007","from_type":"spec","to":"SPEC-004","to_type":"spec","type":"references"},{"from":"SPEC-007","from_type":"spec","to":"SPEC-006","to_type":"spec","type":"references"}],"tags":["execution","layer-5","output-processing","parsing","streaming"]}
{"id":"SPEC-008","uuid":"1ece2c76-6874-4849-9dd4-1555b885ec88","title":"Inline Feedback Visualization for Spec Documents","file_path":"specs/inline_feedback_visualization_for_spec_documents.md","content":"\n# Inline Feedback Visualization for Spec Documents\n\n## Overview\n\nImplement a Google Docs-style feedback visualization system for spec documents that displays feedback inline with the document content or aligned in a side panel. This replaces the current separate column approach with a more integrated, contextual feedback experience.\n\n## Goals\n\n- **Contextual Feedback**: Show feedback aligned with the specific lines/sections it references\n- **Visual Clarity**: Use highlights and indicators to show where feedback exists\n- **Flexible Layout**: Support both general document comments and line-specific feedback\n- **Minimal Dependencies**: Leverage existing Tiptap editor without paid extensions\n- **Responsive Design**: Work across different screen sizes\n\n## Current State\n\nCurrently, `SpecDetailPage` displays feedback in a completely separate `SpecFeedbackPanel` column with no visual connection to the referenced content. Users must manually correlate feedback with document locations using line numbers.\n\n**Key files:**\n- `frontend/src/pages/SpecDetailPage.tsx` - Main spec view page\n- `frontend/src/components/specs/SpecFeedbackPanel.tsx` - Current feedback panel\n- `frontend/src/components/specs/TiptapEditor.tsx` - Rich text editor\n- `frontend/src/components/specs/SpecViewer.tsx` - Markdown source view\n\n## Proposed Design\n\n### Hybrid Approach: Margin Indicators + Aligned Side Panel\n\n```\n┌───────────────────────────────────────┬─────────────────────┐\n│                Spec Content           │ Feedback Panel      │\n│                                       │                     │\n│ # Introduction                        │ 💭 General Comments │\n│ This spec... [💬] ← highlighted       │   \"Overall good\"    │\n│                                       │                     │\n│ ## Architecture                       │ 💬 Line 6          │\n│ System design...                      │   \"Missing details\" │\n│ Implementation [💬] ← highlighted     │   ↑ aligned        │\n│                                       │                     │\n└───────────────────────────────────────┴─────────────────────┘\n```\n\n### Key Features\n\n1. **Inline Indicators**: Show 💬 emoji or icon at feedback locations\n2. **Text Highlighting**: Subtle background color on referenced text\n3. **Aligned Comments**: Side panel comments vertically aligned with their anchors\n4. **General Comments**: Unanchored feedback shown at top of panel\n5. **Interactive**: Click indicator or highlight to focus the comment\n\n## Technical Approach\n\n### Architecture Decision: Free Tiptap Features Only\n\nSince Tiptap's Collaboration and Comments extensions are paid features, we'll use:\n\n- ✅ **Custom Marks** - For text highlighting (free)\n- ✅ **ProseMirror Decorations** - For overlay indicators (free)\n- ✅ **Native DOM APIs** - For position tracking (`getBoundingClientRect`)\n- ✅ **React State** - For coordinating editor and panel\n\n### Component Structure\n\n```typescript\nSpecDetailPage\n├── SpecEditor (with feedback extensions)\n│   ├── TiptapEditor\n│   │   ├── FeedbackMark (highlight text)\n│   │   └── FeedbackDecorations (add indicators)\n│   └── Feedback indicators overlaid\n└── AlignedFeedbackPanel\n    ├── GeneralComments (no anchor)\n    └── AnchoredComments (positioned absolutely)\n```\n\n### Key Components\n\n1. **FeedbackMark** - Custom Tiptap mark extension for highlighting text with feedback\n2. **FeedbackDecorations** - ProseMirror plugin for adding clickable indicators\n3. **useFeedbackPositions** - React hook for tracking vertical positions\n4. **AlignedFeedbackPanel** - Component displaying comments aligned with document\n\n## Implementation Phases\n\n### Phase 1: Basic Infrastructure\n\n**Tasks:**\n- Create `FeedbackMark` Tiptap extension\n- Create `useFeedbackPositions` hook\n- Create `AlignedFeedbackPanel` component\n- Update `SpecDetailPage` layout for side-by-side view\n- Implement basic position tracking with scroll sync\n\n**Files to create:**\n- `frontend/src/components/specs/extensions/FeedbackMark.ts`\n- `frontend/src/hooks/useFeedbackPositions.ts`\n- `frontend/src/components/specs/AlignedFeedbackPanel.tsx`\n\n**Files to modify:**\n- `frontend/src/components/specs/TiptapEditor.tsx`\n- `frontend/src/pages/SpecDetailPage.tsx`\n\n**Deliverable**: Feedback panel shows comments aligned with rough positions\n\n### Phase 2: Decorations & Indicators\n\n**Tasks:**\n- Implement `FeedbackDecorations` extension\n- Add clickable indicators (💬) in document margins\n- Wire up click handlers to focus comments\n- Add hover states for highlights\n- Implement scroll-to-comment functionality\n\n**Files to create:**\n- `frontend/src/components/specs/extensions/FeedbackDecorations.ts`\n\n**Deliverable**: Visual indicators in document, clickable to show comments\n\n### Phase 3: Polish & Edge Cases\n\n**Tasks:**\n- Handle feedback without anchors (general comments)\n- Handle stale anchors (content changed, line moved)\n- Optimize position updates (debouncing, throttling)\n- Add transitions/animations for smooth UX\n- Test with long documents and many comments\n- Mobile responsive behavior (stack instead of side-by-side)\n\n**Deliverable**: Production-ready feature with edge cases handled\n\n### Phase 4: Advanced Features (Optional)\n\n**Tasks:**\n- Filter comments by type in side panel\n- Show/hide resolved comments\n- Keyboard navigation between comments\n- Minimap showing comment distribution\n- Export with comment indicators\n\n## Technical Considerations\n\n### Anchor Resolution\n\nWhen feedback has an anchor, resolve the position using this priority:\n\n1. **Exact text match**: Search for `anchor.text_snippet` in document\n2. **Line number**: Fall back to `anchor.line_number` if text moved\n3. **Section heading**: Use `anchor.section_heading` as last resort\n4. **Mark as stale**: If none match, show in \"Stale Comments\" section\n\n### Performance\n\n- **Debounce position updates**: 100ms delay on scroll/resize\n- **Memoize calculations**: Use `useMemo` for filtered feedback lists\n- **Virtual scrolling**: If >50 comments, consider virtualization\n- **Lazy decorations**: Only create decorations for visible viewport\n\n### View Modes\n\nSupport both Formatted (Tiptap) and Markdown views:\n\n- **Formatted**: Use Tiptap marks and decorations\n- **Markdown**: Show indicators in line number gutter\n\n## Dependencies\n\n**No new dependencies required** - uses existing:\n- `@tiptap/react` (already installed)\n- `@tiptap/core` (already installed)\n- Native browser APIs (`getBoundingClientRect`, `IntersectionObserver`)\n- React hooks (`useState`, `useEffect`, `useRef`)\n\n**Optional lightweight additions** (if needed):\n- `floating-ui` (7kb) - For smarter popover positioning\n- `react-intersection-observer` (3.5kb) - For performance optimization\n\n## Success Metrics\n\n- Feedback is visually connected to document locations\n- Users can quickly identify which content has feedback\n- Position sync is smooth and performant (no jank on scroll)\n- Works in both Formatted and Markdown view modes\n- Mobile experience is usable (stacked or simplified layout)\n","priority":1,"archived":1,"archived_at":"2025-11-05T05:39:21.988Z","created_at":"2025-10-29 10:10:27","updated_at":"2025-11-05 05:39:21","parent_id":null,"parent_uuid":null,"relationships":[],"tags":["feedback","frontend","tiptap","ui/ux"]}
{"id":"SPEC-009","uuid":"8ef5d62f-6681-4207-a088-230caae2e884","title":"AG-UI Protocol Integration","file_path":"specs/ag_ui_protocol_integration.md","content":"# AG-UI Protocol Integration Specification\n\n## Overview\n\nThis specification details the integration of the AG-UI (Agent-User Interaction) Protocol into the sudocode execution system. AG-UI is a lightweight, event-based protocol that standardizes how AI agents connect to user-facing applications, enabling real-time streaming of agent execution state to frontend applications.\n\nThis spec builds on **SPEC-007 (Output Processing Layer)** which provides the foundation for parsing agent output into structured `StreamMessage` format. The AG-UI integration adds a second transformation layer that converts these generic messages into standardized AG-UI events.\n\n**Transformation Flow:**\n\n```\nRaw Agent Output → [SPEC-007] → StreamMessage → [SPEC-009] → AgUiEvent → SSE → Frontend\n                    OutputProcessor              AgUiAdapter\n```\n\nThe integration consists of three main layers:\n\n1. **AG-UI Adapter Layer**: Transforms `StreamMessage` (from SPEC-007) into standardized AG-UI events\n1. **SSE Transport Layer**: Streams AG-UI events to frontend via Server-Sent Events\n1. **Frontend Integration**: Consumes and displays AG-UI events in real-time\n\n## Design Goals\n\n1. **Standardized**: Use AG-UI's 17 event types for consistent agent communication\n1. **Real-time**: Stream events as they occur, not after completion\n1. **Multi-Agent Ready**: Support any AG-UI compatible agent (Claude Code, Cursor, etc.)\n1. **SSE-based**: Stream events via Server-Sent Events for simplicity and native browser support\n1. **Type-Safe**: Full TypeScript typing with Zod validation\n1. **Observable**: Complete visibility into agent execution lifecycle\n1. **Layered**: Clean separation between parsing (SPEC-007) and protocol transformation (SPEC-009)\n\n## Architecture\n\n```\n┌──────────────────────────────────────────────────────────────┐\n│                 Frontend (React)                             │\n├──────────────────────────────────────────────────────────────┤\n│                                                              │\n│  ┌────────────────────┐     ┌──────────────────────────┐   │\n│  │  useAgUiStream()   │────▶│  ExecutionMonitor        │   │\n│  │  Hook              │     │  Component               │   │\n│  └────────┬───────────┘     └──────────────────────────┘   │\n│           │                                                  │\n│           │ EventSource (SSE)                               │\n│           │                                                  │\n└───────────┼──────────────────────────────────────────────────┘\n            │\n            │ Server-Sent Events\n            ▼\n┌──────────────────────────────────────────────────────────────┐\n│            SSE Transport Layer (Server)                      │\n├──────────────────────────────────────────────────────────────┤\n│                                                              │\n│              ┌─────────────────────┐                        │\n│              │   SseTransport      │                        │\n│              │   (EventStream)     │                        │\n│              └─────────┬───────────┘                        │\n│                        │                                     │\n└────────────────────────┼────────────────────────────────────┘\n                         │\n                         │ AG-UI Events\n                         ▼\n┌──────────────────────────────────────────────────────────────┐\n│            AG-UI Adapter Layer (Server)                      │\n├──────────────────────────────────────────────────────────────┤\n│                                                              │\n│  ┌────────────────────────────────────────────────────────┐ │\n│  │         AgUiEventAdapter                               │ │\n│  │                                                        │ │\n│  │  Transforms StreamMessage → AgUiEvent                 │ │\n│  │                                                        │ │\n│  │  ┌──────────────┐  ┌──────────────┐  ┌─────────────┐ │ │\n│  │  │ Tool Call    │  │ Message      │  │ State       │ │ │\n│  │  │ Mapper       │  │ Mapper       │  │ Mapper      │ │ │\n│  │  └──────────────┘  └──────────────┘  └─────────────┘ │ │\n│  └────────────┬───────────────────────────────────────────┘ │\n│               │                                             │\n└───────────────┼─────────────────────────────────────────────┘\n                │\n                │ StreamMessage (SPEC-007)\n                ▼\n┌──────────────────────────────────────────────────────────────┐\n│     Output Processing Layer (SPEC-007)                       │\n├──────────────────────────────────────────────────────────────┤\n│                                                              │\n│  ┌────────────────────────────────────────────────────────┐ │\n│  │         StreamJsonProcessor                            │ │\n│  │                                                        │ │\n│  │  Parses Raw Output → StreamMessage                    │ │\n│  │                                                        │ │\n│  │  Types: assistant | tool_use | tool_result | error   │ │\n│  └────────────┬───────────────────────────────────────────┘ │\n│               │                                             │\n└───────────────┼─────────────────────────────────────────────┘\n                │\n                │ Raw stdout/stderr\n                ▼\n┌──────────────────────────────────────────────────────────────┐\n│     Process Layer (SPEC-003)                                 │\n├──────────────────────────────────────────────────────────────┤\n│  SimpleProcessManager │ LinearOrchestrator (SPEC-006)       │\n└──────────────────────────────────────────────────────────────┘\n```\n\n**Layer Responsibilities:**\n\n- **SPEC-003 (Process Layer)**: Spawns agent process, captures raw output\n- **SPEC-007 (Output Processing)**: Parses raw output into `StreamMessage` format\n- **SPEC-009 (AG-UI Adapter)**: Transforms `StreamMessage` into AG-UI events\n- **SSE Transport**: Broadcasts AG-UI events to connected clients\n- **Frontend**: Consumes and displays events in real-time\n\n## Part 1: AG-UI Adapter Layer\n\n### Core Types\n\n#### AG-UI Event Types Enum\n\n```typescript\nexport enum AgUiEventType {\n  // Lifecycle Events\n  RUN_STARTED = 'RUN_STARTED',\n  RUN_FINISHED = 'RUN_FINISHED',\n  RUN_ERROR = 'RUN_ERROR',\n  STEP_STARTED = 'STEP_STARTED',\n  STEP_FINISHED = 'STEP_FINISHED',\n\n  // Text Message Events\n  TEXT_MESSAGE_START = 'TEXT_MESSAGE_START',\n  TEXT_MESSAGE_CONTENT = 'TEXT_MESSAGE_CONTENT',\n  TEXT_MESSAGE_END = 'TEXT_MESSAGE_END',\n\n  // Tool Call Events\n  TOOL_CALL_START = 'TOOL_CALL_START',\n  TOOL_CALL_ARGS = 'TOOL_CALL_ARGS',\n  TOOL_CALL_END = 'TOOL_CALL_END',\n  TOOL_CALL_RESULT = 'TOOL_CALL_RESULT',\n\n  // State Management Events\n  STATE_SNAPSHOT = 'STATE_SNAPSHOT',\n  STATE_DELTA = 'STATE_DELTA',\n  MESSAGES_SNAPSHOT = 'MESSAGES_SNAPSHOT',\n\n  // Special Events\n  RAW = 'RAW',\n  CUSTOM = 'CUSTOM',\n}\n```\n\n#### Base Event Schema\n\n```typescript\nimport { z } from 'zod';\n\nexport const BaseEventSchema = z.object({\n  type: z.nativeEnum(AgUiEventType),\n  timestamp: z.number().optional(),\n  rawEvent: z.any().optional(),\n});\n\nexport type BaseEvent = z.infer<typeof BaseEventSchema>;\n```\n\n#### Lifecycle Event Schemas\n\n```typescript\n// RUN_STARTED\nexport const RunStartedEventSchema = BaseEventSchema.extend({\n  type: z.literal(AgUiEventType.RUN_STARTED),\n  runId: z.string(),\n  threadId: z.string().optional(),\n  workflowId: z.string().optional(),\n});\n\nexport type RunStartedEvent = z.infer<typeof RunStartedEventSchema>;\n\n// RUN_FINISHED\nexport const RunFinishedEventSchema = BaseEventSchema.extend({\n  type: z.literal(AgUiEventType.RUN_FINISHED),\n  runId: z.string(),\n  result: z.any().optional(),\n});\n\nexport type RunFinishedEvent = z.infer<typeof RunFinishedEventSchema>;\n\n// RUN_ERROR\nexport const RunErrorEventSchema = BaseEventSchema.extend({\n  type: z.literal(AgUiEventType.RUN_ERROR),\n  runId: z.string(),\n  error: z.object({\n    message: z.string(),\n    code: z.string().optional(),\n    stack: z.string().optional(),\n  }),\n});\n\nexport type RunErrorEvent = z.infer<typeof RunErrorEventSchema>;\n\n// STEP_STARTED\nexport const StepStartedEventSchema = BaseEventSchema.extend({\n  type: z.literal(AgUiEventType.STEP_STARTED),\n  runId: z.string(),\n  stepId: z.string(),\n  stepName: z.string(),\n});\n\nexport type StepStartedEvent = z.infer<typeof StepStartedEventSchema>;\n\n// STEP_FINISHED\nexport const StepFinishedEventSchema = BaseEventSchema.extend({\n  type: z.literal(AgUiEventType.STEP_FINISHED),\n  runId: z.string(),\n  stepId: z.string(),\n  status: z.enum(['success', 'error']),\n  output: z.any().optional(),\n});\n\nexport type StepFinishedEvent = z.infer<typeof StepFinishedEventSchema>;\n```\n\n#### Text Message Event Schemas\n\n```typescript\n// TEXT_MESSAGE_START\nexport const TextMessageStartEventSchema = BaseEventSchema.extend({\n  type: z.literal(AgUiEventType.TEXT_MESSAGE_START),\n  messageId: z.string(),\n  role: z.enum(['assistant', 'user', 'system']),\n});\n\nexport type TextMessageStartEvent = z.infer<typeof TextMessageStartEventSchema>;\n\n// TEXT_MESSAGE_CONTENT\nexport const TextMessageContentEventSchema = BaseEventSchema.extend({\n  type: z.literal(AgUiEventType.TEXT_MESSAGE_CONTENT),\n  messageId: z.string(),\n  delta: z.string(),\n});\n\nexport type TextMessageContentEvent = z.infer<typeof TextMessageContentEventSchema>;\n\n// TEXT_MESSAGE_END\nexport const TextMessageEndEventSchema = BaseEventSchema.extend({\n  type: z.literal(AgUiEventType.TEXT_MESSAGE_END),\n  messageId: z.string(),\n});\n\nexport type TextMessageEndEvent = z.infer<typeof TextMessageEndEventSchema>;\n```\n\n#### Tool Call Event Schemas\n\n```typescript\n// TOOL_CALL_START\nexport const ToolCallStartEventSchema = BaseEventSchema.extend({\n  type: z.literal(AgUiEventType.TOOL_CALL_START),\n  toolCallId: z.string(),\n  toolCallName: z.string(),\n  parentMessageId: z.string().optional(),\n});\n\nexport type ToolCallStartEvent = z.infer<typeof ToolCallStartEventSchema>;\n\n// TOOL_CALL_ARGS\nexport const ToolCallArgsEventSchema = BaseEventSchema.extend({\n  type: z.literal(AgUiEventType.TOOL_CALL_ARGS),\n  toolCallId: z.string(),\n  delta: z.string(), // JSON fragment\n});\n\nexport type ToolCallArgsEvent = z.infer<typeof ToolCallArgsEventSchema>;\n\n// TOOL_CALL_END\nexport const ToolCallEndEventSchema = BaseEventSchema.extend({\n  type: z.literal(AgUiEventType.TOOL_CALL_END),\n  toolCallId: z.string(),\n});\n\nexport type ToolCallEndEvent = z.infer<typeof ToolCallEndEventSchema>;\n\n// TOOL_CALL_RESULT\nexport const ToolCallResultEventSchema = BaseEventSchema.extend({\n  type: z.literal(AgUiEventType.TOOL_CALL_RESULT),\n  messageId: z.string(),\n  toolCallId: z.string(),\n  content: z.string(),\n  role: z.literal('tool').optional(),\n});\n\nexport type ToolCallResultEvent = z.infer<typeof ToolCallResultEventSchema>;\n```\n\n#### State Management Event Schemas\n\n```typescript\n// STATE_SNAPSHOT\nexport const StateSnapshotEventSchema = BaseEventSchema.extend({\n  type: z.literal(AgUiEventType.STATE_SNAPSHOT),\n  runId: z.string(),\n  state: z.record(z.any()),\n});\n\nexport type StateSnapshotEvent = z.infer<typeof StateSnapshotEventSchema>;\n\n// STATE_DELTA (JSON Patch RFC 6902)\nexport const JsonPatchOperationSchema = z.object({\n  op: z.enum(['add', 'remove', 'replace', 'move', 'copy', 'test']),\n  path: z.string(),\n  value: z.any().optional(),\n  from: z.string().optional(),\n});\n\nexport const StateDeltaEventSchema = BaseEventSchema.extend({\n  type: z.literal(AgUiEventType.STATE_DELTA),\n  runId: z.string(),\n  delta: z.array(JsonPatchOperationSchema),\n});\n\nexport type StateDeltaEvent = z.infer<typeof StateDeltaEventSchema>;\n\n// MESSAGES_SNAPSHOT\nexport const MessageSchema = z.object({\n  id: z.string(),\n  role: z.enum(['user', 'assistant', 'system', 'tool']),\n  content: z.string(),\n  timestamp: z.string().optional(),\n});\n\nexport const MessagesSnapshotEventSchema = BaseEventSchema.extend({\n  type: z.literal(AgUiEventType.MESSAGES_SNAPSHOT),\n  runId: z.string(),\n  messages: z.array(MessageSchema),\n});\n\nexport type MessagesSnapshotEvent = z.infer<typeof MessagesSnapshotEventSchema>;\n```\n\n#### Custom and Raw Event Schemas\n\n```typescript\n// RAW\nexport const RawEventSchema = BaseEventSchema.extend({\n  type: z.literal(AgUiEventType.RAW),\n  event: z.any(),\n  source: z.string().optional(),\n});\n\nexport type RawEvent = z.infer<typeof RawEventSchema>;\n\n// CUSTOM\nexport const CustomEventSchema = BaseEventSchema.extend({\n  type: z.literal(AgUiEventType.CUSTOM),\n  name: z.string(),\n  value: z.any(),\n});\n\nexport type CustomEvent = z.infer<typeof CustomEventSchema>;\n```\n\n#### Discriminated Union\n\n```typescript\nexport const AgUiEventSchema = z.discriminatedUnion('type', [\n  RunStartedEventSchema,\n  RunFinishedEventSchema,\n  RunErrorEventSchema,\n  StepStartedEventSchema,\n  StepFinishedEventSchema,\n  TextMessageStartEventSchema,\n  TextMessageContentEventSchema,\n  TextMessageEndEventSchema,\n  ToolCallStartEventSchema,\n  ToolCallArgsEventSchema,\n  ToolCallEndEventSchema,\n  ToolCallResultEventSchema,\n  StateSnapshotEventSchema,\n  StateDeltaEventSchema,\n  MessagesSnapshotEventSchema,\n  RawEventSchema,\n  CustomEventSchema,\n]);\n\nexport type AgUiEvent = z.infer<typeof AgUiEventSchema>;\n```\n\n### AG-UI Event Adapter Implementation\n\nThe `AgUiEventAdapter` is the core component that transforms `StreamMessage` objects (from SPEC-007's `OutputProcessor`) into AG-UI events. It subscribes to the output processor's event stream and maps each message type to the appropriate AG-UI event(s).\n\n**Key Principle**: This adapter is protocol-agnostic at its input (works with any `StreamMessage` source) and protocol-specific at its output (emits AG-UI events).\n\n```typescript\n// server/src/execution/output/ag-ui-adapter.ts\nimport { StreamMessage, ExecutionProgress } from './types.js';\nimport { AgUiEvent, AgUiEventType } from './ag-ui-types.js';\nimport { generateId } from '../utils.js';\n\nexport class AgUiEventAdapter {\n  private listeners: Array<(event: AgUiEvent) => void> = [];\n  private messageBuffers = new Map<string, string[]>();\n  private toolCallBuffers = new Map<string, string>();\n\n  constructor() {}\n\n  /**\n   * Transform a StreamMessage from Claude Code into AG-UI events\n   */\n  transformStreamMessage(\n    message: StreamMessage,\n    processId: string\n  ): AgUiEvent[] {\n    const events: AgUiEvent[] = [];\n\n    switch (message.type) {\n      case 'assistant':\n        events.push(...this.handleAssistantMessage(message, processId));\n        break;\n      case 'tool_use':\n        events.push(...this.handleToolUse(message, processId));\n        break;\n      case 'tool_result':\n        events.push(...this.handleToolResult(message, processId));\n        break;\n      case 'result':\n        events.push(...this.handleResult(message, processId));\n        break;\n      case 'error':\n        events.push(...this.handleError(message, processId));\n        break;\n    }\n\n    // Emit all events\n    events.forEach(event => this.emit(event));\n\n    return events;\n  }\n\n  /**\n   * Handle Claude assistant messages\n   */\n  private handleAssistantMessage(\n    message: StreamMessage,\n    processId: string\n  ): AgUiEvent[] {\n    const events: AgUiEvent[] = [];\n    const contents = Array.isArray(message.data.message?.content)\n      ? message.data.message.content\n      : [message.data.message?.content];\n\n    for (const content of contents) {\n      if (!content) continue;\n\n      if (content.type === 'text') {\n        // Text message: START → CONTENT → END\n        const messageId = generateId('msg');\n\n        events.push({\n          type: AgUiEventType.TEXT_MESSAGE_START,\n          messageId,\n          role: 'assistant',\n          timestamp: Date.now(),\n        });\n\n        events.push({\n          type: AgUiEventType.TEXT_MESSAGE_CONTENT,\n          messageId,\n          delta: content.text,\n          timestamp: Date.now(),\n        });\n\n        events.push({\n          type: AgUiEventType.TEXT_MESSAGE_END,\n          messageId,\n          timestamp: Date.now(),\n        });\n      } else if (content.type === 'tool_use') {\n        // Tool call: START → ARGS → END\n        const toolCallId = content.id || generateId('tool');\n\n        events.push({\n          type: AgUiEventType.TOOL_CALL_START,\n          toolCallId,\n          toolCallName: content.name,\n          timestamp: Date.now(),\n        });\n\n        // Serialize arguments as JSON\n        const argsJson = JSON.stringify(content.input);\n        events.push({\n          type: AgUiEventType.TOOL_CALL_ARGS,\n          toolCallId,\n          delta: argsJson,\n          timestamp: Date.now(),\n        });\n\n        events.push({\n          type: AgUiEventType.TOOL_CALL_END,\n          toolCallId,\n          timestamp: Date.now(),\n        });\n      }\n    }\n\n    return events;\n  }\n\n  /**\n   * Handle tool usage events\n   */\n  private handleToolUse(\n    message: StreamMessage,\n    processId: string\n  ): AgUiEvent[] {\n    const toolCallId = message.data.id || generateId('tool');\n\n    return [\n      {\n        type: AgUiEventType.TOOL_CALL_START,\n        toolCallId,\n        toolCallName: message.data.name,\n        timestamp: Date.now(),\n      },\n      {\n        type: AgUiEventType.TOOL_CALL_ARGS,\n        toolCallId,\n        delta: JSON.stringify(message.data.input),\n        timestamp: Date.now(),\n      },\n      {\n        type: AgUiEventType.TOOL_CALL_END,\n        toolCallId,\n        timestamp: Date.now(),\n      },\n    ];\n  }\n\n  /**\n   * Handle tool result events\n   */\n  private handleToolResult(\n    message: StreamMessage,\n    processId: string\n  ): AgUiEvent[] {\n    const messageId = generateId('msg');\n    const toolCallId = message.data.tool_use_id || message.data.id;\n\n    return [\n      {\n        type: AgUiEventType.TOOL_CALL_RESULT,\n        messageId,\n        toolCallId,\n        content: JSON.stringify(message.data.content),\n        role: 'tool',\n        timestamp: Date.now(),\n      },\n    ];\n  }\n\n  /**\n   * Handle execution result (final usage stats)\n   */\n  private handleResult(\n    message: StreamMessage,\n    processId: string\n  ): AgUiEvent[] {\n    // Could emit a CUSTOM event with usage stats\n    return [\n      {\n        type: AgUiEventType.CUSTOM,\n        name: 'usage_stats',\n        value: {\n          usage: message.data.usage,\n          cost: this.calculateCost(message.data.usage),\n        },\n        timestamp: Date.now(),\n      },\n    ];\n  }\n\n  /**\n   * Handle error events\n   */\n  private handleError(\n    message: StreamMessage,\n    processId: string\n  ): AgUiEvent[] {\n    const error = message.data.error || message.data;\n\n    return [\n      {\n        type: AgUiEventType.RUN_ERROR,\n        runId: processId,\n        error: {\n          message: error.message || error.toString(),\n          code: error.code,\n          stack: error.stack,\n        },\n        timestamp: Date.now(),\n      },\n    ];\n  }\n\n  /**\n   * Emit progress update as STATE_DELTA\n   */\n  emitProgressDelta(progress: ExecutionProgress): void {\n    const event: AgUiEvent = {\n      type: AgUiEventType.STATE_DELTA,\n      runId: progress.processId,\n      delta: [\n        {\n          op: 'replace',\n          path: '/progress',\n          value: {\n            toolCalls: progress.toolCalls.length,\n            filesChanged: progress.filesChanged,\n            currentActivity: progress.currentActivity,\n          },\n        },\n      ],\n      timestamp: Date.now(),\n    };\n\n    this.emit(event);\n  }\n\n  /**\n   * Emit state snapshot\n   */\n  emitStateSnapshot(runId: string, state: Record<string, any>): void {\n    const event: AgUiEvent = {\n      type: AgUiEventType.STATE_SNAPSHOT,\n      runId,\n      state,\n      timestamp: Date.now(),\n    };\n\n    this.emit(event);\n  }\n\n  /**\n   * Register event listener\n   */\n  onEvent(listener: (event: AgUiEvent) => void): void {\n    this.listeners.push(listener);\n  }\n\n  /**\n   * Remove event listener\n   */\n  offEvent(listener: (event: AgUiEvent) => void): void {\n    const index = this.listeners.indexOf(listener);\n    if (index >= 0) {\n      this.listeners.splice(index, 1);\n    }\n  }\n\n  /**\n   * Emit event to all listeners\n   */\n  private emit(event: AgUiEvent): void {\n    this.listeners.forEach(listener => {\n      try {\n        listener(event);\n      } catch (error) {\n        console.error('Error in AG-UI event listener:', error);\n      }\n    });\n  }\n\n  private calculateCost(usage: any): number {\n    // Simplified cost calculation\n    const inputCostPer1M = 3.0;\n    const outputCostPer1M = 15.0;\n\n    const inputCost = (usage.input_tokens / 1000000) * inputCostPer1M;\n    const outputCost = (usage.output_tokens / 1000000) * outputCostPer1M;\n\n    return inputCost + outputCost;\n  }\n}\n```\n\n### Integration with SPEC-007 Output Processor\n\nThe AgUiAdapter integrates with SPEC-007's `StreamJsonProcessor` by subscribing to its output messages. This creates a clean pipeline where SPEC-007 handles parsing and SPEC-009 handles protocol transformation.\n\n**Pattern**: Wire the output processor's message events to the AG-UI adapter's transformation method.\n\n```typescript\n// server/src/execution/output/ag-ui-integration.ts\nimport { StreamJsonProcessor } from './stream-json-processor.js';\nimport { AgUiEventAdapter } from './ag-ui-adapter.js';\n\n/**\n * Wire SPEC-007's output processor to SPEC-009's AG-UI adapter\n */\nexport function createAgUiPipeline(\n  processor: StreamJsonProcessor,\n  adapter: AgUiEventAdapter,\n  processId: string\n): void {\n  // Subscribe to processor's message stream\n  // Note: This requires adding a message event to StreamJsonProcessor\n  processor.onMessage?.((message: StreamMessage) => {\n    adapter.transformStreamMessage(message, processId);\n  });\n\n  // Alternative: If StreamJsonProcessor doesn't have onMessage,\n  // wrap its processLine method\n  const originalProcessLine = processor.processLine.bind(processor);\n  processor.processLine = (line: string) => {\n    const message = originalProcessLine(line);\n    if (message) {\n      adapter.transformStreamMessage(message, processId);\n    }\n    return message;\n  };\n}\n\n/**\n * Factory function to create a complete AG-UI pipeline\n */\nexport function createAgUiSystem(processId: string) {\n  const processor = new StreamJsonProcessor({\n    format: 'stream-json',\n    captureToolCalls: true,\n    captureFileChanges: true,\n    emitProgressEvents: true,\n  });\n\n  const adapter = new AgUiEventAdapter();\n\n  // Wire them together\n  createAgUiPipeline(processor, adapter, processId);\n\n  return { processor, adapter };\n}\n```\n\n**Usage Example:**\n\n```typescript\n// Create the pipeline\nconst { processor, adapter } = createAgUiSystem('process-123');\n\n// Connect adapter to SSE transport\nconst sseTransport = new SseTransport();\nadapter.onEvent(event => {\n  sseTransport.broadcastToRun('process-123', event);\n});\n\n// Feed raw output from process manager\nprocessManager.onOutput('process-123', (data, type) => {\n  if (type === 'stdout') {\n    const lines = data.toString().split('\\n');\n    for (const line of lines) {\n      processor.processLine(line); // → StreamMessage → AgUiEvent → SSE\n    }\n  }\n});\n```\n\n### Integration with LinearOrchestrator\n\n```typescript\n// server/src/execution/workflow/linear-orchestrator.ts (MODIFIED)\nimport { AgUiEventAdapter } from '../output/ag-ui-adapter.js';\nimport { AgUiEventType } from '../output/ag-ui-types.js';\n\nexport class LinearOrchestrator implements IWorkflowOrchestrator {\n  private agUiAdapter: AgUiEventAdapter;\n\n  constructor(\n    private executor: IResilientExecutor,\n    private storage?: IWorkflowStorage,\n    agUiAdapter?: AgUiEventAdapter\n  ) {\n    this.agUiAdapter = agUiAdapter || new AgUiEventAdapter();\n  }\n\n  async startWorkflow(\n    workflow: WorkflowDefinition,\n    initialContext?: Partial<WorkflowContext>\n  ): Promise<string> {\n    const execution = /* ... create execution ... */;\n\n    // Emit RUN_STARTED\n    this.agUiAdapter.onEvent({\n      type: AgUiEventType.RUN_STARTED,\n      runId: execution.id,\n      threadId: workflow.id,\n      workflowId: workflow.id,\n      timestamp: Date.now(),\n    });\n\n    this.executeWorkflow(workflow, execution).catch(error => {\n      // Emit RUN_ERROR\n      this.agUiAdapter.onEvent({\n        type: AgUiEventType.RUN_ERROR,\n        runId: execution.id,\n        error: {\n          message: error.message,\n          stack: error.stack,\n        },\n        timestamp: Date.now(),\n      });\n    });\n\n    return execution.id;\n  }\n\n  private async executeWorkflow(\n    workflow: WorkflowDefinition,\n    execution: WorkflowExecution,\n    startFromStep?: string\n  ): Promise<void> {\n    execution.status = 'running';\n\n    for (let i = startIndex; i < workflow.steps.length; i++) {\n      const step = workflow.steps[i];\n\n      // Emit STEP_STARTED\n      this.agUiAdapter.onEvent({\n        type: AgUiEventType.STEP_STARTED,\n        runId: execution.id,\n        stepId: step.id,\n        stepName: step.name,\n        timestamp: Date.now(),\n      });\n\n      try {\n        const result = await this.executeStep(step, execution, workflow);\n\n        // Emit STEP_FINISHED\n        this.agUiAdapter.onEvent({\n          type: AgUiEventType.STEP_FINISHED,\n          runId: execution.id,\n          stepId: step.id,\n          status: 'success',\n          output: result,\n          timestamp: Date.now(),\n        });\n\n        // ... existing checkpoint logic\n      } catch (error) {\n        // Emit STEP_FINISHED with error\n        this.agUiAdapter.onEvent({\n          type: AgUiEventType.STEP_FINISHED,\n          runId: execution.id,\n          stepId: step.id,\n          status: 'error',\n          timestamp: Date.now(),\n        });\n\n        throw error;\n      }\n    }\n\n    // Emit RUN_FINISHED\n    this.agUiAdapter.onEvent({\n      type: AgUiEventType.RUN_FINISHED,\n      runId: execution.id,\n      result: {\n        completedSteps: execution.completedSteps.length,\n        outputs: execution.context.outputs,\n      },\n      timestamp: Date.now(),\n    });\n  }\n\n  /**\n   * Get AG-UI adapter for transport layer\n   */\n  getAgUiAdapter(): AgUiEventAdapter {\n    return this.agUiAdapter;\n  }\n}\n```\n\n## Part 2: AG-UI Transport Layer\n\n### Server-Sent Events (SSE) Transport\n\n```typescript\n// server/src/execution/transport/sse-transport.ts\nimport { Response } from 'express';\nimport { AgUiEvent } from '../output/ag-ui-types.js';\n\nexport interface SseClient {\n  id: string;\n  response: Response;\n  runId?: string;\n  connectedAt: Date;\n}\n\nexport class SseTransport {\n  private clients = new Map<string, SseClient>();\n  private heartbeatInterval: NodeJS.Timeout | null = null;\n\n  constructor(\n    private heartbeatIntervalMs: number = 30000 // 30 seconds\n  ) {\n    this.startHeartbeat();\n  }\n\n  /**\n   * Handle new SSE connection\n   */\n  handleConnection(\n    clientId: string,\n    res: Response,\n    runId?: string\n  ): void {\n    // Set SSE headers\n    res.writeHead(200, {\n      'Content-Type': 'text/event-stream',\n      'Cache-Control': 'no-cache, no-transform',\n      'Connection': 'keep-alive',\n      'X-Accel-Buffering': 'no', // Disable nginx buffering\n    });\n\n    // Create client\n    const client: SseClient = {\n      id: clientId,\n      response: res,\n      runId,\n      connectedAt: new Date(),\n    };\n\n    this.clients.set(clientId, client);\n\n    // Handle client disconnect\n    res.on('close', () => {\n      this.removeClient(clientId);\n    });\n\n    // Send initial connection event\n    this.sendToClient(clientId, {\n      type: AgUiEventType.CUSTOM,\n      name: 'connection_established',\n      value: { clientId, runId },\n      timestamp: Date.now(),\n    });\n  }\n\n  /**\n   * Send event to specific client\n   */\n  sendToClient(clientId: string, event: AgUiEvent): boolean {\n    const client = this.clients.get(clientId);\n    if (!client) return false;\n\n    try {\n      const data = JSON.stringify(event);\n      client.response.write(`event: ${event.type}\\n`);\n      client.response.write(`data: ${data}\\n\\n`);\n      return true;\n    } catch (error) {\n      console.error(`Error sending event to client ${clientId}:`, error);\n      this.removeClient(clientId);\n      return false;\n    }\n  }\n\n  /**\n   * Broadcast event to all clients\n   */\n  broadcast(event: AgUiEvent): void {\n    this.clients.forEach((client, clientId) => {\n      this.sendToClient(clientId, event);\n    });\n  }\n\n  /**\n   * Broadcast event to clients subscribed to specific run\n   */\n  broadcastToRun(runId: string, event: AgUiEvent): void {\n    this.clients.forEach((client, clientId) => {\n      if (client.runId === runId) {\n        this.sendToClient(clientId, event);\n      }\n    });\n  }\n\n  /**\n   * Remove client\n   */\n  removeClient(clientId: string): void {\n    const client = this.clients.get(clientId);\n    if (client) {\n      try {\n        client.response.end();\n      } catch (error) {\n        // Ignore errors when ending response\n      }\n      this.clients.delete(clientId);\n    }\n  }\n\n  /**\n   * Start heartbeat to keep connections alive\n   */\n  private startHeartbeat(): void {\n    this.heartbeatInterval = setInterval(() => {\n      this.clients.forEach((client, clientId) => {\n        try {\n          client.response.write(': heartbeat\\n\\n');\n        } catch (error) {\n          this.removeClient(clientId);\n        }\n      });\n    }, this.heartbeatIntervalMs);\n  }\n\n  /**\n   * Stop heartbeat\n   */\n  stopHeartbeat(): void {\n    if (this.heartbeatInterval) {\n      clearInterval(this.heartbeatInterval);\n      this.heartbeatInterval = null;\n    }\n  }\n\n  /**\n   * Get active client count\n   */\n  getClientCount(): number {\n    return this.clients.size;\n  }\n\n  /**\n   * Cleanup all clients\n   */\n  shutdown(): void {\n    this.stopHeartbeat();\n    this.clients.forEach((client, clientId) => {\n      this.removeClient(clientId);\n    });\n  }\n}\n```\n\n### Transport Manager\n\nSimplified transport manager that coordinates SSE transport with AG-UI adapter.\n\n```typescript\n// server/src/execution/transport/transport-manager.ts\nimport { AgUiEvent } from '../output/ag-ui-types.js';\nimport { AgUiEventAdapter } from '../output/ag-ui-adapter.js';\nimport { SseTransport } from './sse-transport.js';\n\nexport class TransportManager {\n  private sseTransport: SseTransport;\n\n  constructor() {\n    this.sseTransport = new SseTransport();\n  }\n\n  /**\n   * Connect AG-UI adapter to SSE transport\n   */\n  connectAdapter(adapter: AgUiEventAdapter, runId?: string): void {\n    adapter.onEvent((event: AgUiEvent) => {\n      if (runId) {\n        this.broadcastToRun(runId, event);\n      } else {\n        this.broadcast(event);\n      }\n    });\n  }\n\n  /**\n   * Broadcast event to all clients\n   */\n  broadcast(event: AgUiEvent): void {\n    this.sseTransport.broadcast(event);\n  }\n\n  /**\n   * Broadcast to specific run\n   */\n  broadcastToRun(runId: string, event: AgUiEvent): void {\n    this.sseTransport.broadcastToRun(runId, event);\n  }\n\n  /**\n   * Get SSE transport\n   */\n  getSseTransport(): SseTransport {\n    return this.sseTransport;\n  }\n\n  /**\n   * Cleanup\n   */\n  shutdown(): void {\n    this.sseTransport.shutdown();\n  }\n}\n```\n\n### API Routes\n\n```typescript\n// server/src/routes/executions-stream.ts\nimport { Router, Request, Response } from 'express';\nimport { TransportManager } from '../execution/transport/transport-manager.js';\nimport { generateId } from '../execution/utils.js';\n\nexport function createExecutionStreamRoutes(\n  transportManager: TransportManager\n): Router {\n  const router = Router();\n\n  /**\n   * SSE endpoint for execution streaming\n   * GET /api/executions/:executionId/stream\n   */\n  router.get('/:executionId/stream', (req: Request, res: Response) => {\n    const { executionId } = req.params;\n    const clientId = generateId('client');\n\n    // TODO: Add authentication/authorization\n\n    const sseTransport = transportManager.getSseTransport();\n    sseTransport.handleConnection(clientId, res, executionId);\n  });\n\n  return router;\n}\n```\n\n## Part 3: Frontend Integration\n\n### React Hook for AG-UI Streaming\n\n```typescript\n// frontend/src/hooks/useAgUiStream.ts\nimport { useEffect, useState, useRef, useCallback } from 'react';\nimport { AgUiEvent, AgUiEventType } from '../types/ag-ui';\n\nexport interface AgUiStreamState {\n  status: 'connecting' | 'connected' | 'disconnected' | 'error';\n  events: AgUiEvent[];\n  messages: Array<{\n    id: string;\n    role: string;\n    content: string;\n  }>;\n  toolCalls: Array<{\n    id: string;\n    name: string;\n    args: any;\n    result?: any;\n    status: 'running' | 'completed' | 'error';\n  }>;\n  currentStep?: {\n    id: string;\n    name: string;\n  };\n  progress?: {\n    toolCalls: number;\n    filesChanged: string[];\n    currentActivity?: string;\n  };\n  error?: string;\n}\n\nexport interface UseAgUiStreamOptions {\n  executionId: string;\n  onEvent?: (event: AgUiEvent) => void;\n  onError?: (error: Error) => void;\n}\n\nexport function useAgUiStream(options: UseAgUiStreamOptions) {\n  const { executionId, onEvent, onError } = options;\n\n  const [state, setState] = useState<AgUiStreamState>({\n    status: 'connecting',\n    events: [],\n    messages: [],\n    toolCalls: [],\n  });\n\n  const eventSourceRef = useRef<EventSource | null>(null);\n  const messageBuffers = useRef<Map<string, string[]>>(new Map());\n  const toolCallBuffers = useRef<Map<string, string>>(new Map());\n\n  const handleEvent = useCallback((event: AgUiEvent) => {\n    // Call custom handler\n    onEvent?.(event);\n\n    // Update state based on event type\n    setState(prev => {\n      const newState = { ...prev };\n      newState.events = [...prev.events, event];\n\n      switch (event.type) {\n        case AgUiEventType.TEXT_MESSAGE_START:\n          messageBuffers.current.set(event.messageId, []);\n          break;\n\n        case AgUiEventType.TEXT_MESSAGE_CONTENT:\n          const buffer = messageBuffers.current.get(event.messageId) || [];\n          buffer.push(event.delta);\n          messageBuffers.current.set(event.messageId, buffer);\n          break;\n\n        case AgUiEventType.TEXT_MESSAGE_END:\n          const content = messageBuffers.current.get(event.messageId)?.join('') || '';\n          newState.messages = [\n            ...prev.messages,\n            {\n              id: event.messageId,\n              role: 'assistant',\n              content,\n            },\n          ];\n          messageBuffers.current.delete(event.messageId);\n          break;\n\n        case AgUiEventType.TOOL_CALL_START:\n          newState.toolCalls = [\n            ...prev.toolCalls,\n            {\n              id: event.toolCallId,\n              name: event.toolCallName,\n              args: null,\n              status: 'running',\n            },\n          ];\n          toolCallBuffers.current.set(event.toolCallId, '');\n          break;\n\n        case AgUiEventType.TOOL_CALL_ARGS:\n          const argBuffer = toolCallBuffers.current.get(event.toolCallId) || '';\n          toolCallBuffers.current.set(event.toolCallId, argBuffer + event.delta);\n          break;\n\n        case AgUiEventType.TOOL_CALL_END:\n          const argsJson = toolCallBuffers.current.get(event.toolCallId) || '{}';\n          newState.toolCalls = prev.toolCalls.map(tc =>\n            tc.id === event.toolCallId\n              ? { ...tc, args: JSON.parse(argsJson) }\n              : tc\n          );\n          toolCallBuffers.current.delete(event.toolCallId);\n          break;\n\n        case AgUiEventType.TOOL_CALL_RESULT:\n          newState.toolCalls = prev.toolCalls.map(tc =>\n            tc.id === event.toolCallId\n              ? { ...tc, result: event.content, status: 'completed' }\n              : tc\n          );\n          break;\n\n        case AgUiEventType.STEP_STARTED:\n          newState.currentStep = {\n            id: event.stepId,\n            name: event.stepName,\n          };\n          break;\n\n        case AgUiEventType.STEP_FINISHED:\n          if (prev.currentStep?.id === event.stepId) {\n            newState.currentStep = undefined;\n          }\n          break;\n\n        case AgUiEventType.STATE_DELTA:\n          // Apply JSON Patch to progress\n          event.delta.forEach(patch => {\n            if (patch.path === '/progress') {\n              newState.progress = patch.value;\n            }\n          });\n          break;\n\n        case AgUiEventType.RUN_ERROR:\n          newState.error = event.error.message;\n          break;\n      }\n\n      return newState;\n    });\n  }, [onEvent]);\n\n  useEffect(() => {\n    // Use Server-Sent Events for real-time streaming\n    const eventSource = new EventSource(\n      `/api/executions/${executionId}/stream`\n    );\n\n    eventSourceRef.current = eventSource;\n\n    eventSource.onopen = () => {\n      setState(prev => ({ ...prev, status: 'connected' }));\n    };\n\n    // Listen to all AG-UI event types\n    Object.values(AgUiEventType).forEach(eventType => {\n      eventSource.addEventListener(eventType, (e: MessageEvent) => {\n        try {\n          const event: AgUiEvent = JSON.parse(e.data);\n          handleEvent(event);\n        } catch (error) {\n          console.error('Error parsing AG-UI event:', error);\n        }\n      });\n    });\n\n    eventSource.onerror = (error) => {\n      setState(prev => ({\n        ...prev,\n        status: 'error',\n        error: 'Connection lost',\n      }));\n      onError?.(new Error('EventSource error'));\n      eventSource.close();\n    };\n\n    return () => {\n      eventSource.close();\n    };\n  }, [executionId, handleEvent, onError]);\n\n  return state;\n}\n```\n\n### Execution Monitor Component\n\n```typescript\n// frontend/src/components/executions/ExecutionMonitor.tsx\nimport React from 'react';\nimport { useAgUiStream } from '../../hooks/useAgUiStream';\nimport { MessageStream } from './MessageStream';\nimport { ToolCallViewer } from './ToolCallViewer';\nimport { ProgressIndicator } from './ProgressIndicator';\n\nexport interface ExecutionMonitorProps {\n  executionId: string;\n  onComplete?: () => void;\n}\n\nexport const ExecutionMonitor: React.FC<ExecutionMonitorProps> = ({\n  executionId,\n  onComplete,\n}) => {\n  const stream = useAgUiStream({\n    executionId,\n    onEvent: (event) => {\n      if (event.type === 'RUN_FINISHED' && onComplete) {\n        onComplete();\n      }\n    },\n  });\n\n  return (\n    <div className=\"execution-monitor\">\n      <div className=\"execution-header\">\n        <h2>Execution: {executionId}</h2>\n        <div className=\"status-badge\" data-status={stream.status}>\n          {stream.status}\n        </div>\n      </div>\n\n      {stream.error && (\n        <div className=\"error-banner\">\n          <strong>Error:</strong> {stream.error}\n        </div>\n      )}\n\n      {stream.currentStep && (\n        <div className=\"current-step\">\n          <strong>Current Step:</strong> {stream.currentStep.name}\n        </div>\n      )}\n\n      {stream.progress && (\n        <ProgressIndicator progress={stream.progress} />\n      )}\n\n      <div className=\"execution-content\">\n        <div className=\"messages-section\">\n          <h3>Messages</h3>\n          <MessageStream messages={stream.messages} />\n        </div>\n\n        <div className=\"tool-calls-section\">\n          <h3>Tool Calls ({stream.toolCalls.length})</h3>\n          <ToolCallViewer toolCalls={stream.toolCalls} />\n        </div>\n      </div>\n    </div>\n  );\n};\n```\n\n### Tool Call Viewer Component\n\n```typescript\n// frontend/src/components/executions/ToolCallViewer.tsx\nimport React, { useState } from 'react';\n\nexport interface ToolCall {\n  id: string;\n  name: string;\n  args: any;\n  result?: any;\n  status: 'running' | 'completed' | 'error';\n}\n\nexport interface ToolCallViewerProps {\n  toolCalls: ToolCall[];\n}\n\nexport const ToolCallViewer: React.FC<ToolCallViewerProps> = ({ toolCalls }) => {\n  const [expandedIds, setExpandedIds] = useState<Set<string>>(new Set());\n\n  const toggleExpand = (id: string) => {\n    setExpandedIds(prev => {\n      const next = new Set(prev);\n      if (next.has(id)) {\n        next.delete(id);\n      } else {\n        next.add(id);\n      }\n      return next;\n    });\n  };\n\n  return (\n    <div className=\"tool-call-viewer\">\n      {toolCalls.length === 0 && (\n        <div className=\"empty-state\">No tool calls yet</div>\n      )}\n\n      {toolCalls.map(toolCall => (\n        <div\n          key={toolCall.id}\n          className=\"tool-call-item\"\n          data-status={toolCall.status}\n        >\n          <div\n            className=\"tool-call-header\"\n            onClick={() => toggleExpand(toolCall.id)}\n          >\n            <span className=\"tool-name\">{toolCall.name}</span>\n            <span className=\"tool-status\">{toolCall.status}</span>\n          </div>\n\n          {expandedIds.has(toolCall.id) && (\n            <div className=\"tool-call-details\">\n              {toolCall.args && (\n                <div className=\"tool-args\">\n                  <strong>Arguments:</strong>\n                  <pre>{JSON.stringify(toolCall.args, null, 2)}</pre>\n                </div>\n              )}\n\n              {toolCall.result && (\n                <div className=\"tool-result\">\n                  <strong>Result:</strong>\n                  <pre>{JSON.stringify(toolCall.result, null, 2)}</pre>\n                </div>\n              )}\n            </div>\n          )}\n        </div>\n      ))}\n    </div>\n  );\n};\n```\n\n### Message Stream Component\n\n```typescript\n// frontend/src/components/executions/MessageStream.tsx\nimport React, { useEffect, useRef } from 'react';\n\nexport interface Message {\n  id: string;\n  role: string;\n  content: string;\n}\n\nexport interface MessageStreamProps {\n  messages: Message[];\n  autoScroll?: boolean;\n}\n\nexport const MessageStream: React.FC<MessageStreamProps> = ({\n  messages,\n  autoScroll = true,\n}) => {\n  const containerRef = useRef<HTMLDivElement>(null);\n\n  useEffect(() => {\n    if (autoScroll && containerRef.current) {\n      containerRef.current.scrollTop = containerRef.current.scrollHeight;\n    }\n  }, [messages, autoScroll]);\n\n  return (\n    <div ref={containerRef} className=\"message-stream\">\n      {messages.length === 0 && (\n        <div className=\"empty-state\">No messages yet</div>\n      )}\n\n      {messages.map(message => (\n        <div key={message.id} className=\"message\" data-role={message.role}>\n          <div className=\"message-role\">{message.role}</div>\n          <div className=\"message-content\">\n            <pre>{message.content}</pre>\n          </div>\n        </div>\n      ))}\n    </div>\n  );\n};\n```\n\n### Progress Indicator Component\n\n```typescript\n// frontend/src/components/executions/ProgressIndicator.tsx\nimport React from 'react';\n\nexport interface Progress {\n  toolCalls: number;\n  filesChanged: string[];\n  currentActivity?: string;\n}\n\nexport interface ProgressIndicatorProps {\n  progress: Progress;\n}\n\nexport const ProgressIndicator: React.FC<ProgressIndicatorProps> = ({\n  progress,\n}) => {\n  return (\n    <div className=\"progress-indicator\">\n      {progress.currentActivity && (\n        <div className=\"current-activity\">\n          <span className=\"activity-icon\">⚙️</span>\n          <span className=\"activity-text\">{progress.currentActivity}</span>\n        </div>\n      )}\n\n      <div className=\"progress-stats\">\n        <div className=\"stat\">\n          <strong>Tool Calls:</strong> {progress.toolCalls}\n        </div>\n        <div className=\"stat\">\n          <strong>Files Changed:</strong> {progress.filesChanged.length}\n        </div>\n      </div>\n\n      {progress.filesChanged.length > 0 && (\n        <div className=\"files-changed\">\n          <strong>Modified Files:</strong>\n          <ul>\n            {progress.filesChanged.map((file, index) => (\n              <li key={index}>{file}</li>\n            ))}\n          </ul>\n        </div>\n      )}\n    </div>\n  );\n};\n```\n\n## Testing Strategy\n\n### Unit Tests\n\n```typescript\n// server/src/execution/output/ag-ui-adapter.test.ts\ndescribe('AgUiEventAdapter', () => {\n  it('should transform Claude assistant message to AG-UI events', () => {\n    const adapter = new AgUiEventAdapter();\n    const events: AgUiEvent[] = [];\n\n    adapter.onEvent(event => events.push(event));\n\n    const message: StreamMessage = {\n      type: 'assistant',\n      data: {\n        type: 'assistant',\n        message: {\n          content: [\n            { type: 'text', text: 'Hello world' }\n          ]\n        }\n      },\n      timestamp: new Date(),\n      raw: ''\n    };\n\n    adapter.transformStreamMessage(message, 'process-1');\n\n    expect(events.length).toBe(3);\n    expect(events[0].type).toBe(AgUiEventType.TEXT_MESSAGE_START);\n    expect(events[1].type).toBe(AgUiEventType.TEXT_MESSAGE_CONTENT);\n    expect(events[2].type).toBe(AgUiEventType.TEXT_MESSAGE_END);\n  });\n\n  it('should transform tool use to AG-UI tool call events', () => {\n    const adapter = new AgUiEventAdapter();\n    const events: AgUiEvent[] = [];\n\n    adapter.onEvent(event => events.push(event));\n\n    const message: StreamMessage = {\n      type: 'assistant',\n      data: {\n        type: 'assistant',\n        message: {\n          content: [\n            {\n              type: 'tool_use',\n              id: 'tool-123',\n              name: 'Read',\n              input: { file_path: '/path/to/file.ts' }\n            }\n          ]\n        }\n      },\n      timestamp: new Date(),\n      raw: ''\n    };\n\n    adapter.transformStreamMessage(message, 'process-1');\n\n    expect(events[0].type).toBe(AgUiEventType.TOOL_CALL_START);\n    expect(events[1].type).toBe(AgUiEventType.TOOL_CALL_ARGS);\n    expect(events[2].type).toBe(AgUiEventType.TOOL_CALL_END);\n  });\n});\n```\n\n### Integration Tests\n\n```typescript\n// server/src/execution/transport/sse-transport.test.ts\ndescribe('SseTransport', () => {\n  it('should send events to connected clients', (done) => {\n    const transport = new SseTransport();\n    const mockRes = {\n      writeHead: jest.fn(),\n      write: jest.fn(),\n      on: jest.fn(),\n    };\n\n    transport.handleConnection('client-1', mockRes as any);\n\n    const event: AgUiEvent = {\n      type: AgUiEventType.TEXT_MESSAGE_START,\n      messageId: 'msg-1',\n      role: 'assistant',\n      timestamp: Date.now(),\n    };\n\n    transport.sendToClient('client-1', event);\n\n    expect(mockRes.write).toHaveBeenCalledWith(\n      expect.stringContaining('TEXT_MESSAGE_START')\n    );\n\n    done();\n  });\n});\n```\n\n### E2E Tests\n\n```typescript\n// frontend/src/hooks/useAgUiStream.test.tsx\ndescribe('useAgUiStream', () => {\n  it('should receive and process AG-UI events', async () => {\n    const { result } = renderHook(() =>\n      useAgUiStream({ executionId: 'exec-1' })\n    );\n\n    // Wait for connection\n    await waitFor(() => {\n      expect(result.current.status).toBe('connected');\n    });\n\n    // Simulate events (mock EventSource)\n    // ...\n\n    await waitFor(() => {\n      expect(result.current.messages.length).toBeGreaterThan(0);\n    });\n  });\n});\n```\n\n## File Structure\n\n```\nserver/src/execution/\n├── output/\n│   ├── types.ts                    # SPEC-007: StreamMessage, ExecutionProgress types\n│   ├── processor.ts                # SPEC-007: IOutputProcessor interface\n│   ├── stream-json-processor.ts    # SPEC-007: Parses raw output → StreamMessage\n│   ├── ag-ui-types.ts              # SPEC-009: AG-UI event schemas (300 lines)\n│   ├── ag-ui-adapter.ts            # SPEC-009: StreamMessage → AgUiEvent (400 lines)\n│   └── ag-ui-integration.ts        # SPEC-009: Wire SPEC-007 to SPEC-009 (100 lines)\n├── transport/\n│   ├── sse-transport.ts            # SSE transport (200 lines)\n│   └── transport-manager.ts        # SSE coordinator (100 lines)\n├── workflow/\n│   └── linear-orchestrator.ts      # Modified to emit lifecycle events\n└── routes/\n    └── executions-stream.ts        # SSE endpoint (100 lines)\n\nfrontend/src/\n├── types/\n│   └── ag-ui.ts                    # Frontend AG-UI types (100 lines)\n├── hooks/\n│   └── useAgUiStream.ts            # React hook for SSE streaming (150 lines)\n└── components/executions/\n    ├── ExecutionMonitor.tsx        # Main dashboard (250 lines)\n    ├── ToolCallViewer.tsx          # Tool call display (150 lines)\n    ├── MessageStream.tsx           # Message streaming (150 lines)\n    └── ProgressIndicator.tsx       # Progress display (100 lines)\n\n.sudocode/specs/\n├── output_processing_layer_real_time_parsing.md  # SPEC-007\n└── ag_ui_protocol_integration.md                 # SPEC-009 (this spec)\n```\n\n**Key Files:**\n\n- **SPEC-007 Foundation** (`output/` dir): Parses agent output into `StreamMessage`\n- **SPEC-009 Protocol** (`ag-ui-*.ts`): Transforms `StreamMessage` into AG-UI events\n- **Integration** (`ag-ui-integration.ts`): Wires SPEC-007 → SPEC-009\n- **Transport** (`sse-transport.ts`): Streams AG-UI events to frontend via SSE\n\n## Implementation Checklist\n\n### Backend\n\n- Define AG-UI event types and Zod schemas\n- Implement AG-UI event adapter\n- Integrate adapter with StreamJsonProcessor\n- Integrate adapter with LinearOrchestrator\n- Implement SSE transport\n- Implement WebSocket transport\n- Create transport manager\n- Add SSE API endpoint\n- Add WebSocket endpoint\n- Write unit tests for adapter\n- Write integration tests for transports\n\n### Frontend\n\n- Define AG-UI types for frontend\n- Implement useAgUiStream hook\n- Create ExecutionMonitor component\n- Create ToolCallViewer component\n- Create MessageStream component\n- Create ProgressIndicator component\n- Add styling for components\n- Write unit tests for hook\n- Write E2E tests for components\n\n### Documentation\n\n- Write specification document\n- Add usage examples\n- Create API documentation\n- Update README with AG-UI integration\n\n## Usage Example\n\n### Backend Integration\n\n```typescript\n// server/src/index.ts\nimport { TransportManager } from './execution/transport/transport-manager.js';\nimport { AgUiEventAdapter } from './execution/output/ag-ui-adapter.js';\nimport { LinearOrchestrator } from './execution/workflow/linear-orchestrator.js';\n\n// Create transport manager\nconst transportManager = new TransportManager();\n\n// Create AG-UI adapter\nconst agUiAdapter = new AgUiEventAdapter();\n\n// Connect adapter to transports\ntransportManager.connectAdapter(agUiAdapter);\n\n// Create orchestrator with AG-UI support\nconst orchestrator = new LinearOrchestrator(\n  executor,\n  storage,\n  agUiAdapter\n);\n\n// Start workflow - events automatically stream to frontend\nconst executionId = await orchestrator.startWorkflow(workflow);\n```\n\n### Frontend Integration\n\n```typescript\n// App.tsx\nimport { ExecutionMonitor } from './components/executions/ExecutionMonitor';\n\nfunction App() {\n  const [executionId, setExecutionId] = useState<string | null>(null);\n\n  return (\n    <div>\n      {executionId && (\n        <ExecutionMonitor\n          executionId={executionId}\n          onComplete={() => console.log('Execution completed!')}\n        />\n      )}\n    </div>\n  );\n}\n```\n\n## Related Specs\n\n- [[SPEC-003]] - Process Layer (provides output streaming)\n- [[SPEC-004]] - Engine Layer (task execution)\n- [[SPEC-005]] - Task Execution Layer (resilience)\n- [[SPEC-006]] - Workflow Layer (orchestration, integrates lifecycle events)\n- [[SPEC-007]] - Output Processing Layer (provides StreamJsonProcessor)\n","priority":2,"archived":0,"archived_at":null,"created_at":"2025-10-30 08:17:27","updated_at":"2025-11-03T03:10:12.588Z","parent_id":null,"parent_uuid":null,"relationships":[{"from":"SPEC-009","from_type":"spec","to":"SPEC-003","to_type":"spec","type":"references"},{"from":"SPEC-009","from_type":"spec","to":"SPEC-004","to_type":"spec","type":"references"},{"from":"SPEC-009","from_type":"spec","to":"SPEC-006","to_type":"spec","type":"references"},{"from":"SPEC-009","from_type":"spec","to":"SPEC-007","to_type":"spec","type":"references"}],"tags":[]}
{"id":"SPEC-010","uuid":"ba3bb9ff-d3a2-403a-ac5c-8addf7064fb0","title":"Worktree Management Design","file_path":"specs/worktree_management_design.md","content":"# Worktree Management Design\n\n## Overview\n\nThis spec describes the design for managing git worktrees to isolate Claude Code execution sessions in sudocode. The design is informed by analysis of reference implementations:\n\n- **vibe-kanban**: Comprehensive worktree management with robust cleanup and state tracking\n- **CodeMachine-CLI**: No worktree management (not applicable)\n\n## Motivation\n\nCurrently, sudocode runs Claude Code sessions in the main working directory. To support:\n\n1. **Concurrent sessions** - Run multiple Claude Code sessions simultaneously without conflicts\n1. **Issue isolation** - Each issue gets its own isolated git environment\n1. **Branch management** - Automatically manage branches per issue/session\n1. **Cleanup** - Reliable cleanup of session artifacts\n\nWe need to implement git worktree management.\n\n## Architecture\n\n### Layer Structure\n\nBuilding on sudocode's existing execution architecture:\n\n```\n┌─────────────────────────────────────┐\n│   Workflow Layer                     │\n│   - orchestrates multi-step flows   │\n└──────────────┬──────────────────────┘\n               │\n┌──────────────▼──────────────────────┐\n│   Engine Layer                       │\n│   - manages task queue & lifecycle  │\n└──────────────┬──────────────────────┘\n               │\n┌──────────────▼──────────────────────┐\n│   Resilience Layer                   │\n│   - retry & circuit breaker logic   │\n└──────────────┬──────────────────────┘\n               │\n┌──────────────▼──────────────────────┐\n│   Process Layer                      │\n│   - spawns/manages processes        │\n└──────────────┬──────────────────────┘\n               │\n      ┌────────▼────────┐\n      │  Worktree Layer │  ← NEW\n      │  - git isolation│\n      └─────────────────┘\n```\n\n### Core Components\n\n#### 1\\. WorktreeManager\n\n**Location**: `server/src/execution/worktree/manager.ts`\n\n**Responsibilities**:\n\n- Create git worktrees for sessions\n- Ensure worktree existence (recreate if needed)\n- Cleanup worktrees and git metadata\n- Handle race conditions with locking\n- Prune orphaned worktree metadata\n- Read and apply configuration from `.sudocode/config.json`\n\n**Key Methods**:\n\n```typescript\ninterface IWorktreeManager {\n  /**\n   * Create a new worktree for a session\n   * @param repoPath - Path to the main git repository\n   * @param branchName - Branch name for the worktree\n   * @param worktreePath - Where to create the worktree\n   * @param baseBranch - Branch to base the new branch on\n   * @param createBranch - Whether to create the branch\n   */\n  createWorktree(\n    repoPath: string,\n    branchName: string,\n    worktreePath: string,\n    baseBranch: string,\n    createBranch: boolean\n  ): Promise<void>;\n\n  /**\n   * Ensure worktree exists, recreating if necessary\n   * Uses locking to prevent race conditions\n   */\n  ensureWorktreeExists(\n    repoPath: string,\n    branchName: string,\n    worktreePath: string\n  ): Promise<void>;\n\n  /**\n   * Clean up a worktree (filesystem + git metadata)\n   */\n  cleanupWorktree(\n    worktreePath: string,\n    repoPath?: string\n  ): Promise<void>;\n\n  /**\n   * Check if worktree is properly set up\n   */\n  isWorktreeValid(\n    repoPath: string,\n    worktreePath: string\n  ): Promise<boolean>;\n}\n```\n\n**Implementation Notes** (from vibe-kanban):\n\n- Use **git CLI** (not libgit2/nodegit) for reliability\n- Implement **per-path locking** to prevent concurrent creation conflicts\n- **Comprehensive cleanup**: Remove both filesystem and `.git/worktrees/<name>` metadata\n- **Retry logic**: If creation fails due to metadata conflicts, cleanup and retry\n- **Validation**: Check both filesystem existence AND git metadata registration\n- **Configuration**: Load settings from `.sudocode/config.json` on initialization\n\n#### 2\\. Session Model Extension\n\n**Location**: Database schema + models\n\n**New Fields**:\n\n```typescript\ninterface Session {\n  id: string;\n  issueId: string;\n\n  // NEW: Worktree tracking\n  worktreePath: string | null;        // Path to the worktree\n  branchName: string;                  // Git branch for this session\n  targetBranch: string;                // Base/target branch (e.g., 'main')\n  worktreeDeleted: boolean;            // Cleanup flag\n\n  // Existing fields...\n  status: SessionStatus;\n  createdAt: Date;\n  updatedAt: Date;\n}\n```\n\n**Database Migration**:\n\n```sql\n-- Add worktree fields to sessions table\nALTER TABLE sessions ADD COLUMN worktree_path TEXT;\nALTER TABLE sessions ADD COLUMN branch_name TEXT NOT NULL;\nALTER TABLE sessions ADD COLUMN target_branch TEXT NOT NULL;\nALTER TABLE sessions ADD COLUMN worktree_deleted BOOLEAN NOT NULL DEFAULT FALSE;\n\n-- Index for cleanup queries\nCREATE INDEX idx_sessions_worktree_deleted ON sessions(worktree_deleted);\n```\n\n#### 3\\. Git CLI Wrapper\n\n**Location**: `server/src/execution/worktree/git-cli.ts`\n\n**Purpose**: Wrap git commands for worktree operations\n\n```typescript\ninterface IGitCli {\n  /**\n   * Add a new worktree\n   * Equivalent to: git worktree add <path> <branch>\n   */\n  worktreeAdd(\n    repoPath: string,\n    worktreePath: string,\n    branch: string,\n    force?: boolean\n  ): Promise<void>;\n\n  /**\n   * Remove a worktree\n   * Equivalent to: git worktree remove <path> --force\n   */\n  worktreeRemove(\n    repoPath: string,\n    worktreePath: string,\n    force?: boolean\n  ): Promise<void>;\n\n  /**\n   * Prune worktree metadata\n   * Equivalent to: git worktree prune\n   */\n  worktreePrune(repoPath: string): Promise<void>;\n\n  /**\n   * List all worktrees\n   * Equivalent to: git worktree list\n   */\n  worktreeList(repoPath: string): Promise<WorktreeInfo[]>;\n\n  /**\n   * Create a branch\n   * Equivalent to: git branch <name> <base>\n   */\n  createBranch(\n    repoPath: string,\n    branchName: string,\n    baseBranch: string\n  ): Promise<void>;\n}\n```\n\n**Implementation**:\n\n- Use `child_process.exec` or `execa` for git commands\n- Proper error handling and output parsing\n- Shell command construction with proper escaping\n- Support for sparse-checkout if configured\n\n#### 4\\. ProcessConfig Extension\n\n**Location**: `server/src/execution/process/types.ts`\n\n**Extension**:\n\n```typescript\nexport interface ProcessConfig {\n  executablePath: string;\n  args: string[];\n\n  // CHANGED: workDir now optional, calculated from session\n  workDir?: string;\n\n  // NEW: Session reference for worktree lookup\n  sessionId?: string;\n\n  env?: Record<string, string>;\n  timeout?: number;\n  idleTimeout?: number;\n  retry?: {\n    maxAttempts: number;\n    backoffMs: number;\n  };\n}\n```\n\n#### 5\\. Session Lifecycle Integration\n\n**Location**: New service layer\n\n```typescript\ninterface ISessionService {\n  /**\n   * Create a new session with worktree\n   */\n  createSession(params: {\n    issueId: string;\n    baseBranch: string;\n    repoPath: string;\n  }): Promise<Session>;\n\n  /**\n   * Ensure session worktree is ready\n   */\n  ensureSessionReady(sessionId: string): Promise<void>;\n\n  /**\n   * Cleanup session and worktree\n   */\n  cleanupSession(sessionId: string): Promise<void>;\n\n  /**\n   * Get working directory for session\n   */\n  getSessionWorkDir(sessionId: string): Promise<string>;\n}\n```\n\n## Implementation Strategy\n\n### Phase 1: Foundation (Week 1)\n\n- Create worktree manager interface and basic implementation\n- Implement git CLI wrapper\n- Add configuration schema and loading from `.sudocode/config.json`\n- Add database schema for worktree tracking\n- Write unit tests for worktree operations\n\n### Phase 2: Integration (Week 2)\n\n- Integrate worktree manager with process layer\n- Update session lifecycle to create/cleanup worktrees\n- Modify process spawning to use worktree paths\n- Add worktree validation checks\n- Implement configuration-driven behavior (auto-create/delete branches)\n\n### Phase 3: Robustness (Week 3)\n\n- Implement locking mechanism\n- Add retry logic for creation failures\n- Implement comprehensive cleanup (filesystem + metadata)\n- Add orphaned worktree detection and cleanup\n- Implement sparse-checkout support\n\n### Phase 4: Testing & Polish (Week 4)\n\n- Integration tests for concurrent session scenarios\n- Cleanup on startup (handle crashed sessions)\n- Performance testing\n- Configuration validation and documentation\n\n## Key Design Decisions\n\n### 1\\. Worktree Naming Convention\n\n**Pattern**: `<project-name>-<session-id>-<branch-name>`\n\n**Example**: `sudocode-abc123-fix-issue-42`\n\n**Location**: Configurable via `worktreeStoragePath` in config (default: `.sudocode/worktrees/`)\n\n**Benefits**:\n\n- Easy to identify which session owns the worktree\n- Unique per session\n- Human-readable for debugging\n\n### 2\\. Branch Naming Convention\n\n**Pattern**: `<branchPrefix>/<session-id>/<issue-title>`\n\n**Example**: `sudocode/abc123/fix-authentication-bug`\n\n**Configuration**: `branchPrefix` is configurable (default: \"sudocode\")\n\n**Benefits**:\n\n- Clear namespace separation\n- Maps directly to session\n- Compatible with git best practices\n- Customizable prefix for team conventions\n\n### 3\\. Cleanup Strategy\n\n**When to cleanup**:\n\n1. **On session completion** - Normal cleanup path\n1. **On session failure** - Cleanup after errors\n1. **On server startup** - Cleanup orphaned worktrees (if `cleanupOrphanedWorktreesOnStartup` enabled)\n1. **Manual cleanup** - Admin tool for force cleanup\n\n**Cleanup process**:\n\n```typescript\nasync function cleanupWorktree(session: Session) {\n  // 1. Stop any running processes\n  await stopSessionProcesses(session.id);\n\n  // 2. Mark as deleted in DB (prevents race conditions)\n  await markWorktreeDeleted(session.id);\n\n  // 3. Remove git worktree registration\n  await gitCli.worktreeRemove(repoPath, session.worktreePath, true);\n\n  // 4. Force cleanup metadata directory\n  await forceCleanupMetadata(repoPath, session.branchName);\n\n  // 5. Remove filesystem directory\n  await fs.rm(session.worktreePath, { recursive: true, force: true });\n\n  // 6. Prune stale worktree entries\n  await gitCli.worktreePrune(repoPath);\n\n  // 7. Delete branch if configured to auto-delete\n  if (config.autoDeleteBranches) {\n    await gitCli.deleteBranch(repoPath, session.branchName);\n  }\n}\n```\n\n### 4\\. Race Condition Handling\n\n**Problem**: Multiple requests might try to create the same worktree concurrently.\n\n**Solution**: Per-path mutex using async locks\n\n```typescript\nimport { AsyncMutex } from 'async-mutex';\n\nclass WorktreeManager {\n  private locks = new Map<string, AsyncMutex>();\n\n  async ensureWorktreeExists(\n    repoPath: string,\n    branchName: string,\n    worktreePath: string\n  ): Promise<void> {\n    // Get or create lock for this specific path\n    let lock = this.locks.get(worktreePath);\n    if (!lock) {\n      lock = new AsyncMutex();\n      this.locks.set(worktreePath, lock);\n    }\n\n    // Acquire lock before proceeding\n    const release = await lock.acquire();\n    try {\n      // Check if already exists\n      if (await this.isWorktreeValid(repoPath, worktreePath)) {\n        return;\n      }\n\n      // Create worktree\n      await this.createWorktree(repoPath, branchName, worktreePath, baseBranch, false);\n    } finally {\n      release();\n    }\n  }\n}\n```\n\n### 5\\. Error Recovery\n\n**Scenarios to handle**:\n\n1. **Metadata exists but filesystem doesn't**\n\n- Solution: Force cleanup metadata, recreate\n\n1. **Filesystem exists but metadata doesn't**\n\n- Solution: Remove filesystem, recreate\n\n1. **Creation fails with \"already exists\"**\n\n- Solution: Cleanup completely, retry once\n\n1. **Git repository is locked**\n\n- Solution: Wait and retry with exponential backoff\n\n1. **Invalid configuration**\n\n- Solution: Validate config on load, use defaults for invalid values, warn user\n\n## API Design\n\n### REST Endpoints\n\n```typescript\n// Create session with worktree\nPOST /api/sessions\n{\n  \"issueId\": \"ISSUE-001\",\n  \"baseBranch\": \"main\"\n}\nResponse: {\n  \"sessionId\": \"abc123\",\n  \"worktreePath\": \"/tmp/sudocode-worktrees/...\",\n  \"branchName\": \"sudocode/abc123/fix-bug\"\n}\n\n// Get session info\nGET /api/sessions/:sessionId\nResponse: {\n  \"id\": \"abc123\",\n  \"issueId\": \"ISSUE-001\",\n  \"worktreePath\": \"/tmp/sudocode-worktrees/...\",\n  \"branchName\": \"sudocode/abc123/fix-bug\",\n  \"targetBranch\": \"main\",\n  \"status\": \"running\"\n}\n\n// Cleanup session\nDELETE /api/sessions/:sessionId\nResponse: { \"success\": true }\n\n// Admin: List all worktrees\nGET /api/admin/worktrees\nResponse: [\n  {\n    \"sessionId\": \"abc123\",\n    \"path\": \"/tmp/sudocode-worktrees/...\",\n    \"branch\": \"sudocode/abc123/fix-bug\",\n    \"createdAt\": \"2025-10-30T10:00:00Z\",\n    \"deleted\": false\n  }\n]\n\n// Admin: Cleanup orphaned worktrees\nPOST /api/admin/worktrees/cleanup\nResponse: {\n  \"cleaned\": 3,\n  \"failed\": 0\n}\n```\n\n## Testing Strategy\n\n### Unit Tests\n\n```typescript\ndescribe('WorktreeManager', () => {\n  it('should create a new worktree');\n  it('should handle concurrent creation requests');\n  it('should cleanup worktree completely');\n  it('should recover from partial cleanup');\n  it('should validate worktree existence');\n  it('should handle metadata conflicts');\n});\n\ndescribe('GitCli', () => {\n  it('should execute git worktree add');\n  it('should execute git worktree remove');\n  it('should parse git worktree list output');\n  it('should handle git errors gracefully');\n});\n```\n\n### Integration Tests\n\n```typescript\ndescribe('Session Lifecycle', () => {\n  it('should create session with worktree');\n  it('should run Claude Code in worktree');\n  it('should cleanup worktree on completion');\n  it('should handle multiple concurrent sessions');\n  it('should recover orphaned worktrees on startup');\n});\n```\n\n## Reference Implementation Insights\n\n### From vibe-kanban\n\n**Key Learnings**:\n\n1. **Use git CLI, not libgit2** - More reliable for worktree operations\n1. **Lock per path** - Prevents race conditions\n1. **Comprehensive cleanup** - Must remove both filesystem AND metadata\n1. **Retry logic** - Handle metadata conflicts by cleanup + retry\n1. **Database tracking** - `worktree_deleted` flag prevents double cleanup\n1. **Container abstraction** - Higher-level interface over worktree details\n\n**Code References**:\n\n- `crates/services/src/services/worktree_manager.rs` - Core worktree logic\n- `crates/services/src/services/container.rs` - Higher-level abstraction\n- `crates/db/src/models/task_attempt.rs` - Database model\n- Database migrations show evolution of worktree tracking\n\n## Configuration\n\nAll worktree settings will be configurable via `.sudocode/config.json`. This provides flexibility for different team workflows and repository sizes.\n\n### Configuration Schema\n\n```typescript\ninterface WorktreeConfig {\n  // Where to store worktrees\n  // Default: \".sudocode/worktrees\" (relative to project root)\n  // Can be absolute path like \"/tmp/sudocode-worktrees\"\n  worktreeStoragePath: string;\n\n  // Auto-create branches for new sessions\n  // Default: true\n  autoCreateBranches: boolean;\n\n  // Auto-delete branches when session is cleaned up\n  // Default: false (keep branches for history)\n  autoDeleteBranches: boolean;\n\n  // Use sparse-checkout for worktrees (for large repos)\n  // Default: false\n  enableSparseCheckout: boolean;\n\n  // Patterns for sparse-checkout (only if enableSparseCheckout=true)\n  // Example: [\"src/\", \"package.json\", \"tsconfig.json\"]\n  sparseCheckoutPatterns?: string[];\n\n  // Branch naming prefix\n  // Default: \"sudocode\"\n  branchPrefix: string;\n\n  // Cleanup orphaned worktrees on server startup\n  // Default: true\n  cleanupOrphanedWorktreesOnStartup: boolean;\n}\n```\n\n### Example config.json\n\n```json\n{\n  \"worktree\": {\n    \"worktreeStoragePath\": \".sudocode/worktrees\",\n    \"autoCreateBranches\": true,\n    \"autoDeleteBranches\": false,\n    \"enableSparseCheckout\": false,\n    \"branchPrefix\": \"sudocode\",\n    \"cleanupOrphanedWorktreesOnStartup\": true\n  }\n}\n```\n\n### Configuration Details\n\n**Storage Location**:\n\n- **Default**: `.sudocode/worktrees/` (relative to project root)\n- **Alternatives**: Absolute paths like `/tmp/sudocode-worktrees/` or `~/.sudocode/worktrees/`\n- **Benefits**: User-controlled, can optimize for disk I/O or temp cleanup needs\n\n**Concurrent Sessions**:\n\n- **Support**: Multiple sessions per issue allowed\n- **Design assumption**: Typically one session per issue at a time\n- **Benefit**: Worktrees enable safe concurrent sessions if needed (e.g., testing different approaches)\n\n**Branch Lifecycle**:\n\n- **Creation**: Configurable via `autoCreateBranches` (default: true)\n- **Deletion**: Configurable via `autoDeleteBranches` (default: false)\n- **Rationale**: Keep branches by default for git history; users can enable auto-deletion if preferred\n\n**Sparse Checkout**:\n\n- **Configurable**: Enable/disable via `enableSparseCheckout`\n- **Use case**: Large monorepos where full checkout is slow/wasteful\n- **Patterns**: Specify which paths to include in worktree\n\n**Future: Cloud Deployment**:\n\n- Design uses `container_ref` abstraction (like vibe-kanban)\n- Local implementation uses worktree paths\n- Future cloud implementation could use devcontainer IDs\n- Not in scope for initial implementation\n\n## Next Steps\n\n1. **Review this design** with team\n1. **Prototype** worktree manager with basic operations\n1. **Test** race condition handling\n1. **Integrate** with existing execution layers\n1. **Document** usage patterns for future developers\n\n## References\n\n- `/Users/alexngai/GitHub/sudocode/references/vibe-kanban/crates/services/src/services/worktree_manager.rs`\n- `/Users/alexngai/GitHub/sudocode/references/vibe-kanban/crates/services/src/services/container.rs`\n- [Git worktree documentation](https://git-scm.com/docs/git-worktree)\n","priority":2,"archived":0,"archived_at":null,"created_at":"2025-10-30 20:47:36","updated_at":"2025-11-03T03:10:12.586Z","parent_id":null,"parent_uuid":null,"relationships":[],"tags":[]}
{"id":"SPEC-011","uuid":"05ffaeb2-ee36-4155-836e-c49d583f5093","title":"Issue-to-Execution System Specification","file_path":"specs/issue_to_execution_system.md","content":"# Issue-to-Execution System Specification\n\n## Overview\n\nThe Issue-to-Execution System bridges sudocode's issue tracking with the execution infrastructure, enabling users to run AI agents directly on issues. This system transforms issues into executable workflows, manages execution lifecycle, supports iterative feedback loops, and provides real-time progress monitoring.\n\nThis spec integrates:\n- [[SPEC-003]] through [[SPEC-007]] - Execution infrastructure layers\n- [[SPEC-009]] - AG-UI protocol integration for real-time streaming\n- [[SPEC-010]] - Worktree management for execution isolation\n\n## Design Goals\n\n1. **Template-Driven**: Configurable prompt templates shown/edited before dispatch\n2. **Flexible Execution**: Support both isolated worktrees and local git tree\n3. **Configurable**: Execution settings modifiable before agent starts\n4. **Interactive**: Follow-up mechanism matching Claude Code's interaction flow\n5. **Observable**: Real-time progress via AG-UI event streaming\n6. **Resilient**: Auto-save, crash recovery, cleanup management\n\n## Architecture\n\n```\n┌───────────────────────────────────────────────────────────────────────┐\n│                        Frontend (React)                               │\n├───────────────────────────────────────────────────────────────────────┤\n│                                                                       │\n│  IssuePanel                                                          │\n│  ├─ [Run Agent] Button → ExecutionConfigDialog                      │\n│  │   ├─ Template Preview (editable)                                 │\n│  │   ├─ Execution Mode: [Worktree | Local]                         │\n│  │   ├─ Base Branch: [main ▼]                                      │\n│  │   ├─ Model: [claude-sonnet-4 ▼]                                 │\n│  │   └─ [Start Execution]                                          │\n│  │                                                                   │\n│  └─ ExecutionHistory                                                │\n│      └─ List of past executions with status                        │\n│                                                                       │\n│  ExecutionView                                                       │\n│  ├─ ExecutionMonitor (AG-UI streaming)                             │\n│  │   ├─ Real-time tool calls                                       │\n│  │   ├─ File changes                                               │\n│  │   └─ Progress indicators                                        │\n│  │                                                                   │\n│  └─ FollowUpPanel                                                   │\n│      ├─ Feedback textarea                                          │\n│      └─ [Send Follow-up]                                           │\n│                                                                       │\n└───────────────────────────────────────────────────────────────────────┘\n                                │\n                                ▼\n┌───────────────────────────────────────────────────────────────────────┐\n│                         Backend (Server)                              │\n├───────────────────────────────────────────────────────────────────────┤\n│                                                                       │\n│  API Routes                                                          │\n│  ├─ POST   /api/issues/:issueId/executions/prepare                 │\n│  │   → Returns template preview + defaults                          │\n│  │                                                                   │\n│  ├─ POST   /api/issues/:issueId/executions                         │\n│  │   → Creates and starts execution                                │\n│  │                                                                   │\n│  ├─ GET    /api/executions/:executionId                            │\n│  │   → Returns execution state                                      │\n│  │                                                                   │\n│  ├─ GET    /api/executions/:executionId/stream (SSE)               │\n│  │   → Real-time AG-UI events                                      │\n│  │                                                                   │\n│  ├─ POST   /api/executions/:executionId/follow-up                  │\n│  │   → Continues execution with user feedback                      │\n│  │                                                                   │\n│  └─ DELETE /api/executions/:executionId                            │\n│      → Cancels execution + cleanup                                  │\n│                                                                       │\n├───────────────────────────────────────────────────────────────────────┤\n│                                                                       │\n│  ExecutionService                                                    │\n│  ├─ prepareExecution(issueId, config?)                             │\n│  │   ├─ Load issue + related specs/feedback                        │\n│  │   ├─ Render prompt template                                     │\n│  │   └─ Return preview                                             │\n│  │                                                                   │\n│  ├─ createExecution(issueId, config)                               │\n│  │   ├─ Create DB record                                           │\n│  │   ├─ Setup execution environment                                │\n│  │   │   ├─ [Worktree Mode] Create isolated worktree              │\n│  │   │   └─ [Local Mode] Validate working directory               │\n│  │   ├─ Build workflow definition                                  │\n│  │   ├─ Start LinearOrchestrator                                   │\n│  │   └─ Return executionId                                         │\n│  │                                                                   │\n│  ├─ createFollowUp(executionId, feedback)                          │\n│  │   ├─ Load execution state                                       │\n│  │   ├─ Append feedback to context                                │\n│  │   ├─ Create follow-up workflow step                            │\n│  │   └─ Resume orchestrator                                        │\n│  │                                                                   │\n│  └─ cleanupExecution(executionId, mode)                            │\n│      ├─ [Auto] Cleanup on success                                  │\n│      ├─ [Manual] User-triggered cleanup                            │\n│      └─ [OnStartup] Orphaned worktree cleanup                      │\n│                                                                       │\n├───────────────────────────────────────────────────────────────────────┤\n│                                                                       │\n│  PromptTemplateEngine                                                │\n│  ├─ renderTemplate(template, context)                               │\n│  ├─ getDefaultTemplate(taskType)                                    │\n│  └─ validateTemplate(template)                                      │\n│                                                                       │\n│  WorktreeManager (SPEC-010)                                          │\n│  ├─ createWorktree(executionId, baseBranch)                        │\n│  ├─ getWorktreePath(executionId)                                   │\n│  └─ removeWorktree(executionId)                                    │\n│                                                                       │\n│  LinearOrchestrator + AgUiAdapter (SPEC-006, 009)                   │\n│  └─ Executes workflow with real-time event streaming               │\n│                                                                       │\n└───────────────────────────────────────────────────────────────────────┘\n```\n\n## Part 1: Core Types\n\n### Execution Database Entity\n\n```typescript\n/**\n * Execution - Persistent execution record\n *\n * Stored in database to track all agent executions for issues\n */\nexport interface Execution {\n  // Identity\n  id: string;                        // UUID\n  issueId: string;                   // Parent issue\n\n  // Configuration\n  mode: ExecutionMode;               // 'worktree' | 'local'\n  baseBranch: string;                // Base git branch\n  worktreePath?: string;             // Path if using worktree mode\n  prompt: string;                    // Rendered prompt sent to agent\n\n  // State\n  status: ExecutionStatus;\n  workflowExecutionId: string;       // Links to WorkflowExecution\n\n  // Metadata\n  model: string;                     // e.g., 'claude-sonnet-4'\n  config: ExecutionConfig;           // User-configurable settings\n\n  // Lifecycle\n  createdAt: Date;\n  startedAt?: Date;\n  completedAt?: Date;\n  cancelledAt?: Date;\n\n  // Results\n  filesChanged?: string[];\n  error?: string;\n\n  // Relationships\n  parentExecutionId?: string;        // If this is a follow-up\n  followUpExecutionIds?: string[];   // Child follow-ups\n}\n\nexport type ExecutionMode =\n  | 'worktree'  // Isolated git worktree\n  | 'local';    // Local working directory\n\nexport type ExecutionStatus =\n  | 'preparing'   // Template being prepared\n  | 'pending'     // Created, not yet started\n  | 'running'     // Agent executing\n  | 'paused'      // Execution paused (awaiting follow-up)\n  | 'completed'   // Successfully finished\n  | 'failed'      // Execution failed\n  | 'cancelled';  // User cancelled\n```\n\n### ExecutionConfig\n\n```typescript\n/**\n * ExecutionConfig - User-configurable execution settings\n */\nexport interface ExecutionConfig {\n  // Agent settings\n  model?: string;                    // Override default model\n  maxTokens?: number;\n  temperature?: number;\n\n  // Execution behavior\n  timeout?: number;                  // Overall timeout (ms)\n  retryPolicy?: RetryPolicy;         // From SPEC-005\n\n  // Worktree settings (if mode === 'worktree')\n  baseBranch?: string;               // Branch to base worktree on\n  branchName?: string;               // Override auto-generated branch name\n  cleanupMode?: CleanupMode;         // When to cleanup worktree\n\n  // Workflow settings\n  checkpointInterval?: number;       // Steps between checkpoints\n  continueOnStepFailure?: boolean;   // Continue after step failure\n\n  // Output settings\n  captureFileChanges?: boolean;\n  captureToolCalls?: boolean;\n}\n\nexport type CleanupMode =\n  | 'auto'       // Cleanup on successful completion\n  | 'manual'     // User must manually cleanup\n  | 'never';     // Never auto-cleanup (for debugging)\n```\n\n### PromptTemplate\n\n```typescript\n/**\n * PromptTemplate - Configurable template for generating agent prompts\n */\nexport interface PromptTemplate {\n  id: string;\n  name: string;\n  description: string;\n\n  // Template types\n  type: 'issue' | 'spec' | 'custom';\n\n  // Template content with variables\n  template: string;\n\n  // Available variables in template\n  variables: PromptVariable[];\n\n  // Metadata\n  isDefault?: boolean;\n  createdAt: Date;\n  updatedAt: Date;\n}\n\nexport interface PromptVariable {\n  name: string;                      // e.g., 'issueId', 'title', 'description'\n  description: string;\n  type: 'string' | 'number' | 'boolean' | 'array' | 'object';\n  required: boolean;\n  defaultValue?: any;\n}\n\n/**\n * Default issue prompt template\n */\nexport const DEFAULT_ISSUE_TEMPLATE = `Fix issue {{issueId}}: {{title}}\n\n## Description\n{{description}}\n\n{{#if relatedSpecs}}\n## Related Specifications\n{{#each relatedSpecs}}\n- [[{{id}}]]: {{title}}\n{{/each}}\n{{/if}}\n\n{{#if feedback}}\n## Feedback from Previous Attempts\n{{#each feedback}}\n- {{content}} (from {{issueId}})\n{{/each}}\n{{/if}}\n\nPlease implement a solution for this issue. Make sure to:\n1. Read and understand the issue requirements\n2. Check related specifications for context\n3. Write clean, well-tested code\n4. Update documentation if needed\n`;\n```\n\n### ExecutionPrepareResult\n\n```typescript\n/**\n * ExecutionPrepareResult - Preview before starting execution\n */\nexport interface ExecutionPrepareResult {\n  // Rendered preview\n  renderedPrompt: string;\n\n  // Issue context\n  issue: {\n    id: string;\n    title: string;\n    description: string;\n  };\n\n  // Related context\n  relatedSpecs: Array<{ id: string; title: string }>;\n  relatedFeedback: Array<{ issueId: string; content: string }>;\n\n  // Default configuration\n  defaultConfig: ExecutionConfig;\n\n  // Available options\n  availableModels: string[];\n  availableBranches: string[];\n  availableTemplates: PromptTemplate[];\n\n  // Validation\n  warnings?: string[];\n  errors?: string[];\n}\n```\n\n## Part 2: Service Layer\n\n### ExecutionService\n\n```typescript\nexport class ExecutionService {\n  constructor(\n    private db: Database,\n    private worktreeManager: WorktreeManager,\n    private orchestratorFactory: OrchestratorFactory,\n    private transportManager: TransportManager\n  ) {}\n\n  /**\n   * Prepare execution - render template and show preview\n   */\n  async prepareExecution(\n    issueId: string,\n    options?: {\n      templateId?: string;\n      config?: Partial<ExecutionConfig>;\n    }\n  ): Promise<ExecutionPrepareResult> {\n    // 1. Load issue\n    const issue = await this.db.issues.findById(issueId);\n    if (!issue) {\n      throw new Error(`Issue ${issueId} not found`);\n    }\n\n    // 2. Load related specs (via relationships)\n    const relatedSpecs = await this.db.relationships.getRelatedSpecs(issueId);\n\n    // 3. Load feedback from related issues\n    const relatedFeedback = await this.db.feedback.getForIssue(issueId);\n\n    // 4. Get template\n    const template = options?.templateId\n      ? await this.db.templates.findById(options.templateId)\n      : await this.getDefaultTemplate('issue');\n\n    // 5. Build context for template rendering\n    const context = {\n      issueId: issue.id,\n      title: issue.title,\n      description: issue.description,\n      relatedSpecs: relatedSpecs.map(s => ({\n        id: s.id,\n        title: s.title,\n      })),\n      feedback: relatedFeedback.map(f => ({\n        issueId: f.fromIssueId,\n        content: f.content,\n      })),\n    };\n\n    // 6. Render template\n    const renderedPrompt = this.templateEngine.render(\n      template.template,\n      context\n    );\n\n    // 7. Get default config\n    const defaultConfig: ExecutionConfig = {\n      model: 'claude-sonnet-4',\n      baseBranch: 'main',\n      cleanupMode: 'auto',\n      checkpointInterval: 1,\n      continueOnStepFailure: false,\n      captureFileChanges: true,\n      captureToolCalls: true,\n      ...options?.config,\n    };\n\n    // 8. Get available options\n    const availableModels = ['claude-sonnet-4', 'claude-opus-4'];\n    const availableBranches = await this.gitService.listBranches();\n    const availableTemplates = await this.db.templates.findByType('issue');\n\n    // 9. Validate\n    const warnings: string[] = [];\n    const errors: string[] = [];\n\n    if (!renderedPrompt.trim()) {\n      errors.push('Rendered prompt is empty');\n    }\n\n    // Check for uncommitted changes if using local mode\n    if (options?.config?.mode === 'local') {\n      const hasChanges = await this.gitService.hasUncommittedChanges();\n      if (hasChanges) {\n        warnings.push(\n          'Working directory has uncommitted changes. ' +\n          'Consider using worktree mode for isolation.'\n        );\n      }\n    }\n\n    return {\n      renderedPrompt,\n      issue: {\n        id: issue.id,\n        title: issue.title,\n        description: issue.description,\n      },\n      relatedSpecs,\n      relatedFeedback,\n      defaultConfig,\n      availableModels,\n      availableBranches,\n      availableTemplates,\n      warnings,\n      errors,\n    };\n  }\n\n  /**\n   * Create and start execution\n   */\n  async createExecution(\n    issueId: string,\n    config: ExecutionConfig,\n    prompt: string\n  ): Promise<Execution> {\n    // 1. Validate\n    if (!prompt.trim()) {\n      throw new Error('Prompt cannot be empty');\n    }\n\n    const issue = await this.db.issues.findById(issueId);\n    if (!issue) {\n      throw new Error(`Issue ${issueId} not found`);\n    }\n\n    // 2. Determine execution mode\n    const mode = config.mode || 'worktree';\n    let worktreePath: string | undefined;\n    let workDir: string;\n\n    if (mode === 'worktree') {\n      // Create isolated worktree\n      const executionId = generateId('exec');\n      worktreePath = await this.worktreeManager.createWorktree(\n        executionId,\n        config.baseBranch || 'main',\n        config.branchName\n      );\n      workDir = worktreePath;\n    } else {\n      // Use local working directory\n      workDir = process.cwd();\n    }\n\n    // 3. Create execution record\n    const execution: Execution = {\n      id: generateId('exec'),\n      issueId,\n      mode,\n      baseBranch: config.baseBranch || 'main',\n      worktreePath,\n      prompt,\n      status: 'pending',\n      workflowExecutionId: '', // Will be set below\n      model: config.model || 'claude-sonnet-4',\n      config,\n      createdAt: new Date(),\n    };\n\n    await this.db.executions.create(execution);\n\n    // 4. Build workflow definition\n    const workflow: WorkflowDefinition = {\n      id: `issue-${issueId}-workflow`,\n      steps: [\n        {\n          id: 'implement',\n          taskType: 'issue',\n          prompt,\n          dependencies: [],\n          retryPolicy: config.retryPolicy,\n          timeout: config.timeout,\n        },\n      ],\n      initialContext: {\n        issueId,\n        executionId: execution.id,\n        mode,\n      },\n      config: {\n        checkpointInterval: config.checkpointInterval,\n        continueOnStepFailure: config.continueOnStepFailure,\n      },\n      metadata: {\n        workDir,\n      },\n    };\n\n    // 5. Create AG-UI adapter for this execution\n    const agUiAdapter = new AgUiEventAdapter(\n      execution.id,\n      execution.id // threadId = executionId\n    );\n\n    // Connect to SSE transport\n    this.transportManager.connectAdapter(agUiAdapter, execution.id);\n\n    // 6. Create and start orchestrator\n    const orchestrator = this.orchestratorFactory.create(agUiAdapter);\n\n    const workflowExecutionId = await orchestrator.startWorkflow(\n      workflow,\n      workDir,\n      {\n        checkpointInterval: config.checkpointInterval,\n        initialContext: workflow.initialContext,\n      }\n    );\n\n    // 7. Update execution with workflow ID\n    execution.workflowExecutionId = workflowExecutionId;\n    execution.status = 'running';\n    execution.startedAt = new Date();\n    await this.db.executions.update(execution);\n\n    // 8. Setup completion handlers\n    orchestrator.onWorkflowComplete(async (executionId, result) => {\n      await this.handleWorkflowComplete(execution.id, result);\n    });\n\n    orchestrator.onWorkflowFailed(async (executionId, error) => {\n      await this.handleWorkflowFailed(execution.id, error);\n    });\n\n    return execution;\n  }\n\n  /**\n   * Create follow-up execution (continue in same worktree)\n   */\n  async createFollowUp(\n    executionId: string,\n    feedback: string\n  ): Promise<Execution> {\n    // 1. Load parent execution\n    const parentExecution = await this.db.executions.findById(executionId);\n    if (!parentExecution) {\n      throw new Error(`Execution ${executionId} not found`);\n    }\n\n    if (parentExecution.status === 'running') {\n      throw new Error('Cannot create follow-up while execution is running');\n    }\n\n    // 2. Build follow-up prompt\n    const followUpPrompt = `${parentExecution.prompt}\n\n---\n\nUser feedback: ${feedback}\n\nPlease address the feedback above and continue working on the issue.`;\n\n    // 3. Create follow-up execution (same mode, same worktree if applicable)\n    const followUpExecution: Execution = {\n      id: generateId('exec'),\n      issueId: parentExecution.issueId,\n      mode: parentExecution.mode,\n      baseBranch: parentExecution.baseBranch,\n      worktreePath: parentExecution.worktreePath, // Reuse same worktree\n      prompt: followUpPrompt,\n      status: 'pending',\n      workflowExecutionId: '',\n      model: parentExecution.model,\n      config: parentExecution.config,\n      parentExecutionId: parentExecution.id,\n      createdAt: new Date(),\n    };\n\n    await this.db.executions.create(followUpExecution);\n\n    // 4. Update parent to track this follow-up\n    parentExecution.followUpExecutionIds = [\n      ...(parentExecution.followUpExecutionIds || []),\n      followUpExecution.id,\n    ];\n    await this.db.executions.update(parentExecution);\n\n    // 5. Start execution (same as createExecution but reuse worktree)\n    const workDir = parentExecution.worktreePath || process.cwd();\n\n    const workflow: WorkflowDefinition = {\n      id: `issue-${parentExecution.issueId}-follow-up-workflow`,\n      steps: [\n        {\n          id: 'follow-up',\n          taskType: 'issue',\n          prompt: followUpPrompt,\n          dependencies: [],\n        },\n      ],\n      initialContext: {\n        issueId: parentExecution.issueId,\n        executionId: followUpExecution.id,\n        parentExecutionId: parentExecution.id,\n        mode: parentExecution.mode,\n      },\n    };\n\n    const agUiAdapter = new AgUiEventAdapter(\n      followUpExecution.id,\n      followUpExecution.id\n    );\n    this.transportManager.connectAdapter(agUiAdapter, followUpExecution.id);\n\n    const orchestrator = this.orchestratorFactory.create(agUiAdapter);\n    const workflowExecutionId = await orchestrator.startWorkflow(\n      workflow,\n      workDir\n    );\n\n    followUpExecution.workflowExecutionId = workflowExecutionId;\n    followUpExecution.status = 'running';\n    followUpExecution.startedAt = new Date();\n    await this.db.executions.update(followUpExecution);\n\n    return followUpExecution;\n  }\n\n  /**\n   * Cancel execution and cleanup\n   */\n  async cancelExecution(executionId: string): Promise<void> {\n    const execution = await this.db.executions.findById(executionId);\n    if (!execution) {\n      throw new Error(`Execution ${executionId} not found`);\n    }\n\n    // 1. Cancel workflow orchestrator\n    const orchestrator = this.orchestratorFactory.get(\n      execution.workflowExecutionId\n    );\n    if (orchestrator) {\n      await orchestrator.cancelWorkflow(execution.workflowExecutionId);\n    }\n\n    // 2. Update status\n    execution.status = 'cancelled';\n    execution.cancelledAt = new Date();\n    await this.db.executions.update(execution);\n\n    // 3. Cleanup if auto mode\n    if (execution.config.cleanupMode === 'auto' && execution.worktreePath) {\n      await this.cleanupExecution(executionId);\n    }\n  }\n\n  /**\n   * Cleanup execution resources\n   */\n  async cleanupExecution(executionId: string): Promise<void> {\n    const execution = await this.db.executions.findById(executionId);\n    if (!execution) {\n      throw new Error(`Execution ${executionId} not found`);\n    }\n\n    // Only cleanup if using worktree mode\n    if (execution.mode === 'worktree' && execution.worktreePath) {\n      await this.worktreeManager.removeWorktree(executionId);\n    }\n  }\n\n  /**\n   * Get execution by ID\n   */\n  async getExecution(executionId: string): Promise<Execution | null> {\n    return this.db.executions.findById(executionId);\n  }\n\n  /**\n   * List executions for an issue\n   */\n  async listExecutions(issueId: string): Promise<Execution[]> {\n    return this.db.executions.findByIssueId(issueId);\n  }\n\n  /**\n   * Handle workflow completion\n   */\n  private async handleWorkflowComplete(\n    executionId: string,\n    result: WorkflowResult\n  ): Promise<void> {\n    const execution = await this.db.executions.findById(executionId);\n    if (!execution) return;\n\n    execution.status = 'completed';\n    execution.completedAt = new Date();\n    execution.filesChanged = result.outputs.filesChanged || [];\n    await this.db.executions.update(execution);\n\n    // Auto-cleanup if configured\n    if (execution.config.cleanupMode === 'auto' && result.success) {\n      await this.cleanupExecution(executionId);\n    }\n  }\n\n  /**\n   * Handle workflow failure\n   */\n  private async handleWorkflowFailed(\n    executionId: string,\n    error: Error\n  ): Promise<void> {\n    const execution = await this.db.executions.findById(executionId);\n    if (!execution) return;\n\n    execution.status = 'failed';\n    execution.completedAt = new Date();\n    execution.error = error.message;\n    await this.db.executions.update(execution);\n  }\n\n  /**\n   * Get default template for task type\n   */\n  private async getDefaultTemplate(type: string): Promise<PromptTemplate> {\n    const defaultTemplates = await this.db.templates.findByType(type);\n    const defaultTemplate = defaultTemplates.find(t => t.isDefault);\n\n    if (!defaultTemplate) {\n      // Return built-in default\n      return {\n        id: 'default-issue',\n        name: 'Default Issue Template',\n        description: 'Default template for issue execution',\n        type: 'issue',\n        template: DEFAULT_ISSUE_TEMPLATE,\n        variables: [\n          {\n            name: 'issueId',\n            description: 'Issue identifier',\n            type: 'string',\n            required: true,\n          },\n          {\n            name: 'title',\n            description: 'Issue title',\n            type: 'string',\n            required: true,\n          },\n          {\n            name: 'description',\n            description: 'Issue description',\n            type: 'string',\n            required: true,\n          },\n        ],\n        isDefault: true,\n        createdAt: new Date(),\n        updatedAt: new Date(),\n      };\n    }\n\n    return defaultTemplate;\n  }\n}\n```\n\n### PromptTemplateEngine\n\n```typescript\n/**\n * Simple template engine with Handlebars-like syntax\n */\nexport class PromptTemplateEngine {\n  /**\n   * Render template with context variables\n   */\n  render(template: string, context: Record<string, any>): string {\n    let result = template;\n\n    // Replace simple variables: {{variable}}\n    result = result.replace(/\\{\\{([^}#/]+)\\}\\}/g, (match, key) => {\n      const value = this.getValue(context, key.trim());\n      return value !== undefined ? String(value) : match;\n    });\n\n    // Handle conditionals: {{#if variable}}...{{/if}}\n    result = result.replace(\n      /\\{\\{#if ([^}]+)\\}\\}([\\s\\S]*?)\\{\\{\\/if\\}\\}/g,\n      (match, key, content) => {\n        const value = this.getValue(context, key.trim());\n        return value ? content : '';\n      }\n    );\n\n    // Handle loops: {{#each array}}...{{/each}}\n    result = result.replace(\n      /\\{\\{#each ([^}]+)\\}\\}([\\s\\S]*?)\\{\\{\\/each\\}\\}/g,\n      (match, key, itemTemplate) => {\n        const array = this.getValue(context, key.trim());\n        if (!Array.isArray(array)) return '';\n\n        return array\n          .map(item => this.render(itemTemplate, item))\n          .join('');\n      }\n    );\n\n    return result;\n  }\n\n  /**\n   * Get nested value from context\n   */\n  private getValue(context: Record<string, any>, path: string): any {\n    const keys = path.split('.');\n    let value: any = context;\n\n    for (const key of keys) {\n      if (value === null || value === undefined) return undefined;\n      value = value[key];\n    }\n\n    return value;\n  }\n\n  /**\n   * Validate template syntax\n   */\n  validate(template: string): { valid: boolean; errors: string[] } {\n    const errors: string[] = [];\n\n    // Check for balanced tags\n    const ifCount = (template.match(/\\{\\{#if/g) || []).length;\n    const endIfCount = (template.match(/\\{\\{\\/if\\}\\}/g) || []).length;\n    if (ifCount !== endIfCount) {\n      errors.push(`Unbalanced {{#if}} tags (${ifCount} vs ${endIfCount})`);\n    }\n\n    const eachCount = (template.match(/\\{\\{#each/g) || []).length;\n    const endEachCount = (template.match(/\\{\\{\\/each\\}\\}/g) || []).length;\n    if (eachCount !== endEachCount) {\n      errors.push(`Unbalanced {{#each}} tags (${eachCount} vs ${endEachCount})`);\n    }\n\n    return {\n      valid: errors.length === 0,\n      errors,\n    };\n  }\n}\n```\n\n## Part 3: API Routes\n\n```typescript\n// server/src/routes/executions.ts\n\n/**\n * Prepare execution - preview before starting\n * POST /api/issues/:issueId/executions/prepare\n */\nrouter.post(\n  '/issues/:issueId/executions/prepare',\n  async (req: Request, res: Response) => {\n    const { issueId } = req.params;\n    const { templateId, config } = req.body;\n\n    const result = await executionService.prepareExecution(issueId, {\n      templateId,\n      config,\n    });\n\n    res.json(result);\n  }\n);\n\n/**\n * Create and start execution\n * POST /api/issues/:issueId/executions\n */\nrouter.post(\n  '/issues/:issueId/executions',\n  async (req: Request, res: Response) => {\n    const { issueId } = req.params;\n    const { config, prompt } = req.body;\n\n    const execution = await executionService.createExecution(\n      issueId,\n      config,\n      prompt\n    );\n\n    res.json(execution);\n  }\n);\n\n/**\n * Get execution by ID\n * GET /api/executions/:executionId\n */\nrouter.get(\n  '/executions/:executionId',\n  async (req: Request, res: Response) => {\n    const { executionId } = req.params;\n    const execution = await executionService.getExecution(executionId);\n\n    if (!execution) {\n      return res.status(404).json({ error: 'Execution not found' });\n    }\n\n    res.json(execution);\n  }\n);\n\n/**\n * Stream execution events (SSE)\n * GET /api/executions/:executionId/stream\n */\nrouter.get(\n  '/executions/:executionId/stream',\n  async (req: Request, res: Response) => {\n    const { executionId } = req.params;\n    const clientId = generateId('client');\n\n    // Get SSE transport from transport manager\n    const sseTransport = transportManager.getSseTransport();\n    sseTransport.handleConnection(clientId, res, executionId);\n  }\n);\n\n/**\n * Create follow-up execution\n * POST /api/executions/:executionId/follow-up\n */\nrouter.post(\n  '/executions/:executionId/follow-up',\n  async (req: Request, res: Response) => {\n    const { executionId } = req.params;\n    const { feedback } = req.body;\n\n    const followUpExecution = await executionService.createFollowUp(\n      executionId,\n      feedback\n    );\n\n    res.json(followUpExecution);\n  }\n);\n\n/**\n * Cancel execution\n * DELETE /api/executions/:executionId\n */\nrouter.delete(\n  '/executions/:executionId',\n  async (req: Request, res: Response) => {\n    const { executionId } = req.params;\n    await executionService.cancelExecution(executionId);\n    res.json({ message: 'Execution cancelled' });\n  }\n);\n\n/**\n * List executions for issue\n * GET /api/issues/:issueId/executions\n */\nrouter.get(\n  '/issues/:issueId/executions',\n  async (req: Request, res: Response) => {\n    const { issueId } = req.params;\n    const executions = await executionService.listExecutions(issueId);\n    res.json(executions);\n  }\n);\n```\n\n## Part 4: Frontend Components\n\n### ExecutionConfigDialog\n\n```typescript\n// frontend/src/components/executions/ExecutionConfigDialog.tsx\n\nexport interface ExecutionConfigDialogProps {\n  issueId: string;\n  onStart: (config: ExecutionConfig, prompt: string) => void;\n  onCancel: () => void;\n}\n\nexport const ExecutionConfigDialog: React.FC<ExecutionConfigDialogProps> = ({\n  issueId,\n  onStart,\n  onCancel,\n}) => {\n  const [preparing, setPreparing] = useState(true);\n  const [preview, setPreview] = useState<ExecutionPrepareResult | null>(null);\n  const [prompt, setPrompt] = useState('');\n  const [config, setConfig] = useState<ExecutionConfig>({\n    mode: 'worktree',\n    model: 'claude-sonnet-4',\n    baseBranch: 'main',\n    cleanupMode: 'auto',\n  });\n\n  // Load preview on mount\n  useEffect(() => {\n    async function loadPreview() {\n      const response = await fetch(\n        `/api/issues/${issueId}/executions/prepare`,\n        {\n          method: 'POST',\n          headers: { 'Content-Type': 'application/json' },\n          body: JSON.stringify({ config }),\n        }\n      );\n      const result = await response.json();\n      setPreview(result);\n      setPrompt(result.renderedPrompt);\n      setPreparing(false);\n    }\n    loadPreview();\n  }, [issueId]);\n\n  const handleStart = () => {\n    onStart(config, prompt);\n  };\n\n  if (preparing || !preview) {\n    return <div>Loading...</div>;\n  }\n\n  return (\n    <Dialog>\n      <DialogHeader>\n        <DialogTitle>Configure Execution</DialogTitle>\n      </DialogHeader>\n\n      <div className=\"space-y-4\">\n        {/* Warnings */}\n        {preview.warnings && preview.warnings.length > 0 && (\n          <div className=\"bg-yellow-50 p-3 rounded\">\n            {preview.warnings.map((w, i) => (\n              <div key={i} className=\"text-sm text-yellow-800\">\n                ⚠️ {w}\n              </div>\n            ))}\n          </div>\n        )}\n\n        {/* Execution Mode */}\n        <div>\n          <label className=\"block text-sm font-medium mb-2\">\n            Execution Mode\n          </label>\n          <select\n            value={config.mode}\n            onChange={(e) =>\n              setConfig({ ...config, mode: e.target.value as ExecutionMode })\n            }\n            className=\"w-full border rounded p-2\"\n          >\n            <option value=\"worktree\">Isolated Worktree (Recommended)</option>\n            <option value=\"local\">Local Working Directory</option>\n          </select>\n          <p className=\"text-xs text-gray-500 mt-1\">\n            {config.mode === 'worktree'\n              ? 'Creates isolated git worktree for safe execution'\n              : 'Runs in your current working directory'}\n          </p>\n        </div>\n\n        {/* Base Branch (if worktree mode) */}\n        {config.mode === 'worktree' && (\n          <div>\n            <label className=\"block text-sm font-medium mb-2\">\n              Base Branch\n            </label>\n            <select\n              value={config.baseBranch}\n              onChange={(e) =>\n                setConfig({ ...config, baseBranch: e.target.value })\n              }\n              className=\"w-full border rounded p-2\"\n            >\n              {preview.availableBranches.map((branch) => (\n                <option key={branch} value={branch}>\n                  {branch}\n                </option>\n              ))}\n            </select>\n          </div>\n        )}\n\n        {/* Model */}\n        <div>\n          <label className=\"block text-sm font-medium mb-2\">Model</label>\n          <select\n            value={config.model}\n            onChange={(e) => setConfig({ ...config, model: e.target.value })}\n            className=\"w-full border rounded p-2\"\n          >\n            {preview.availableModels.map((model) => (\n              <option key={model} value={model}>\n                {model}\n              </option>\n            ))}\n          </select>\n        </div>\n\n        {/* Cleanup Mode (if worktree) */}\n        {config.mode === 'worktree' && (\n          <div>\n            <label className=\"block text-sm font-medium mb-2\">\n              Worktree Cleanup\n            </label>\n            <select\n              value={config.cleanupMode}\n              onChange={(e) =>\n                setConfig({\n                  ...config,\n                  cleanupMode: e.target.value as CleanupMode,\n                })\n              }\n              className=\"w-full border rounded p-2\"\n            >\n              <option value=\"auto\">Auto (on success)</option>\n              <option value=\"manual\">Manual</option>\n              <option value=\"never\">Never (debugging)</option>\n            </select>\n          </div>\n        )}\n\n        {/* Prompt Preview (Editable) */}\n        <div>\n          <label className=\"block text-sm font-medium mb-2\">\n            Prompt (Editable)\n          </label>\n          <textarea\n            value={prompt}\n            onChange={(e) => setPrompt(e.target.value)}\n            className=\"w-full border rounded p-2 font-mono text-sm\"\n            rows={15}\n          />\n        </div>\n      </div>\n\n      <DialogFooter>\n        <button onClick={onCancel} className=\"btn-secondary\">\n          Cancel\n        </button>\n        <button\n          onClick={handleStart}\n          disabled={preview.errors && preview.errors.length > 0}\n          className=\"btn-primary\"\n        >\n          Start Execution\n        </button>\n      </DialogFooter>\n    </Dialog>\n  );\n};\n```\n\n### ExecutionView\n\n```typescript\n// frontend/src/components/executions/ExecutionView.tsx\n\nexport interface ExecutionViewProps {\n  executionId: string;\n}\n\nexport const ExecutionView: React.FC<ExecutionViewProps> = ({\n  executionId,\n}) => {\n  const [execution, setExecution] = useState<Execution | null>(null);\n  const [showFollowUp, setShowFollowUp] = useState(false);\n\n  const agUiStream = useAgUiStream({\n    executionId,\n    onEvent: {\n      onRunFinished: () => {\n        // Reload execution to get final state\n        loadExecution();\n      },\n    },\n  });\n\n  useEffect(() => {\n    loadExecution();\n  }, [executionId]);\n\n  const loadExecution = async () => {\n    const response = await fetch(`/api/executions/${executionId}`);\n    const data = await response.json();\n    setExecution(data);\n  };\n\n  const handleFollowUp = async (feedback: string) => {\n    await fetch(`/api/executions/${executionId}/follow-up`, {\n      method: 'POST',\n      headers: { 'Content-Type': 'application/json' },\n      body: JSON.stringify({ feedback }),\n    });\n    setShowFollowUp(false);\n  };\n\n  const handleCancel = async () => {\n    await fetch(`/api/executions/${executionId}`, {\n      method: 'DELETE',\n    });\n    loadExecution();\n  };\n\n  if (!execution) {\n    return <div>Loading...</div>;\n  }\n\n  return (\n    <div className=\"execution-view\">\n      {/* Header */}\n      <div className=\"flex items-center justify-between mb-4\">\n        <div>\n          <h2 className=\"text-xl font-semibold\">\n            Execution {execution.id}\n          </h2>\n          <div className=\"flex items-center gap-2 text-sm text-gray-600\">\n            <span>Mode: {execution.mode}</span>\n            <span>•</span>\n            <span>Model: {execution.model}</span>\n            <span>•</span>\n            <span className={`status-${execution.status}`}>\n              {execution.status}\n            </span>\n          </div>\n        </div>\n\n        <div className=\"flex gap-2\">\n          {execution.status === 'running' && (\n            <button onClick={handleCancel} className=\"btn-danger\">\n              Cancel\n            </button>\n          )}\n          {['completed', 'failed'].includes(execution.status) && (\n            <button\n              onClick={() => setShowFollowUp(true)}\n              className=\"btn-primary\"\n            >\n              Follow Up\n            </button>\n          )}\n        </div>\n      </div>\n\n      {/* Execution Monitor (AG-UI streaming) */}\n      <ExecutionMonitor\n        executionId={executionId}\n        onComplete={() => loadExecution()}\n      />\n\n      {/* Follow-up Dialog */}\n      {showFollowUp && (\n        <FollowUpDialog\n          onSubmit={handleFollowUp}\n          onCancel={() => setShowFollowUp(false)}\n        />\n      )}\n    </div>\n  );\n};\n```\n\n### FollowUpDialog\n\n```typescript\n// frontend/src/components/executions/FollowUpDialog.tsx\n\nexport interface FollowUpDialogProps {\n  onSubmit: (feedback: string) => void;\n  onCancel: () => void;\n}\n\nexport const FollowUpDialog: React.FC<FollowUpDialogProps> = ({\n  onSubmit,\n  onCancel,\n}) => {\n  const [feedback, setFeedback] = useState('');\n\n  const handleSubmit = () => {\n    if (feedback.trim()) {\n      onSubmit(feedback);\n    }\n  };\n\n  return (\n    <Dialog>\n      <DialogHeader>\n        <DialogTitle>Provide Follow-up Feedback</DialogTitle>\n      </DialogHeader>\n\n      <div className=\"space-y-4\">\n        <p className=\"text-sm text-gray-600\">\n          Describe what changes you'd like the agent to make, or ask questions\n          about the implementation.\n        </p>\n\n        <textarea\n          value={feedback}\n          onChange={(e) => setFeedback(e.target.value)}\n          placeholder=\"e.g., 'Please add error handling for edge cases' or 'Can you explain why you chose this approach?'\"\n          className=\"w-full border rounded p-3\"\n          rows={6}\n        />\n      </div>\n\n      <DialogFooter>\n        <button onClick={onCancel} className=\"btn-secondary\">\n          Cancel\n        </button>\n        <button\n          onClick={handleSubmit}\n          disabled={!feedback.trim()}\n          className=\"btn-primary\"\n        >\n          Send Follow-up\n        </button>\n      </DialogFooter>\n    </Dialog>\n  );\n};\n```\n\n## Part 5: Database Schema\n\n```sql\n-- Executions table\nCREATE TABLE executions (\n  id TEXT PRIMARY KEY,\n  issue_id TEXT NOT NULL REFERENCES issues(id),\n\n  -- Configuration\n  mode TEXT NOT NULL CHECK(mode IN ('worktree', 'local')),\n  base_branch TEXT NOT NULL,\n  worktree_path TEXT,\n  prompt TEXT NOT NULL,\n\n  -- State\n  status TEXT NOT NULL CHECK(status IN (\n    'preparing', 'pending', 'running', 'paused',\n    'completed', 'failed', 'cancelled'\n  )),\n  workflow_execution_id TEXT NOT NULL,\n\n  -- Metadata\n  model TEXT NOT NULL,\n  config JSONB NOT NULL,\n\n  -- Lifecycle\n  created_at TIMESTAMP NOT NULL DEFAULT NOW(),\n  started_at TIMESTAMP,\n  completed_at TIMESTAMP,\n  cancelled_at TIMESTAMP,\n\n  -- Results\n  files_changed JSONB,\n  error TEXT,\n\n  -- Relationships\n  parent_execution_id TEXT REFERENCES executions(id),\n\n  -- Indexes\n  INDEX idx_executions_issue_id (issue_id),\n  INDEX idx_executions_status (status),\n  INDEX idx_executions_parent (parent_execution_id)\n);\n\n-- Prompt templates table\nCREATE TABLE prompt_templates (\n  id TEXT PRIMARY KEY,\n  name TEXT NOT NULL,\n  description TEXT,\n  type TEXT NOT NULL CHECK(type IN ('issue', 'spec', 'custom')),\n  template TEXT NOT NULL,\n  variables JSONB NOT NULL,\n  is_default BOOLEAN DEFAULT FALSE,\n  created_at TIMESTAMP NOT NULL DEFAULT NOW(),\n  updated_at TIMESTAMP NOT NULL DEFAULT NOW(),\n\n  INDEX idx_templates_type (type),\n  INDEX idx_templates_default (is_default)\n);\n```\n\n## Testing Strategy\n\n### Unit Tests\n\n1. **PromptTemplateEngine**\n   - Variable substitution\n   - Conditional rendering\n   - Loop rendering\n   - Nested paths\n   - Template validation\n\n2. **ExecutionService**\n   - prepareExecution builds correct preview\n   - createExecution with worktree mode\n   - createExecution with local mode\n   - createFollowUp reuses worktree\n   - Cleanup modes work correctly\n\n### Integration Tests\n\n1. **End-to-end execution flow**\n   - Prepare → Create → Stream → Complete\n   - Follow-up workflow\n   - Cancel and cleanup\n\n2. **Worktree isolation**\n   - Multiple concurrent executions don't interfere\n   - Follow-ups work in same worktree\n\n### E2E Tests\n\n1. **Frontend workflow**\n   - Open config dialog → edit prompt → start\n   - Monitor real-time progress\n   - Submit follow-up\n   - View execution history\n\n## Implementation Checklist\n\n### Backend\n\n- [ ] Define Execution entity schema\n- [ ] Create database migrations\n- [ ] Implement PromptTemplateEngine\n- [ ] Implement ExecutionService\n- [ ] Add API routes for executions\n- [ ] Integrate with WorktreeManager\n- [ ] Wire up AG-UI streaming\n- [ ] Add default prompt templates\n- [ ] Write unit tests\n- [ ] Write integration tests\n\n### Frontend\n\n- [ ] Create ExecutionConfigDialog component\n- [ ] Create ExecutionView component\n- [ ] Create FollowUpDialog component\n- [ ] Add \"Run Agent\" button to IssuePanel\n- [ ] Add execution history to IssuePanel\n- [ ] Wire up SSE streaming with useAgUiStream\n- [ ] Add styling and animations\n- [ ] Write component tests\n- [ ] Write E2E tests\n\n### Documentation\n\n- [ ] API documentation\n- [ ] User guide for running executions\n- [ ] Template syntax documentation\n- [ ] Troubleshooting guide\n\n## Usage Example\n\n```typescript\n// 1. User clicks \"Run Agent\" on issue\n// Frontend opens ExecutionConfigDialog\n\n// 2. Dialog prepares execution\nconst preview = await fetch('/api/issues/ISSUE-001/executions/prepare', {\n  method: 'POST',\n  body: JSON.stringify({ config: { mode: 'worktree' } }),\n});\n\n// 3. User edits prompt, configures settings, clicks \"Start\"\nconst execution = await fetch('/api/issues/ISSUE-001/executions', {\n  method: 'POST',\n  body: JSON.stringify({\n    config: {\n      mode: 'worktree',\n      model: 'claude-sonnet-4',\n      baseBranch: 'main',\n      cleanupMode: 'auto',\n    },\n    prompt: editedPrompt,\n  }),\n});\n\n// 4. Frontend connects to SSE stream\nconst eventSource = new EventSource(\n  `/api/executions/${execution.id}/stream`\n);\n\n// 5. Real-time events flow via AG-UI protocol\n// RUN_STARTED → STEP_STARTED → TOOL_CALL_START → ... → RUN_FINISHED\n\n// 6. User provides feedback\nawait fetch(`/api/executions/${execution.id}/follow-up`, {\n  method: 'POST',\n  body: JSON.stringify({\n    feedback: 'Please add error handling for edge cases',\n  }),\n});\n\n// 7. New execution starts in same worktree with appended feedback\n```\n\n## Related Specs\n\n- [[SPEC-003]] - Process Layer (spawns Claude Code processes)\n- [[SPEC-004]] - Engine Layer (task queuing)\n- [[SPEC-005]] - Resilience Layer (retry logic)\n- [[SPEC-006]] - Workflow Layer (LinearOrchestrator)\n- [[SPEC-007]] - Output Processing (parses stream-json)\n- [[SPEC-009]] - AG-UI Integration (real-time events)\n- [[SPEC-010]] - Worktree Management (execution isolation)\n","priority":2,"archived":0,"archived_at":null,"created_at":"2025-10-31 04:41:21","updated_at":"2025-11-03T03:10:12.584Z","parent_id":null,"parent_uuid":null,"relationships":[{"from":"SPEC-011","from_type":"spec","to":"SPEC-003","to_type":"spec","type":"references"},{"from":"SPEC-011","from_type":"spec","to":"SPEC-004","to_type":"spec","type":"references"},{"from":"SPEC-011","from_type":"spec","to":"SPEC-006","to_type":"spec","type":"references"},{"from":"SPEC-011","from_type":"spec","to":"SPEC-007","to_type":"spec","type":"references"},{"from":"SPEC-011","from_type":"spec","to":"SPEC-009","to_type":"spec","type":"references"},{"from":"SPEC-011","from_type":"spec","to":"SPEC-010","to_type":"spec","type":"references"}],"tags":[]}
{"id":"SPEC-012","uuid":"a77d2a0d-bae8-4582-a1e0-fb42cad68d35","title":"Issue-to-Execution System","file_path":"specs/issue_to_execution_system_SPEC-012.md","content":"End-to-end system for running AI agents on issues with template-based prompts, configurable execution modes (worktree/local), follow-up interactions, and real-time progress monitoring via AG-UI streaming.\n\n**Key Features:**\n\n- Template-driven prompt generation with preview/edit\n- Isolated worktree execution OR local git tree\n- Configurable execution settings (model, cleanup, retries)\n- Follow-up mechanism like Claude Code interaction flow\n- Real-time progress via AG-UI + SSE\n- Auto/manual cleanup options\n\n**Architecture:**\n\n- ExecutionService orchestrates lifecycle\n- PromptTemplateEngine renders customizable templates\n- WorktreeManager provides execution isolation\n- LinearOrchestrator + AgUiAdapter stream real-time events\n- Frontend components for config, monitoring, follow-ups\n\nIntegrates with SPEC-003 through SPEC-010.\n","priority":0,"archived":1,"archived_at":"2025-10-31T08:15:16.563Z","created_at":"2025-10-31 04:41:30","updated_at":"2025-11-03T03:10:12.591Z","parent_id":null,"parent_uuid":null,"relationships":[],"tags":["ag-ui","execution","integration","issue-management","templates","worktree"]}
{"id":"SPEC-013","uuid":"a1df3333-a59c-424a-bc19-9b5cacdecc46","title":"Merge Conflict Resolution & Multi-Developer Improvements","file_path":"specs/merge_conflict_resolution_multi_developer_improvem.md","content":"Comprehensive improvements to sudocode's JSONL storage system to handle merge conflicts, ID collisions, and reference integrity in multi-developer, multi-branch environments.\n\n## Background\n\nSudocode uses a git-native storage model with JSONL files for specs and issues. While this approach works well for single-developer workflows, several problems emerge in multi-developer scenarios:\n\n1. **ID Collision Risk**: Sequential ID generation can create the same ID on different branches\n2. **Reference Corruption**: Inline `[[ID]]` references become orphaned after collision resolution\n3. **Manual Merge Burden**: No tooling to assist with JSONL merge conflicts\n4. **Limited Collision Resolution**: Only one strategy (renumber incoming), not always optimal\n5. **No Reference Validation**: Broken references go undetected\n\nThis spec addresses all identified issues with a phased improvement plan. See full spec at `specs/merge_conflict_resolution.md` for complete details.\n\n## Problem Analysis\n\n### P1: ID Collision on Concurrent Creation (HIGH)\n- Sequential ID generation causes race conditions across branches\n- Example: Two branches both create ISSUE-042 with different UUIDs\n- Results in merge conflicts requiring manual resolution\n\n### P2: Inline Reference Corruption (HIGH)\n- When IDs are renumbered, `[[ID]]` references in markdown aren't updated\n- Silent corruption - references appear valid but point to wrong entity\n- No validation catches these broken references\n\n### P3: JSONL Merge Conflicts (MEDIUM-HIGH)\n- Large JSONL files (308KB+) with line-by-line conflicts\n- No tooling to assist resolution\n- Manual editing error-prone and time-consuming\n\n### P4: Limited Collision Detection & Resolution (MEDIUM)\n- Only one strategy: always renumber incoming entity\n- Doesn't consider age, reference count, or branch hierarchy\n- No user notification or choice\n\n### P5: Reference Integrity Issues (MEDIUM)\n- References stored in 3 places: SQLite, JSONL, markdown\n- No validation ensures consistency\n- Stale references go undetected\n\n### P6: Lack of Merge Tooling (MEDIUM)\n- Zero automation for conflict resolution\n- No pre-commit validation\n- No post-merge validation\n\n## Proposed Solutions\n\n### Solution 1: Pre-Commit ID Collision Detection\n- New command: `sudocode validate-ids`\n- Git pre-commit hook to catch collisions early\n- Zero runtime overhead (only on commit)\n\n### Solution 2: Reference Validation & Repair\n- New command: `sudocode validate-refs --fix`\n- Scans markdown for broken `[[ID]]` references\n- Automated reference updates after ID renumbering\n- Can suggest replacements for broken references\n\n### Solution 3: Interactive Conflict Resolution\n- New command: `sudocode conflicts detect`\n- New command: `sudocode conflicts resolve --interactive`\n- Guided resolution with metadata display\n- Auto-resolution with configurable strategies\n\n### Solution 4: Custom Git Merge Driver\n- Teach git to merge JSONL files intelligently\n- UUID-aware merging\n- Automatic collision resolution\n- Fallback to manual resolution on conflicts\n\n### Solution 5: Improved Collision Resolution Strategy\n- Multiple strategies: older-wins, more-refs-wins, main-wins, etc.\n- Configurable via `config.json`\n- User choice and control\n\n### Solution 6: Collision Audit Log\n- New table: `collision_log` in database\n- Tracks all collisions and resolutions\n- New command: `sudocode collisions show`\n- Complete audit trail for debugging\n\n## Implementation Phases\n\n### Phase 1: Detection & Validation (Week 1)\n- Pre-commit ID validation\n- Reference validation command\n- Documentation\n\n**Issues**:\n- Implement pre-commit ID validation\n- Implement reference validation command\n- Write multi-developer workflow docs\n\n### Phase 2: Automated Repair (Week 2)\n- Automated reference updates\n- Collision logging\n- Integration tests\n\n**Issues**:\n- Automated reference updates on collision\n- Add collision_log table\n- Implement collision logging\n- Integration tests\n\n### Phase 3: Interactive Resolution (Week 3)\n- Conflict detection and resolution commands\n- Collision resolution strategies\n- Strategy configuration\n\n**Issues**:\n- Implement conflict detection command\n- Implement interactive conflict resolver\n- Implement auto-resolution strategies\n- Add collision strategy to config\n\n### Phase 4: Git Integration (Week 4)\n- Custom git merge driver\n- E2E tests\n- Polish and edge cases\n\n**Issues**:\n- Implement custom git merge driver\n- Document merge driver setup\n- E2E test: Multi-developer workflow\n\n## Configuration\n\nNew config options in `config.json`:\n```json\n{\n  \"collision_resolution\": {\n    \"strategy\": \"older-wins\",\n    \"prompt_on_conflict\": true,\n    \"auto_update_references\": true\n  },\n  \"validation\": {\n    \"pre_commit_check\": true,\n    \"warn_on_broken_refs\": true\n  },\n  \"merge_driver\": {\n    \"enabled\": true,\n    \"fallback_to_manual\": true\n  }\n}\n```\n\n## Success Metrics\n\n- **Collision Detection Rate**: % caught pre-commit\n- **Automatic Merge Success**: % of JSONL merges without manual intervention\n- **Reference Validation**: % of broken references detected and fixed\n- **Developer Satisfaction**: Survey feedback on conflict resolution\n- **Merge Velocity**: Time from PR creation to merge\n\n## Risks & Mitigation\n\n- **Breaking Workflows**: All features opt-in, backward compatible\n- **Performance**: Validation is optional, runs only on changed files\n- **Merge Driver Complexity**: Extensive testing, clear fallback\n- **User Confusion**: Documentation, training, gradual rollout\n\n## Future Enhancements\n\n- Predictive collision avoidance\n- Distributed ID generation\n- Semantic merge with LLM\n- Web-based conflict visualization UI\n- Branch-aware workflows\n","priority":0,"archived":0,"archived_at":null,"created_at":"2025-10-31 07:22:36","updated_at":"2025-11-03T03:10:12.590Z","parent_id":null,"parent_uuid":null,"relationships":[],"tags":["data-integrity","git","infrastructure","multi-developer"]}
{"id":"SPEC-014","uuid":"52d430bc-c5be-4b16-9de9-d0af3ff9726f","title":"Execution Logs Design","file_path":"specs/execution_logs_design.md","content":"# Execution Logs Design\n\n## Overview\n\nExecution logs provide full history replay and debugging capabilities for agent executions. The design is inspired by vibe-kanban's approach but adapted for sudocode's durable file storage model.\n\n## Architecture\n\n### Storage Layers\n\n```\n┌─────────────────────────────────────────────────────────┐\n│                    Execution Logs                        │\n├─────────────────────────────────────────────────────────┤\n│                                                          │\n│  Layer 1: Real-time Streaming (AG-UI Protocol)          │\n│  ├─ SSE/WebSocket to frontend                           │\n│  ├─ Tool calls, file changes, progress                  │\n│  └─ Ephemeral - not persisted                           │\n│                                                          │\n│  Layer 2: Database Cache (execution_logs table)         │\n│  ├─ JSONL format in SQLite                              │\n│  ├─ Append-only for efficiency                          │\n│  ├─ One record per execution                            │\n│  └─ Fast local access                                   │\n│                                                          │\n│  Layer 3: Durable File Storage (executions.jsonl)       │\n│  ├─ Newline-delimited JSON file                         │\n│  ├─ Version controlled with git                         │\n│  ├─ Includes execution metadata + full logs             │\n│  └─ Similar to issues.jsonl and specs.jsonl             │\n│                                                          │\n└─────────────────────────────────────────────────────────┘\n```\n\n## Database Schema\n\n### execution_logs Table\n\n```sql\nCREATE TABLE execution_logs (\n    execution_id TEXT PRIMARY KEY,\n    logs TEXT NOT NULL DEFAULT '',          -- JSONL format\n    byte_size INTEGER NOT NULL DEFAULT 0,\n    created_at INTEGER NOT NULL DEFAULT (unixepoch()),\n    updated_at INTEGER NOT NULL DEFAULT (unixepoch()),\n    FOREIGN KEY (execution_id) REFERENCES executions(id) ON DELETE CASCADE\n);\n\n-- Indexes\nCREATE INDEX idx_execution_logs_updated_at ON execution_logs(updated_at);\nCREATE INDEX idx_execution_logs_byte_size ON execution_logs(byte_size);\n```\n\n### Relationship\n\n```\nexecutions (1) ←→ (0..1) execution_logs\n```\n\n- One execution can have zero or one log record\n- Logs are optional - only created when detailed logging is enabled\n- Foreign key ensures cascade delete when execution is removed\n\n## Log Message Format\n\n### JSONL Structure\n\nEach line in the `logs` field is a JSON object:\n\n```jsonl\n{\"type\":\"stdout\",\"data\":\"Starting execution...\\n\",\"timestamp\":1730361234567}\n{\"type\":\"ag_ui_event\",\"data\":{\"event\":\"tool_call\",\"payload\":{...}},\"timestamp\":1730361235789}\n{\"type\":\"tool_call\",\"data\":{\"tool\":\"Read\",\"input\":{...},\"output\":{...}},\"timestamp\":1730361236012}\n{\"type\":\"stderr\",\"data\":\"Warning: deprecated API\\n\",\"timestamp\":1730361237345}\n{\"type\":\"user_input\",\"data\":\"Please add error handling\",\"timestamp\":1730361240000}\n{\"type\":\"finished\",\"data\":{\"exitCode\":0},\"timestamp\":1730361250123}\n```\n\n### Message Types\n\n| Type | Description | Data Format |\n|------|-------------|-------------|\n| `stdout` | Standard output | String |\n| `stderr` | Standard error | String |\n| `tool_call` | Tool invocation | `{tool, input, output?, error?}` |\n| `ag_ui_event` | AG-UI protocol event | `{event, payload}` |\n| `user_input` | User feedback/follow-up | String |\n| `system` | System messages | String |\n| `finished` | Completion marker | `{exitCode?, error?}` |\n\n## Append-Only Operations\n\n### Efficient Incremental Updates\n\n```sql\n-- Append a new log line\nUPDATE execution_logs\nSET logs = logs || $new_line,\n    byte_size = byte_size + $line_byte_size,\n    updated_at = unixepoch()\nWHERE execution_id = $execution_id;\n```\n\nBenefits:\n- No need to load entire log into memory\n- Efficient for streaming scenarios\n- Works well with SQLite's page-based storage\n\n## Integration Points\n\n### 1. During Execution (Real-time)\n\n```typescript\n// As execution runs, append log messages\nawait executionLogsService.appendLog(executionId, {\n  type: \"tool_call\",\n  data: { tool: \"Read\", input: { file_path: \"...\" } },\n  timestamp: Date.now()\n});\n```\n\n### 2. After Execution (Sync to File)\n\n```typescript\n// Sync execution and logs to executions.jsonl\nawait syncExecutionToDisk(executionId);\n\n// Format in executions.jsonl:\n{\n  \"execution\": {\n    \"id\": \"exec-123\",\n    \"issueId\": \"ISSUE-001\",\n    \"status\": \"completed\",\n    ...\n  },\n  \"logs\": [\n    {\"type\":\"stdout\",\"data\":\"...\",\"timestamp\":...},\n    ...\n  ]\n}\n```\n\n### 3. Import/Export\n\n```typescript\n// Export executions from cache.db to executions.jsonl\nsudocode export --executions\n\n// Import executions from executions.jsonl to cache.db\nsudocode import --executions\n```\n\n## Use Cases\n\n### 1. Debugging Failed Executions\n\n```typescript\n// Load full execution history\nconst execution = await db.executions.findById('exec-123');\nconst logs = await db.executionLogs.findById('exec-123');\nconst messages = ExecutionLogsUtil.parseJsonl(logs.logs);\n\n// Filter for errors\nconst errors = messages.filter(m => m.type === 'stderr');\n```\n\n### 2. Replay Execution in UI\n\n```typescript\n// Stream historical logs to frontend\nconst messages = ExecutionLogsUtil.parseJsonl(logs.logs);\nfor (const msg of messages) {\n  // Send to UI with original timing\n  await delay(msg.timestamp - prevTimestamp);\n  socket.send(JSON.stringify(msg));\n}\n```\n\n### 3. Generate Execution Report\n\n```typescript\n// Summarize execution activity\nconst logs = ExecutionLogsUtil.parseJsonl(logs.logs);\nconst toolCalls = ExecutionLogsUtil.filterByType(logs, 'tool_call');\nconst filesChanged = toolCalls\n  .filter(t => t.data.tool === 'Write' || t.data.tool === 'Edit')\n  .length;\n```\n\n## Storage Management\n\n### Size Limits\n\n- Default: Store last 10MB of logs per execution\n- Configurable via execution config\n- Old logs can be truncated or archived to file storage\n\n### Cleanup Strategy\n\n```typescript\n// After successful sync to executions.jsonl\nif (config.cleanupLogsAfterSync) {\n  await db.executionLogs.delete(executionId);\n}\n\n// Or compress to summary\nconst summary = summarizeLogs(logs);\nawait db.executions.update(executionId, { summary });\nawait db.executionLogs.delete(executionId);\n```\n\n## Comparison with Vibe-Kanban\n\n| Aspect | Vibe-Kanban | Sudocode |\n|--------|-------------|----------|\n| **Storage Format** | JSONL in SQLite | JSONL in SQLite + file |\n| **Message Types** | Stdout, Stderr, JsonPatch, SessionId | Extended set including tool_call, ag_ui_event |\n| **Append Method** | SQL concatenation | SQL concatenation |\n| **Durable Storage** | SQLite only | SQLite + executions.jsonl |\n| **One-to-One** | execution_process ↔ logs | execution ↔ logs |\n\n## Future Enhancements\n\n1. **Compression**: Gzip logs in database to save space\n2. **Streaming API**: `/api/executions/:id/logs/stream` endpoint\n3. **Search**: Full-text search across logs\n4. **Retention Policy**: Auto-archive old logs to file storage\n5. **Log Levels**: Add severity levels (debug, info, warn, error)\n\n## Implementation Checklist\n\n- [x] Schema definition (`execution_logs` table)\n- [x] TypeScript types (`execution-logs.ts`)\n- [x] Design documentation\n- [ ] Database service layer (`ExecutionLogsService`)\n- [ ] Integration with `ExecutionService`\n- [ ] SSE streaming endpoint\n- [ ] Sync to `executions.jsonl`\n- [ ] Import/export CLI commands\n- [ ] Frontend log viewer component\n","priority":2,"archived":0,"archived_at":null,"created_at":"2025-10-31 09:58:18","updated_at":"2025-11-03T03:10:12.582Z","parent_id":null,"parent_uuid":null,"relationships":[],"tags":[]}
{"id":"SPEC-015","uuid":"9e5b7f07-5fc0-424b-858b-349df045dee0","title":"Git Synchronization Architecture for Multi-Remote and Multi-Worktree","file_path":"specs/git_synchronization_architecture_for_multi_remote_.md","content":"Comprehensive architecture for managing sudocode state across two collaboration scenarios:\n\n**Tier 1: Multi-Remote Synchronization** - Multiple developers on separate machines pushing/pulling to shared remote, with focus on minimizing conflicts through CRDT-inspired structures, ID lock files, and custom merge drivers.\n\n**Tier 2: Local Multi-Worktree Management** - Single developer managing multiple git worktrees locally, with main worktree as leader and centralized coordination for consistency.\n\n## Key Innovations\n\n### Multi-Remote (Tier 1)\n- **CRDT-Inspired Entity Schema**: LWW fields, vector clocks, lamport timestamps for deterministic merging\n- **ID Lock File**: `.sudocode/id-lock.json` with custom merge driver for tracking ID allocations\n- **Custom JSONL Merge Driver**: UUID-based merging with automatic collision resolution\n- **ID Range Reservation**: Developers can reserve ID ranges to prevent collisions\n- **Lamport Clock Resolution**: Deterministic collision resolution without coordination\n\n### Multi-Worktree (Tier 2)\n- **Coordination File**: `.git/sudocode-coordination.json` shared across all worktrees\n- **Main as Leader**: Main worktree is authoritative for ID allocation\n- **Pessimistic Locking**: Claim issues to prevent concurrent work\n- **Fast Sync**: Local filesystem sync without network roundtrips\n- **Guided Merge**: Automated merge-to-main workflow with conflict detection\n\n## Architecture Highlights\n\n**Enhanced Entity Structure**:\n```typescript\n{\n  id: \"ISSUE-043\",           // Display ID\n  uuid: \"aaa-111\",           // True identity\n  version: 5,                // Edit counter\n  lamport_clock: 17,         // Total ordering\n  vector_clock: {...},       // Causality tracking\n  title: LWWField<string>,   // CRDT field\n  content: LWWField<string>, // CRDT field\n}\n```\n\n**ID Lock File** for collision tracking\n**Custom Merge Drivers** for JSONL and lock files\n**Worktree Coordination** for local management\n\n## Implementation Plan\n\n5-week phased rollout:\n1. Enhanced entity schema with CRDT metadata\n2. ID lock file and merge driver\n3. JSONL merge driver with collision resolution\n4. Worktree coordination system\n5. Multi-remote validation and auto-resolution\n\nSee full spec at `specs/git_synchronization_architecture.md` for complete details.\n","priority":0,"archived":0,"archived_at":null,"created_at":"2025-11-01 04:52:31","updated_at":"2025-11-03T03:10:12.589Z","parent_id":null,"parent_uuid":null,"relationships":[],"tags":["crdt","distributed-systems","git","infrastructure","synchronization","worktree"]}
{"id":"SPEC-016","uuid":"def61b37-9524-4c17-8857-a35885619d2a","title":"Durable Execution Event Storage","file_path":"specs/durable_execution_event_storage.md","content":"# Durable Execution Event Storage\n\n## Overview\n\nEnhance the execution event system to persist both raw agent output AND AG-UI protocol events to the database, enabling complete durable storage that survives server restarts and allows historical access to execution data.\n\n## Problem Statement\n\nCurrently, execution events are only stored in an in-memory `EventBuffer` which has several limitations:\n\n1. **Ephemeral**: Events are lost on server restart\n2. **Limited History**: Buffer is pruned after 1 hour of inactivity\n3. **Race Conditions**: Clients connecting late may miss events if buffer is cleared\n4. **Memory Constraints**: Unbounded growth for long-running executions\n5. **No Persistence**: Cannot view execution details after server restart\n6. **Incomplete Data**: AG-UI events lose some original agent message context\n\n## Goals\n\n1. **Durability**: Execution events survive server restarts\n2. **Completeness**: Store both raw agent messages and AG-UI events\n3. **Historical Access**: View execution details days/weeks after completion\n4. **Efficient Storage**: Indexed, queryable database storage\n5. **Performance**: Maintain fast event delivery to active clients\n6. **Backwards Compatible**: Work with existing EventBuffer for active executions\n\n## Storage Strategy: Two-Track Approach\n\n### Track 1: Raw Agent Output (Complete)\nStore original agent messages as-is for debugging and regeneration:\n- Full Claude stream-json messages\n- Preserves all metadata (message IDs, model, stop reasons)\n- Appendable (newline-delimited JSON)\n- Useful for debugging and audit trails\n\n### Track 2: AG-UI Events (Structured)\nStore transformed AG-UI events for fast replay:\n- Pre-processed events ready for frontend\n- Indexed by sequence and type\n- Queryable by event type, time range\n- Optimized for SSE streaming\n\n## Architecture\n\n**Dual-Write with Dual-Track Storage**:\n```\n┌───────────────────────────────────────────────────────────┐\n│              ClaudeCodeOutputProcessor                     │\n│                                                            │\n│  Raw Line ──┬──> Parse ──> OutputMessage                  │\n│             │                    │                         │\n│             │                    ▼                         │\n│             │            AG-UI Transformation             │\n│             │                    │                         │\n└─────────────┼────────────────────┼─────────────────────────┘\n              │                    │\n              │                    │\n              ▼                    ▼\n      ┌──────────────┐    ┌──────────────┐\n      │ Raw Logs     │    │ AG-UI Events │\n      │ (append)     │    │ (structured) │\n      └──────────────┘    └──────────────┘\n              │                    │\n              └────────┬───────────┘\n                       ▼\n            ┌────────────────────┐\n            │  execution_logs    │\n            │   (database)       │\n            └────────────────────┘\n                       │\n                       ▼\n               ┌──────────────┐\n               │ EventBuffer  │\n               │ (in-memory)  │\n               └──────────────┘\n                       │\n                       ▼\n                 SSE Clients\n```\n\n## Database Schema\n\n### Updated `execution_logs` Table\n\n**Current Schema**:\n```sql\nCREATE TABLE IF NOT EXISTS execution_logs (\n    execution_id TEXT PRIMARY KEY,\n    logs TEXT NOT NULL DEFAULT '',\n    byte_size INTEGER NOT NULL DEFAULT 0,\n    created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,\n    updated_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,\n    FOREIGN KEY (execution_id) REFERENCES executions(id) ON DELETE CASCADE\n);\n```\n\n**Updated Schema**:\n```sql\nCREATE TABLE IF NOT EXISTS execution_logs (\n    execution_id TEXT PRIMARY KEY,\n    \n    -- Raw agent output (append-only, newline-delimited JSON)\n    raw_logs TEXT NOT NULL DEFAULT '',\n    raw_logs_byte_size INTEGER NOT NULL DEFAULT 0,\n    raw_logs_line_count INTEGER NOT NULL DEFAULT 0,\n    \n    -- AG-UI events (JSON array of structured events)\n    ag_ui_events TEXT NOT NULL DEFAULT '[]',\n    ag_ui_events_count INTEGER NOT NULL DEFAULT 0,\n    \n    -- Metadata\n    last_sequence_number INTEGER NOT NULL DEFAULT -1,\n    created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,\n    updated_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,\n    \n    FOREIGN KEY (execution_id) REFERENCES executions(id) ON DELETE CASCADE\n);\n```\n\n**Design Decisions**:\n- **Single table**: All execution logs/events in one place\n- **`raw_logs`**: Newline-delimited JSON, append-only, preserves everything\n- **`ag_ui_events`**: JSON array of AG-UI events with sequence numbers\n- **Counts**: Track line/event counts for fast metadata queries\n- **`last_sequence_number`**: Track latest sequence for appending\n- **One row per execution**: Simple PRIMARY KEY, no pagination needed for typical executions\n\n### Indexes\n\n```sql\nCREATE INDEX IF NOT EXISTS idx_execution_logs_updated_at \n    ON execution_logs(updated_at);\nCREATE INDEX IF NOT EXISTS idx_execution_logs_byte_size \n    ON execution_logs(raw_logs_byte_size);\nCREATE INDEX IF NOT EXISTS idx_execution_logs_event_count \n    ON execution_logs(ag_ui_events_count);\n```\n\n## Data Format Examples\n\n### Raw Logs Format\nNewline-delimited JSON (NDJSON), one Claude message per line:\n```\n{\"type\":\"assistant\",\"message\":{\"id\":\"msg_1\",\"content\":[{\"type\":\"text\",\"text\":\"Let me help\"}]}}\n{\"type\":\"assistant\",\"message\":{\"id\":\"msg_2\",\"content\":[{\"type\":\"tool_use\",\"id\":\"tool_1\",\"name\":\"Read\",\"input\":{...}}]}}\n{\"type\":\"tool_result\",\"result\":{\"tool_use_id\":\"tool_1\",\"content\":[{\"type\":\"text\",\"text\":\"...\"}]}}\n```\n\n### AG-UI Events Format\nJSON array with sequence numbers:\n```json\n[\n  {\"sequence\": 0, \"event\": {\"type\": \"RUN_STARTED\", \"runId\": \"...\", \"timestamp\": 123}},\n  {\"sequence\": 1, \"event\": {\"type\": \"TOOL_CALL_START\", \"toolCallId\": \"tool_1\", \"timestamp\": 124}},\n  {\"sequence\": 2, \"event\": {\"type\": \"TOOL_CALL_ARGS\", \"toolCallId\": \"tool_1\", \"delta\": \"...\", \"timestamp\": 125}}\n]\n```\n\n## Component Design\n\n### 1. ExecutionLogsStore Service\n\n**File**: `server/src/services/execution-logs-store.ts`\n\n**Responsibilities**:\n- Append raw agent output lines\n- Append AG-UI events with sequence numbers\n- Query logs and events\n- Provide statistics\n\n**Key Methods**:\n```typescript\nclass ExecutionLogsStore {\n  // Initialize logs for new execution\n  initializeLogs(executionId: string): void\n  \n  // Append raw agent output\n  appendRawLog(executionId: string, line: string): void\n  appendRawLogs(executionId: string, lines: string[]): void\n  \n  // Append AG-UI events\n  appendEvent(executionId: string, event: AgUiEvent): number  // Returns sequence number\n  appendEvents(executionId: string, events: AgUiEvent[]): number[]\n  \n  // Read operations\n  getRawLogs(executionId: string): string[]\n  getAgUiEvents(executionId: string, fromSequence?: number): BufferedEvent[]\n  getLogMetadata(executionId: string): LogMetadata\n  \n  // Cleanup\n  deleteLogs(executionId: string): void\n  pruneOldLogs(olderThanMs: number): number\n  \n  // Statistics\n  getStats(): StorageStats\n}\n```\n\n**Performance Considerations**:\n- Use SQLite transactions for batch appends\n- Parse JSON only when needed\n- Keep metadata (counts, sizes) updated incrementally\n- Consider JSONB extension for event queries (future)\n\n### 2. Dual Persistence in ExecutionService\n\n**File**: `server/src/services/execution-service.ts`\n\n**Changes**:\n```typescript\n// In createExecution(), capture both raw output and AG-UI events\n\nlet lineBuffer = '';\nengine = new SimpleExecutionEngine(processManager, {\n  maxConcurrent: 1,\n  onOutput: (data, type) => {\n    if (type === 'stdout') {\n      lineBuffer += data.toString();\n      let newlineIndex;\n      while ((newlineIndex = lineBuffer.indexOf('\\n')) !== -1) {\n        const line = lineBuffer.slice(0, newlineIndex);\n        lineBuffer = lineBuffer.slice(newlineIndex + 1);\n        \n        if (line.trim()) {\n          // 1. Store raw line immediately\n          logsStore.appendRawLog(execution.id, line).catch(err => {\n            console.error('Failed to store raw log:', err);\n          });\n          \n          // 2. Process through AG-UI pipeline\n          agUiSystem.processor.processLine(line).catch((err) => {\n            console.error('[ExecutionService] Error processing output line:', err);\n          });\n        }\n      }\n    }\n  },\n});\n\n// Connect processor to adapter - adapter will persist AG-UI events\nagUiSystem.adapter.onEvent((event) => {\n  logsStore.appendEvent(execution.id, event).catch(err => {\n    console.error('Failed to store AG-UI event:', err);\n  });\n});\n```\n\n### 3. TransportManager Integration\n\n**File**: `server/src/execution/transport/transport-manager.ts`\n\n**Changes**:\n```typescript\nclass TransportManager {\n  private logsStore: ExecutionLogsStore | null;\n  \n  constructor(config?: { enablePersistence?: boolean }) {\n    if (config?.enablePersistence) {\n      this.logsStore = new ExecutionLogsStore(getDatabase());\n    }\n  }\n  \n  broadcastToRun(runId: string, event: AgUiEvent): void {\n    // 1. Add to in-memory buffer (fast, for active clients)\n    this.eventBuffer.addEvent(runId, event);\n    \n    // 2. Events are persisted by ExecutionService listener (see above)\n    \n    // 3. Broadcast to connected clients\n    this.sseTransport.broadcastToRun(runId, event);\n  }\n  \n  getBufferedEvents(runId: string, fromSequence?: number): BufferedEvent[] {\n    // Try database first (durable), fallback to memory\n    if (this.logsStore) {\n      try {\n        const dbEvents = this.logsStore.getAgUiEvents(runId, fromSequence);\n        if (dbEvents.length > 0) {\n          console.log('[TransportManager] Loaded events from database', {\n            runId, eventCount: dbEvents.length, fromSequence\n          });\n          return dbEvents;\n        }\n      } catch (err) {\n        console.warn('[TransportManager] Database load failed, using buffer:', err);\n      }\n    }\n    return this.eventBuffer.getEvents(runId, fromSequence);\n  }\n}\n```\n\n### 4. SSE Endpoint\n\n**File**: `server/src/routes/executions-stream.ts`\n\n**No changes needed** - existing code already uses `transportManager.getBufferedEvents()`\n\n### 5. Cleanup Service\n\n**File**: `server/src/services/execution-logs-cleanup.ts`\n\n```typescript\nexport class ExecutionLogsCleanup {\n  private store: ExecutionLogsStore;\n  \n  start(intervalMs: number, retentionMs: number): void {\n    setInterval(() => this.runCleanup(retentionMs), intervalMs);\n    this.runCleanup(retentionMs); // Run immediately\n  }\n  \n  private runCleanup(retentionMs: number): void {\n    const pruned = this.store.pruneOldLogs(retentionMs);\n    const stats = this.store.getStats();\n    console.log('[ExecutionLogsCleanup] Cleanup completed', {\n      prunedExecutions: pruned,\n      totalExecutions: stats.totalExecutions,\n      avgEventsPerExecution: stats.avgEventsPerExecution.toFixed(2),\n    });\n  }\n}\n```\n\n**Cleanup Strategy**:\n- Delete all logs for completed executions older than retention period\n- Optionally keep only raw logs (smaller) or only AG-UI events (structured)\n- Configurable per-execution retention in future\n\n## Migration Plan\n\n### Phase 1: Schema Update\n1. Update `EXECUTION_LOGS_TABLE` in `types/src/schema.ts`\n2. Create migration function in `server/src/services/db.ts`\n3. Handle existing data (if any - likely none since table unused)\n\n### Phase 2: Storage Service\n1. Implement `ExecutionLogsStore` service\n2. Add methods for raw logs and AG-UI events\n3. Write comprehensive unit tests\n\n### Phase 3: Integration\n1. Update `ExecutionService` to capture raw output\n2. Add event listener to persist AG-UI events\n3. Update `TransportManager` to read from database\n4. Initialize `logsStore` in server startup\n\n### Phase 4: Cleanup\n1. Implement `ExecutionLogsCleanup` service\n2. Start cleanup job on server init\n3. Add graceful shutdown handling\n\n### Phase 5: Testing\n1. Unit tests for `ExecutionLogsStore`\n2. Integration tests for end-to-end persistence\n3. Test server restart scenarios\n4. Test cleanup and pruning logic\n5. Verify both raw logs and AG-UI events are persisted\n\n## Storage Size Analysis\n\n**Typical Execution**:\n- 100 Claude messages × 500 bytes = 50 KB raw logs\n- 500 AG-UI events × 200 bytes = 100 KB events\n- **Total: ~150 KB per execution**\n\n**1000 Executions**: ~150 MB (manageable)\n**With 30-day retention**: Depends on execution frequency\n\n**Optimization Options**:\n1. Compress old logs (gzip can achieve 5-10x compression on JSON)\n2. Prune detailed events, keep summaries\n3. Move to separate archive table after N days\n4. Use SQLite's JSON features for selective queries\n\n## Configuration\n\n```typescript\ninterface ServerConfig {\n  executionLogs: {\n    enablePersistence: boolean;      // Default: true\n    storeRawLogs: boolean;           // Default: true\n    storeAgUiEvents: boolean;        // Default: true\n    cleanupIntervalMs: number;       // Default: 3600000 (1 hour)\n    retentionMs: number;             // Default: 2592000000 (30 days)\n    compressOldLogs: boolean;        // Default: false (future)\n  }\n}\n```\n\n## Success Criteria\n\n1. ✅ Both raw logs and AG-UI events persist across server restarts\n2. ✅ Frontend can load execution history from any point in time\n3. ✅ Can regenerate AG-UI events from raw logs if needed\n4. ✅ No performance degradation for active executions\n5. ✅ Database queries complete in < 100ms for typical executions\n6. ✅ Storage grows predictably with configurable cleanup\n7. ✅ All tests pass including new persistence tests\n\n## Benefits of Two-Track Storage\n\n✅ **Completeness**: Raw logs preserve everything for debugging\n✅ **Performance**: AG-UI events ready for instant replay\n✅ **Flexibility**: Can regenerate different event formats from raw logs\n✅ **Audit Trail**: Complete record of agent interactions\n✅ **Simple Schema**: Single table, one row per execution\n✅ **Efficient**: Text storage is cheap, JSON is queryable\n\n## Trade-offs\n\n**Pros**:\n- Complete data retention\n- Fast event replay\n- Debugging capabilities\n- Future-proof (can regenerate events)\n\n**Cons**:\n- ~2x storage (raw + events)\n- Slightly more complex append logic\n- Need to parse JSON on read\n\n**Mitigation**:\n- Prune old executions aggressively\n- Compress archived logs\n- Store only critical events after N days\n\n## Non-Goals\n\n- Real-time log streaming (use SSE for active executions)\n- Full-text search on logs (can be added later)\n- Multi-server log synchronization (single server for now)\n- Log compression (future optimization)\n\n## Future Enhancements\n\n1. **Selective Storage**: Option to store only raw OR only events\n2. **Compression**: Gzip old logs for 5-10x space savings\n3. **Archive Table**: Move old logs to separate table\n4. **Log Export**: Download execution logs as JSON/text\n5. **Log Replay**: Regenerate AG-UI events from raw logs\n6. **Filtering API**: REST endpoint to query logs/events\n7. **JSONB**: Use SQLite JSON functions for event queries\n\n## Related Components\n\n- [[SPEC-007]]: Output Processing Layer (generates events)\n- [[SPEC-009]]: AG-UI Protocol (event format)\n- Event Buffer (`server/src/execution/transport/event-buffer.ts`)\n- Transport Manager (`server/src/execution/transport/transport-manager.ts`)\n- Database Schema (`types/src/schema.ts`)\n\n## References\n\n- AG-UI Protocol: https://github.com/anthropics/anthropic-quickstarts/tree/main/computer-use-demo/ui\n- Claude Stream JSON Format: Claude Code CLI output format\n- NDJSON: http://ndjson.org/\n- SQLite JSON: https://www.sqlite.org/json1.html","priority":1,"archived":0,"archived_at":null,"created_at":"2025-11-03 10:03:41","updated_at":"2025-11-03 10:22:11","parent_id":null,"parent_uuid":null,"relationships":[],"tags":["ag-ui","database","events","execution","persistence"]}
{"id":"SPEC-017","uuid":"193cbc9e-9a6f-4db4-b93b-1e7f2e414d66","title":"CopilotKit UI Migration Specification","file_path":"specs/copilotkit_ui_migration_specification.md","content":"# CopilotKit UI Migration Specification\n\n## Overview\nThis specification outlines the migration from custom AG-UI React components to CopilotKit's pre-built UI library. CopilotKit, created by the AG-UI protocol authors, provides production-ready React components that natively consume AG-UI events, allowing us to reduce ~85% of our custom UI code while gaining additional features.\n\n## Background\n\n### Current Implementation\n- **Custom Components**: `ExecutionMonitor`, `AgentTrajectory`, `MessageStream` (~1,500 LOC)\n- **Custom Hook**: `useAgUiStream` for AG-UI event consumption (~650 LOC)\n- **Manual SSE**: Direct EventSource connection management\n- **Custom State Management**: Manual tracking of messages, tool calls, execution state\n\n### Problems with Current Approach\n1. **High Maintenance Burden**: Custom UI code requires ongoing maintenance\n2. **Missing Features**: Lack of built-in threading, error handling, accessibility\n3. **Code Duplication**: Reimplementing patterns that CopilotKit provides\n4. **Limited Resources**: Team time better spent on core features\n\n## Goals\n\n### Primary Goals\n1. **Reduce UI Code by 85%+**: Replace custom components with CopilotKit\n2. **Improve UX**: Leverage CopilotKit's polished, battle-tested UI\n3. **Maintain Compatibility**: Keep AG-UI protocol integration intact\n4. **Zero Downtime**: Migrate incrementally without breaking existing features\n\n### Secondary Goals\n1. **Better Accessibility**: WCAG-compliant components out of the box\n2. **Responsive Design**: Mobile-friendly execution monitoring\n3. **Extensibility**: Easier to add new features using CopilotKit patterns\n4. **Developer Experience**: Reduce onboarding time for new developers\n\n## Architecture\n\n### Component Mapping\n\n| Current Component | CopilotKit Replacement | Lines Saved |\n|-------------------|------------------------|-------------|\n| `ExecutionMonitor` | `CopilotSidebar` or `CopilotChat` | ~350 |\n| `AgentTrajectory` | `useCopilotChatHeadless_c` + built-in rendering | ~280 |\n| `MessageStream` | Built-in message rendering | ~125 |\n| `useAgUiStream` | `useCoAgent` + `useCoAgentStateRender` | ~650 |\n| Tool call rendering | `useCopilotAction` with `render` | ~200 |\n| **Total** | | **~1,605 LOC** |\n\n### New Architecture\n\n```\n┌─────────────────────────────────────────┐\n│         CopilotKit Provider             │\n│  (Handles AG-UI connection & state)     │\n└──────────────┬──────────────────────────┘\n               │\n       ┌───────┴────────┐\n       │                │\n   ┌───▼────┐      ┌────▼────┐\n   │ UI     │      │ Headless│\n   │ Layer  │      │ Hooks   │\n   └────────┘      └─────────┘\n       │                │\n   ┌───▼────────────────▼───┐\n   │   Your Application     │\n   │   - Execution Pages    │\n   │   - Issue Management   │\n   └────────────────────────┘\n```\n\n### Runtime Connection\n\n```\nFrontend (React)              Backend (Node.js)\n┌──────────────┐             ┌──────────────┐\n│ CopilotKit   │             │ AG-UI Events │\n│   Provider   │─────HTTP────▶ SSE Stream   │\n└──────────────┘             └──────────────┘\n       │                            │\n       │ AG-UI Protocol             │\n       ▼                            ▼\n┌──────────────┐             ┌──────────────┐\n│ CopilotChat  │             │ Execution    │\n│ Component    │             │ Monitor      │\n└──────────────┘             └──────────────┘\n```\n\n## Implementation Plan\n\n### Phase 1: Setup & Proof of Concept (1-2 days)\n\n#### 1.1 Install Dependencies\n```bash\nnpm install @copilotkit/react-ui @copilotkit/react-core @copilotkit/runtime\n```\n\n**Dependencies Added:**\n- `@copilotkit/react-ui`: Pre-built UI components\n- `@copilotkit/react-core`: Headless hooks and core functionality\n- `@copilotkit/runtime`: Runtime for AG-UI integration\n\n#### 1.2 Create Runtime Endpoint\nCreate `/api/copilotkit/route.ts` to bridge CopilotKit with existing AG-UI streams.\n\n**Key Components:**\n- `CopilotRuntime`: Manages agent connections\n- `HttpAgent`: Connects to existing AG-UI SSE endpoints\n- Route handler for POST requests\n\n#### 1.3 Create Proof-of-Concept Page\nCreate `ExecutionPageCopilotKit.tsx` to demonstrate CopilotKit working alongside existing implementation.\n\n**Success Criteria:**\n- CopilotKit connects to existing AG-UI stream\n- Messages display in CopilotKit UI\n- Tool calls render properly\n- No regressions in existing execution page\n\n### Phase 2: Component Migration (2-3 days)\n\n#### 2.1 Migrate ExecutionMonitor\nReplace `<ExecutionMonitor>` with `<CopilotSidebar>`.\n\n**Before:**\n```tsx\n<ExecutionMonitor \n  executionId={id} \n  onComplete={handleComplete}\n  onError={handleError}\n/>\n```\n\n**After:**\n```tsx\n<CopilotSidebar\n  labels={{\n    title: \"Execution Monitor\",\n    initial: \"Monitoring execution...\"\n  }}\n  defaultOpen={true}\n/>\n```\n\n**Changes Required:**\n- Update `ExecutionView.tsx`\n- Add CopilotKit provider wrapper\n- Map callbacks to CopilotKit events\n- Update tests\n\n#### 2.2 Migrate Tool Call Rendering\nReplace custom tool call UI with `useCopilotAction`.\n\n**For Each Tool Type:**\n- `Read` → Custom render component\n- `Write` → Custom render component\n- `Edit` → Custom render component\n- `Bash` → Custom render component\n- Issue/Spec operations → Custom render components\n\n**Example:**\n```tsx\nuseCopilotAction({\n  name: \"read_file\",\n  available: \"disabled\", // Render only\n  render: ({ status, args, result }) => (\n    <ToolCallCard\n      name=\"Read\"\n      status={status}\n      args={args}\n      result={result}\n    />\n  )\n});\n```\n\n#### 2.3 Migrate State Management\nReplace `useAgUiStream` with `useCoAgent`.\n\n**Migration Steps:**\n1. Create agent state interface\n2. Replace hook calls\n3. Update state access patterns\n4. Migrate event handlers\n\n### Phase 3: Cleanup & Optimization (1 day)\n\n#### 3.1 Remove Deprecated Components\n- Delete `ExecutionMonitor.tsx`\n- Delete `AgentTrajectory.tsx`\n- Delete `MessageStream.tsx`\n- Delete `useAgUiStream.ts`\n\n#### 3.2 Update Tests\n- Migrate component tests to CopilotKit patterns\n- Add integration tests for runtime endpoint\n- Update E2E tests\n\n#### 3.3 Documentation\n- Update component documentation\n- Add CopilotKit setup guide\n- Create migration guide for future features\n\n### Phase 4: Polish & Launch (1 day)\n\n#### 4.1 Styling & Customization\n- Apply custom theme to CopilotKit components\n- Add custom markdown renderers if needed\n- Adjust layout and spacing\n\n#### 4.2 Performance Optimization\n- Lazy load CopilotKit components\n- Optimize bundle size\n- Add loading states\n\n#### 4.3 Launch\n- Deploy to staging\n- User acceptance testing\n- Deploy to production\n\n## Technical Specifications\n\n### API Surface Changes\n\n#### New Exports\n```typescript\n// src/components/copilotkit/ExecutionCopilot.tsx\nexport function ExecutionCopilot({ executionId }: Props)\n\n// src/components/copilotkit/ToolRenderers.tsx\nexport function useToolRenderers()\nexport function ReadFileRenderer({ args, status, result }: Props)\nexport function WriteFileRenderer({ args, status, result }: Props)\n// ... more renderers\n```\n\n#### Deprecated Exports (Mark for Phase 3 removal)\n```typescript\n// src/components/executions/ExecutionMonitor.tsx (deprecated)\n// src/components/executions/AgentTrajectory.tsx (deprecated)\n// src/components/executions/MessageStream.tsx (deprecated)\n// src/hooks/useAgUiStream.ts (deprecated)\n```\n\n### Configuration\n\n#### Environment Variables\n```bash\n# .env\nCOPILOTKIT_PUBLIC_API_KEY=optional_for_cloud_features\nNEXT_PUBLIC_COPILOTKIT_ENDPOINT=/api/copilotkit\n```\n\n#### CopilotKit Config\n```typescript\n// src/config/copilotkit.ts\nexport const copilotKitConfig = {\n  runtimeUrl: process.env.NEXT_PUBLIC_COPILOTKIT_ENDPOINT,\n  agents: {\n    execution: \"execution_agent\",\n    planning: \"planning_agent\",\n  },\n  theme: {\n    primaryColor: \"#your-brand-color\",\n    borderRadius: \"8px\",\n  },\n};\n```\n\n### Data Flow\n\n#### AG-UI Event Flow\n```\nBackend (Python/Node)\n  │\n  ├─ Emit AG-UI Events\n  │   ├─ TEXT_MESSAGE_START\n  │   ├─ TEXT_MESSAGE_CONTENT\n  │   ├─ TEXT_MESSAGE_END\n  │   ├─ TOOL_CALL_START\n  │   ├─ TOOL_CALL_ARGS\n  │   ├─ TOOL_CALL_END\n  │   └─ TOOL_CALL_RESULT\n  │\n  ▼\nSSE Stream (/api/executions/:id/stream)\n  │\n  ▼\nCopilotKit Runtime (/api/copilotkit)\n  │\n  ├─ Parse AG-UI events\n  ├─ Maintain conversation state\n  └─ Stream to frontend\n  │\n  ▼\nFrontend (React)\n  │\n  ├─ CopilotKit Provider\n  │   ├─ useCoAgent (state management)\n  │   ├─ useCopilotAction (tool rendering)\n  │   └─ useCoAgentStateRender (custom UI)\n  │\n  ▼\nUI Components\n  ├─ CopilotSidebar (execution monitor)\n  ├─ Custom tool renderers\n  └─ Status indicators\n```\n\n## Testing Strategy\n\n### Unit Tests\n- **Tool Renderers**: Test each `useCopilotAction` render function\n- **State Hooks**: Test `useCoAgent` state management\n- **Runtime Endpoint**: Test AG-UI event parsing\n\n### Integration Tests\n- **End-to-End Flow**: Create execution → monitor → complete\n- **Error Handling**: Network errors, AG-UI errors\n- **Real-time Updates**: Verify SSE connection and updates\n\n### Migration Tests\n- **Side-by-Side Comparison**: Run old and new UI in parallel\n- **Feature Parity**: Verify all existing features work\n- **Performance**: Compare bundle size and render performance\n\n## Risks & Mitigations\n\n### Risk 1: CopilotKit Incompatibility\n**Probability**: Low  \n**Impact**: High  \n**Mitigation**: \n- CopilotKit created AG-UI protocol (perfect compatibility)\n- Proof-of-concept in Phase 1 validates compatibility\n- Fallback: Continue with current implementation\n\n### Risk 2: Missing Features\n**Probability**: Medium  \n**Impact**: Medium  \n**Mitigation**:\n- Headless hooks provide full control if needed\n- Custom renderers for specialized requirements\n- Community support for feature requests\n\n### Risk 3: Learning Curve\n**Probability**: Low  \n**Impact**: Low  \n**Mitigation**:\n- Comprehensive documentation available\n- Incremental migration reduces complexity\n- POC phase allows team learning\n\n### Risk 4: Bundle Size Increase\n**Probability**: Medium  \n**Impact**: Low  \n**Mitigation**:\n- Tree-shaking removes unused components\n- Lazy loading for execution pages\n- Monitor bundle size throughout migration\n\n## Success Metrics\n\n### Quantitative Metrics\n- **Code Reduction**: Achieve ≥80% reduction in UI code\n- **Bundle Size**: Maintain or reduce current bundle size\n- **Performance**: Page load time ≤ current implementation\n- **Test Coverage**: Maintain ≥90% test coverage\n\n### Qualitative Metrics\n- **Developer Velocity**: Reduce time to add new features by 50%\n- **Bug Reports**: No increase in UI-related bugs\n- **User Satisfaction**: Equal or better UX feedback\n- **Code Maintainability**: Improved code readability scores\n\n## Timeline\n\n| Phase | Duration | Dependencies |\n|-------|----------|--------------|\n| Phase 1: POC | 1-2 days | None |\n| Phase 2: Migration | 2-3 days | Phase 1 complete |\n| Phase 3: Cleanup | 1 day | Phase 2 complete |\n| Phase 4: Polish | 1 day | Phase 3 complete |\n| **Total** | **5-7 days** | |\n\n**Milestone Dates** (assuming start date):\n- Day 0: Spec approved, begin implementation\n- Day 2: POC complete, decision point\n- Day 5: Migration complete\n- Day 6: Cleanup and tests complete\n- Day 7: Production deployment\n\n## Decision Points\n\n### Day 2: POC Review\n**Decision**: Continue with migration or revert?  \n**Criteria**:\n- ✅ CopilotKit successfully displays AG-UI events\n- ✅ Tool calls render correctly\n- ✅ Performance acceptable\n- ✅ Team comfortable with CopilotKit patterns\n\n**If NO → Abort migration, keep current implementation**  \n**If YES → Proceed to Phase 2**\n\n### Day 5: Feature Parity Check\n**Decision**: Deploy to staging or continue development?  \n**Criteria**:\n- ✅ All existing features working\n- ✅ Tests passing\n- ✅ No performance regressions\n\n## Rollback Plan\n\n### If Issues Found in Production\n1. **Immediate**: Feature flag to show old UI\n2. **Short-term**: Revert to previous deployment\n3. **Long-term**: Fix issues and redeploy\n\n### Rollback Triggers\n- Critical bugs affecting > 10% of users\n- Performance degradation > 20%\n- Data loss or corruption\n- Security vulnerabilities\n\n## Maintenance Plan\n\n### Post-Migration\n1. **Monitor**: Track error rates and performance\n2. **Optimize**: Profile and optimize as needed\n3. **Document**: Update all documentation\n4. **Train**: Team knowledge sharing session\n\n### Long-term\n1. **Updates**: Keep CopilotKit updated quarterly\n2. **Feedback**: Gather user feedback on new UI\n3. **Iterate**: Continuous improvement based on feedback\n4. **Contribute**: Contribute improvements back to CopilotKit\n\n## Approval\n\n### Stakeholders\n- [ ] Engineering Lead - Technical approval\n- [ ] Product Manager - Feature parity approval  \n- [ ] Designer - UX/UI approval\n- [ ] QA Lead - Testing strategy approval\n\n### Sign-off Required From\n- [ ] **Technical Owner**: Confirms architecture soundness\n- [ ] **Product Owner**: Confirms feature requirements met\n- [ ] **Security Team**: Confirms no security concerns\n\n---\n\n## Appendix\n\n### A. CopilotKit Component Reference\n- `CopilotKit`: Root provider component\n- `CopilotChat`: Full-featured chat interface\n- `CopilotSidebar`: Collapsible sidebar chat\n- `CopilotPopup`: Floating popup chat\n- `useCoAgent`: Shared state management hook\n- `useCopilotAction`: Define tools with custom rendering\n- `useCoAgentStateRender`: Custom UI for agent state\n\n### B. AG-UI Event Types Supported\n- ✅ `TEXT_MESSAGE_START`, `TEXT_MESSAGE_CONTENT`, `TEXT_MESSAGE_END`\n- ✅ `TOOL_CALL_START`, `TOOL_CALL_ARGS`, `TOOL_CALL_END`, `TOOL_CALL_RESULT`\n- ✅ `RUN_STARTED`, `RUN_FINISHED`, `RUN_ERROR`\n- ✅ `STEP_STARTED`, `STEP_FINISHED`\n- ✅ `STATE_SNAPSHOT`, `STATE_DELTA`\n- ✅ `CUSTOM` events\n\n### C. Resources\n- **CopilotKit Docs**: https://docs.copilotkit.ai\n- **AG-UI Protocol**: https://www.copilotkit.ai/ag-ui\n- **GitHub Repository**: https://github.com/CopilotKit/CopilotKit\n- **Example Apps**: https://github.com/CopilotKit/CopilotKit/tree/main/examples\n\n### D. Questions & Answers\n\n**Q: Will this break our existing AG-UI backend?**  \nA: No. CopilotKit consumes AG-UI events without requiring backend changes.\n\n**Q: Can we customize the UI?**  \nA: Yes. Deep customization via CSS, custom components, and headless hooks.\n\n**Q: What about our custom tool renderers?**  \nA: Preserved via `useCopilotAction` with custom render functions.\n\n**Q: Is CopilotKit free?**  \nA: Yes, open-source under MIT license. Optional paid cloud features available.\n\n**Q: What if CopilotKit doesn't meet our needs?**  \nA: Fallback to headless hooks for full control, or keep current implementation.","priority":0,"archived":0,"archived_at":null,"created_at":"2025-11-03 18:21:32","updated_at":"2025-11-03 18:21:32","parent_id":null,"parent_uuid":null,"relationships":[],"tags":["architecture","copilotkit","migration","ui"]}
{"id":"SPEC-018","uuid":"eadaa9cf-3f5c-433c-ac46-e8d252b4b515","title":"Hash-Based ID System Migration","file_path":"specs/hash_based_id_system_migration.md","content":"# Overview\n\nMigrate sudocode's ID generation system from sequential IDs (`SPEC-001`, `ISSUE-001`) to hash-based IDs (`s-x7k9`, `i-a3f2`) while maintaining backward compatibility. The new system derives short, stable hash IDs from UUIDs to provide better distributed workflow support while keeping dual ID architecture.\n\n# Motivation\n\n- **Reduce merge conflicts**: Sequential IDs cause conflicts in multi-branch/multi-agent workflows\n- **Stable IDs**: Hash derived from UUID means content changes don't affect ID\n- **Shorter format**: 4-8 character hash IDs vs full 36-character UUIDs for human-facing references\n- **Backwards compatible**: Legacy IDs (`SPEC-001`, `ISSUE-001`) continue to work\n- **Simpler than content-based**: No need for collision remapping since UUID guarantees uniqueness\n\n# Design\n\n## ID Format\n\n### New Format (Hash-Based)\n- **Issues**: `i-{hash}` (e.g., `i-x7k9`, `i-a3f2dd`)\n- **Specs**: `s-{hash}` (e.g., `s-14sh`, `s-9k2p7a`)\n- **Hash length**: Adaptive 4-8 characters based on entity count\n\n### Legacy Format (Sequential)\n- **Issues**: `ISSUE-001`, `ISSUE-042`\n- **Specs**: `SPEC-001`, `SPEC-042`\n- **Support**: Maintained indefinitely, no migration required\n\n## Hash Generation Algorithm\n\n```typescript\n// 1. Generate UUID (once per entity, never changes)\nuuid = crypto.randomUUID()  // \"a3f2e4d1-8c9b-4a5e-9d2f-1b3c4e5a6b7c\"\n\n// 2. Hash the UUID (SHA256 for distribution)\nhash = SHA256(uuid)  // deterministic from UUID\n\n// 3. Convert to base36 (0-9, a-z)\nbase36 = hash.toString(36)  // more compact than hex\n\n// 4. Take first N characters (adaptive length)\nshortHash = base36.substring(0, adaptiveLength(count))\n\n// 5. Format with prefix\nid = prefix + \"-\" + shortHash  // \"i-x7k9p\"\n```\n\n## Adaptive Length Strategy\n\nHash length grows proportionally with entity count to maintain collision probability under 25% (birthday paradox):\n\n| Entity Count | Hash Length | Example ID | Namespace Size |\n|--------------|-------------|------------|----------------|\n| 0-979        | 4 chars     | `i-x7k9`   | ~1.7M          |\n| 980-5,899    | 5 chars     | `i-x7k9p`  | ~60M           |\n| 5,900-34,999 | 6 chars     | `i-x7k9p1` | ~2.2B          |\n| 35,000-211,999 | 7 chars   | `i-x7k9p1a` | ~78B          |\n| 212,000+     | 8 chars     | `i-x7k9p1a4` | ~2.8T         |\n\n**Formula**: Based on birthday paradox probability calculation\n```\nP(collision) ≈ 1 - e^(-n²/2N)\nwhere n = number of items, N = namespace size (36^length)\n```\n\n## Collision Handling\n\nAlthough UUID-based hashing makes collisions extremely rare, the system handles them by trying progressively longer hashes:\n\n```typescript\nfor (let length = baseLength; length <= 8; length++) {\n  candidate = generateHash(uuid, length)\n  if (!exists(candidate)) {\n    return candidate\n  }\n}\nthrow Error(\"Failed to generate unique ID\")\n```\n\n## Database Schema\n\n**No changes required** - the existing dual-ID schema supports both formats:\n\n```typescript\ninterface Issue {\n  id: string;        // \"i-x7k9p\" (new) or \"ISSUE-001\" (legacy)\n  uuid: string;      // \"a3f2e4d1-...\" (unchanged)\n  title: string;\n  content: string;\n  // ... rest unchanged\n}\n\ninterface Spec {\n  id: string;        // \"s-14sh\" (new) or \"SPEC-001\" (legacy)\n  uuid: string;      // \"a3f2e4d1-...\" (unchanged)\n  title: string;\n  content: string;\n  // ... rest unchanged\n}\n```\n\n## ID Validation\n\nSupport both legacy and hash formats:\n\n```typescript\n// Legacy format: SPEC-001, ISSUE-001\nisLegacyID(id) = /^(SPEC|ISSUE)-\\d+$/.test(id)\n\n// Hash format: i-x7k9, s-14sh\nisHashID(id) = /^[is]-[0-9a-z]{4,8}$/.test(id)\n\n// Accept both in all CLI commands and API endpoints\n```\n\n# Implementation Plan\n\n## Phase 1: Core ID Generator\n**Files**: `cli/src/id-generator.ts`\n\n1. Add `getAdaptiveHashLength(count: number): number`\n2. Add `hashUUIDToBase36(uuid: string, length: number): string`\n3. Add `generateHashIDFromUUID(db, uuid, entityType, count): string`\n4. Add `isLegacyID(id: string): boolean`\n5. Add `isHashID(id: string): boolean`\n6. Update `generateSpecId()` to return `{id, uuid}` with hash-based ID\n7. Update `generateIssueId()` to return `{id, uuid}` with hash-based ID\n\n## Phase 2: CLI Operations\n**Files**: `cli/src/operations/*.ts`\n\nUpdate all operations that create issues/specs:\n1. `cli/src/operations/issue.ts` - `createIssue()`\n2. `cli/src/operations/spec.ts` - `createSpec()`\n3. Handle returned `{id, uuid}` tuple from generator\n4. Support both legacy and hash IDs in lookups\n\n## Phase 3: MCP Server\n**Files**: `mcp/src/sudocode.ts`\n\nUpdate MCP tools to handle both ID formats:\n1. `upsert_issue` - use new generator\n2. `upsert_spec` - use new generator\n3. `show_issue`, `show_spec` - support both formats\n4. `list_issues`, `list_specs` - display both formats\n\n## Phase 4: Frontend\n**Files**: `frontend/src/components/**/*.tsx`\n\nUpdate UI components to handle both formats:\n1. ID parsing and validation\n2. Display formatting (no prefix confusion)\n3. Search/filter by either format\n\n## Phase 5: Server\n**Files**: `server/src/services/db.ts`, `server/src/routes/*.ts`\n\n1. Update database service to use new generator\n2. Support both formats in all API endpoints\n3. Update TypeScript types if needed\n\n## Phase 6: Tests\nUpdate all test files to:\n1. Test hash ID generation\n2. Test adaptive length scaling\n3. Test collision handling\n4. Test legacy ID compatibility\n5. Test both formats in all operations\n\n# Migration Strategy\n\n## For Users\n\n**No action required** - the migration is transparent:\n\n1. **Existing entities**: Keep their legacy IDs (`SPEC-001`, `ISSUE-001`) forever\n2. **New entities**: Automatically get hash IDs (`s-x7k9`, `i-a3f2`)\n3. **References**: Both formats work in all commands and content\n4. **No data migration**: System supports both formats simultaneously\n\n## For Content References\n\nContent references remain stable:\n\n```markdown\n# In a spec or issue:\nSee [[ISSUE-001]] for details  ✅ works\nSee [[i-x7k9p]] for details     ✅ works\n```\n\nLegacy IDs in existing content continue to work since those entities keep their IDs.\n\n## Optional Migration Command\n\nFor users who want uniform IDs, provide optional migration:\n\n```bash\n# NOT implemented in Phase 1, but possible future enhancement\n$ sudocode migrate --to-hash-ids\n\n# Would update:\n# 1. Regenerate hash IDs from existing UUIDs\n# 2. Update all content references\n# 3. Provide rollback capability\n```\n\n# Benefits\n\n1. **Stability**: Hash from UUID means content changes don't affect ID\n2. **Uniqueness**: UUID guarantees no collisions (simpler than beads)\n3. **Brevity**: 4-8 chars vs 36-char UUID\n4. **Backwards compatible**: Legacy IDs continue working\n5. **Adaptive**: Grows with database size\n6. **Distributed-friendly**: No counter coordination needed\n7. **Simpler implementation**: No nonce/remapping logic needed\n\n# Trade-offs\n\n## Advantages over Current System\n- ✅ Fewer merge conflicts in multi-branch workflows\n- ✅ No sequential counter coordination\n- ✅ Shorter than displaying full UUIDs\n\n## Advantages over Beads' System\n- ✅ Stable IDs (content changes don't affect hash)\n- ✅ Simpler (no nonce, no remapping)\n- ✅ UUID guarantees uniqueness\n\n## Disadvantages\n- ❌ Loss of chronological ordering (can't tell `i-x7k9` is newer than `i-a3f2`)\n- ❌ Slightly less human-readable than sequential numbers\n- ❌ Migration adds complexity to codebase\n\n# Testing Strategy\n\n## Unit Tests\n1. Hash generation from UUID\n2. Base36 encoding correctness\n3. Adaptive length calculation\n4. Collision detection and handling\n5. Legacy ID detection\n6. Hash ID validation\n\n## Integration Tests\n1. Create issue with hash ID\n2. Create spec with hash ID\n3. Lookup by hash ID\n4. Lookup by legacy ID\n5. Mixed format in relationships\n6. Content references with both formats\n\n## Property Tests\n1. Hash determinism (same UUID → same hash)\n2. Collision probability matches theory\n3. Hash length increases correctly with count\n4. All generated IDs pass validation\n\n# Rollout Plan\n\n1. **Alpha**: Merge to main, flag as experimental\n2. **Beta**: Test with development team for 1-2 weeks\n3. **Release**: Include in next minor version with migration guide\n4. **Documentation**: Update README and docs with new ID format\n\n# Future Enhancements\n\n1. **Substring matching**: Support `sudocode show x7k9` (no prefix)\n2. **Migration command**: Optional tool to migrate legacy IDs\n3. **ID analytics**: Track hash length distribution\n4. **Custom prefixes**: Allow users to configure prefixes beyond `i-` and `s-`","priority":1,"archived":0,"archived_at":null,"created_at":"2025-11-04 18:53:23","updated_at":"2025-11-04 18:53:23","parent_id":null,"parent_uuid":null,"relationships":[],"tags":[]}
{"id":"SPEC-019","uuid":"2dd21db4-c6d4-4de3-a1ff-8d3bc586af41","title":"JSONL Merge Conflict Resolver","file_path":"specs/jsonl_merge_conflict_resolver.md","content":"\n# JSONL Merge Conflict Resolver\n\n## Overview\n\nImplement automatic merge conflict resolution for `issues.jsonl` and `specs.jsonl` files. This utility will resolve git merge conflicts deterministically using UUID-based deduplication and timestamp-based prioritization. The implementation includes both a manual CLI command and an optional git merge driver for seamless integration with git workflows.\n\n## Problem Statement\n\nWhen multiple developers work on separate branches and modify issues or specs, git merges can produce conflicts in JSONL files:\n\n```jsonl\n{\"id\":\"ISSUE-001\",\"uuid\":\"abc-123\",...}\n<<<<<<< HEAD\n{\"id\":\"ISSUE-002\",\"uuid\":\"def-456\",\"title\":\"Feature A\",\"updated_at\":\"2025-11-01T10:00:00Z\"}\n=======\n{\"id\":\"ISSUE-002\",\"uuid\":\"ghi-789\",\"title\":\"Feature B\",\"updated_at\":\"2025-11-04T10:00:00Z\"}\n>>>>>>> feature-branch\n{\"id\":\"ISSUE-003\",\"uuid\":\"jkl-012\",...}\n```\n\nManual resolution is error-prone and time-consuming. This spec defines an automatic resolution strategy that:\n- Preserves all unique data (no data loss)\n- Resolves conflicts deterministically (same result on any machine)\n- Maintains git-friendly JSONL sorting by `created_at`\n\n## Resolution Strategy\n\n### Core Rules\n\n1. **Different UUIDs** → Keep both entries (they represent different entities)\n   - If IDs conflict, rename the older one deterministically\n   - Example: `ISSUE-042` → `ISSUE-042-conflict-{first-8-chars-of-uuid}`\n\n2. **Same UUID, Same ID** → Keep the entry with most recent `updated_at` timestamp\n   - Merge metadata (relationships, tags) from both versions\n\n3. **Same UUID, Different IDs** → Keep both, rename the older one\n   - This handles race conditions where same entity got different IDs\n\n4. **Sort Result** → All entries sorted by `created_at` after resolution\n\n### Metadata Merging\n\nWhen resolving entries with same UUID/ID, merge:\n- **Relationships**: Union of all unique relationships from both versions\n- **Tags**: Union of all unique tags from both versions\n- **Content**: Use content from entry with most recent `updated_at`\n- **All other fields**: Use values from most recent entry\n\n### Deterministic ID Renaming\n\n```typescript\nfunction generateConflictId(originalId: string, uuid: string): string {\n  // Use first 8 chars of UUID for consistency\n  return `${originalId}-conflict-${uuid.slice(0, 8)}`;\n}\n```\n\nThis ensures:\n- Same UUID always generates same conflict ID\n- Conflict IDs are human-readable\n- No random elements (fully deterministic)\n\n## Implementation Architecture\n\n### File Structure\n\n```\ncli/src/\n├── merge-resolver.ts          # Core resolution logic\n├── cli/\n│   └── merge-commands.ts      # CLI command handlers\n└── cli.ts                     # Register commands\n\ncli/tests/\n└── unit/\n    └── merge-resolver.test.ts # Unit tests\n```\n\n### Core Module: `merge-resolver.ts`\n\n**Responsibilities:**\n- Parse JSONL files with git conflict markers\n- Apply resolution rules to deduplicate entries\n- Merge metadata from conflicting versions\n- Sort final result by `created_at`\n\n**Key Functions:**\n\n```typescript\n/**\n * Parse JSONL file containing git conflict markers\n * Returns structured representation of clean sections and conflicts\n */\nexport function parseMergeConflictFile(content: string): ConflictSection[]\n\ninterface ConflictSection {\n  type: 'clean' | 'conflict';\n  lines: string[];           // Lines without conflict markers\n  ours?: string[];          // Lines from HEAD (between <<<<<<< and =======)\n  theirs?: string[];        // Lines from incoming (between ======= and >>>>>>>)\n  marker?: ConflictMarker;  // Original marker info for debugging\n}\n\ninterface ConflictMarker {\n  start: number;  // Line number of <<<<<<<\n  middle: number; // Line number of =======\n  end: number;    // Line number of >>>>>>>\n  oursLabel: string;   // Label after <<<<<<< (e.g., \"HEAD\")\n  theirsLabel: string; // Label after >>>>>>> (e.g., \"feature-branch\")\n}\n\n/**\n * Resolve all entities using UUID-based deduplication\n * Handles different UUIDs, same UUID conflicts, and metadata merging\n */\nexport function resolveEntities<T extends JSONLEntity>(\n  entities: T[],\n  options?: ResolveOptions\n): ResolvedResult<T>\n\ninterface ResolveOptions {\n  verbose?: boolean;  // Include detailed resolution info\n}\n\ninterface ResolvedResult<T> {\n  entities: T[];           // Deduplicated and sorted entities\n  stats: ResolutionStats;  // What happened during resolution\n}\n\ninterface ResolutionStats {\n  totalInput: number;\n  totalOutput: number;\n  conflicts: ConflictResolution[];\n}\n\ninterface ConflictResolution {\n  type: 'different-uuids' | 'same-uuid-different-id' | 'same-uuid-same-id';\n  uuid: string;\n  originalIds: string[];\n  resolvedIds: string[];\n  action: string;  // Human-readable description\n}\n\n/**\n * Merge metadata from multiple versions of same entity\n */\nexport function mergeMetadata<T extends JSONLEntity>(\n  entities: T[]\n): T\n\n/**\n * Check if file contains git conflict markers\n */\nexport function hasGitConflictMarkers(filePath: string): boolean\n\n/**\n * Three-way merge for git merge driver\n * Merges base, ours, and theirs versions\n */\nexport function mergeThreeWay<T extends JSONLEntity>(\n  base: T[],\n  ours: T[],\n  theirs: T[]\n): ResolvedResult<T>\n```\n\n**Algorithm Details:**\n\n```typescript\nexport function resolveEntities<T extends JSONLEntity>(\n  entities: T[],\n  options: ResolveOptions = {}\n): ResolvedResult<T> {\n  const stats: ResolutionStats = {\n    totalInput: entities.length,\n    totalOutput: 0,\n    conflicts: []\n  };\n\n  // Group entities by UUID\n  const byUuid = new Map<string, T[]>();\n  for (const entity of entities) {\n    if (!byUuid.has(entity.uuid)) {\n      byUuid.set(entity.uuid, []);\n    }\n    byUuid.get(entity.uuid)!.push(entity);\n  }\n\n  const resolved: T[] = [];\n\n  // Process each UUID group\n  for (const [uuid, group] of byUuid) {\n    if (group.length === 1) {\n      // No conflict - single entity with this UUID\n      resolved.push(group[0]);\n      continue;\n    }\n\n    // Check if all have same ID\n    const ids = new Set(group.map(e => e.id));\n\n    if (ids.size === 1) {\n      // Same UUID, same ID → Keep most recent, merge metadata\n      const merged = mergeMetadata(group);\n      resolved.push(merged);\n\n      stats.conflicts.push({\n        type: 'same-uuid-same-id',\n        uuid,\n        originalIds: [group[0].id],\n        resolvedIds: [merged.id],\n        action: `Kept most recent version, merged ${group.length} versions`\n      });\n    } else {\n      // Same UUID, different IDs → Keep all, rename duplicates\n      const sorted = [...group].sort((a, b) =>\n        compareTimestamps(a.updated_at, b.updated_at)\n      );\n\n      // Keep most recent ID as-is\n      const keeper = sorted[sorted.length - 1];\n      resolved.push(keeper);\n\n      const originalIds = [];\n      const resolvedIds = [keeper.id];\n\n      // Rename older versions\n      for (let i = 0; i < sorted.length - 1; i++) {\n        const entity = { ...sorted[i] };\n        originalIds.push(entity.id);\n\n        if (entity.id !== keeper.id) {\n          entity.id = generateConflictId(entity.id, uuid);\n        } else {\n          entity.id = generateConflictId(entity.id, uuid);\n        }\n\n        resolvedIds.push(entity.id);\n        resolved.push(entity);\n      }\n\n      stats.conflicts.push({\n        type: 'same-uuid-different-id',\n        uuid,\n        originalIds,\n        resolvedIds,\n        action: `Renamed ${sorted.length - 1} conflicting IDs`\n      });\n    }\n  }\n\n  // Sort by created_at (git-friendly)\n  resolved.sort((a, b) => {\n    const aDate = a.created_at || '';\n    const bDate = b.created_at || '';\n    if (aDate < bDate) return -1;\n    if (aDate > bDate) return 1;\n    return (a.id || '').localeCompare(b.id || '');\n  });\n\n  stats.totalOutput = resolved.length;\n\n  return { entities: resolved, stats };\n}\n\nexport function mergeMetadata<T extends JSONLEntity>(\n  entities: T[]\n): T {\n  // Sort by updated_at, keep most recent as base\n  const sorted = [...entities].sort((a, b) =>\n    compareTimestamps(b.updated_at, a.updated_at)\n  );\n\n  const base = { ...sorted[0] };\n\n  // Merge relationships (union of unique)\n  const relationshipSet = new Set<string>();\n  for (const entity of entities) {\n    if (entity.relationships) {\n      for (const rel of entity.relationships) {\n        relationshipSet.add(JSON.stringify(rel));\n      }\n    }\n  }\n  base.relationships = Array.from(relationshipSet).map(r => JSON.parse(r));\n\n  // Merge tags (union of unique)\n  const tagSet = new Set<string>();\n  for (const entity of entities) {\n    if (entity.tags) {\n      for (const tag of entity.tags) {\n        tagSet.add(tag);\n      }\n    }\n  }\n  base.tags = Array.from(tagSet);\n\n  return base;\n}\n\nfunction compareTimestamps(a: string | undefined, b: string | undefined): number {\n  if (!a && !b) return 0;\n  if (!a) return -1;\n  if (!b) return 1;\n\n  // Normalize timestamps to ISO format\n  const normalizeTs = (ts: string) => {\n    const hasZone = ts.endsWith('Z') || ts.includes('+') || /[+-]\\d{2}:\\d{2}$/.test(ts);\n    return hasZone ? ts : ts.replace(' ', 'T') + 'Z';\n  };\n\n  const dateA = new Date(normalizeTs(a));\n  const dateB = new Date(normalizeTs(b));\n\n  return dateA.getTime() - dateB.getTime();\n}\n\nfunction generateConflictId(originalId: string, uuid: string): string {\n  return `${originalId}-conflict-${uuid.slice(0, 8)}`;\n}\n```\n\n### CLI Commands Module: `merge-commands.ts`\n\n**Responsibilities:**\n- Handle manual conflict resolution command\n- Handle git merge driver command\n- Provide user-friendly output and error messages\n- Support dry-run mode for safety\n\n**Manual Resolution Command:**\n\n```typescript\nexport async function handleResolveConflicts(\n  db: Database.Database,\n  outputDir: string,\n  options: {\n    dryRun?: boolean;\n    verbose?: boolean;\n    json?: boolean;\n  }\n): Promise<void> {\n  const issuesPath = path.join(outputDir, 'issues.jsonl');\n  const specsPath = path.join(outputDir, 'specs.jsonl');\n\n  // Check for conflicts\n  const issuesHasConflict = fs.existsSync(issuesPath) && hasGitConflictMarkers(issuesPath);\n  const specsHasConflict = fs.existsSync(specsPath) && hasGitConflictMarkers(specsPath);\n\n  if (!issuesHasConflict && !specsHasConflict) {\n    if (!options.json) {\n      console.log(chalk.green('✓ No merge conflicts found in JSONL files'));\n    } else {\n      console.log(JSON.stringify({ success: true, conflicts: 0 }));\n    }\n    return;\n  }\n\n  const results: any[] = [];\n\n  // Resolve issues.jsonl\n  if (issuesHasConflict) {\n    const result = await resolveFile(issuesPath, 'issue', options);\n    results.push({ file: 'issues.jsonl', ...result });\n  }\n\n  // Resolve specs.jsonl\n  if (specsHasConflict) {\n    const result = await resolveFile(specsPath, 'spec', options);\n    results.push({ file: 'specs.jsonl', ...result });\n  }\n\n  // Re-sync to database if not dry-run\n  if (!options.dryRun) {\n    await syncMarkdownToDatabase(db, { outputDir });\n\n    if (!options.json) {\n      console.log(chalk.green('✓ Re-synced to database'));\n    }\n  }\n\n  // Output results\n  if (options.json) {\n    console.log(JSON.stringify({ success: true, results }));\n  } else {\n    printResolveResults(results, options);\n  }\n}\n\nasync function resolveFile(\n  filePath: string,\n  entityType: 'issue' | 'spec',\n  options: { dryRun?: boolean; verbose?: boolean }\n): Promise<any> {\n  // Read file with conflict markers\n  const content = fs.readFileSync(filePath, 'utf8');\n\n  // Parse conflicts\n  const sections = parseMergeConflictFile(content);\n\n  // Extract all entities (from both clean and conflict sections)\n  const allEntities: JSONLEntity[] = [];\n\n  for (const section of sections) {\n    if (section.type === 'clean') {\n      for (const line of section.lines) {\n        if (line.trim()) {\n          try {\n            allEntities.push(JSON.parse(line));\n          } catch (e) {\n            console.warn(chalk.yellow(`Warning: Skipping malformed line: ${line.slice(0, 50)}...`));\n          }\n        }\n      }\n    } else {\n      // Conflict section - include both ours and theirs\n      for (const line of [...(section.ours || []), ...(section.theirs || [])]) {\n        if (line.trim()) {\n          try {\n            allEntities.push(JSON.parse(line));\n          } catch (e) {\n            console.warn(chalk.yellow(`Warning: Skipping malformed line: ${line.slice(0, 50)}...`));\n          }\n        }\n      }\n    }\n  }\n\n  // Resolve conflicts\n  const { entities: resolved, stats } = resolveEntities(allEntities, { verbose: options.verbose });\n\n  // Write back if not dry-run\n  if (!options.dryRun) {\n    await writeJSONL(filePath, resolved);\n  }\n\n  return { stats, entityType };\n}\n\nfunction printResolveResults(results: any[], options: { verbose?: boolean; dryRun?: boolean }): void {\n  for (const result of results) {\n    const { file, stats, entityType } = result;\n\n    console.log(chalk.bold(`\\n${file}:`));\n    console.log(`  Input:  ${stats.totalInput} ${entityType}s`);\n    console.log(`  Output: ${stats.totalOutput} ${entityType}s`);\n\n    if (stats.conflicts.length > 0) {\n      console.log(chalk.yellow(`  Resolved ${stats.conflicts.length} conflict(s):`));\n\n      for (const conflict of stats.conflicts) {\n        if (options.verbose) {\n          console.log(`    - ${conflict.action}`);\n          console.log(`      UUID: ${conflict.uuid}`);\n          console.log(`      IDs: ${conflict.originalIds.join(', ')} → ${conflict.resolvedIds.join(', ')}`);\n        } else {\n          console.log(`    - ${conflict.action}`);\n        }\n      }\n    }\n\n    if (options.dryRun) {\n      console.log(chalk.gray('  (dry-run - no changes written)'));\n    } else {\n      console.log(chalk.green('  ✓ Resolved and written'));\n    }\n  }\n}\n```\n\n**Git Merge Driver Command:**\n\n```typescript\nexport async function handleMergeDriver(options: {\n  base: string;    // Common ancestor version\n  ours: string;    // HEAD version (also used as output)\n  theirs: string;  // Incoming version\n  marker?: number; // Conflict marker size (provided by git)\n}): Promise<void> {\n  try {\n    // Log merge attempt for debugging\n    const logPath = path.join(process.cwd(), '.sudocode', 'merge-driver.log');\n    fs.appendFileSync(\n      logPath,\n      `[${new Date().toISOString()}] Merging: ${options.ours}\\n`\n    );\n\n    // Read all three versions\n    const baseEntities = fs.existsSync(options.base)\n      ? await readJSONL(options.base, { skipErrors: true })\n      : [];\n    const ourEntities = await readJSONL(options.ours, { skipErrors: true });\n    const theirEntities = await readJSONL(options.theirs, { skipErrors: true });\n\n    // Perform three-way merge\n    const { entities: merged, stats } = mergeThreeWay(\n      baseEntities,\n      ourEntities,\n      theirEntities\n    );\n\n    // Write result to output (ours file)\n    await writeJSONL(options.ours, merged);\n\n    // Log success\n    fs.appendFileSync(\n      logPath,\n      `  ✓ Success: ${baseEntities.length} (base) + ${ourEntities.length} (ours) + ${theirEntities.length} (theirs) → ${merged.length} (merged)\\n`\n    );\n\n    // Exit 0 = success, git will use this result\n    process.exit(0);\n\n  } catch (error) {\n    // Log failure\n    const logPath = path.join(process.cwd(), '.sudocode', 'merge-driver.log');\n    fs.appendFileSync(\n      logPath,\n      `  ✗ Failed: ${error instanceof Error ? error.message : String(error)}\\n`\n    );\n\n    // Exit 1 = failure, git will leave conflict markers\n    console.error('Merge driver failed:', error);\n    process.exit(1);\n  }\n}\n```\n\n**Init Merge Driver Setup Command:**\n\n```typescript\nexport async function handleInitMergeDriver(options: {\n  global?: boolean;  // Install globally vs per-repo\n}): Promise<void> {\n  const configFile = options.global\n    ? path.join(os.homedir(), '.gitconfig')\n    : path.join(process.cwd(), '.git', 'config');\n\n  // Check if .git exists (not in global mode)\n  if (!options.global && !fs.existsSync(path.join(process.cwd(), '.git'))) {\n    console.error(chalk.red('Error: Not in a git repository'));\n    console.error('Run this command from a git repository, or use --global');\n    process.exit(1);\n  }\n\n  // Add merge driver config\n  const configSection = `\n[merge \"sudocode-jsonl\"]\n\\tname = Sudocode JSONL automatic merge resolver\n\\tdriver = sudocode merge-driver --base=%O --ours=%A --theirs=%B\n\\trecursive = binary\n`;\n\n  // Check if already configured\n  if (fs.existsSync(configFile)) {\n    const content = fs.readFileSync(configFile, 'utf8');\n    if (content.includes('[merge \"sudocode-jsonl\"]')) {\n      console.log(chalk.yellow('Merge driver already configured in git config'));\n    } else {\n      fs.appendFileSync(configFile, configSection);\n      console.log(chalk.green(`✓ Added merge driver to ${configFile}`));\n    }\n  } else {\n    fs.writeFileSync(configFile, configSection);\n    console.log(chalk.green(`✓ Created ${configFile} with merge driver`));\n  }\n\n  // Add .gitattributes (only for local, not global)\n  if (!options.global) {\n    const gitattributesPath = path.join(process.cwd(), '.gitattributes');\n    const attributesLine = '.sudocode/*.jsonl merge=sudocode-jsonl\\n';\n\n    if (fs.existsSync(gitattributesPath)) {\n      const content = fs.readFileSync(gitattributesPath, 'utf8');\n      if (!content.includes('merge=sudocode-jsonl')) {\n        fs.appendFileSync(gitattributesPath, attributesLine);\n        console.log(chalk.green('✓ Added merge driver to .gitattributes'));\n      } else {\n        console.log(chalk.yellow('Merge driver already configured in .gitattributes'));\n      }\n    } else {\n      fs.writeFileSync(gitattributesPath, attributesLine);\n      console.log(chalk.green('✓ Created .gitattributes with merge driver'));\n    }\n\n    console.log(chalk.cyan('\\nℹ  Remember to commit .gitattributes to share with your team!'));\n  }\n\n  // Test the setup\n  console.log(chalk.bold('\\nTesting merge driver setup...'));\n  const testResult = await testMergeDriver();\n\n  if (testResult.success) {\n    console.log(chalk.green('✓ Merge driver is working correctly'));\n  } else {\n    console.log(chalk.red('✗ Merge driver test failed:'));\n    console.log(chalk.red(`  ${testResult.error}`));\n  }\n}\n\nasync function testMergeDriver(): Promise<{ success: boolean; error?: string }> {\n  // Create temp files for testing\n  const tmpDir = fs.mkdtempSync(path.join(os.tmpdir(), 'sudocode-merge-test-'));\n\n  try {\n    const base = path.join(tmpDir, 'base.jsonl');\n    const ours = path.join(tmpDir, 'ours.jsonl');\n    const theirs = path.join(tmpDir, 'theirs.jsonl');\n\n    // Write test data\n    const testEntity = {\n      id: 'TEST-001',\n      uuid: 'test-uuid-123',\n      title: 'Test',\n      content: 'Test',\n      created_at: '2025-01-01T00:00:00Z',\n      updated_at: '2025-01-01T00:00:00Z',\n      relationships: [],\n      tags: []\n    };\n\n    await writeJSONL(base, [testEntity]);\n    await writeJSONL(ours, [testEntity]);\n    await writeJSONL(theirs, [testEntity]);\n\n    // Test merge driver\n    await handleMergeDriver({ base, ours, theirs });\n\n    // Check result\n    const result = await readJSONL(ours);\n    if (result.length !== 1 || result[0].id !== 'TEST-001') {\n      throw new Error('Unexpected merge result');\n    }\n\n    return { success: true };\n  } catch (error) {\n    return {\n      success: false,\n      error: error instanceof Error ? error.message : String(error)\n    };\n  } finally {\n    // Cleanup\n    fs.rmSync(tmpDir, { recursive: true, force: true });\n  }\n}\n```\n\n### CLI Registration in `cli.ts`\n\n```typescript\n// Import merge command handlers\nimport {\n  handleResolveConflicts,\n  handleMergeDriver,\n  handleInitMergeDriver,\n} from \"./cli/merge-commands.js\";\n\n// Manual conflict resolution command\nprogram\n  .command('resolve-conflicts')\n  .description('Automatically resolve merge conflicts in JSONL files')\n  .option('--dry-run', 'Show what would be done without making changes')\n  .option('--verbose', 'Show detailed resolution information')\n  .action(async (options) => {\n    initDB();\n    await handleResolveConflicts(db!, outputDir, { ...options, json: jsonOutput });\n  });\n\n// Git merge driver command (called by git)\nprogram\n  .command('merge-driver')\n  .description('Git merge driver for JSONL files (called automatically by git)')\n  .requiredOption('--base <path>', 'Base/ancestor version file path')\n  .requiredOption('--ours <path>', 'Our version file path (HEAD)')\n  .requiredOption('--theirs <path>', 'Their version file path (incoming branch)')\n  .option('--marker-size <size>', 'Conflict marker size (provided by git)', parseInt)\n  .action(async (options) => {\n    // Don't call initDB - this runs during git merge, might not have db access\n    await handleMergeDriver(options);\n  });\n\n// Setup merge driver configuration\nprogram\n  .command('init-merge-driver')\n  .description('Configure git to use sudocode for automatic JSONL merge resolution')\n  .option('--global', 'Install globally (all repos) instead of just current repo')\n  .action(async (options) => {\n    await handleInitMergeDriver(options);\n  });\n```\n\n## Testing Strategy\n\n### Unit Tests (`cli/tests/unit/merge-resolver.test.ts`)\n\n**Test Cases:**\n\n```typescript\ndescribe('parseMergeConflictFile', () => {\n  it('should parse file with no conflicts', () => {\n    const content = '{\"id\":\"A\"}\\n{\"id\":\"B\"}\\n';\n    const sections = parseMergeConflictFile(content);\n\n    expect(sections).toHaveLength(1);\n    expect(sections[0].type).toBe('clean');\n    expect(sections[0].lines).toHaveLength(2);\n  });\n\n  it('should parse file with single conflict', () => {\n    const content = `{\"id\":\"A\"}\n<<<<<<< HEAD\n{\"id\":\"B\",\"uuid\":\"uuid-1\"}\n=======\n{\"id\":\"B\",\"uuid\":\"uuid-2\"}\n>>>>>>> feature\n{\"id\":\"C\"}`;\n\n    const sections = parseMergeConflictFile(content);\n\n    expect(sections).toHaveLength(3);\n    expect(sections[0].type).toBe('clean');\n    expect(sections[1].type).toBe('conflict');\n    expect(sections[1].ours).toEqual(['{\"id\":\"B\",\"uuid\":\"uuid-1\"}']);\n    expect(sections[1].theirs).toEqual(['{\"id\":\"B\",\"uuid\":\"uuid-2\"}']);\n    expect(sections[2].type).toBe('clean');\n  });\n\n  it('should handle multiple conflicts', () => {\n    // Test with multiple conflict sections\n  });\n\n  it('should handle nested conflict markers', () => {\n    // Test with conflict markers in content (rare edge case)\n  });\n});\n\ndescribe('resolveEntities', () => {\n  it('should keep single entity unchanged', () => {\n    const entities = [\n      { id: 'A', uuid: 'uuid-1', created_at: '2025-01-01T00:00:00Z', updated_at: '2025-01-01T00:00:00Z' }\n    ];\n\n    const { entities: resolved, stats } = resolveEntities(entities);\n\n    expect(resolved).toHaveLength(1);\n    expect(resolved[0].id).toBe('A');\n    expect(stats.conflicts).toHaveLength(0);\n  });\n\n  it('should keep both entities with different UUIDs', () => {\n    const entities = [\n      { id: 'A', uuid: 'uuid-1', created_at: '2025-01-01', updated_at: '2025-01-01' },\n      { id: 'A', uuid: 'uuid-2', created_at: '2025-01-02', updated_at: '2025-01-02' }\n    ];\n\n    const { entities: resolved, stats } = resolveEntities(entities);\n\n    expect(resolved).toHaveLength(2);\n    expect(resolved[0].id).toBe('A-conflict-uuid-1'); // Older one renamed\n    expect(resolved[1].id).toBe('A'); // Newer one keeps ID\n    expect(stats.conflicts).toHaveLength(1);\n    expect(stats.conflicts[0].type).toBe('same-uuid-different-id');\n  });\n\n  it('should keep most recent when same UUID and ID', () => {\n    const entities = [\n      {\n        id: 'A',\n        uuid: 'uuid-1',\n        title: 'Old',\n        created_at: '2025-01-01T00:00:00Z',\n        updated_at: '2025-01-01T00:00:00Z',\n        relationships: [],\n        tags: ['old']\n      },\n      {\n        id: 'A',\n        uuid: 'uuid-1',\n        title: 'New',\n        created_at: '2025-01-01T00:00:00Z',\n        updated_at: '2025-01-02T00:00:00Z',\n        relationships: [],\n        tags: ['new']\n      }\n    ];\n\n    const { entities: resolved } = resolveEntities(entities);\n\n    expect(resolved).toHaveLength(1);\n    expect(resolved[0].title).toBe('New'); // Most recent\n    expect(resolved[0].tags).toEqual(['old', 'new']); // Merged\n  });\n\n  it('should merge relationships from multiple versions', () => {\n    const entities = [\n      {\n        id: 'A',\n        uuid: 'uuid-1',\n        updated_at: '2025-01-01T00:00:00Z',\n        relationships: [{ from: 'A', to: 'B', type: 'blocks' }]\n      },\n      {\n        id: 'A',\n        uuid: 'uuid-1',\n        updated_at: '2025-01-02T00:00:00Z',\n        relationships: [{ from: 'A', to: 'C', type: 'related' }]\n      }\n    ];\n\n    const { entities: resolved } = resolveEntities(entities);\n\n    expect(resolved).toHaveLength(1);\n    expect(resolved[0].relationships).toHaveLength(2);\n  });\n\n  it('should sort result by created_at', () => {\n    const entities = [\n      { id: 'C', uuid: 'uuid-3', created_at: '2025-03-01', updated_at: '2025-03-01' },\n      { id: 'A', uuid: 'uuid-1', created_at: '2025-01-01', updated_at: '2025-01-01' },\n      { id: 'B', uuid: 'uuid-2', created_at: '2025-02-01', updated_at: '2025-02-01' }\n    ];\n\n    const { entities: resolved } = resolveEntities(entities);\n\n    expect(resolved.map(e => e.id)).toEqual(['A', 'B', 'C']);\n  });\n});\n\ndescribe('mergeThreeWay', () => {\n  it('should handle clean three-way merge', () => {\n    const base = [\n      { id: 'A', uuid: 'uuid-1', title: 'Base', updated_at: '2025-01-01' }\n    ];\n    const ours = [\n      { id: 'A', uuid: 'uuid-1', title: 'Ours', updated_at: '2025-01-02' }\n    ];\n    const theirs = [\n      { id: 'A', uuid: 'uuid-1', title: 'Theirs', updated_at: '2025-01-03' }\n    ];\n\n    const { entities: merged } = mergeThreeWay(base, ours, theirs);\n\n    expect(merged).toHaveLength(1);\n    expect(merged[0].title).toBe('Theirs'); // Most recent\n  });\n\n  it('should handle additions on both sides', () => {\n    const base = [\n      { id: 'A', uuid: 'uuid-1', created_at: '2025-01-01', updated_at: '2025-01-01' }\n    ];\n    const ours = [\n      ...base,\n      { id: 'B', uuid: 'uuid-2', created_at: '2025-01-02', updated_at: '2025-01-02' }\n    ];\n    const theirs = [\n      ...base,\n      { id: 'C', uuid: 'uuid-3', created_at: '2025-01-03', updated_at: '2025-01-03' }\n    ];\n\n    const { entities: merged } = mergeThreeWay(base, ours, theirs);\n\n    expect(merged).toHaveLength(3);\n    expect(merged.map(e => e.id).sort()).toEqual(['A', 'B', 'C']);\n  });\n});\n\ndescribe('hasGitConflictMarkers', () => {\n  it('should detect conflict markers', () => {\n    const tmpFile = path.join(os.tmpdir(), 'test-conflict.jsonl');\n    fs.writeFileSync(tmpFile, '<<<<<<< HEAD\\n{\"id\":\"A\"}\\n=======\\n{\"id\":\"B\"}\\n>>>>>>>\\n');\n\n    expect(hasGitConflictMarkers(tmpFile)).toBe(true);\n\n    fs.unlinkSync(tmpFile);\n  });\n\n  it('should return false for clean file', () => {\n    const tmpFile = path.join(os.tmpdir(), 'test-clean.jsonl');\n    fs.writeFileSync(tmpFile, '{\"id\":\"A\"}\\n{\"id\":\"B\"}\\n');\n\n    expect(hasGitConflictMarkers(tmpFile)).toBe(false);\n\n    fs.unlinkSync(tmpFile);\n  });\n});\n```\n\n### Integration Tests\n\n```typescript\ndescribe('resolve-conflicts command integration', () => {\n  it('should resolve conflicts in issues.jsonl', async () => {\n    // Setup: Create test repo with conflict\n    // Execute: Run resolve-conflicts command\n    // Verify: Check file is clean and entities are correct\n  });\n\n  it('should handle dry-run mode', async () => {\n    // Verify no files are modified in dry-run\n  });\n});\n\ndescribe('merge-driver integration', () => {\n  it('should successfully merge via git', async () => {\n    // Setup: Create git repo with two branches\n    // Create conflicting changes\n    // Verify: Git merge succeeds automatically\n  });\n});\n```\n\n## Usage Documentation\n\n### Manual Conflict Resolution\n\n**Basic usage:**\n```bash\n# After git merge produces conflicts\ngit merge feature-branch\n# Conflict in .sudocode/issues.jsonl!\n\n# Resolve automatically\nsudocode resolve-conflicts\n\n# Review and commit\ngit add .sudocode/issues.jsonl\ngit commit\n```\n\n**Dry-run mode:**\n```bash\n# Preview what would happen without making changes\nsudocode resolve-conflicts --dry-run\n```\n\n**Verbose output:**\n```bash\n# See detailed information about each conflict resolution\nsudocode resolve-conflicts --verbose\n```\n\n**Example output:**\n```\nissues.jsonl:\n  Input:  248 issues\n  Output: 246 issues\n  Resolved 3 conflict(s):\n    - Kept most recent version, merged 2 versions\n    - Renamed 1 conflicting IDs\n    - Kept both ISSUE-042 (different UUIDs)\n  ✓ Resolved and written\n\nspecs.jsonl:\n  Input:  87 specs\n  Output: 87 specs\n  No conflicts\n  ✓ Resolved and written\n\n✓ Re-synced to database\n```\n\n### Git Merge Driver Setup\n\n**One-time setup (per repository):**\n```bash\n# Configure git to use sudocode merge driver\nsudocode init-merge-driver\n\n# Output:\n# ✓ Added merge driver to .git/config\n# ✓ Created .gitattributes with merge driver\n# ℹ  Remember to commit .gitattributes to share with your team!\n# Testing merge driver setup...\n# ✓ Merge driver is working correctly\n```\n\n**Global setup (all repositories):**\n```bash\n# Install for all your git repositories\nsudocode init-merge-driver --global\n\n# Output:\n# ✓ Added merge driver to ~/.gitconfig\n# ℹ  Each repository will need .gitattributes configured separately\n```\n\n**After setup, merges are automatic:**\n```bash\n# Normal git workflow - conflicts are auto-resolved\ngit merge feature-branch\n# Merge completed successfully!\n```\n\n**Check merge driver logs:**\n```bash\n# View merge driver activity\ncat .sudocode/merge-driver.log\n\n# Example output:\n# [2025-11-04T10:30:00.000Z] Merging: .sudocode/issues.jsonl\n#   ✓ Success: 245 (base) + 246 (ours) + 247 (theirs) → 246 (merged)\n```\n\n## Error Handling\n\n### Malformed JSON Lines\n\n```typescript\n// Skip malformed lines with warning\ntry {\n  entity = JSON.parse(line);\n} catch (error) {\n  if (!options.skipErrors) {\n    throw new Error(`Malformed JSON at line ${lineNum}: ${error.message}`);\n  }\n  console.warn(chalk.yellow(`Warning: Skipping malformed line ${lineNum}`));\n  continue;\n}\n```\n\n### Missing Timestamps\n\n```typescript\n// Fall back to created_at if updated_at is missing\nfunction getComparisonTimestamp(entity: JSONLEntity): string {\n  return entity.updated_at || entity.created_at || '1970-01-01T00:00:00Z';\n}\n```\n\n### Parent Reference Updates\n\nIf an entity's ID is renamed due to conflict, update any parent_id references:\n\n```typescript\nfunction updateParentReferences(entities: JSONLEntity[], idMap: Map<string, string>): void {\n  for (const entity of entities) {\n    if (entity.parent_id && idMap.has(entity.parent_id)) {\n      entity.parent_id = idMap.get(entity.parent_id);\n    }\n  }\n}\n```\n\n### Merge Driver Failures\n\nIf merge driver fails (exit 1), git will leave conflict markers for manual review:\n\n```typescript\ntry {\n  // Attempt automatic merge\n  await handleMergeDriver(options);\n  process.exit(0);\n} catch (error) {\n  // Log error and let git handle it manually\n  logError(error);\n  process.exit(1); // Git will show conflict markers\n}\n```\n\n## Edge Cases\n\n### 1. Nested Conflict Markers\nIf conflict markers appear in JSON content (rare), escape them during parsing.\n\n### 2. Empty Conflict Sections\n```jsonl\n<<<<<<< HEAD\n=======\n{\"id\":\"NEW\",\"uuid\":\"new-uuid\"}\n>>>>>>> feature\n```\nHandle empty sections by treating as deletion vs. addition.\n\n### 3. Relationship Cycles\nAfter ID renaming, check for and warn about relationship cycles.\n\n### 4. Binary Files\nDetect and skip binary files with warning:\n```typescript\nif (isBinaryFile(filePath)) {\n  console.warn('Skipping binary file');\n  return;\n}\n```\n\n## Performance Considerations\n\n- **Streaming**: Use streaming reads for large JSONL files (>10MB)\n- **Memory**: Process entities in batches if memory is constrained\n- **Atomic writes**: Use temp file + rename to prevent corruption\n- **Database sync**: Only sync once after resolving all files\n\n## Success Criteria\n\n✅ Resolves conflicts in issues.jsonl and specs.jsonl automatically\n✅ Preserves all unique data (no data loss)\n✅ Deterministic results (same input → same output)\n✅ Maintains git-friendly sorting by created_at\n✅ Merges metadata (relationships, tags) correctly\n✅ Supports dry-run mode for safety\n✅ Provides clear, actionable output\n✅ Integrates with git as merge driver\n✅ Handles malformed JSON gracefully\n✅ Passes all unit and integration tests\n\n## Future Enhancements\n\n1. **Interactive Mode**: Let user choose between conflicting versions\n2. **Custom Rules**: Allow project-specific resolution strategies via config\n3. **Merge Summaries**: Generate markdown summary of what was merged\n4. **Pre-commit Hook**: Warn if committing files with conflict markers\n5. **GUI**: Visual diff tool for complex conflicts\n","priority":1,"archived":0,"archived_at":null,"created_at":"2025-11-05 00:13:21","updated_at":"2025-11-05T00:16:01.867Z","parent_id":null,"parent_uuid":null,"relationships":[],"tags":["cli","git","jsonl","merge"]}
{"id":"s-6hl1","uuid":"e205fb13-dc67-4b8e-9ee2-130bf48febd2","title":"Migrate server to use agent-execution-engine npm package","file_path":"specs/migrate_server_to_use_agent_execution_engine_npm_p.md","content":"# Migrate server to use agent-execution-engine npm package\n\n## Overview\n\nRefactor the server codebase to use the `agent-execution-engine` npm package instead of duplicated code in `server/src/execution/`. This will eliminate code duplication, improve maintainability, and ensure consistency with the standalone execution engine library.\n\n## Background\n\nThe `agent-execution-engine` was recently extracted from this repository into a standalone package available at `https://github.com/alexngai/agent-execution-engine`. The server currently has duplicated copies of:\n\n- Process management layer (`process/`)\n- Execution engine layer (`engine/`)\n- Resilience layer (`resilience/`)\n- Workflow orchestration layer (`workflow/`)\n\nThese layers are identical (or nearly identical) to the agent-execution-engine package and should be replaced with npm imports.\n\n## Architecture Analysis\n\n### Code to Replace (use npm package)\n\n**Current duplicated code in `server/src/execution/`:**\n\n1. **Process Layer** (`process/`)\n   - `simple-manager.ts` - SimpleProcessManager implementation\n   - `manager.ts` - IProcessManager interface\n   - `types.ts` - Process types\n   - `utils.ts` - Process utilities\n   - **Exception**: Keep `process/builders/` subdirectory (server-specific Claude config builders)\n\n2. **Engine Layer** (`engine/`)\n   - `simple-engine.ts` - SimpleExecutionEngine implementation\n   - `engine.ts` - IExecutionEngine interface\n   - `types.ts` - Engine types\n\n3. **Resilience Layer** (`resilience/`)\n   - `resilient-executor.ts` - ResilientExecutor implementation\n   - `circuit-breaker.ts` - CircuitBreakerManager\n   - `retry.ts` - Retry utilities\n   - `executor.ts` - IResilientExecutor interface\n   - `types.ts` - Resilience types\n\n4. **Workflow Layer** (`workflow/`)\n   - `linear-orchestrator.ts` - LinearOrchestrator implementation\n   - `orchestrator.ts` - IWorkflowOrchestrator interface\n   - `memory-storage.ts` - InMemoryWorkflowStorage\n   - `types.ts` - Workflow types\n   - `utils.ts` - Workflow utilities\n\n### Code to Keep (server-specific)\n\n**Server-specific components in `server/src/execution/`:**\n\n1. **Worktree Management** (`worktree/`)\n   - Git worktree isolation for concurrent executions\n   - Race condition prevention with per-path mutex locks\n   - Local database setup per worktree\n   - JSONL syncing from main repo\n   - Comprehensive cleanup and validation\n\n2. **Output Processing** (`output/`)\n   - `claude-code-output-processor.ts` - Parses Claude's stream-json output\n   - `ag-ui-adapter.ts` - Transforms domain events to AG-UI protocol\n   - `ag-ui-integration.ts` - Factory functions and wiring\n   - `claude-to-ag-ui.ts` - Transformation helpers (shareable with frontend)\n   - `types.ts` - Output processing types\n\n3. **Transport Layer** (`transport/`)\n   - `sse-transport.ts` - Server-sent events connection management\n   - `event-buffer.ts` - In-memory event buffering for late-joining clients\n   - `transport-manager.ts` - Facade between adapters and SSE transport\n\n4. **Process Builders** (`process/builders/`)\n   - `claude.ts` - Claude-specific process configuration\n\n## Verified Compatibility\n\nThe agent-execution-engine's `LinearOrchestrator` **already supports** the server's custom dependencies:\n\n```typescript\n// From agent-execution-engine/src/workflow/linear-orchestrator.ts:85-86\nconstructor(\n  executor: IResilientExecutor,\n  storage?: IWorkflowStorage,\n  agUiAdapter?: any, // AgUiEventAdapter from server (optional)\n  lifecycleService?: any // ExecutionLifecycleService from server (optional)\n)\n```\n\nThis means we can do a **direct replacement** without any compatibility issues.\n\n## Migration Plan\n\n### Phase 1: Add npm Dependency\n\n**Update `server/package.json`:**\n\n```json\n{\n  \"dependencies\": {\n    \"agent-execution-engine\": \"^0.0.2\",\n    // ... existing dependencies\n  }\n}\n```\n\n**Run installation:**\n```bash\nnpm --prefix server install\n```\n\n### Phase 2: Update Imports\n\n**Primary file to update: `server/src/services/execution-service.ts`**\n\n**Before:**\n```typescript\nimport { SimpleProcessManager } from \"../execution/process/simple-manager.js\";\nimport { SimpleExecutionEngine } from \"../execution/engine/simple-engine.js\";\nimport { ResilientExecutor } from \"../execution/resilience/resilient-executor.js\";\nimport { LinearOrchestrator } from \"../execution/workflow/linear-orchestrator.js\";\nimport type { WorkflowDefinition } from \"../execution/workflow/types.js\";\n```\n\n**After:**\n```typescript\nimport { \n  SimpleProcessManager,\n  SimpleExecutionEngine,\n  ResilientExecutor,\n  LinearOrchestrator,\n  type WorkflowDefinition\n} from \"agent-execution-engine\";\n```\n\n**Other files to update:**\n- Search for all imports from `../execution/process/`, `../execution/engine/`, `../execution/resilience/`, `../execution/workflow/`\n- Replace with imports from `agent-execution-engine`\n- Update relative paths accordingly\n\n### Phase 3: Remove Duplicated Directories\n\n**Remove these directories from `server/src/execution/`:**\n\n```bash\n# From server/ directory\nrm -rf src/execution/process/simple-manager.ts\nrm -rf src/execution/process/manager.ts\nrm -rf src/execution/process/types.ts\nrm -rf src/execution/process/utils.ts\n# Keep: src/execution/process/builders/\n\nrm -rf src/execution/engine/\nrm -rf src/execution/resilience/\nrm -rf src/execution/workflow/\n```\n\n**Keep these directories:**\n- `src/execution/worktree/` - Server-specific git worktree management\n- `src/execution/output/` - Server-specific output processing\n- `src/execution/transport/` - Server-specific SSE streaming\n- `src/execution/process/builders/` - Server-specific process configuration\n\n### Phase 4: Update Output Processing Layer\n\n**Files to update for type imports:**\n\n- `server/src/execution/output/claude-code-output-processor.ts`\n- `server/src/execution/output/ag-ui-adapter.ts`\n\n**Example type import updates:**\n```typescript\n// Before\nimport type { ExecutionTask } from \"../engine/types.js\";\n\n// After\nimport type { ExecutionTask } from \"agent-execution-engine\";\n```\n\n### Phase 5: Verify Integration\n\n**Update tests:**\n- Check all test files in `server/tests/` that import execution layer types\n- Update imports to use `agent-execution-engine`\n\n**Type checking:**\n```bash\nnpm --prefix server run typecheck\n```\n\n**Unit tests:**\n```bash\nnpm --prefix server test -- --run\n```\n\n**E2E tests:**\n```bash\nnpm --prefix server test:e2e\n```\n\n## Expected File Structure After Migration\n\n```\nserver/src/execution/\n├── worktree/           # Server-specific (KEEP)\n│   ├── manager.ts\n│   ├── git-cli.ts\n│   ├── config.ts\n│   ├── types.ts\n│   └── index.ts\n├── output/             # Server-specific (KEEP)\n│   ├── claude-code-output-processor.ts\n│   ├── ag-ui-adapter.ts\n│   ├── ag-ui-integration.ts\n│   ├── claude-to-ag-ui.ts\n│   ├── types.ts\n│   └── index.ts\n├── transport/          # Server-specific (KEEP)\n│   ├── sse-transport.ts\n│   ├── event-buffer.ts\n│   ├── transport-manager.ts\n│   └── index.ts\n└── process/            # Partial (KEEP builders only)\n    └── builders/\n        └── claude.ts\n```\n\n## Import Map\n\n| Old Import | New Import |\n|-----------|-----------|\n| `../execution/process/simple-manager` | `agent-execution-engine` |\n| `../execution/process/manager` | `agent-execution-engine` |\n| `../execution/process/types` | `agent-execution-engine` |\n| `../execution/engine/simple-engine` | `agent-execution-engine` |\n| `../execution/engine/engine` | `agent-execution-engine` |\n| `../execution/engine/types` | `agent-execution-engine` |\n| `../execution/resilience/resilient-executor` | `agent-execution-engine` |\n| `../execution/resilience/circuit-breaker` | `agent-execution-engine` |\n| `../execution/resilience/retry` | `agent-execution-engine` |\n| `../execution/resilience/executor` | `agent-execution-engine` |\n| `../execution/resilience/types` | `agent-execution-engine` |\n| `../execution/workflow/linear-orchestrator` | `agent-execution-engine` |\n| `../execution/workflow/orchestrator` | `agent-execution-engine` |\n| `../execution/workflow/memory-storage` | `agent-execution-engine` |\n| `../execution/workflow/types` | `agent-execution-engine` |\n| `../execution/workflow/utils` | `agent-execution-engine` |\n\n## Risk Mitigation\n\n### Low Risk\n\nThe migration is **low risk** because:\n\n1. **Code is identical** - The agent-execution-engine was extracted from this exact codebase\n2. **Interfaces match** - All types and interfaces are the same\n3. **Dependencies are optional** - LinearOrchestrator accepts server-specific dependencies as `any` types\n4. **No breaking changes** - The package exports are compatible with current usage\n\n### Testing Strategy\n\n1. **Type checking first** - Verify all imports resolve correctly\n2. **Unit tests** - Ensure isolated components still work\n3. **Integration tests** - Verify service layer integration\n4. **E2E tests** - Test full execution flow end-to-end\n5. **Manual testing** - Run actual executions through the UI\n\n## Success Criteria\n\n- [ ] `agent-execution-engine` added as npm dependency\n- [ ] All imports updated to use `agent-execution-engine` package\n- [ ] Duplicated directories removed from `server/src/execution/`\n- [ ] Server-specific code (`worktree/`, `output/`, `transport/`) unchanged\n- [ ] Type checking passes (`npm run typecheck`)\n- [ ] All unit tests pass (`npm test`)\n- [ ] All E2E tests pass (`npm test:e2e`)\n- [ ] Manual execution testing confirms functionality\n- [ ] No regression in execution performance or reliability\n\n## Benefits\n\n1. **Eliminate code duplication** - Single source of truth for execution engine\n2. **Easier maintenance** - Updates to execution engine only need to happen in one place\n3. **Version control** - Can independently version and release execution engine\n4. **Reusability** - Other projects can use the same execution engine\n5. **Clearer boundaries** - Explicit separation between generic engine and server-specific code\n\n## Future Considerations\n\nAfter this migration:\n\n1. **Process builders** - Consider moving `process/builders/claude.ts` into the agent-execution-engine package as an example agent adapter\n2. **Output processing** - Consider extracting output processing layer into separate `@sudocode-ai/output-processing` package\n3. **Worktree management** - Consider extracting worktree layer into separate `@sudocode-ai/worktree-manager` package","priority":1,"archived":0,"archived_at":null,"created_at":"2025-11-19 06:04:21","updated_at":"2025-11-19 06:04:21","parent_id":null,"parent_uuid":null,"relationships":[],"tags":["architecture","dependencies","execution-engine","refactor"]}
{"id":"s-5d2c","uuid":"bc47487d-b14f-428e-a705-65395e87860e","title":"Multi-Project Server Architecture","file_path":"specs/multi_project_server_architecture.md","content":"# Multi-Project Server Architecture\n\nTransform the sudocode server from a single-project architecture to a project-agnostic server capable of managing multiple projects simultaneously.\n\n## Executive Summary\n\nThe server will run from any directory and allow users to open, switch between, and manage different sudocode projects across different repositories.\n\n### Key Goals\n\n1. Run server from any directory (not tied to a specific project)\n1. Support opening multiple projects simultaneously\n1. Maintain file watching and execution services for all active projects\n1. Provide project management UI for browsing, creating, and switching projects\n1. Ensure backward compatibility with existing single-project usage\n\n## Architecture Overview\n\n### Hybrid Architecture: Monolithic Core + Worker Executions\n\nThe server uses a **hybrid architecture** that combines the simplicity of a monolithic server with the isolation benefits of worker processes:\n\n**Monolithic Core** (single server process):\n\n- HTTP/WebSocket server (single port)\n- Project registry and management\n- Database connections (all projects)\n- File watchers (all projects)\n- Transport managers (SSE streaming)\n\n**Worker Executions** (isolated child processes):\n\n- Each Claude Code execution runs in a separate Node.js process\n- Workers are spawned on-demand and terminated after completion\n- Workers communicate with main server via IPC (Inter-Process Communication)\n- Workers have independent memory/CPU resources\n\n**Rationale**: This hybrid approach provides:\n\n1. **Execution isolation** - One execution crash doesn't affect others or the main server\n1. **Memory isolation** - Long-running executions don't exhaust main process heap\n1. **Resource limits** - Can cap CPU/memory per execution\n1. **Simpler than full hub-spoke** - Most services remain in main process\n1. **Future-proof** - Can evolve to full hub-and-spoke later if remote execution is needed\n\n```typescript\n// Main Server Process\nProjectManager\n├── Project Context 1 (sudocode-a1b2c3d4)\n│   ├── Database connection\n│   ├── File watcher\n│   ├── Transport manager\n│   └── ExecutionWorkerPool ───→ [Worker Process 1: Execution exec-abc]\n│                           └──→ [Worker Process 2: Execution exec-xyz]\n└── Project Context 2 (myapp-x7y8z9)\n    └── ExecutionWorkerPool ───→ [Worker Process 3: Execution exec-def]\n```\n\n### Project Identification\n\nProjects are identified using deterministic, human-readable IDs:\n\n```typescript\nfunction generateProjectId(projectPath: string): string {\n  const repoName = path.basename(projectPath)\n  const safeName = repoName.toLowerCase()\n    .replace(/[^a-z0-9-]/g, '-')\n    .replace(/-+/g, '-')\n    .slice(0, 32)\n  \n  const hash = crypto.createHash('sha256')\n    .update(projectPath)\n    .digest('hex')\n    .slice(0, 8)\n  \n  return `${safeName}-${hash}`\n}\n// Example: /Users/alex/repos/sudocode → \"sudocode-a1b2c3d4\"\n```\n\n### Configuration Storage\n\nProject registry stored at `~/.config/sudocode/projects.json`:\n\n```json\n{\n  \"version\": 1,\n  \"projects\": {\n    \"sudocode-a1b2c3d4\": {\n      \"id\": \"sudocode-a1b2c3d4\",\n      \"name\": \"sudocode\",\n      \"path\": \"/Users/alex/repos/sudocode\",\n      \"sudocodeDir\": \"/Users/alex/repos/sudocode/.sudocode\",\n      \"registeredAt\": \"2025-01-20T10:00:00Z\",\n      \"lastOpenedAt\": \"2025-01-20T15:30:00Z\",\n      \"favorite\": false\n    }\n  },\n  \"recentProjects\": [\"sudocode-a1b2c3d4\"],\n  \"settings\": {\n    \"maxRecentProjects\": 10,\n    \"autoOpenLastProject\": false\n  }\n}\n```\n\n### Multi-Project Service Architecture\n\n```typescript\nclass ProjectManager {\n  private projects: Map<string, ProjectContext> = new Map()\n  \n  async openProject(projectPath: string): Promise<ProjectContext>\n  async closeProject(projectId: string): Promise<void>\n  \n  getProject(projectId: string): ProjectContext | null\n  getAllOpenProjects(): ProjectContext[]\n  isProjectOpen(projectId: string): boolean\n}\n\nclass ProjectContext {\n  id: string\n  path: string\n  sudocodeDir: string\n\n  // Each project has independent services\n  db: Database.Database\n  transportManager: TransportManager\n  executionWorkerPool: ExecutionWorkerPool  // NEW: Manages worker processes\n  logsStore: ExecutionLogsStore\n  watcher: ServerWatcherControl\n  worktreeManager: WorktreeManager\n}\n\nclass ExecutionWorkerPool {\n  private workers: Map<executionId, WorkerProcess>\n  private projectId: string\n\n  // Spawn isolated worker process for execution\n  async startExecution(execution: Execution): Promise<void>\n\n  // Cancel execution (kills worker process)\n  async cancelExecution(executionId: string): Promise<void>\n\n  // Monitor worker health, restart on crash\n  private handleWorkerExit(executionId: string, exitCode: number): void\n\n  // Resource limits per worker (optional)\n  private readonly maxMemoryMB: number = 512\n  private readonly maxConcurrentWorkers: number = 3\n}\n```\n\n**Key Design**:\n\n- All open projects run services simultaneously in the main process\n- Executions are isolated in worker processes for crash protection and resource isolation\n- Workers are ephemeral (spawn on start, terminate on completion)\n\n### API Design\n\nUses `X-Project-ID` header for stateless project context:\n\n```typescript\n// Client sends header with every request\nGET /api/issues\nHeaders: { \"X-Project-ID\": \"sudocode-a1b2c3d4\" }\n\n// Server middleware extracts project context\napp.use((req, res, next) => {\n  const projectId = req.headers['x-project-id']\n  if (projectId) {\n    req.project = projectManager.getProject(projectId)\n  }\n  next()\n})\n\n// Routes use project context\nrouter.get('/issues', (req, res) => {\n  const issues = getIssues(req.project!.db)\n  res.json(issues)\n})\n```\n\n### Frontend Architecture\n\n**Project Context Management**:\n\n- React context tracks `currentProjectId`\n- Persists to localStorage\n- API client automatically injects `X-Project-ID` header\n\n**UI Components**:\n\n1. `/projects` page - Full project management interface\n1. Navbar quick-switcher - Dropdown with recent projects (Cmd+P shortcut)\n1. Empty state - Onboarding for new users\n\n**Project Switching Flow**:\n\n1. User selects project from switcher\n1. Update `currentProjectId` in context\n1. Update `X-Project-ID` header in API client\n1. Resubscribe WebSocket to new project\n1. Invalidate React Query cache\n1. Refetch all data (~500ms total)\n\n### WebSocket Strategy\n\n**Project-Scoped Subscriptions**:\n\n```typescript\n// Client subscribes to specific project\nwsClient.subscribe({\n  projectId: 'sudocode-a1b2c3d4',\n  entityType: 'all' // or 'issue', 'spec', 'execution'\n})\n\n// All messages include projectId\n{\n  type: 'issue_updated',\n  projectId: 'sudocode-a1b2c3d4',\n  entityId: 'i-abc123',\n  data: { ... }\n}\n\n// New project lifecycle messages\n{ type: 'project_opened', data: { projectId, name, path } }\n{ type: 'project_closed', data: { projectId } }\n```\n\n### Database Connection Management\n\n**Caching Strategy**:\n\n- Database connections cached with 30-minute TTL\n- Fast project switching (reuse existing connections)\n- Memory-efficient (evict unused connections)\n- SQLite databases are small (~few MB each)\n\n### Execution Worker Pool Architecture\n\n**Worker Lifecycle**:\n\n```typescript\n// Main server spawns worker on execution start\nclass ExecutionWorkerPool {\n  async startExecution(execution: Execution): Promise<void> {\n    const worker = spawn('node', ['dist/workers/execution-worker.js'], {\n      detached: false,  // Kill with parent\n      stdio: ['ipc'],   // IPC for bidirectional communication\n      env: {\n        EXECUTION_ID: execution.id,\n        PROJECT_ID: this.projectId,\n        REPO_PATH: execution.worktree_path,\n        DB_PATH: this.dbPath,\n        MAX_MEMORY_MB: '512',\n        NODE_OPTIONS: '--max-old-space-size=512'  // Hard memory limit\n      }\n    });\n\n    // Forward logs from worker to transport manager\n    worker.on('message', (msg: WorkerMessage) => {\n      if (msg.type === 'log') {\n        this.transportManager.sendEvent(execution.id, msg.data);\n      } else if (msg.type === 'status') {\n        this.updateExecutionStatus(execution.id, msg.status);\n      }\n    });\n\n    // Handle worker crash/exit\n    worker.on('exit', (code, signal) => {\n      if (code !== 0) {\n        this.handleWorkerFailure(execution.id, code, signal);\n      }\n      this.workers.delete(execution.id);\n    });\n\n    this.workers.set(execution.id, worker);\n  }\n}\n\n// Worker process runs execution independently\n// server/src/workers/execution-worker.ts\nasync function main() {\n  const { EXECUTION_ID, REPO_PATH, DB_PATH } = process.env;\n\n  // Worker has isolated database connection\n  const db = initDatabase({ path: DB_PATH });\n  const execution = getExecution(db, EXECUTION_ID);\n\n  // Run Claude Code execution\n  const orchestrator = new LinearOrchestrator(/* ... */);\n  const result = await orchestrator.execute(/* ... */);\n\n  // Report completion to main process\n  process.send!({ type: 'complete', result });\n  process.exit(0);\n}\n```\n\n**IPC Message Protocol**:\n\n```typescript\n// Worker → Main\ntype WorkerMessage =\n  | { type: 'log', data: OutputEvent }\n  | { type: 'status', status: ExecutionStatus }\n  | { type: 'complete', result: ExecutionResult }\n  | { type: 'error', error: string }\n\n// Main → Worker\ntype MainMessage =\n  | { type: 'cancel' }\n  | { type: 'ping' }\n```\n\n**Resource Limits**:\n\n- Memory: 512MB per worker (via `--max-old-space-size`)\n- Concurrent workers per project: 3 (configurable)\n- Worker spawn timeout: 10 seconds\n- Worker idle timeout: None (terminates on completion)\n\n**Crash Handling**:\n\n- Worker exit code 0: Normal completion\n- Worker exit code 1: Execution failed (expected)\n- Worker exit code 137: OOM killed (log warning, mark execution failed)\n- Worker killed by signal: Unexpected crash (mark execution failed, log error)\n\n## Requirements\n\n### Functional Requirements\n\n**FR1: Project Registration**\n\n- Browse filesystem for `.sudocode` directories\n- Initialize new sudocode projects\n- Validate project structure\n- Persist registered projects\n\n**FR2: Multi-Project Operations**\n\n- Maintain connections to all open projects\n- Independent file watchers per project\n- Concurrent executions across projects\n- Isolated database connections\n\n**FR3: Project Switching (UI-level)**\n\n- Display current active project\n- Switch between open projects\n- Project-scoped WebSocket subscriptions\n- Project-scoped React Query cache\n\n**FR4: Project Management UI**\n\n- Dedicated `/projects` page\n- Quick project switcher in navbar\n- Recent projects display\n- Project status indicators\n\n**FR5: Backward Compatibility**\n\n- Auto-detect project in cwd if no projects configured\n- Existing CLI workflows continue to work\n- Database schema unchanged\n\n### Non-Functional Requirements\n\n**NFR1: Performance**\n\n- Project switching < 500ms\n- Database connection caching\n- Minimal CPU/memory per file watcher\n\n**NFR2: Reliability**\n\n- Graceful handling of deleted/moved projects\n- Proper resource cleanup\n- No memory leaks\n- Execution isolation (one crash doesn't affect others)\n- Worker process supervision (restart on failure)\n\n**NFR3: Resource Limits**\n\n- Cap memory per execution worker (512MB default)\n- Limit concurrent executions per project (3 default)\n- Main server process remains responsive during heavy executions\n- Prevent OOM crashes from long-running executions\n\n**NFR4: Usability**\n\n- Clear visual indication of current project\n- Obvious error messages\n- Intuitive project creation flow\n\n## Implementation Phases\n\n### Phase 1: Multi-Project Server Core (Current Scope)\n\n**Deliverables**:\n\n1. Project registry with persistent storage\n1. Project management API endpoints\n1. Multi-project service architecture\n1. Header-based project routing\n1. Database connection caching\n1. Project-scoped file watchers\n1. **Execution worker pool** (isolated execution processes)\n1. **Worker-to-main IPC** (execution logs, status updates)\n1. Frontend project management page\n1. Frontend navbar quick-switcher\n1. WebSocket project subscriptions\n1. React Query cache invalidation on project switch\n\n**Success Criteria**:\n\n- Can register multiple projects from UI\n- Can switch between projects in < 500ms\n- File watchers run independently per project\n- Executions run concurrently across projects (isolated in workers)\n- Worker crashes don't affect main server or other executions\n- No memory leaks after switching projects 10+ times\n- Main server remains responsive during 3+ concurrent long-running executions\n- Backward compatible with single-project CLI usage\n\n**Estimated Effort**: 8-10 days (added 3 days for worker pool implementation)\n\n### Phase 2: Enhanced Project Management (Future)\n\n- Project initialization wizard\n- Project templates\n- Project search/filtering\n- Project favorites/pinning\n- Project metadata editing\n- Bulk operations\n\n**Estimated Effort**: 3-4 days\n\n### Phase 3: URL-Based Multi-Project Routing (Future)\n\n- URL structure: `/projects/:projectId/issues`\n- Browser tabs for different projects\n- Split-view mode (side-by-side projects)\n- Per-project browser history\n- Deep linking\n\n**Estimated Effort**: 4-5 days\n\n## File Structure Changes\n\n### Server\n\n```\nserver/src/\n├── services/\n│   ├── project-registry.ts        [NEW] Config file management\n│   ├── project-context.ts         [NEW] ProjectContext class\n│   ├── project-manager.ts         [NEW] ProjectManager orchestration\n│   ├── execution-worker-pool.ts   [NEW] Worker process management\n│   ├── db.ts                      [MODIFIED] Accept sudocodeDir param\n│   ├── watcher.ts                 [MODIFIED] Accept sudocodeDir param\n│   └── websocket.ts               [MODIFIED] Add projectId to messages\n├── workers/\n│   ├── execution-worker.ts        [NEW] Worker entry point\n│   └── worker-ipc.ts              [NEW] IPC message protocol\n├── routes/\n│   ├── projects.ts                [NEW] Project management endpoints\n│   ├── issues.ts                  [MODIFIED] Use req.project\n│   ├── specs.ts                   [MODIFIED] Use req.project\n│   ├── relationships.ts           [MODIFIED] Use req.project\n│   ├── feedback.ts                [MODIFIED] Use req.project\n│   └── executions.ts              [MODIFIED] Use req.project, worker pool\n├── middleware/\n│   └── project-context.ts         [NEW] Inject project from header\n├── types/\n│   └── project.ts                 [NEW] Project-related types\n└── index.ts                       [MODIFIED] Initialize ProjectManager\n```\n\n### Frontend\n\n```\nfrontend/src/\n├── contexts/\n│   └── ProjectContext.tsx         [NEW] Current project state\n├── hooks/\n│   ├── useProject.ts              [NEW] Access project context\n│   └── useProjects.ts             [NEW] Fetch projects\n├── pages/\n│   └── ProjectsPage.tsx           [NEW] Project management page\n├── components/\n│   ├── projects/\n│   │   ├── ProjectCard.tsx        [NEW] Project card component\n│   │   ├── ProjectBrowser.tsx     [NEW] File browser\n│   │   ├── ProjectSwitcher.tsx    [NEW] Navbar dropdown\n│   │   └── EmptyState.tsx         [NEW] No projects state\n│   └── layout/\n│       └── MainLayout.tsx         [MODIFIED] Add ProjectSwitcher\n├── lib/\n│   └── api.ts                     [MODIFIED] Add project endpoints\n└── App.tsx                        [MODIFIED] Add ProjectProvider\n```\n\n### Types\n\n```\ntypes/src/\n├── project.ts                     [NEW] Shared project types\n└── websocket.ts                   [MODIFIED] Add project message types\n```\n\n## API Endpoints\n\n### Project Management\n\n```\nGET    /api/projects               List all registered projects\nGET    /api/projects/open          List currently open projects\nPOST   /api/projects/open          Open a project by path\nPOST   /api/projects/:id/close     Close an open project\nDELETE /api/projects/:id           Unregister a project\nGET    /api/projects/recent        Get recent projects\nPOST   /api/projects/validate      Validate a project path\nPOST   /api/projects/init          Initialize new sudocode project\n```\n\n### Entity Routes (Require X-Project-ID header)\n\n```\nGET/POST/PUT/DELETE /api/issues\nGET/POST/PUT/DELETE /api/specs\nGET/POST/DELETE     /api/relationships\nGET/POST/PUT/DELETE /api/feedback\nPOST/GET/DELETE     /api/executions\n```\n\n## Testing Strategy\n\n### Unit Tests\n\n- ProjectRegistry config management\n- ProjectManager open/close/validate\n- Project ID generation\n- Database caching and TTL eviction\n- Middleware project context injection\n- Frontend ProjectContext state management\n- API client header injection\n- **ExecutionWorkerPool spawn/cancel/monitor**\n- **Worker IPC message protocol**\n\n### Integration Tests\n\n- Project lifecycle (open → file watch → edit → WebSocket)\n- Project switching (watchers stop/start correctly)\n- Multi-project executions (independent operation, worker isolation)\n- **Worker crash recovery** (main server stays healthy)\n- **Worker memory limits** (process terminates on OOM)\n- Resource cleanup (no memory leaks, no orphaned workers)\n- Invalid project handling\n\n### E2E Tests\n\n- New user onboarding flow\n- Project switching with data verification\n- Multi-project concurrent operations\n- Server restart persistence\n\n### Performance Tests\n\n- Opening 10 projects < 5 seconds\n- Project switching < 500ms\n- Memory with 5 open projects < 500MB (main process only)\n- Database cache eviction performance\n- **Worker spawn time < 500ms**\n- **3+ concurrent executions across projects don't saturate event loop**\n- **Main server API latency < 100ms during heavy executions**\n\n## Success Metrics\n\n**Functional**:\n\n- Register and open 3+ projects\n- Switch between projects in < 500ms\n- Independent file watchers per project\n- Concurrent executions across projects (worker-isolated)\n- Worker crashes don't affect main server\n- Correct WebSocket subscriptions\n\n**Quality**:\n\n- 90%+ test coverage on new code\n- Zero memory leaks in main process (30+ minute test)\n- No orphaned worker processes after shutdown\n- No regressions in single-project usage\n- Clear error messages for all failures\n\n**User Experience**:\n\n- Intuitive project management UI\n- Instant-feeling project switching\n- Clear indication of current project\n- Easy project discovery and registration\n\n## Future Evolution: Hub-and-Spoke Architecture\n\nThe hybrid architecture is designed to evolve into a full **hub-and-spoke** model when remote execution becomes a requirement:\n\n**Hub-and-Spoke Model** (Phase 4, future):\n\n```\nHub Server (Port 3000)\n├── HTTP Gateway (proxy to spokes)\n├── WebSocket Multiplexer\n├── Spoke Manager (spawn/monitor spokes)\n└── Routes to:\n    ├── Local Spoke 1 (Port 3001) → Project A\n    ├── Local Spoke 2 (Port 3002) → Project B\n    └── Remote Spoke (tcp://server:3000) → Project C on remote machine\n```\n\n**Migration Path**:\n\n1. **Phase 1** (Current): Hybrid architecture (monolithic + worker executions)\n1. **Phase 2**: Refactor services to be \"spoke-compatible\" (pass projectId everywhere)\n1. **Phase 3**: Extract ProjectContext into standalone runnable spoke server\n1. **Phase 4**: Add hub layer for spoke orchestration and remote registration\n\n**When to Migrate**:\n\n- Users need remote execution (run sudocode server on cloud VM)\n- Projects are too large/numerous for single machine (10+ projects)\n- Need true process isolation for entire project services (not just executions)\n- Resource contention becomes issue even with worker isolation\n\n**Design Decisions for Future-Proofing**:\n\n- ProjectContext is self-contained (all state in one object)\n- Services take `projectId` parameter (IPC-ready)\n- Transport layer is abstract (can swap HTTP/IPC later)\n- Worker pool pattern can extend to full spoke processes\n\n## Reference\n\nSee `references/multi-project-server-spec.md` for complete implementation details, code examples, and step-by-step guide.","priority":0,"archived":0,"archived_at":null,"created_at":"2025-11-20 09:46:58","updated_at":"2025-11-20 11:01:00","parent_id":null,"parent_uuid":null,"relationships":[],"tags":[]}
{"id":"s-87x7","uuid":"3a11c617-7ae9-459d-aaa7-26b05b580e81","title":"Migrate to Direct Execution Pattern with ClaudeCodeExecutor","file_path":"specs/migrate_to_direct_execution_pattern_with_claudecod.md","content":"# Migration to Direct Execution Pattern with ClaudeCodeExecutor\n\n## Context\n\nThe current execution system uses a **manual layer-by-layer approach** to spawn and manage Claude Code CLI processes. With the upgrade to `agent-execution-engine` 0.0.6, a new **direct execution pattern** is available via `ClaudeCodeExecutor` that provides significant architectural improvements.\n\n### Current Architecture (Manual Stacking)\n\n```\nExecutionService\n  └─→ SimpleProcessManager (spawn process, manage I/O)\n      └─→ SimpleExecutionEngine (task queueing)\n          └─→ ResilientExecutor (retry logic)\n              └─→ LinearOrchestrator (workflow lifecycle)\n                  └─→ Manual CLI arg building\n                  └─→ Custom stream-json parsing (AG-UI processor)\n```\n\n**Current Implementation**:\n- **Location**: `server/src/services/execution-service.ts:335-582` (createExecution)\n- **Location**: `server/src/workers/execution-worker.ts:145-300` (worker process)\n- **Lines of code**: ~500 lines (duplicated between service + worker)\n- **Manual responsibilities**:\n  - Build Claude CLI arguments manually (lines 370-376, 708-714)\n  - Parse stdout line-by-line with `ClaudeCodeOutputProcessor`\n  - Buffer incomplete lines for stream-json parsing\n  - Wire AG-UI events manually\n  - Handle process lifecycle events across 4 layers\n\n### New Architecture (Direct Execution)\n\n```\nClaudeCodeExecutor\n  ├─→ Spawns Claude process with bidirectional protocol\n  ├─→ ProtocolPeer (stdin/stdout communication)\n  ├─→ ClaudeAgentClient (control request/response handling)\n  └─→ normalizeOutput() → NormalizedEntry stream\n```\n\n**New Capabilities**:\n- **Bidirectional protocol**: Built-in control request/response handling\n- **Normalized output**: Consistent `NormalizedEntry` format across agents\n- **Session management**: Built-in `resumeTask()` for session resumption\n- **Approval services**: `IApprovalService` interface for tool approvals\n- **Protocol-level error handling**: Automatic retries, timeouts\n- **No manual arg building**: Config-driven execution\n\n## Problems with Current Approach\n\n### 1. Code Duplication\n- Execution logic duplicated between:\n  - `server/src/services/execution-service.ts` (in-process path)\n  - `server/src/workers/execution-worker.ts` (worker pool path)\n- Same layer stacking pattern repeated in both locations\n- Maintenance burden: bug fixes require changes in 2 places\n\n### 2. Manual Protocol Handling\n- Manual CLI argument construction\n- Manual stream-json parsing with line buffering\n- Custom AG-UI event mapping from parsed output\n- Error-prone: easy to miss edge cases in parsing\n\n### 3. Limited Session Management\n- Session resumption requires manual worktree recreation\n- No built-in session ID tracking\n- Complex follow-up execution logic (lines 594-906)\n\n### 4. Missing Features\n- No approval service integration\n- Cannot leverage bidirectional protocol capabilities\n- Limited error recovery at protocol level\n\n### 5. Complexity\n- 4 layer abstractions to understand\n- Event handlers registered across multiple components\n- Difficult to trace execution flow\n\n## Goals\n\n### Primary Goals\n1. **Reduce code complexity**: Eliminate manual layer stacking\n2. **Remove duplication**: Single execution implementation shared by service + worker\n3. **Leverage protocol features**: Use bidirectional communication, approval services\n4. **Enable session resumption**: Use built-in `resumeTask()` API\n5. **Improve maintainability**: Clear separation of concerns\n\n### Secondary Goals\n6. **Prepare for multi-agent support**: Normalized output format works across agents\n7. **Better error handling**: Protocol-level error recovery\n8. **Performance**: Reduce overhead from multiple layers\n\n### Non-Goals\n- **NOT changing AG-UI protocol**: Keep existing SSE streaming interface\n- **NOT modifying database schema**: Maintain current execution records\n- **NOT breaking existing APIs**: Keep ExecutionService public interface\n\n## Requirements\n\n### Functional Requirements\n\n#### FR1: Execution Lifecycle\n- MUST support creating executions with worktree isolation\n- MUST support follow-up executions with session resumption\n- MUST support cancellation of running executions\n- MUST maintain existing status transitions (pending → running → completed/failed/stopped)\n\n#### FR2: Output Processing\n- MUST convert normalized output to AG-UI events\n- MUST persist raw logs to `ExecutionLogsStore`\n- MUST broadcast events via `TransportManager` for SSE streaming\n- MUST maintain compatibility with existing AG-UI frontend\n\n#### FR3: Lifecycle Integration\n- MUST integrate with `ExecutionLifecycleService` for:\n  - Worktree creation/cleanup\n  - Execution status updates in database\n  - WebSocket broadcast notifications\n- MUST support both in-process and worker pool execution\n\n#### FR4: Worker Pool Compatibility\n- MUST support isolated execution in worker processes\n- MUST maintain IPC protocol with main process\n- MUST handle worker cancellation gracefully\n\n#### FR5: Session Management\n- MUST support session resumption via `resumeTask()`\n- SHOULD track session IDs for follow-up executions\n- SHOULD recreate worktrees if they don't exist\n\n### Non-Functional Requirements\n\n#### NFR1: Performance\n- MUST NOT regress execution latency\n- SHOULD reduce memory overhead (fewer layer instances)\n- Target: <5% latency increase acceptable\n\n#### NFR2: Reliability\n- MUST maintain >99% success rate for executions\n- MUST handle process crashes gracefully\n- MUST not lose output logs during failures\n\n#### NFR3: Maintainability\n- MUST reduce lines of code by >30%\n- MUST eliminate code duplication between service/worker\n- MUST improve code clarity (single execution path)\n\n#### NFR4: Testability\n- MUST maintain test coverage >80%\n- MUST add integration tests for new adapter components\n\n#### NFR5: Backward Compatibility\n- MUST maintain existing ExecutionService API\n- MUST support existing execution configurations\n- MUST NOT break existing frontend integrations\n\n## Architecture Design\n\n### Component Overview\n\n```\n┌─────────────────────────────────────────────────────────────┐\n│                    ExecutionService                         │\n│  ┌───────────────────────────────────────────────────────┐  │\n│  │              ClaudeExecutorWrapper                    │  │\n│  │  ┌─────────────────────────────────────────────────┐  │  │\n│  │  │          ClaudeCodeExecutor                     │  │  │\n│  │  │  - executeTask()                                │  │  │\n│  │  │  - resumeTask()                                 │  │  │\n│  │  │  - normalizeOutput()                            │  │  │\n│  │  └─────────────────────────────────────────────────┘  │  │\n│  │                                                         │  │\n│  │  ┌─────────────────────────────────────────────────┐  │  │\n│  │  │    NormalizedEntryToAgUiAdapter                 │  │  │\n│  │  │  - processEntry(NormalizedEntry)                │  │  │\n│  │  │  - Convert to AG-UI events                      │  │  │\n│  │  └─────────────────────────────────────────────────┘  │  │\n│  │                                                         │  │\n│  │  Integrations:                                          │  │\n│  │  - ExecutionLifecycleService (worktrees, DB)           │  │\n│  │  - ExecutionLogsStore (log persistence)                │  │\n│  │  - TransportManager (SSE streaming)                    │  │\n│  │  - WebSocket broadcasts (status updates)               │  │\n│  └───────────────────────────────────────────────────────┘  │\n└─────────────────────────────────────────────────────────────┘\n```\n\n### New Components\n\n#### 1. NormalizedEntryToAgUiAdapter\n**Purpose**: Convert `NormalizedEntry` stream to AG-UI events\n\n**Location**: `server/src/execution/output/normalized-to-ag-ui-adapter.ts`\n\n**Responsibilities**:\n- Parse `NormalizedEntry` discriminated union\n- Map entry types to AG-UI event types:\n  - `assistant_message` → `TextMessageStart/Content/End`\n  - `tool_use` → `ToolCallStart/Args/End`\n  - `tool_result` → `ToolCallResult`\n  - `error` → `RunError`\n- Maintain message ID tracking for AG-UI protocol\n- Handle thinking blocks (convert to text messages)\n\n**Interface**:\n```typescript\nclass NormalizedEntryToAgUiAdapter {\n  constructor(private agUiAdapter: AgUiEventAdapter);\n  \n  async processEntry(entry: NormalizedEntry): Promise<void>;\n  private handleAssistantMessage(entry: NormalizedEntry): Promise<void>;\n  private handleToolUse(entry: NormalizedEntry): Promise<void>;\n  private extractToolArgs(action: ActionType): any;\n}\n```\n\n#### 2. ClaudeExecutorWrapper\n**Purpose**: Wrap `ClaudeCodeExecutor` with lifecycle management\n\n**Location**: `server/src/execution/executors/claude-executor-wrapper.ts`\n\n**Responsibilities**:\n- Create and configure `ClaudeCodeExecutor` instance\n- Wire normalized output to AG-UI adapter\n- Integrate with `ExecutionLifecycleService`\n- Persist logs to `ExecutionLogsStore`\n- Emit WebSocket broadcasts for status changes\n- Handle process lifecycle (start/stop/error)\n- Support session resumption via `resumeTask()`\n\n**Interface**:\n```typescript\nclass ClaudeExecutorWrapper {\n  constructor(\n    workDir: string,\n    lifecycleService: ExecutionLifecycleService,\n    logsStore: ExecutionLogsStore,\n    projectId: string,\n    transportManager?: TransportManager\n  );\n  \n  async executeWithLifecycle(\n    executionId: string,\n    task: ExecutionTask,\n    workDir: string\n  ): Promise<void>;\n  \n  async resumeWithLifecycle(\n    executionId: string,\n    sessionId: string,\n    task: ExecutionTask,\n    workDir: string\n  ): Promise<void>;\n  \n  async cancel(executionId: string): Promise<void>;\n}\n```\n\n### Data Flow\n\n#### Execution Flow\n```\n1. ExecutionService.createExecution()\n   ↓\n2. Create ClaudeExecutorWrapper\n   ↓\n3. wrapper.executeWithLifecycle()\n   ├─→ Setup AG-UI adapter + normalized adapter\n   ├─→ Connect to TransportManager\n   ├─→ ClaudeCodeExecutor.executeTask()\n   │   ├─→ Spawn Claude process\n   │   ├─→ Setup ProtocolPeer (stdin/stdout)\n   │   └─→ Send user message via protocol\n   ├─→ normalizeOutput() stream\n   │   └─→ For each NormalizedEntry:\n   │       ├─→ Persist to ExecutionLogsStore\n   │       └─→ Convert to AG-UI via adapter\n   ├─→ Wait for process exit\n   └─→ Update execution status (completed/failed)\n```\n\n#### Session Resumption Flow\n```\n1. ExecutionService.createFollowUp()\n   ↓\n2. Extract sessionId from previous execution\n   ↓\n3. wrapper.resumeWithLifecycle(sessionId, ...)\n   ├─→ ClaudeCodeExecutor.resumeTask(sessionId)\n   │   └─→ Spawn Claude with --resume-session\n   └─→ Same output processing as executeWithLifecycle()\n```\n\n## Migration Strategy\n\n### Phase 1: Create Adapters & Integration Tests ✅ COMPLETE\n**Duration**: 2 days  \n**Risk**: Low\n\n**Tasks**:\n1. ✅ Implement `NormalizedEntryToAgUiAdapter`\n   - Map all `NormalizedEntry.type.kind` variants to AG-UI events\n   - Unit tests with mock AG-UI adapter\n   - All 16 tests passing\n\n2. ✅ Implement `ClaudeExecutorWrapper`\n   - Create executor with config\n   - Wire lifecycle hooks\n   - Integrate logs/transport/broadcasts\n   - Unit tests with mocked dependencies\n   - All 13 tests passing\n\n3. ✅ Integration tests\n   - Test normalized adapter with real AG-UI events\n   - Test wrapper with mock executor\n   - All 11 integration tests passing\n   - Full component integration validated\n\n**Deliverables**:\n- ✅ `server/src/execution/output/normalized-to-ag-ui-adapter.ts`\n- ✅ `server/src/execution/executors/claude-executor-wrapper.ts`\n- ✅ Unit test files for both components\n- ✅ Integration test suite\n- ✅ Documentation: Architecture diagrams\n\n**Success Criteria**:\n- ✅ All tests pass (40/40 tests)\n- ✅ Code review approved\n- ✅ No production impact (additive only)\n\n### Phase 2: Direct Migration to New Execution Path\n**Duration**: 2-3 days  \n**Risk**: Low (feature not actively used in production)\n\nSince this feature is not in active production use, we can skip the gradual rollout strategy and directly replace the old execution path with the new one.\n\n**Tasks**:\n\n1. **Replace ExecutionService.createExecution()**\n   - Remove manual layer stacking (SimpleProcessManager, SimpleExecutionEngine, etc.)\n   - Use `ClaudeExecutorWrapper` directly\n   - Keep same public interface\n   - Wire to existing lifecycle/logs/transport\n   \n2. **Update createFollowUp() for session resumption**\n   - Use `wrapper.resumeWithLifecycle()` with session ID\n   - Simplify worktree recreation logic\n   - Remove manual session handling\n\n3. **Update worker pool (execution-worker.ts)**\n   - Replace manual execution with `ClaudeExecutorWrapper`\n   - Keep IPC protocol unchanged for compatibility\n   - Ensure worker cancellation works correctly\n\n4. **Remove legacy code**\n   - Delete manual layer stacking from both locations\n   - Remove `ClaudeCodeOutputProcessor` (replaced by normalized adapter)\n   - Clean up ~500 lines of duplicated code\n   - Remove unused SimpleProcessManager, SimpleExecutionEngine, etc.\n\n5. **Testing & Validation**\n   - Run all existing execution tests\n   - Test execution creation\n   - Test session resumption\n   - Test cancellation\n   - Test worker pool executions\n   - Verify AG-UI frontend compatibility\n\n**Deliverables**:\n- Simplified `execution-service.ts` with direct execution\n- Simplified `execution-worker.ts` with direct execution\n- Removed legacy execution layers (~500 lines)\n- All existing tests passing\n- No breaking changes to public APIs\n\n**Success Criteria**:\n- All existing tests pass\n- Performance delta <5%\n- No critical bugs\n- Frontend continues to work correctly\n\n### Phase 3: Final Cleanup & Documentation\n**Duration**: 1-2 days  \n**Risk**: Low\n\n**Tasks**:\n\n1. **Code cleanup**\n   - Remove any remaining unused imports\n   - Clean up commented-out legacy code\n   - Ensure consistent error handling patterns\n\n2. **Database optimization (optional)**\n   - Consider adding session ID column to executions table\n   - Would enable better session tracking\n\n3. **Documentation update**\n   - Update architecture docs\n   - Add migration notes for future reference\n   - Document new execution flow\n   - Update code comments\n\n4. **Performance validation**\n   - Measure execution latency before/after\n   - Measure memory usage\n   - Document performance improvements\n\n**Deliverables**:\n- Clean codebase with no legacy execution code\n- Updated documentation\n- Performance comparison report\n- Migration retrospective\n\n**Success Criteria**:\n- Code is clean and well-documented\n- Test coverage maintained >80%\n- Team understands new architecture\n- Performance improvements documented\n\n## Testing Strategy\n\n### Unit Tests\n\n#### NormalizedEntryToAgUiAdapter ✅\n- ✅ Test each `NormalizedEntry.type.kind` mapping\n- ✅ Test message ID generation and tracking\n- ✅ Test tool call lifecycle (start → args → result → end)\n- ✅ Test error handling\n\n#### ClaudeExecutorWrapper ✅\n- ✅ Test lifecycle hooks (start/complete/error)\n- ✅ Test log persistence\n- ✅ Test AG-UI adapter integration\n- ✅ Test session resumption\n- ✅ Test cancellation\n\n### Integration Tests ✅\n\n#### Full Execution Flow ✅\n- ✅ Create execution → process output → verify AG-UI events\n- ✅ Test with mocked ClaudeCodeExecutor\n- ✅ Verify log persistence\n- ✅ Verify WebSocket broadcasts\n- ✅ All 11 integration tests passing\n\n### Acceptance Tests (Phase 2)\n- Execute real sudocode issues\n- Verify frontend receives events correctly\n- Test session resumption with follow-up\n- Test cancellation mid-execution\n- Test worker pool execution\n\n## Risk Assessment\n\n| Risk | Probability | Impact | Mitigation |\n|------|------------|--------|------------|\n| **AG-UI event incompatibility** | Low | High | Extensive integration testing validated compatibility |\n| **Performance regression** | Low | Medium | Benchmark before/after; acceptable since not in active production |\n| **Worker pool IPC issues** | Medium | Medium | Keep IPC protocol unchanged; test worker thoroughly |\n| **Session resumption bugs** | Low | Medium | Extensive testing with `resumeTask()`; well-tested in Phase 1 |\n| **Breaking frontend** | Low | High | Maintain AG-UI event compatibility; frontend integration tests |\n\n### Rollback Plan\n\n**Phase 2**: \n- If critical issues discovered: revert commits\n- Restore legacy code from git history\n- No data migration required (database schema unchanged)\n\n**Phase 3**:\n- Low risk phase (cleanup only)\n- Can defer indefinitely if needed\n\n## Success Metrics\n\n### Quantitative Metrics\n- **Code reduction**: ≥30% fewer lines in execution logic (~500 lines removed)\n- **Performance**: <5% latency increase (acceptable for non-production feature)\n- **Reliability**: ≥99% execution success rate\n- **Test coverage**: ≥80% maintained\n\n### Qualitative Metrics\n- **Maintainability**: Easier to understand and modify (single execution path)\n- **Extensibility**: Ready for multi-agent support\n- **Developer satisfaction**: Positive feedback from team\n\n### Business Metrics\n- **No user-facing regressions**\n- **Session resumption feature enabled**\n- **Foundation for future features** (approval services, multi-agent)\n\n## Timeline\n\n| Phase | Duration | Status |\n|-------|----------|--------|\n| Phase 1: Adapters & Tests | 2 days | ✅ COMPLETE |\n| Phase 2: Direct Migration | 2-3 days | 🔄 READY TO START |\n| Phase 3: Cleanup | 1-2 days | ⏳ PENDING |\n| **Total** | **~1 week** | - |\n\n## Open Questions\n\n1. **Session ID storage**: Should we add a dedicated `session_id` column to executions table?\n   - **Decision needed by**: Phase 3\n   - **Impact**: Database migration required if yes\n   - **Recommendation**: Defer to Phase 3, not critical for initial migration\n\n2. **Approval service integration**: Should we implement custom approval service now or later?\n   - **Decision needed by**: Phase 3\n   - **Impact**: Additional development time\n   - **Recommendation**: Later - not needed for basic execution\n\n3. **Performance monitoring**: What metrics should we track post-migration?\n   - **Decision needed by**: Phase 2\n   - **Impact**: Helps validate migration success\n   - **Recommendation**: Track execution latency, success rate, memory usage\n\n## References\n\n### Code Locations\n- Current execution service: `server/src/services/execution-service.ts`\n- Current worker: `server/src/workers/execution-worker.ts`\n- AG-UI integration: `server/src/execution/output/ag-ui-integration.ts`\n- Package docs: `node_modules/agent-execution-engine/README.md`\n\n### Implemented Components (Phase 1)\n- ✅ NormalizedEntryToAgUiAdapter: `server/src/execution/output/normalized-to-ag-ui-adapter.ts`\n- ✅ ClaudeExecutorWrapper: `server/src/execution/executors/claude-executor-wrapper.ts`\n- ✅ ExecutionLogsStore normalized support: `server/src/services/execution-logs-store.ts`\n- ✅ Integration tests: `server/tests/integration/execution/direct-execution-phase1.test.ts`\n\n### External Documentation\n- agent-execution-engine README: Executor pattern examples\n- Claude Code API: Stream-json protocol\n- AG-UI protocol: Event types and sequencing","priority":1,"archived":0,"archived_at":null,"created_at":"2025-11-22 04:38:22","updated_at":"2025-11-22 08:19:39","parent_id":null,"parent_uuid":null,"relationships":[],"tags":["architecture","claude-code","execution-engine","migration"]}
{"id":"s-9mtp","uuid":"0aacb002-0194-477f-b32a-ecefd3145576","title":"Multi-Agent Execution Support","file_path":"specs/multi_agent_execution_support.md","content":"# Multi-Agent Execution Support\n\n## Overview\n\nAdd comprehensive support for multiple AI coding agents (Claude Code, Codex, GitHub Copilot, Cursor) within the sudocode execution system. Users will be able to select their preferred agent on a per-execution basis, with each agent having its own configuration options and capabilities while maintaining a unified execution experience.\n\n## Background\n\nThe current sudocode system is tightly coupled to Claude Code as the only supported agent. However, the underlying **agent-execution-engine** package was designed from the ground up to support multiple CLI-based AI agents through:\n\n- **Agent Adapter Pattern**: `IAgentAdapter<TConfig>` interface for pluggable agents\n- **Agent Registry**: Centralized registry for runtime agent discovery\n- **Normalized Output Format**: Agent-agnostic `NormalizedEntry` stream that works across all agents\n- **Layered Architecture**: Process management, execution engine, resilience, and workflow orchestration layers\n\nRecent migration to the **direct execution pattern** (Phase 1 complete, Phase 2 ready) has positioned us well for multi-agent support by:\n- Eliminating code duplication between service and worker\n- Adopting protocol-level features (bidirectional communication, session resumption)\n- Implementing `NormalizedEntryToAgUiAdapter` that works for any agent outputting normalized format\n\n## Goals\n\n### Primary Goals\n\n1. **Agent Selection**: Enable users to choose from multiple agents when creating executions\n2. **Generic Executor Architecture**: Refactor `ClaudeExecutorWrapper` to support any agent adapter\n3. **Agent Registry Integration**: Integrate agent-execution-engine's registry system on the server\n4. **Initial Agent Support**: Implement adapters for Codex, GitHub Copilot, and Cursor\n5. **Configuration UI**: Provide agent-specific configuration options in the frontend\n6. **Per-Execution Agent Selection**: Allow different agents for different executions within the same project\n\n### Secondary Goals\n\n1. **Capability-Based UI**: Show/hide configuration options based on agent capabilities\n2. **Configuration Validation**: Validate agent-specific configs before execution\n3. **Graceful Degradation**: Handle unimplemented/unavailable agents gracefully\n4. **Backwards Compatibility**: Ensure existing Claude Code executions continue to work\n\n### Non-Goals (Future Work)\n\n- Per-project default agent settings\n- Global default agent preferences\n- Agent-specific configuration presets/templates\n- Dynamic form generation from agent metadata\n- Multi-agent workflows (chaining different agents)\n- Agent switching mid-execution\n- Agent performance comparison tools\n\n## User Stories\n\n### As a Developer\n\n1. **Agent Selection**\n   - I want to select my preferred agent (Claude Code, Codex, Copilot, Cursor) when creating a new execution\n   - I want to see which agents are available and which are coming soon\n   - I want to see what each agent is capable of (modes, streaming, structured output)\n\n2. **Configuration**\n   - I want to configure agent-specific settings (model, mode, API keys) appropriate to my selected agent\n   - I want invalid configurations to be caught before execution starts\n   - I want sensible defaults that work out-of-the-box for each agent\n\n3. **Execution Experience**\n   - I want the same unified execution experience (logs, terminal, status) regardless of which agent I use\n   - I want to resume/replay executions using the agent they were originally run with\n   - I want my choice of agent to be remembered in the execution history\n\n### As a System Administrator\n\n1. **Agent Management**\n   - I want to see which agents are registered and available\n   - I want agents to fail gracefully if their CLI is not installed\n   - I want clear error messages when agent execution fails\n\n## Architecture\n\n### System Overview\n\n```\n┌─────────────────────────────────────────────────────────────┐\n│                         Frontend                             │\n│  ┌────────────────────────────────────────────────────────┐ │\n│  │  AgentConfigPanel                                       │ │\n│  │  - Agent selection dropdown                             │ │\n│  │  - Agent-specific configuration forms                   │ │\n│  │  - Capability-based UI controls                         │ │\n│  └────────────────────────────────────────────────────────┘ │\n│                            ▼                                 │\n│  ┌────────────────────────────────────────────────────────┐ │\n│  │  POST /api/executions { agentType, config, ... }        │ │\n│  └────────────────────────────────────────────────────────┘ │\n└─────────────────────────────────────────────────────────────┘\n                             ▼\n┌─────────────────────────────────────────────────────────────┐\n│                      Server (Backend)                        │\n│  ┌────────────────────────────────────────────────────────┐ │\n│  │  AgentRegistryService                                   │ │\n│  │  - Maintains registry of available agents               │ │\n│  │  - Provides agent metadata and capabilities             │ │\n│  │  - GET /api/agents endpoint                             │ │\n│  └────────────────────────────────────────────────────────┘ │\n│                            ▼                                 │\n│  ┌────────────────────────────────────────────────────────┐ │\n│  │  ExecutionService                                       │ │\n│  │  - createExecution(agentType, config)                   │ │\n│  │  - Uses createExecutorForAgent() factory                │ │\n│  │  - Validates config against agent schema                │ │\n│  └────────────────────────────────────────────────────────┘ │\n│                            ▼                                 │\n│  ┌────────────────────────────────────────────────────────┐ │\n│  │  AgentExecutorWrapper<TConfig>   (Generic!)             │ │\n│  │  - Accepts IAgentAdapter<TConfig>                       │ │\n│  │  - Integrates with lifecycle, logs, transport           │ │\n│  │  - Supports any agent that implements adapter interface │ │\n│  └────────────────────────────────────────────────────────┘ │\n│                            ▼                                 │\n│  ┌────────────────────────────────────────────────────────┐ │\n│  │  Agent-Execution-Engine (Core Library)                  │ │\n│  │  ┌──────────────────────────────────────────────────┐  │ │\n│  │  │  Registered Adapters:                             │  │ │\n│  │  │  - ClaudeCodeAdapter                              │  │ │\n│  │  │  - CodexAdapter                                   │  │ │\n│  │  │  - CopilotAdapter                                 │  │ │\n│  │  │  - CursorAdapter                                  │  │ │\n│  │  └──────────────────────────────────────────────────┘  │ │\n│  │                       ▼                                  │ │\n│  │  Executor (ClaudeCodeExecutor, etc.)                    │ │\n│  │  → NormalizedEntry stream (agent-agnostic)              │ │\n│  └────────────────────────────────────────────────────────┘ │\n│                            ▼                                 │\n│  ┌────────────────────────────────────────────────────────┐ │\n│  │  NormalizedEntryToAgUiAdapter                           │ │\n│  │  - Converts to AG-UI events (works for all agents!)     │ │\n│  └────────────────────────────────────────────────────────┘ │\n└─────────────────────────────────────────────────────────────┘\n```\n\n### Key Components\n\n#### 1. Agent Registry System\n\n**Location**: `server/src/services/agent-registry.ts` (new)\n\n**Responsibilities**:\n- Initialize and maintain the `AgentRegistry` from agent-execution-engine\n- Register all available agent adapters on server startup\n- Provide API to query available agents and their metadata\n- Lookup agent adapters by type\n\n**API**:\n```typescript\ninterface AgentRegistryService {\n  initialize(): void;\n  getAvailableAgents(): AgentMetadata[];\n  getAdapter(agentType: AgentType): IAgentAdapter<any>;\n  isAgentImplemented(agentType: AgentType): boolean;\n}\n```\n\n**Endpoint**: `GET /api/agents`\n```json\n{\n  \"agents\": [\n    {\n      \"type\": \"claude-code\",\n      \"displayName\": \"Claude Code\",\n      \"description\": \"Anthropic's official CLI for Claude\",\n      \"supportedModes\": [\"structured\", \"interactive\", \"hybrid\"],\n      \"supportsStreaming\": true,\n      \"supportsStructuredOutput\": true,\n      \"implemented\": true\n    },\n    {\n      \"type\": \"codex\",\n      \"displayName\": \"OpenAI Codex\",\n      \"description\": \"OpenAI's code generation model\",\n      \"supportedModes\": [\"structured\"],\n      \"supportsStreaming\": false,\n      \"supportsStructuredOutput\": true,\n      \"implemented\": false\n    }\n    // ... more agents\n  ]\n}\n```\n\n#### 2. Generic Executor Wrapper\n\n**Location**: `server/src/execution/executors/agent-executor-wrapper.ts` (refactored from `claude-executor-wrapper.ts`)\n\n**Changes**:\n- Make class generic: `AgentExecutorWrapper<TConfig extends BaseAgentConfig>`\n- Accept `IAgentAdapter<TConfig>` in constructor\n- Use `adapter.buildProcessConfig(config)` to create process configuration\n- Remove Claude Code-specific assumptions\n- Keep all lifecycle integration (worktrees, logs, transport, broadcasts)\n\n**Before**:\n```typescript\nclass ClaudeExecutorWrapper {\n  constructor(private config: ClaudeConfig) {\n    // Hardcoded Claude Code executor\n    this.executor = new ClaudeCodeExecutor(/*...*/);\n  }\n}\n```\n\n**After**:\n```typescript\nclass AgentExecutorWrapper<TConfig extends BaseAgentConfig> {\n  constructor(\n    private adapter: IAgentAdapter<TConfig>,\n    private config: TConfig\n  ) {\n    // Use adapter to build process config\n    const processConfig = adapter.buildProcessConfig(config);\n    // Create generic executor using the adapter's executor class\n    this.executor = createExecutorFromAdapter(adapter, processConfig);\n  }\n}\n```\n\n**Factory Function**:\n```typescript\nfunction createExecutorForAgent(\n  agentType: AgentType,\n  config: any\n): AgentExecutorWrapper<any> {\n  const adapter = agentRegistry.getAdapter(agentType);\n  \n  // Validate config\n  const errors = adapter.validateConfig?.(config);\n  if (errors?.length) {\n    throw new ValidationError(errors);\n  }\n  \n  return new AgentExecutorWrapper(adapter, config);\n}\n```\n\n#### 3. Agent Adapters\n\nEach agent requires an adapter implementing `IAgentAdapter<TConfig>`:\n\n**Claude Code Adapter** (already exists in agent-execution-engine):\n- Location: `agent-execution-engine/src/agents/claude/adapter.ts`\n- Config: `ClaudeCodeConfig` with `print`, `outputFormat`, `verbose`, etc.\n- Modes: `structured`, `interactive`, `hybrid`\n- Output: Native `NormalizedEntry` stream\n\n**Codex Adapter** (new):\n- Location: `server/src/execution/adapters/codex-adapter.ts`\n- Config: API key, model, temperature, max tokens\n- Modes: `structured` only\n- Output: Convert OpenAI API responses to `NormalizedEntry`\n\n**Copilot Adapter** (new):\n- Location: `server/src/execution/adapters/copilot-adapter.ts`\n- Config: GitHub token, model variant\n- Modes: TBD (research needed)\n- Output: Convert Copilot CLI output to `NormalizedEntry`\n\n**Cursor Adapter** (new):\n- Location: `server/src/execution/adapters/cursor-adapter.ts`\n- Config: TBD (research needed)\n- Modes: TBD (research needed)\n- Output: Convert Cursor output to `NormalizedEntry`\n\n#### 4. Frontend Agent Selection\n\n**AgentConfigPanel Updates** (`frontend/src/components/executions/AgentConfigPanel.tsx`):\n\n**New UI Structure**:\n```tsx\n<AgentConfigPanel>\n  {/* NEW: Agent Selection */}\n  <AgentSelector\n    agents={availableAgents}\n    selected={selectedAgent}\n    onChange={handleAgentChange}\n  />\n  \n  {/* Existing: Mode Selection - now filtered by agent capabilities */}\n  <ModeSelector\n    modes={selectedAgent.supportedModes}\n    selected={mode}\n    onChange={handleModeChange}\n  />\n  \n  {/* Agent-specific configuration */}\n  {selectedAgent.type === 'claude-code' && (\n    <ClaudeCodeConfig config={config} onChange={handleConfigChange} />\n  )}\n  \n  {selectedAgent.type === 'codex' && (\n    <CodexConfig config={config} onChange={handleConfigChange} />\n  )}\n  \n  {/* ... other agents */}\n  \n  {/* Advanced: JSON config editor */}\n  <AdvancedConfigEditor config={config} onChange={handleConfigChange} />\n</AgentConfigPanel>\n```\n\n**State Management**:\n```typescript\ninterface ExecutionConfigState {\n  agentType: AgentType;\n  agentConfig: ClaudeCodeConfig | CodexConfig | CopilotConfig | CursorConfig;\n  mode: ExecutionMode;\n  // ... other fields\n}\n```\n\n#### 5. Configuration Storage\n\n**Database** (`types/src/schema.ts`):\n- `executions.agent_type` column (already exists)\n- `executions.config` JSON column stores agent-specific config\n- `executions.mode` stores execution mode\n\n**Config Structure in DB**:\n```json\n{\n  \"agentType\": \"claude-code\",\n  \"config\": {\n    \"print\": \"markdown\",\n    \"outputFormat\": \"stream-json\",\n    \"verbose\": false,\n    \"model\": \"claude-sonnet-4-5\"\n  },\n  \"mode\": \"structured\"\n}\n```\n\n## Implementation Phases\n\n### Phase 1: Core Architecture & Registry (Week 1)\n\n**Goal**: Establish generic executor wrapper and agent registry integration\n\n#### Tasks:\n\n1. **Update Type Definitions**\n   - File: `types/src/index.d.ts`\n   - Update `AgentType` to include: `'claude-code' | 'codex' | 'copilot' | 'cursor'`\n   - Create config types for each agent extending `BaseAgentConfig`\n   - Ensure `Execution` type properly handles multiple agent types\n\n2. **Create Agent Registry Service**\n   - File: `server/src/services/agent-registry.ts` (new)\n   - Initialize `AgentRegistry` from agent-execution-engine\n   - Register Claude Code adapter (from package)\n   - Create stub adapters for Codex, Copilot, Cursor (throw \"not implemented\" errors)\n   - Implement `getAvailableAgents()`, `getAdapter()`, `isAgentImplemented()`\n\n3. **Refactor Executor Wrapper**\n   - File: `server/src/execution/executors/claude-executor-wrapper.ts` → `agent-executor-wrapper.ts`\n   - Make class generic: `AgentExecutorWrapper<TConfig>`\n   - Accept `IAgentAdapter<TConfig>` in constructor\n   - Use `adapter.buildProcessConfig()` for process configuration\n   - Keep all lifecycle integration unchanged\n   - Create `createExecutorForAgent()` factory function\n\n4. **Update Execution Service**\n   - File: `server/src/services/executions.ts`\n   - Modify `createExecution()` to accept `agentType` parameter\n   - Use `createExecutorForAgent()` factory instead of hardcoded wrapper\n   - Add config validation using `adapter.validateConfig()`\n   - Update resume logic to instantiate correct executor based on `agent_type` from DB\n\n5. **Testing**\n   - Unit tests for `AgentRegistryService`\n   - Unit tests for generic `AgentExecutorWrapper`\n   - Integration test: Claude Code execution works with new architecture (regression test)\n   - Integration test: Factory function creates correct wrapper\n\n**Success Criteria**:\n- ✅ Existing Claude Code executions continue to work (no regression)\n- ✅ Agent registry initializes on server startup\n- ✅ Generic executor wrapper passes all tests\n- ✅ Can create executions with explicit `agentType: 'claude-code'`\n\n### Phase 2: Server API Updates (Week 1-2)\n\n**Goal**: Expose agent capabilities and handle agent-specific execution requests\n\n#### Tasks:\n\n1. **Create Agents API Endpoint**\n   - File: `server/src/routes/agents.ts` (new)\n   - Endpoint: `GET /api/agents`\n   - Returns list of available agents with metadata\n   - Includes `implemented` flag for each agent\n   - Add to router in `server/src/index.ts`\n\n2. **Update Execution API**\n   - File: `server/src/routes/executions.ts`\n   - Accept `agentType` in `POST /api/executions` request body\n   - Validate that agent is implemented before creating execution\n   - Return clear error if agent not available\n   - Store `agentType` in database\n\n3. **Error Handling**\n   - Define error types: `AgentNotFoundError`, `AgentNotImplementedError`, `AgentConfigValidationError`\n   - Return appropriate HTTP status codes (404, 501, 400)\n   - Include helpful error messages for frontend display\n\n4. **Testing**\n   - API test: `GET /api/agents` returns expected agent list\n   - API test: Create execution with `agentType: 'claude-code'` succeeds\n   - API test: Create execution with unimplemented agent returns 501\n   - API test: Create execution with invalid agent type returns 400\n\n**Success Criteria**:\n- ✅ `GET /api/agents` returns all registered agents\n- ✅ Can create Claude Code executions via API with explicit agent type\n- ✅ Attempting to create execution with unimplemented agent fails gracefully\n- ✅ All error cases handled with appropriate status codes\n\n### Phase 3: Frontend Agent Selection (Week 2)\n\n**Goal**: Enable agent selection in the UI\n\n#### Tasks:\n\n1. **Fetch Available Agents**\n   - File: `frontend/src/hooks/useAgents.ts` (new)\n   - Hook to fetch agents from `GET /api/agents`\n   - Cache results\n   - Expose loading/error states\n\n2. **Create Agent Selector Component**\n   - File: `frontend/src/components/executions/AgentSelector.tsx` (new)\n   - Dropdown to select agent\n   - Display agent name, description, and implemented status\n   - Disable unimplemented agents with \"Coming Soon\" label\n   - Show agent capabilities on hover/expand\n\n3. **Update AgentConfigPanel**\n   - File: `frontend/src/components/executions/AgentConfigPanel.tsx`\n   - Add `AgentSelector` at top of panel\n   - Track selected agent in state\n   - Filter mode dropdown by `selectedAgent.supportedModes`\n   - Conditionally show streaming toggle based on `selectedAgent.supportsStreaming`\n\n4. **Update Execution Context**\n   - File: `frontend/src/contexts/ExecutionContext.tsx`\n   - Add `agentType` to execution config state\n   - Default to `'claude-code'`\n   - Include in execution creation request\n\n5. **Update Execution Creation**\n   - File: `frontend/src/components/executions/ExecutionConfigDialog.tsx`\n   - Include `agentType` in execution creation request\n   - Display error if agent not available\n   - Show validation errors from server\n\n6. **Testing**\n   - Component test: `AgentSelector` renders available agents\n   - Component test: Unimplemented agents are disabled\n   - Component test: Selecting agent updates execution config\n   - Integration test: Can create execution with selected agent\n   - E2E test: Full execution creation flow with agent selection\n\n**Success Criteria**:\n- ✅ Agent selector dropdown appears in UI\n- ✅ Only Claude Code is enabled initially\n- ✅ Other agents show as \"Coming Soon\"\n- ✅ Selected agent persists in execution config\n- ✅ Can create Claude Code executions through new UI\n\n### Phase 4: Agent Adapter Implementations (Weeks 3-5)\n\n**Goal**: Implement adapters for Codex, Copilot, and Cursor\n\nFor each agent, follow this sub-phase structure:\n\n#### 4.1 Research Phase (Per Agent)\n\n**Tasks**:\n- Research CLI interface, installation, authentication\n- Document command structure and arguments\n- Identify input/output formats\n- Determine supported modes and capabilities\n- Document configuration options\n- Test CLI locally to understand behavior\n\n**Deliverable**: Research document per agent\n\n#### 4.2 Adapter Implementation (Per Agent)\n\n**Tasks**:\n\n1. **Create Adapter Class**\n   - File: `server/src/execution/adapters/{agent}-adapter.ts`\n   - Implement `IAgentAdapter<TConfig>` interface\n   - Define agent-specific config type\n   - Implement `buildProcessConfig()` to translate to generic `ProcessConfig`\n   - Implement `validateConfig()` for config validation\n   - Define `metadata` with capabilities\n\n2. **Create Config Builder**\n   - File: `server/src/execution/adapters/{agent}-config-builder.ts`\n   - Helper functions to build agent-specific config\n   - Sensible defaults\n\n3. **Implement Output Normalization**\n   - If agent doesn't output `NormalizedEntry` format natively:\n   - Create output parser/transformer\n   - Convert agent output to `NormalizedEntry` stream\n   - Handle errors and edge cases\n\n4. **Register Adapter**\n   - Update `server/src/services/agent-registry.ts`\n   - Replace stub with real adapter\n   - Test registration\n\n5. **Frontend Configuration UI**\n   - File: `frontend/src/components/executions/{Agent}ConfigForm.tsx` (new)\n   - Basic form for agent-specific settings\n   - API key input (if needed)\n   - Model selection (if applicable)\n   - Common settings (timeout, etc.)\n   - Integrate with `AgentConfigPanel`\n\n6. **Testing**\n   - Unit tests for adapter methods\n   - Unit tests for config validation\n   - Integration test: Create execution with agent\n   - Integration test: Execute simple task with agent\n   - E2E test: Full execution flow with agent\n\n**Success Criteria (Per Agent)**:\n- ✅ Adapter implements all required interface methods\n- ✅ Config validation works correctly\n- ✅ Can create and run executions with agent\n- ✅ Output is normalized to `NormalizedEntry` format\n- ✅ Frontend shows agent-specific config form\n- ✅ All tests pass\n\n#### Agent Implementation Order:\n\n1. **Codex** (Week 3)\n   - Simplest: API-based, well-documented\n   - Good validation of architecture\n\n2. **Copilot** (Week 4)\n   - CLI-based, similar to Claude Code\n   - Tests adapter pattern for interactive CLIs\n\n3. **Cursor** (Week 5)\n   - Most complex, may require custom integration\n   - Final validation of architecture\n\n### Phase 5: Configuration Enhancements (Week 6)\n\n**Goal**: Improve configuration UX and validation\n\n#### Tasks:\n\n1. **Capability-Based UI Controls**\n   - Update `AgentConfigPanel` to show/hide controls based on capabilities\n   - Mode dropdown: Only show modes in `supportedModes`\n   - Streaming toggle: Only show if `supportsStreaming`\n   - Model selection: Only show for agents that support models\n   - Disable \"Create Execution\" if agent not implemented\n\n2. **Advanced Configuration Editor**\n   - File: `frontend/src/components/executions/AdvancedConfigEditor.tsx` (new)\n   - JSON editor for advanced agent-specific settings\n   - Syntax highlighting\n   - Validation against schema\n   - Collapsible \"Advanced\" section\n\n3. **Configuration Validation**\n   - Client-side validation before submission\n   - Display validation errors inline\n   - Show helpful error messages\n   - Prevent submission of invalid configs\n\n4. **Configuration Defaults**\n   - Server-side: Use `adapter.getDefaultConfig()` for sensible defaults\n   - Frontend: Pre-populate forms with defaults\n   - Allow users to reset to defaults\n\n5. **Testing**\n   - Component tests for capability-based controls\n   - Component tests for config validation\n   - E2E test: Validation prevents invalid execution creation\n\n**Success Criteria**:\n- ✅ UI adapts to agent capabilities\n- ✅ Invalid configs caught before submission\n- ✅ Users can edit advanced settings via JSON\n- ✅ Default configs work out-of-the-box\n\n## Technical Considerations\n\n### Backwards Compatibility\n\n**Existing Executions**:\n- Database already has `agent_type` column\n- Existing executions may have `null` or `'claude-code'` as agent type\n- Migration: Set `agent_type = 'claude-code'` for all existing executions with `null`\n- Resume logic: Default to Claude Code if agent type missing\n\n**API Compatibility**:\n- `POST /api/executions` should accept `agentType` as optional parameter\n- Default to `'claude-code'` if not provided (backwards compatible)\n- Existing clients continue to work without changes\n\n### Security Considerations\n\n**API Key Handling**:\n- Never log API keys\n- Store encrypted in database if persistence needed\n- Transmit over HTTPS only\n- Consider using environment variables for system-wide keys\n\n**Agent CLI Validation**:\n- Validate executable path exists before execution\n- Check executable permissions\n- Sanitize user inputs passed to CLI\n- Prevent command injection via config parameters\n\n**Sandboxing**:\n- Maintain existing worktree isolation\n- Consider additional sandboxing for untrusted agents\n- Limit agent access to project files only\n\n### Performance Considerations\n\n**Agent Registry**:\n- Initialize once on server startup\n- Cache agent metadata\n- Lazy-load adapter implementations if needed\n\n**Output Normalization**:\n- Stream conversion (don't buffer entire output)\n- Handle backpressure for slow consumers\n- Optimize parsing for high-frequency output\n\n**Frontend Caching**:\n- Cache available agents list (rarely changes)\n- Cache agent metadata\n- Invalidate cache on server restart\n\n### Error Handling\n\n**Agent Not Available**:\n- Clear error message: \"Agent '{name}' requires installation of {cli-name}\"\n- Link to installation instructions\n- Disable agent selection in UI\n\n**Config Validation Failures**:\n- Show specific validation errors per field\n- Highlight invalid fields in UI\n- Provide example of valid config\n\n**Execution Failures**:\n- Distinguish agent-specific errors from system errors\n- Include agent name in error context\n- Suggest troubleshooting steps\n\n### Testing Strategy\n\n**Unit Tests**:\n- Agent adapter methods (config building, validation)\n- Agent registry service\n- Generic executor wrapper\n- Config validation logic\n\n**Integration Tests**:\n- End-to-end execution with each agent\n- Agent switching between executions\n- Config persistence and retrieval\n- Output normalization pipeline\n\n**E2E Tests**:\n- Full user flow: select agent → configure → execute → view results\n- Agent switching during session\n- Error cases (invalid config, agent unavailable)\n\n**Regression Tests**:\n- Existing Claude Code executions continue to work\n- API backwards compatibility\n- Database migrations\n\n## Migration Plan\n\n### Database Migration\n\n**Migration**: `Add_agent_type_default.sql`\n```sql\n-- Set agent_type to 'claude-code' for existing executions with NULL\nUPDATE executions \nSET agent_type = 'claude-code' \nWHERE agent_type IS NULL;\n\n-- Ensure agent_type column is NOT NULL going forward\nALTER TABLE executions \nALTER COLUMN agent_type SET DEFAULT 'claude-code';\n```\n\n### Code Migration\n\n**Phase 1**: Refactor to generic wrapper (non-breaking)\n- Create `AgentExecutorWrapper` alongside `ClaudeExecutorWrapper`\n- Update `ExecutionService` to use new wrapper for new executions\n- Keep old wrapper for resuming existing executions\n\n**Phase 2**: Deprecate old wrapper\n- Add migration to set agent_type for all executions\n- Update resume logic to use generic wrapper\n- Mark `ClaudeExecutorWrapper` as deprecated\n\n**Phase 3**: Remove old wrapper\n- Delete `ClaudeExecutorWrapper`\n- All executions use `AgentExecutorWrapper`\n\n## Rollout Plan\n\n### Stage 1: Internal Testing (Week 6)\n- Deploy to staging environment\n- Test with real API keys for each agent\n- Validate full execution flows\n- Performance testing\n- Security review\n\n### Stage 2: Beta Release (Week 7)\n- Release with Claude Code (stable) + Codex (beta)\n- Limited user group testing\n- Collect feedback on UX\n- Monitor errors and performance\n- Iterate on configuration UI\n\n### Stage 3: General Availability (Week 8)\n- Release all agents (mark experimental if needed)\n- Update documentation\n- Announce feature to users\n- Monitor adoption and issues\n\n### Stage 4: Refinement (Ongoing)\n- Add more agents based on user demand\n- Improve configuration UX based on feedback\n- Performance optimizations\n- Advanced features (presets, defaults, etc.)\n\n## Success Metrics\n\n### Functional Metrics\n- All existing Claude Code executions continue to work (100% backwards compatibility)\n- Users can successfully create executions with each implemented agent\n- Agent selection persists correctly in execution history\n- Configuration validation prevents invalid executions\n\n### Performance Metrics\n- Agent registry initialization: < 100ms\n- GET /api/agents response time: < 50ms\n- Execution creation with agent validation: < 200ms\n- Output normalization overhead: < 5% of total execution time\n\n### Quality Metrics\n- Test coverage: > 80% for new code\n- Zero regressions in existing functionality\n- All critical bugs fixed before GA release\n- Documentation completeness: 100%\n\n### Adoption Metrics\n- % of executions using non-Claude agents\n- Most popular agent (besides Claude Code)\n- Configuration error rate (should decrease over time)\n\n## Documentation Requirements\n\n### User Documentation\n\n1. **Agent Selection Guide**\n   - How to choose an agent\n   - Comparison of agent capabilities\n   - When to use which agent\n\n2. **Configuration Guide**\n   - Agent-specific configuration options\n   - How to obtain API keys\n   - Troubleshooting common issues\n\n3. **Agent Installation Guide**\n   - CLI installation instructions per agent\n   - Authentication setup\n   - Verification steps\n\n### Developer Documentation\n\n1. **Architecture Overview**\n   - Multi-agent system design\n   - Component interactions\n   - Data flow diagrams\n\n2. **Adding New Agents**\n   - Adapter implementation guide\n   - Testing requirements\n   - Registration process\n\n3. **API Documentation**\n   - GET /api/agents endpoint\n   - Updated POST /api/executions endpoint\n   - Error codes and responses\n\n## Risks and Mitigations\n\n### Risk 1: Agent CLI Not Installed\n\n**Impact**: Users can't execute with selected agent\n\n**Mitigation**:\n- Check for executable existence before showing agent as available\n- Show clear installation instructions when agent unavailable\n- Allow users to specify custom executable paths\n\n### Risk 2: Inconsistent Output Formats\n\n**Impact**: Output normalization fails for some agents\n\n**Mitigation**:\n- Thoroughly test output normalization for each agent\n- Fallback to raw output display if normalization fails\n- Add debug mode to show raw agent output\n\n### Risk 3: Breaking Changes in Agent CLIs\n\n**Impact**: Adapter stops working after agent update\n\n**Mitigation**:\n- Version-pin agent CLIs in recommendations\n- Detect CLI version and adapt behavior\n- Show warnings for unsupported versions\n- Maintain adapter compatibility matrix\n\n### Risk 4: Performance Degradation\n\n**Impact**: Multi-agent support slows down executions\n\n**Mitigation**:\n- Benchmark performance before and after changes\n- Profile hot paths (output normalization, config validation)\n- Optimize registry lookups (caching, indexing)\n- Monitor production performance metrics\n\n### Risk 5: Security Vulnerabilities\n\n**Impact**: Agent configs expose sensitive data or allow injection attacks\n\n**Mitigation**:\n- Security review of config validation logic\n- Sanitize all user inputs passed to CLI\n- Never log sensitive config fields\n- Follow secure credential storage practices\n- Regular security audits\n\n## Open Questions\n\n1. **Agent Authentication**: How should we handle API keys for each agent?\n   - Store encrypted in database per project?\n   - Use environment variables system-wide?\n   - Prompt user on each execution?\n\n2. **Agent Availability Detection**: How do we check if an agent CLI is installed?\n   - Run `{agent} --version` on startup?\n   - Check PATH for executable?\n   - Allow users to configure custom paths?\n\n3. **Output Format Compatibility**: What if an agent doesn't support structured output?\n   - Parse terminal output with heuristics?\n   - Fall back to raw output display?\n   - Require structured output capability?\n\n4. **Concurrent Multi-Agent Executions**: Should we support running multiple agents in parallel?\n   - Within same execution?\n   - Across different executions?\n   - Resource management considerations?\n\n5. **Agent-Specific Features**: How do we handle features unique to one agent?\n   - Expose in advanced config JSON?\n   - Create agent-specific UI sections?\n   - Document but don't surface in UI?\n\n## Conclusion\n\nThis spec outlines a comprehensive plan to add multi-agent support to sudocode by leveraging the existing agent-execution-engine architecture. The phased approach allows for incremental delivery, starting with core infrastructure and progressively adding agent implementations.\n\nKey success factors:\n- **Generic architecture** that supports any agent implementing the adapter interface\n- **Backwards compatibility** ensuring existing Claude Code executions continue to work\n- **Unified experience** where users get consistent execution interface regardless of agent\n- **Extensibility** making it easy to add new agents in the future\n\nBy completing this work, sudocode will evolve from a Claude Code-specific tool to a **universal AI coding agent orchestration platform**, giving users the flexibility to choose the best agent for their specific needs.","priority":1,"archived":0,"archived_at":null,"created_at":"2025-11-23 20:01:23","updated_at":"2025-11-23 20:01:23","parent_id":null,"parent_uuid":null,"relationships":[],"tags":["architecture","backend","execution","frontend","multi-agent"]}
{"id":"s-8lkf","uuid":"4d9abfb8-512c-424c-842e-1af466119d61","title":"Watcher Event System: Replace Log Parsing with Typed Callbacks","file_path":"specs/s-27p3 - Watcher Event System Replace Log Parsing with Type.md","content":"# Watcher Event System: Replace Log Parsing with Typed Callbacks\n\n## Overview\n\nReplace the fragile log message parsing system with typed event callbacks for communication between the CLI watcher and server. This improves reliability, type safety, and maintainability of the file watching and WebSocket broadcast system.\n\n## Problem Statement\n\n### Current Architecture Issues\n\nThe server currently parses CLI watcher stdout messages with regex to detect entity changes:\n\n```typescript\n// FRAGILE: Regex parsing of log messages\nconst syncMatch = message.match(\n  /\\[watch\\] Synced (spec|issue) ([A-Za-z0-9-]+) (?:to .+ )?\\((created|updated)\\)/\n);\n```\n\n**Critical Problems:**\n\n1. **Silent Failures**: If log format changes, regex doesn't match → no broadcast → UI doesn't update\n2. **No Type Safety**: Regex captures are untyped strings, easy to misuse  \n3. **Fragile Coupling**: Server depends on exact string format from CLI\n4. **Poor Debuggability**: When it fails, no indication of why\n5. **Performance Overhead**: Must query database again to get entity data\n6. **No Metadata**: Can't pass timing, source, or conflict information\n7. **No Project Context**: Events don't indicate which project they belong to (critical for multi-project servers)\n8. **Shared Database Problem**: When CLI updates DB, server's watcher can't detect changes (jsonlNeedsImport returns false)\n\n### Recent Bug Examples\n\n**Bug 1: ID Format Change**\nWhen ID format changed from `ISSUE-001` to `i-x7k9`, the regex pattern stopped matching:\n- MCP tool updates did NOT trigger UI broadcasts\n- Silent failure (no errors, just no updates)\n- Required emergency regex fix to restore functionality\n\n**Bug 2: CLI Update → No UI Update (Current)**\nWhen using CLI or MCP to update entities:\n- CLI updates database directly\n- Server's watcher detects JSONL change\n- `jsonlNeedsImport()` returns `false` (DB already synced)\n- No entity-specific logs emitted\n- Server doesn't know which entities changed\n- **UI never updates** ❌\n\nExample scenario:\n```bash\n# User runs: npx sudocode issue update ISSUE-143 --status closed\n# Expected: UI shows status updated to 'closed'\n# Actual: No UI update (database updated, but server doesn't broadcast)\n```\n\n## Solution: Typed Event Callbacks\n\n### Architecture Overview\n\nReplace stdout parsing with direct typed callbacks:\n\n```\n┌─────────────┐  onEntitySync(event) ┌──────────────┐\n│ CLI Watcher │ ──────────────────▶  │ Server       │\n│             │  EntitySyncEvent     │ Watcher      │\n└─────────────┘                      └──────────────┘\n```\n\nInstead of parsing strings, use structured data:\n\n```typescript\n// BEFORE: Parse string (fragile)\n\"[watch] Synced issue i-x7k9 to markdown (updated)\"\n\n// AFTER: Typed event (robust)\n{\n  entityType: 'issue',\n  entityId: 'i-x7k9',\n  action: 'updated',\n  filePath: '/abs/path/issues/i-x7k9.md',\n  baseDir: '/abs/path/.sudocode',  // NEW: For project identification\n  source: 'jsonl',\n  timestamp: Date,\n  entity: issueObject  // Optional: Avoids DB query\n}\n```\n\n## Multi-Project Support Design\n\n### The Challenge\n\nIn a multi-project server:\n- **Problem**: Multiple projects can have same entity ID (e.g., both have `ISSUE-143`)\n- **Question**: How does server know which project an event belongs to?\n\n### Current Architecture (Closure Scoping)\n\nEach project gets its own watcher with projectId in closure:\n\n```typescript\n// server/src/services/project-manager.ts:126-159\ncontext.watcher = startServerWatcher({\n  db,\n  baseDir: sudocodeDir,\n  onFileChange: (info) => {\n    // projectId available from closure! ✅\n    const projectId = projectId;  // From outer scope\n\n    if (info.entityType === 'issue' && info.entityId) {\n      const issue = getIssueById(db, info.entityId);\n      if (issue) {\n        broadcastIssueUpdate(projectId, info.entityId, 'updated', issue);\n      }\n    }\n  },\n});\n```\n\n**This works** because:\n- Each project has dedicated watcher instance\n- Callback has projectId in closure\n- No cross-project confusion\n\n### Design Decision: Include baseDir\n\n**✅ DECISION: Add `baseDir` to events**\n\nEvents should include `baseDir` for self-contained context:\n\n```typescript\n{\n  entityId: 'ISSUE-143',\n  baseDir: '/abs/path/to/project/.sudocode',  // ✅\n  // Server can use closure OR derive project from baseDir\n}\n```\n\n**Why baseDir?**\n1. ✅ CLI already has it (no computation needed)\n2. ✅ Server can use closure (preferred) OR derive projectId (fallback)\n3. ✅ Events are self-documenting for debugging\n4. ✅ Doesn't force CLI to understand projectId\n5. ✅ Future-proofs for multi-project CLI scenarios\n\n**Rejected Alternatives:**\n- ❌ **No project context**: Can't debug events independently\n- ❌ **Include projectId**: Breaks CLI's project-agnostic design\n- ❌ **Only filePath**: Requires parsing to find `.sudocode` dir\n\n## Type Definitions\n\n### Core Event Types\n\n```typescript\n/**\n * Event fired when an entity is synced between database and markdown\n */\nexport interface EntitySyncEvent {\n  /** Type of entity that was synced */\n  entityType: 'spec' | 'issue';\n\n  /** ID of the entity (e.g., 'i-x7k9', 's-14sh') */\n  entityId: string;\n\n  /** Action that was performed */\n  action: 'created' | 'updated' | 'deleted' | 'no-change';\n\n  /** Absolute path to the markdown file */\n  filePath: string;\n\n  /** Absolute path to the .sudocode directory (for project identification) */\n  baseDir: string;  // ✅ NEW\n\n  /** Source of the change that triggered sync */\n  source: 'markdown' | 'jsonl' | 'database';\n\n  /** Timestamp when event occurred */\n  timestamp: Date;\n\n  /** Optional: Full entity data (avoids DB query in server) */\n  entity?: Spec | Issue;\n\n  /** Optional: Duration of sync operation in milliseconds */\n  duration?: number;\n\n  /** Optional: Whether a merge conflict was resolved */\n  conflictResolved?: boolean;\n}\n\n/**\n * Event fired when a file change is detected (before sync)\n */\nexport interface FileChangeEvent {\n  /** Absolute path to the file */\n  filePath: string;\n\n  /** Absolute path to the .sudocode directory */\n  baseDir: string;  // ✅ NEW\n\n  /** Type of file system event */\n  event: 'add' | 'change' | 'unlink';\n\n  /** Detected entity type (if applicable) */\n  entityType?: 'spec' | 'issue';\n\n  /** Detected entity ID (if applicable) */\n  entityId?: string;\n\n  /** Timestamp */\n  timestamp: Date;\n}\n```\n\n### Updated Watcher Options\n\n```typescript\nexport interface WatcherOptions {\n  db: Database.Database;\n  baseDir: string;\n  debounceDelay?: number;\n  ignoreInitial?: boolean;\n  syncJSONLToMarkdown?: boolean;\n\n  // EXISTING: Keep for backward compatibility and human debugging\n  onLog?: (message: string) => void;\n  onError?: (error: Error) => void;\n\n  // NEW: Typed callbacks for machine consumption\n  /** Called when an entity is synced (after successful sync) */\n  onEntitySync?: (event: EntitySyncEvent) => void | Promise<void>;\n\n  /** Called when a file change is detected (before sync) */\n  onFileChange?: (event: FileChangeEvent) => void | Promise<void>;\n}\n```\n\n## Gap Analysis & Solutions\n\n### Gap 1: Shared Database Problem ✅ SOLUTION PROVIDED\n\n**Problem**: When CLI/MCP updates DB, server can't detect which entities changed.\n\n**Root Cause**:\n```typescript\n// cli/src/watcher.ts (current)\nif (jsonlNeedsImport(filePath)) {  // Returns false when DB already synced!\n  await importFromJSONL(db, { inputDir: baseDir });\n  // Only emits logs INSIDE this block\n  // When DB already synced, no logs = no broadcasts\n}\n```\n\n**Solution**: Emit `onEntitySync` events ALWAYS, not just when import needed.\n\n**Implementation**:\n```typescript\n// cli/src/watcher.ts (AFTER implementing Phase 1)\nconst entityType = basename === \"specs.jsonl\" ? \"spec\" : \"issue\";\n\n// Track entities BEFORE any import\nconst beforeEntities = entityType === \"spec\"\n  ? listSpecs(db).map(s => ({ id: s.id, updated_at: s.updated_at }))\n  : listIssues(db).map(i => ({ id: i.id, updated_at: i.updated_at }));\n\n// Import if needed\nif (jsonlNeedsImport(filePath)) {\n  await importFromJSONL(db, { inputDir: baseDir });\n}\n\n// Track entities AFTER (whether imported or not)\nconst afterEntities = entityType === \"spec\"\n  ? listSpecs(db).map(s => ({ id: s.id, updated_at: s.updated_at }))\n  : listIssues(db).map(i => ({ id: i.id, updated_at: i.updated_at }));\n\n// Emit events for ALL changed entities\nconst changed = detectChangedEntities(beforeEntities, afterEntities);\nfor (const entity of changed) {\n  onEntitySync?.({\n    entityType,\n    entityId: entity.id,\n    action: entity.isNew ? 'created' : 'updated',\n    filePath: entity.filePath,\n    baseDir,\n    source: 'jsonl',\n    timestamp: new Date(),\n    entity: entity.data,  // ✅ Include full entity\n  });\n}\n```\n\n**Key Points**:\n- ✅ Always track before/after state\n- ✅ Emit events even when `jsonlNeedsImport()` returns false\n- ✅ Include full entity data (avoids server DB query)\n- ✅ Solves \"CLI update → no UI update\" bug\n\n### Gap 2: Multi-Project Context ✅ SOLUTION PROVIDED\n\n**Problem**: Events don't indicate which project they belong to.\n\n**Solution**: Include `baseDir` in all events (already in type definitions above).\n\n**Server Implementation**:\n```typescript\n// server/src/services/project-manager.ts\ncontext.watcher = startServerWatcher({\n  db,\n  baseDir: sudocodeDir,\n  onFileChange: (info) => {\n    // OPTION A: Use closure (preferred)\n    const projectId = projectId;  // From outer scope ✅\n\n    // OPTION B: Derive from baseDir (fallback)\n    // const projectId = this.getProjectIdByPath(info.baseDir);\n\n    // Validate baseDir matches (optional safety check)\n    if (info.baseDir !== sudocodeDir) {\n      console.warn(`baseDir mismatch: expected ${sudocodeDir}, got ${info.baseDir}`);\n    }\n\n    // Use entity from event if available (optimization)\n    if (info.entity) {\n      broadcastIssueUpdate(projectId, info.entityId, 'updated', info.entity);\n    } else {\n      const issue = getIssueById(db, info.entityId);\n      if (issue) {\n        broadcastIssueUpdate(projectId, info.entityId, 'updated', issue);\n      }\n    }\n  },\n});\n```\n\n### Gap 3: Testing Coverage ✅ TESTS PROVIDED\n\n**Missing Tests**:\n- Multi-project scenarios\n- Shared database edge case\n- baseDir validation\n\n**Solution**: Comprehensive test suite (see Testing Strategy section below).\n\n## Implementation Plan\n\n### Phase 1: Add Callbacks (Non-Breaking) ✅ Safe\n\n**Goal**: Add new callbacks alongside existing logs, no breaking changes.\n\n**Changes**:\n\n1. **Add types** (`types/src/index.d.ts`):\n```typescript\nexport interface EntitySyncEvent { /* as defined above */ }\nexport interface FileChangeEvent { /* as defined above */ }\n```\n\n2. **Update CLI watcher** (`cli/src/watcher.ts`):\n\n```typescript\n// Add callbacks to options (already defined above)\n\n// In JSONL change handler (~line 399):\nasync function processJSONLChange(filePath: string) {\n  const entityType = basename === \"specs.jsonl\" ? \"spec\" : \"issue\";\n\n  // Track before state\n  const before = entityType === \"spec\"\n    ? listSpecs(db).map(s => ({ id: s.id, updated_at: s.updated_at }))\n    : listIssues(db).map(i => ({ id: i.id, updated_at: i.updated_at }));\n\n  // Import if needed  \n  if (jsonlNeedsImport(filePath)) {\n    await importFromJSONL(db, { inputDir: baseDir });\n    onLog(`[watch] Imported JSONL changes to database`);\n  }\n\n  // Track after state\n  const after = entityType === \"spec\"\n    ? listSpecs(db).map(s => ({ id: s.id, updated_at: s.updated_at }))\n    : listIssues(db).map(i => ({ id: i.id, updated_at: i.updated_at }));\n\n  // Detect changes\n  const beforeMap = new Map(before.map(e => [e.id, e.updated_at]));\n  const afterMap = new Map(after.map(e => [e.id, e.updated_at]));\n\n  // Emit events for changed entities\n  for (const [id, afterTime] of afterMap) {\n    const beforeTime = beforeMap.get(id);\n    const action = !beforeTime ? 'created' : beforeTime !== afterTime ? 'updated' : 'no-change';\n\n    if (action !== 'no-change') {\n      // Get full entity\n      const entity = entityType === 'spec' \n        ? getSpec(db, id)\n        : getIssue(db, id);\n\n      // Find file path\n      const filePath = entity?.file_path \n        ? path.join(baseDir, entity.file_path)\n        : path.join(baseDir, entityType === 'spec' ? 'specs' : 'issues', `${id}.md`);\n\n      // KEEP: Existing log\n      onLog(`[watch] Synced ${entityType} ${id} (${action})`);\n\n      // ADD: Typed callback\n      onEntitySync?.({\n        entityType,\n        entityId: id,\n        action,\n        filePath,\n        baseDir,\n        source: 'jsonl',\n        timestamp: new Date(),\n        entity,  // ✅ Include full entity\n      });\n    }\n  }\n}\n```\n\n3. **In Markdown sync handlers** (emit similar events after MD→DB sync)\n\n**Testing**:\n- Unit tests: Verify callbacks called with correct data\n- Integration tests: Verify existing log parsing still works\n- Ensure no breaking changes\n\n**Timeline**: 1-2 days\n\n### Phase 2: Migrate Server (Backward Compatible) ✅ Safe\n\n**Goal**: Server uses callbacks when available, falls back to parsing.\n\n**Changes**:\n\n1. Update `server/src/services/watcher.ts`:\n\n```typescript\nexport function startServerWatcher(options: ServerWatcherOptions) {\n  const { db, baseDir, onFileChange } = options;\n  let callbackFired = false;\n\n  const control = startCliWatcher({\n    db,\n    baseDir,\n\n    // NEW PATH: Use typed callback (preferred)\n    onEntitySync: (event) => {\n      callbackFired = true;\n      console.log(`[watcher] Entity synced via callback: ${event.entityType} ${event.entityId}`);\n\n      if (onFileChange) {\n        onFileChange({\n          filePath: event.filePath,\n          baseDir: event.baseDir,  // ✅ NEW\n          event: 'change',\n          entityType: event.entityType,\n          entityId: event.entityId,\n          entity: event.entity,  // ✅ Pass through\n          timestamp: event.timestamp,\n        });\n      }\n    },\n\n    // OLD PATH: Fallback to parsing\n    onLog: (message) => {\n      console.log(message);\n\n      // Only parse if callback didn't fire\n      if (!callbackFired && onFileChange && message.includes('[watch] Synced')) {\n        const syncMatch = message.match(\n          /\\[watch\\] Synced (spec|issue) ([A-Za-z0-9-]+) (?:to .+ )?\\((created|updated)\\)/\n        );\n        \n        if (syncMatch) {\n          console.warn('⚠️  Using legacy log parsing (update CLI for callbacks)');\n          const [, entityType, entityId] = syncMatch;\n          \n          onFileChange({\n            filePath: \"\",\n            baseDir,  // Use baseDir from options\n            event: 'change',\n            entityType: entityType as 'spec' | 'issue',\n            entityId,\n            timestamp: new Date(),\n          });\n        }\n      }\n\n      callbackFired = false;  // Reset for next event\n    },\n  });\n\n  return control;\n}\n```\n\n2. Update `ServerWatcherOptions` interface to match:\n\n```typescript\ninterface ServerWatcherOptions {\n  db: Database.Database;\n  baseDir: string;\n  onFileChange?: (info: {\n    filePath: string;\n    baseDir: string;  // ✅ NEW\n    event: 'add' | 'change' | 'unlink';\n    entityType?: 'spec' | 'issue';\n    entityId?: string;\n    entity?: any;  // ✅ NEW\n    timestamp: Date;\n  }) => void;\n}\n```\n\n**Testing**:\n- Test callback path works\n- Test fallback parsing works\n- Test performance improvement (should be 2x faster with callbacks)\n\n**Timeline**: 1-2 days\n\n### Phase 3: Deprecate Parsing ⚠️  Warning\n\n**Goal**: Encourage migration with deprecation warnings.\n\n**Timeline**: 2-3 release cycles\n\n### Phase 4: Remove Parsing 🔴 Breaking\n\n**Goal**: Clean up legacy code.\n\n**Timeline**: After 3+ releases with warnings\n\n## Testing Strategy\n\n### Unit Tests\n\n**CLI Watcher Tests** (`cli/tests/unit/watcher.test.ts`):\n\n```typescript\ndescribe('onEntitySync callback', () => {\n  it('should call onEntitySync when JSONL changes', async () => {\n    const events: EntitySyncEvent[] = [];\n\n    const watcher = startWatcher({\n      db,\n      baseDir,\n      onEntitySync: (event) => events.push(event),\n    });\n\n    // Modify JSONL directly\n    const issue = { id: 'i-test1', title: 'Test', updated_at: new Date().toISOString() };\n    fs.writeFileSync(issuesJsonlPath, JSON.stringify(issue));\n\n    await waitFor(() => events.length > 0);\n\n    expect(events[0]).toMatchObject({\n      entityType: 'issue',\n      entityId: 'i-test1',\n      action: 'updated',\n      source: 'jsonl',\n      baseDir,\n    });\n    expect(events[0].entity).toBeDefined();\n  });\n\n  it('should emit events even when DB already synced', async () => {\n    const events: EntitySyncEvent[] = [];\n\n    // Update DB first (simulating CLI update)\n    updateIssue(db, 'i-test1', { status: 'closed' });\n    exportToJSONL(db, { outputDir: baseDir });\n\n    const watcher = startWatcher({\n      db,\n      baseDir,\n      onEntitySync: (event) => events.push(event),\n    });\n\n    // Touch JSONL file (no actual change, DB already synced)\n    const content = fs.readFileSync(issuesJsonlPath, 'utf8');\n    fs.writeFileSync(issuesJsonlPath, content);\n\n    // Should still emit event!\n    await waitFor(() => events.length > 0);\n    expect(events[0].entityId).toBe('i-test1');\n  });\n});\n```\n\n**Server Watcher Tests** (`server/tests/integration/watcher-broadcasts.test.ts`):\n\n```typescript\ndescribe('Server watcher with typed callbacks', () => {\n  it('should broadcast via onEntitySync callback', async () => {\n    const broadcasts: any[] = [];\n    vi.spyOn(websocketModule, 'broadcastIssueUpdate')\n      .mockImplementation((...args) => broadcasts.push(args));\n\n    const projectManager = new ProjectManager(registry, { watchEnabled: true });\n    const result = await projectManager.openProject(testProjectPath);\n    const projectId = result.ok ? result.value.id : '';\n\n    // CLI updates via MCP\n    updateIssue(db, 'ISSUE-143', { status: 'closed' });\n    exportToJSONL(db, { outputDir: baseDir });\n\n    await waitFor(() => broadcasts.length > 0);\n\n    expect(broadcasts[0][0]).toBe(projectId);\n    expect(broadcasts[0][1]).toBe('ISSUE-143');\n    expect(broadcasts[0][2]).toBe('updated');\n    expect(broadcasts[0][3].status).toBe('closed');\n  });\n});\n```\n\n### Multi-Project Tests\n\n```typescript\ndescribe('Multi-project scenarios', () => {\n  it('should broadcast to correct project with same entity ID', async () => {\n    const project1 = await projectManager.openProject('/path/to/project1');\n    const project2 = await projectManager.openProject('/path/to/project2');\n\n    const broadcasts: any[] = [];\n    vi.spyOn(websocketModule, 'broadcastIssueUpdate')\n      .mockImplementation((...args) => broadcasts.push(args));\n\n    // Update ISSUE-143 in project1 only\n    updateIssue(project1.value.db, 'ISSUE-143', { status: 'closed' });\n    \n    // Should only broadcast to project1\n    expect(broadcasts).toHaveLength(1);\n    expect(broadcasts[0][0]).toBe(project1.value.id);\n  });\n\n  it('should validate baseDir matches watcher baseDir', async () => {\n    const warnings: string[] = [];\n    const warn = console.warn;\n    console.warn = (msg: string) => warnings.push(msg);\n\n    try {\n      const watcher = startServerWatcher({\n        db,\n        baseDir: '/correct/path/.sudocode',\n        onFileChange: (info) => {\n          // Handler receives event with wrong baseDir\n        },\n      });\n\n      // Emit event with mismatched baseDir\n      watcher.emit('entitySync', {\n        baseDir: '/wrong/path/.sudocode',\n        entityId: 'i-test',\n        // ...\n      });\n\n      expect(warnings.some(w => w.includes('baseDir mismatch'))).toBe(true);\n    } finally {\n      console.warn = warn;\n    }\n  });\n});\n```\n\n## Success Metrics\n\n### Reliability\n- ✅ Zero broadcast failures due to log format changes\n- ✅ 100% type safety coverage for event data\n- ✅ All entity updates reflected in UI within 2 seconds\n- ✅ CLI/MCP updates trigger UI broadcasts\n\n### Performance  \n- ✅ 50% reduction in broadcast latency (skip DB query with `entity` field)\n- ✅ 30% reduction in watcher CPU usage (no regex)\n- ✅ No performance regression on any path\n\n### Code Quality\n- ✅ Remove 100+ lines of regex parsing code\n- ✅ Increase test coverage by 20%\n- ✅ Zero TypeScript `any` types in event handling\n\n## Open Questions\n\n### 1. Should entity be included in event? ✅ RESOLVED\n**Decision**: C) Optional, with strong recommendation to include.\n\n**Rationale**: \n- Avoids server DB query (performance)\n- But allows flexibility if entity unavailable\n\n### 2. Should callbacks be async? ✅ RESOLVED\n**Decision**: B) Allow async.\n\n**Rationale**: Broadcasting may involve network I/O.\n\n### 3. Error handling strategy? ✅ RESOLVED\n**Decision**: B) Pass to `onError` callback.\n\n**Rationale**: Non-blocking, better for event-driven systems.\n\n### 4. Should we version the event format? ✅ RESOLVED\n**Decision**: A) Add version field.\n\n**Rationale**: Future-proofing for breaking changes.\n\n```typescript\nexport interface EntitySyncEvent {\n  version: 1;  // ✅ Add this\n  // ... rest of fields\n}\n```\n\n### 5. How should server resolve projectId from baseDir? ✅ RESOLVED\n**Decision**: A) Use closure as primary, B) as fallback.\n\n**Rationale**: Matches current architecture, no changes needed.\n\n## Related Work\n\n### Related Specs\n- [[s-5d2c]] Multi-Project Server Architecture\n- [[SPEC-014]] Execution Logs Design\n\n### Related Issues\n- ISSUE-143: Improve worktree recovery (discovered this bug)\n- Previous regex fix issues\n\n### References\n- `docs/watcher-refactor-design.md`\n- `docs/watcher-flow-comparison.md`\n","priority":2,"archived":0,"archived_at":null,"created_at":"2025-11-24 20:52:04","updated_at":"2025-11-24 21:29:41","parent_id":null,"parent_uuid":null,"relationships":[{"from":"s-8lkf","from_type":"spec","to":"s-5d2c","to_type":"spec","type":"references"}],"tags":[]}
{"id":"s-3v8s","uuid":"cc8a8ba0-1d0f-49a7-a993-b333b02713d0","title":"Context Injection System for Agent Prompts","file_path":"specs/s-5ti5_context_injection_system_for_agent_prompts.md","content":"# Context Injection System for Agent Prompts\n\n## Overview\n\nAdd a comprehensive context injection system to the AgentConfigPanel that allows users to mention files, specs, and issues in their prompts using `@` mentions. The system provides autocomplete search, validation, and automatic content injection for spec/issue references while letting the agent handle file fetching.\n\n## Goals\n\n1. Enable users to mention files using `@` autocomplete with file path insertion\n2. Enable users to mention specs and issues using `@` autocomplete with content injection\n3. Support multi-project environments with project-specific file search\n4. Provide a swappable search strategy interface (starting with git ls-files)\n5. Maintain backwards compatibility with existing execution API\n6. Deliver excellent UX with keyboard navigation and visual feedback\n\n## Non-Goals\n\n- Automatic file content fetching (agent handles this)\n- Complex parsing of unstructured text (only process @mentions)\n- Real-time file watching/indexing (static search is sufficient)\n- Binary file preview/handling\n\n## Architecture\n\n### High-Level Flow\n\n```\nUser types @ in prompt\n  ↓\nContext search activated (files + specs + issues)\n  ↓\nDropdown shows results grouped by type\n  ↓\nUser selects result\n  ↓\nFor files: Insert path string\nFor specs/issues: Insert [[entity-id]] reference\n  ↓\nOn submit: Process prompt\n  ↓\nResolve [[entity-id]] references → inject content\nKeep file paths as-is\n  ↓\nSend final prompt to execution API\n```\n\n### Data Model\n\n```typescript\n// Context search result (unified)\ninterface ContextSearchResult {\n  type: 'file' | 'spec' | 'issue'\n  \n  // For files\n  filePath?: string\n  fileName?: string\n  \n  // For specs/issues\n  entityId?: string      // 's-abc123' or 'i-xyz789'\n  title?: string\n  \n  // Display/insertion\n  displayText: string    // Shown in dropdown\n  secondaryText?: string // Additional context (path/description)\n  insertText: string     // What gets inserted into prompt\n  matchScore?: number    // For ranking results\n}\n\n// Prompt with references to resolve\ninterface PromptWithContext {\n  rawPrompt: string           // User's input with [[refs]]\n  resolvedPrompt: string      // After injecting spec/issue content\n  references: {\n    specs: string[]           // ['s-abc123', ...]\n    issues: string[]          // ['i-xyz789', ...]\n    files: string[]           // ['src/file.ts', ...]\n  }\n}\n```\n\n### Component Architecture\n\n```\nAgentConfigPanel\n  ├─ ContextSearchTextarea (new)\n  │   ├─ Textarea (base)\n  │   ├─ ContextSearchDropdown (new)\n  │   │   ├─ FileResultItem\n  │   │   ├─ SpecResultItem\n  │   │   └─ IssueResultItem\n  │   └─ useContextSearch hook (new)\n  └─ (existing config controls)\n```\n\n## Implementation Requirements\n\n### 1. Frontend Components\n\n#### 1.1 ContextSearchTextarea Component\n\n**Location**: `frontend/src/components/ui/context-search-textarea.tsx`\n\n**Responsibilities**:\n- Detect `@` symbol in text and extract query after it\n- Trigger search with debouncing (300ms)\n- Position dropdown near cursor\n- Handle keyboard navigation (Arrow Up/Down, Enter, Escape)\n- Insert selected result at cursor position\n- Maintain textarea auto-resize behavior\n- Support Cmd/Ctrl+Enter for submit passthrough\n\n**Key Features**:\n```typescript\ninterface ContextSearchTextareaProps {\n  value: string\n  onChange: (value: string) => void\n  onKeyDown?: (e: React.KeyboardEvent) => void\n  placeholder?: string\n  disabled?: boolean\n  className?: string\n  projectId: string  // For project-scoped search\n}\n\n// Internal state\n{\n  isSearching: boolean\n  results: ContextSearchResult[]\n  selectedIndex: number\n  dropdownPosition: { top: number; left: number }\n  showDropdown: boolean\n  currentQuery: string\n}\n```\n\n**Interaction Flow**:\n1. User types `@` → Show dropdown with empty state\n2. User types `@sr` → Search for \"sr\" across files/specs/issues\n3. Arrow keys navigate results\n4. Enter selects highlighted result\n5. Escape closes dropdown\n6. Click outside closes dropdown\n\n**Edge Cases**:\n- Multiple `@` in prompt → Use last one before cursor\n- `@` followed by space → Don't trigger search\n- Dropdown at viewport edge → Flip position\n- Empty results → Show \"No results\" message\n- Network error → Show error state with retry\n\n#### 1.2 ContextSearchDropdown Component\n\n**Location**: `frontend/src/components/ui/context-search-dropdown.tsx`\n\n**Responsibilities**:\n- Render grouped results (Files | Specs | Issues)\n- Highlight selected item\n- Show loading state\n- Handle click selection\n- Display icons/badges for result types\n\n**Structure**:\n```\n┌─────────────────────────────────┐\n│ Files (3)                       │\n├─────────────────────────────────┤\n│ 📄 AgentConfigPanel.tsx         │\n│    src/components/executions/   │\n│ 📄 execution.ts                 │\n│    src/types/                   │\n├─────────────────────────────────┤\n│ Specs (2)                       │\n├─────────────────────────────────┤\n│ 📋 Authentication System        │\n│    s-abc123                     │\n├─────────────────────────────────┤\n│ Issues (1)                      │\n├─────────────────────────────────┤\n│ 🎯 Add OAuth login              │\n│    i-xyz789                     │\n└─────────────────────────────────┘\n```\n\n**Grouping Logic**:\n- Show section headers only if results exist for that type\n- Preserve order within groups (by match score)\n- Limit: 5 files + 5 specs + 5 issues = 15 total results\n\n#### 1.3 useContextSearch Hook\n\n**Location**: `frontend/src/hooks/useContextSearch.ts`\n\n**Responsibilities**:\n- Debounced search across multiple sources\n- Merge and rank results\n- Handle loading/error states\n- Cancel in-flight requests\n\n```typescript\ninterface UseContextSearchParams {\n  query: string\n  projectId: string\n  enabled: boolean\n}\n\ninterface UseContextSearchResult {\n  results: ContextSearchResult[]\n  isLoading: boolean\n  error: Error | null\n  refetch: () => void\n}\n\nfunction useContextSearch(params: UseContextSearchParams): UseContextSearchResult {\n  // Implementation:\n  // 1. Debounce query (300ms)\n  // 2. Parallel search: files + specs + issues\n  // 3. Merge results with ranking\n  // 4. Return sorted, limited results\n}\n```\n\n**Ranking Algorithm**:\n```typescript\nfunction rankResults(results: ContextSearchResult[]): ContextSearchResult[] {\n  // Priority:\n  // 1. Exact match (name/title)\n  // 2. Prefix match\n  // 3. Word boundary match\n  // 4. Contains match\n  // 5. Within each tier, prioritize by:\n  //    - Recent usage (track in localStorage)\n  //    - Shorter paths/titles\n  //    - Alphabetical\n}\n```\n\n### 2. Backend APIs\n\n#### 2.1 File Search API\n\n**Endpoint**: `GET /api/files/search`\n\n**Query Params**:\n- `q`: Search query (required)\n- `limit`: Max results (default 20)\n- `includeDirectories`: Include dirs (default false)\n\n**Response**:\n```typescript\n{\n  success: true,\n  data: {\n    results: [\n      {\n        path: \"src/components/AgentConfigPanel.tsx\",\n        name: \"AgentConfigPanel.tsx\",\n        isFile: true,\n        matchType: \"prefix\"\n      }\n    ]\n  }\n}\n```\n\n**Implementation**:\n\n**Location**: `server/src/routes/files.ts`\n\n```typescript\nrouter.get('/files/search', async (req: Request, res: Response) => {\n  const { q: query, limit = 20, includeDirectories = false } = req.query\n  const projectId = req.headers['x-project-id']\n  \n  // Get project workspace path\n  const project = getProject(projectId)\n  const workspacePath = project.workspacePath\n  \n  // Use strategy to search files\n  const searchStrategy = getFileSearchStrategy(project)\n  const results = await searchStrategy.search(workspacePath, {\n    query: query as string,\n    limit: Number(limit),\n    includeDirectories: Boolean(includeDirectories)\n  })\n  \n  res.json({ success: true, data: { results } })\n})\n```\n\n#### 2.2 File Search Strategy Interface\n\n**Location**: `server/src/services/file-search/strategy.ts`\n\n```typescript\nexport interface FileSearchStrategy {\n  /**\n   * Search for files matching query in workspace\n   */\n  search(workspacePath: string, options: FileSearchOptions): Promise<FileSearchResult[]>\n  \n  /**\n   * Get strategy name for debugging/metrics\n   */\n  getName(): string\n}\n\nexport interface FileSearchOptions {\n  query: string\n  limit: number\n  includeDirectories: boolean\n  excludePatterns?: string[]  // Additional exclusions\n}\n\nexport interface FileSearchResult {\n  path: string           // Relative to workspace root\n  name: string           // Filename only\n  isFile: boolean        // true for files, false for dirs\n  matchType?: 'exact' | 'prefix' | 'contains'\n}\n```\n\n**Strategy Registry**:\n\n**Location**: `server/src/services/file-search/registry.ts`\n\n```typescript\ntype StrategyType = 'git-ls-files' | 'fast-glob' | 'indexed'\n\nclass FileSearchStrategyRegistry {\n  private strategies: Map<StrategyType, FileSearchStrategy>\n  private defaultStrategy: StrategyType = 'git-ls-files'\n  \n  register(type: StrategyType, strategy: FileSearchStrategy): void\n  get(type?: StrategyType): FileSearchStrategy\n  setDefault(type: StrategyType): void\n}\n\nexport const fileSearchRegistry = new FileSearchStrategyRegistry()\n```\n\n#### 2.3 Git Ls-Files Strategy (Initial Implementation)\n\n**Location**: `server/src/services/file-search/git-ls-files-strategy.ts`\n\n```typescript\nexport class GitLsFilesStrategy implements FileSearchStrategy {\n  getName(): string {\n    return 'git-ls-files'\n  }\n  \n  async search(\n    workspacePath: string, \n    options: FileSearchOptions\n  ): Promise<FileSearchResult[]> {\n    // 1. Run: git ls-files in workspacePath\n    // 2. Filter by query (fuzzy match)\n    // 3. Rank by match type\n    // 4. Apply limit\n    // 5. Return results\n    \n    const { stdout } = await execAsync('git ls-files', { cwd: workspacePath })\n    const allFiles = stdout.split('\\n').filter(Boolean)\n    \n    // Filter and rank\n    const matches = allFiles\n      .map(path => this.matchFile(path, options.query))\n      .filter(result => result !== null)\n      .sort((a, b) => this.compareMatchQuality(a, b))\n      .slice(0, options.limit)\n    \n    return matches\n  }\n  \n  private matchFile(path: string, query: string): FileSearchResult | null {\n    const name = path.split('/').pop()!\n    const lowerQuery = query.toLowerCase()\n    const lowerPath = path.toLowerCase()\n    const lowerName = name.toLowerCase()\n    \n    // Exact match (name)\n    if (lowerName === lowerQuery) {\n      return { path, name, isFile: true, matchType: 'exact' }\n    }\n    \n    // Prefix match (name starts with query)\n    if (lowerName.startsWith(lowerQuery)) {\n      return { path, name, isFile: true, matchType: 'prefix' }\n    }\n    \n    // Prefix match (path starts with query)\n    if (lowerPath.startsWith(lowerQuery)) {\n      return { path, name, isFile: true, matchType: 'prefix' }\n    }\n    \n    // Contains match (anywhere in path)\n    if (lowerPath.includes(lowerQuery)) {\n      return { path, name, isFile: true, matchType: 'contains' }\n    }\n    \n    return null\n  }\n  \n  private compareMatchQuality(a: FileSearchResult, b: FileSearchResult): number {\n    const matchOrder = { exact: 0, prefix: 1, contains: 2 }\n    const aOrder = matchOrder[a.matchType!]\n    const bOrder = matchOrder[b.matchType!]\n    \n    if (aOrder !== bOrder) return aOrder - bOrder\n    \n    // Same match type → shorter path wins\n    if (a.path.length !== b.path.length) {\n      return a.path.length - b.path.length\n    }\n    \n    // Same length → alphabetical\n    return a.path.localeCompare(b.path)\n  }\n}\n\n// Register as default\nfileSearchRegistry.register('git-ls-files', new GitLsFilesStrategy())\n```\n\n**Performance Considerations**:\n- Cache `git ls-files` output for 5 seconds (per project)\n- Invalidate cache on file system events (future enhancement)\n- For large repos (>10k files), consider indexing strategy\n\n#### 2.4 Context Resolution API\n\n**Endpoint**: `POST /api/prompts/resolve`\n\n**Purpose**: Resolve [[entity-id]] references in prompt before execution\n\n**Request**:\n```typescript\n{\n  prompt: \"Implement [[s-abc123]] and fix [[i-xyz789]]\",\n  projectId: \"project-uuid\"\n}\n```\n\n**Response**:\n```typescript\n{\n  success: true,\n  data: {\n    resolvedPrompt: \"Implement <spec content> and fix <issue content>\",\n    references: {\n      specs: [\"s-abc123\"],\n      issues: [\"i-xyz789\"],\n      files: []\n    },\n    errors: []  // Array of unresolvable references\n  }\n}\n```\n\n**Implementation**:\n\n**Location**: `server/src/routes/prompts.ts`\n\n```typescript\nrouter.post('/prompts/resolve', async (req: Request, res: Response) => {\n  const { prompt, projectId } = req.body\n  \n  const result = await promptResolver.resolve(prompt, projectId)\n  \n  res.json({ success: true, data: result })\n})\n```\n\n**Prompt Resolver Service**:\n\n**Location**: `server/src/services/prompt-resolver.ts`\n\n```typescript\nexport class PromptResolver {\n  /**\n   * Resolve all [[entity-id]] references in prompt\n   */\n  async resolve(prompt: string, projectId: string): Promise<PromptResolutionResult> {\n    // 1. Extract all [[entity-id]] patterns\n    const references = this.extractReferences(prompt)\n    \n    // 2. Fetch content for specs and issues\n    const project = getProject(projectId)\n    const specContents = await this.fetchSpecs(references.specs, project)\n    const issueContents = await this.fetchIssues(references.issues, project)\n    \n    // 3. Replace [[entity-id]] with content\n    let resolvedPrompt = prompt\n    const errors: string[] = []\n    \n    for (const specId of references.specs) {\n      const content = specContents.get(specId)\n      if (content) {\n        resolvedPrompt = resolvedPrompt.replace(\n          new RegExp(`\\\\[\\\\[${specId}\\\\]\\\\]`, 'g'),\n          this.formatSpecContent(content)\n        )\n      } else {\n        errors.push(`Spec not found: ${specId}`)\n      }\n    }\n    \n    for (const issueId of references.issues) {\n      const content = issueContents.get(issueId)\n      if (content) {\n        resolvedPrompt = resolvedPrompt.replace(\n          new RegExp(`\\\\[\\\\[${issueId}\\\\]\\\\]`, 'g'),\n          this.formatIssueContent(content)\n        )\n      } else {\n        errors.push(`Issue not found: ${issueId}`)\n      }\n    }\n    \n    return {\n      resolvedPrompt,\n      references,\n      errors\n    }\n  }\n  \n  private extractReferences(prompt: string): {\n    specs: string[]\n    issues: string[]\n    files: string[]\n  } {\n    // Regex: [[s-xxxxx]] or [[i-xxxxx]]\n    const specPattern = /\\[\\[(s-[a-z0-9]+)\\]\\]/g\n    const issuePattern = /\\[\\[(i-[a-z0-9]+)\\]\\]/g\n    const filePattern = /@([^\\s]+)/g\n    \n    const specs = [...prompt.matchAll(specPattern)].map(m => m[1])\n    const issues = [...prompt.matchAll(issuePattern)].map(m => m[1])\n    const files = [...prompt.matchAll(filePattern)].map(m => m[1])\n    \n    return {\n      specs: [...new Set(specs)],  // Deduplicate\n      issues: [...new Set(issues)],\n      files: [...new Set(files)]\n    }\n  }\n  \n  private async fetchSpecs(\n    specIds: string[], \n    project: Project\n  ): Promise<Map<string, Spec>> {\n    const specs = new Map<string, Spec>()\n    \n    for (const specId of specIds) {\n      try {\n        const spec = project.specsService.getSpec(specId)\n        if (spec) specs.set(specId, spec)\n      } catch (error) {\n        console.warn(`Failed to fetch spec ${specId}:`, error)\n      }\n    }\n    \n    return specs\n  }\n  \n  private async fetchIssues(\n    issueIds: string[], \n    project: Project\n  ): Promise<Map<string, Issue>> {\n    const issues = new Map<string, Issue>()\n    \n    for (const issueId of issueIds) {\n      try {\n        const issue = project.issuesService.getIssue(issueId)\n        if (issue) issues.set(issueId, issue)\n      } catch (error) {\n        console.warn(`Failed to fetch issue ${issueId}:`, error)\n      }\n    }\n    \n    return issues\n  }\n  \n  private formatSpecContent(spec: Spec): string {\n    return `\n## Spec: ${spec.title} (${spec.id})\n\n${spec.description}\n\n${spec.tags?.length ? `Tags: ${spec.tags.join(', ')}` : ''}\n`.trim()\n  }\n  \n  private formatIssueContent(issue: Issue): string {\n    return `\n## Issue: ${issue.title} (${issue.id})\n\n${issue.description}\n\nStatus: ${issue.status}\n${issue.tags?.length ? `Tags: ${issue.tags.join(', ')}` : ''}\n`.trim()\n  }\n}\n\nexport const promptResolver = new PromptResolver()\n```\n\n### 3. Integration Points\n\n#### 3.1 AgentConfigPanel Integration\n\n**Location**: `frontend/src/components/executions/AgentConfigPanel.tsx`\n\n**Changes**:\n\n```typescript\n// Replace line 481-498 (current Textarea)\n<ContextSearchTextarea\n  ref={textareaRef}\n  value={prompt}\n  onChange={(value) => setPrompt(value)}\n  onKeyDown={handleKeyDown}\n  placeholder={\n    promptPlaceholder ||\n    (loading\n      ? 'Loading prompt...'\n      : isFollowUp\n        ? 'Enter feedback to continue the execution... Use @ to mention files, specs, or issues.'\n        : 'Enter prompt for the agent... Use @ to mention files, specs, or issues.')\n  }\n  disabled={loading}\n  className=\"max-h-[300px] min-h-0 resize-none overflow-y-auto border-none bg-muted/80 py-2 text-sm shadow-none transition-[height] duration-100 focus-visible:ring-0 focus-visible:ring-offset-0\"\n  style={{ height: 'auto' }}\n  projectId={/* Get from context or prop */}\n/>\n```\n\n#### 3.2 Execution Creation Flow\n\n**Current Flow**:\n```\nhandleStart() \n  → onStart(config, prompt, agentType)\n    → executionsApi.create(issueId, { config, prompt, agentType })\n```\n\n**New Flow**:\n```\nhandleStart()\n  → Resolve prompt references (if any)\n    → POST /api/prompts/resolve { prompt, projectId }\n      → Get resolvedPrompt\n  → onStart(config, resolvedPrompt, agentType)\n    → executionsApi.create(issueId, { config, prompt: resolvedPrompt, agentType })\n```\n\n**Implementation**:\n\n```typescript\nconst handleStart = async () => {\n  try {\n    // Resolve references before creating execution\n    let finalPrompt = prompt\n    \n    // Check if prompt contains references\n    if (prompt.includes('[[')) {\n      const resolved = await promptsApi.resolve({\n        prompt,\n        projectId: currentProjectId!\n      })\n      \n      if (resolved.errors.length > 0) {\n        // Show error toast\n        toast.error(`Could not resolve: ${resolved.errors.join(', ')}`)\n        return\n      }\n      \n      finalPrompt = resolved.resolvedPrompt\n    }\n    \n    // Save config to localStorage\n    if (isValidExecutionConfig(config)) {\n      try {\n        localStorage.setItem(LAST_EXECUTION_CONFIG_KEY, JSON.stringify(config))\n        localStorage.setItem(LAST_AGENT_TYPE_KEY, selectedAgentType)\n      } catch (error) {\n        console.warn('Failed to save execution config to localStorage:', error)\n      }\n    }\n    \n    onStart(config, finalPrompt, selectedAgentType)\n    setPrompt('') // Clear the prompt after submission\n  } catch (error) {\n    console.error('Failed to resolve prompt:', error)\n    toast.error('Failed to prepare prompt. Please try again.')\n  }\n}\n```\n\n### 4. Multi-Project Support\n\n#### 4.1 Project Context\n\nAll search operations are scoped to the current project:\n\n```typescript\n// Frontend: Get projectId from context\nimport { useProject } from '@/contexts/ProjectContext'\n\nfunction AgentConfigPanel() {\n  const { currentProject } = useProject()\n  \n  return (\n    <ContextSearchTextarea\n      projectId={currentProject.id}\n      // ...\n    />\n  )\n}\n```\n\n#### 4.2 Backend Project Resolution\n\n```typescript\n// All API endpoints use X-Project-ID header\nconst projectId = req.headers['x-project-id']\nconst project = getProject(projectId)\n\n// File search is scoped to project workspace\nconst workspacePath = project.workspacePath\nconst results = await fileSearchStrategy.search(workspacePath, options)\n```\n\n#### 4.3 Workspace Path Handling\n\nEach project has a configured workspace path:\n\n```typescript\ninterface Project {\n  id: string\n  workspacePath: string  // Absolute path to project root\n  // ...\n}\n\n// File search operates within this workspace\n// All returned paths are relative to workspacePath\n```\n\n### 5. API Updates\n\n#### 5.1 New Routes\n\n**File**: `server/src/routes/files.ts`\n```typescript\nrouter.get('/files/search', handleFileSearch)\n```\n\n**File**: `server/src/routes/prompts.ts`\n```typescript\nrouter.post('/prompts/resolve', handlePromptResolve)\n```\n\n**File**: `server/src/index.ts`\n```typescript\nimport { createFilesRouter } from './routes/files.js'\nimport { createPromptsRouter } from './routes/prompts.js'\n\napp.use('/api', requireProject(), createFilesRouter())\napp.use('/api', requireProject(), createPromptsRouter())\n```\n\n#### 5.2 Frontend API Client\n\n**File**: `frontend/src/lib/api.ts`\n\n```typescript\nexport const filesApi = {\n  search: (query: string, options?: { limit?: number }) =>\n    get<{ results: FileSearchResult[] }>(\n      `/files/search?q=${encodeURIComponent(query)}&limit=${options?.limit || 20}`\n    ).then(res => res.results),\n}\n\nexport const promptsApi = {\n  resolve: (request: { prompt: string; projectId: string }) =>\n    post<PromptResolutionResult>('/prompts/resolve', request),\n}\n```\n\n### 6. Testing Strategy\n\n#### 6.1 Unit Tests\n\n**Frontend**:\n- `ContextSearchTextarea.test.tsx`\n  - @ detection and query extraction\n  - Keyboard navigation\n  - Result insertion at cursor\n  - Edge cases (multiple @, at viewport edge)\n  \n- `useContextSearch.test.ts`\n  - Debouncing behavior\n  - Result merging and ranking\n  - Error handling\n  - Request cancellation\n\n**Backend**:\n- `GitLsFilesStrategy.test.ts`\n  - File matching logic\n  - Ranking algorithm\n  - Edge cases (empty repo, no git)\n  \n- `PromptResolver.test.ts`\n  - Reference extraction\n  - Content injection\n  - Error handling (missing refs)\n  - Multiple references\n\n#### 6.2 Integration Tests\n\n- End-to-end prompt resolution flow\n- Multi-project file search isolation\n- Execution creation with resolved prompt\n\n#### 6.3 Manual Test Cases\n\n1. **Basic file mention**\n   - Type `@src` → See file results\n   - Select file → Path inserted\n   - Submit → Execution created\n\n2. **Spec mention**\n   - Type `@Auth` → See specs with \"Auth\" in title\n   - Select spec → `[[s-abc123]]` inserted\n   - Submit → Spec content injected into prompt\n\n3. **Issue mention**\n   - Type `@Add` → See issues with \"Add\" in title\n   - Select issue → `[[i-xyz789]]` inserted\n   - Submit → Issue content injected into prompt\n\n4. **Mixed mentions**\n   - Type: `Fix [[i-xyz]] in @src/auth.ts per [[s-abc]]`\n   - Submit → Both spec and issue content injected, file path kept\n\n5. **Multi-project**\n   - Switch projects → Search returns different files\n   - References resolve to correct project's specs/issues\n\n6. **Error cases**\n   - Invalid reference → Error message shown\n   - Network error → Retry option\n   - Empty search → \"No results\" message\n\n### 7. Future Enhancements\n\n#### Phase 2: Advanced Search\n- Fuzzy matching with fuse.js\n- Search result caching\n- Recent mentions tracking\n- Keyboard shortcuts (Cmd+K to open search)\n\n#### Phase 3: Rich Previews\n- Hover over mention → Show preview popup\n- File preview with syntax highlighting\n- Spec/issue preview with metadata\n- Click to open in editor\n\n#### Phase 4: Smart Context\n- Auto-suggest related specs for issue\n- Auto-suggest related files for spec\n- Context relevance scoring\n- Learn from user patterns\n\n#### Phase 5: Performance\n- Indexed file search strategy\n- Incremental file watching\n- Search result streaming\n- Virtual scrolling for large result sets\n\n## Success Criteria\n\n1. **Functionality**\n   - ✅ Users can mention files with @ autocomplete\n   - ✅ Users can mention specs with @ autocomplete\n   - ✅ Users can mention issues with @ autocomplete\n   - ✅ Spec/issue content is injected into prompt\n   - ✅ File paths are passed to agent as-is\n   - ✅ Multi-project support works correctly\n\n2. **Performance**\n   - ✅ Search results appear within 500ms\n   - ✅ No UI blocking during search\n   - ✅ Handles repos with 10k+ files\n\n3. **UX**\n   - ✅ Keyboard navigation feels natural\n   - ✅ Dropdown positioning is correct\n   - ✅ Error states are clear\n   - ✅ Loading states are visible\n\n4. **Reliability**\n   - ✅ All tests passing\n   - ✅ No crashes on edge cases\n   - ✅ Graceful degradation on errors\n\n## Open Questions\n\n1. Should we support multiline in dropdown (show wrapped text)?\n   - **Decision Needed**: Truncate with ellipsis vs wrap\n\n2. Should we cache git ls-files output across requests?\n   - **Proposal**: Yes, 5 second TTL per project\n\n3. How to handle very large spec/issue content?\n   - **Proposal**: Truncate at 5000 chars with warning\n\n4. Should @ mentions be syntax highlighted in the textarea?\n   - **Proposal**: Yes, subtle background color for [[refs]]\n\n5. Should we support range selection for files (e.g., @file.ts:10-20)?\n   - **Proposal**: Phase 2 enhancement\n\n## Dependencies\n\n- Frontend: React hooks, shadcn/ui components\n- Backend: git CLI, existing specs/issues services\n- Testing: Vitest, React Testing Library\n\n## Timeline Estimate\n\n- Week 1: Backend file search + strategy interface\n- Week 2: Frontend ContextSearchTextarea component\n- Week 3: Prompt resolver + integration\n- Week 4: Testing + polish\n- Week 5: Spec/issue search integration\n- Week 6: Bug fixes + documentation\n\n## References\n\n- Vibe-kanban FileSearchTextarea: `/references/vibe-kanban/frontend/src/components/ui/file-search-textarea.tsx`\n- Current AgentConfigPanel: `/frontend/src/components/executions/AgentConfigPanel.tsx`\n- Execution API: `/server/src/routes/executions.ts`","priority":1,"archived":0,"archived_at":null,"created_at":"2025-11-26 23:00:25","updated_at":"2025-11-26 23:00:25","parent_id":null,"parent_uuid":null,"relationships":[],"tags":["agent-prompts","context-injection","feature","ui"]}
{"id":"s-1yug","uuid":"cc2b5928-e0bb-474c-91c5-00d94c3224de","title":"Git Diff Viewer for Agent Trajectory UI","file_path":"specs/s-1yug_git_diff_viewer_for_agent_trajectory_ui.md","content":"# Git Diff Viewer for Agent Trajectory UI\n\n## Problem Statement\n\nThe agent execution trajectory monitor UI currently displays tool calls (Edit, Write) in a compact text format. Users cannot easily visualize what code changes were made during execution, making it difficult to:\n- Understand what the agent modified\n- Review code changes at a glance\n- Spot potential issues in agent-generated code\n- Learn from the agent's editing patterns\n\n## Requirements\n\n### Functional Requirements\n\n1. **Diff Viewing for Edit Tool Calls**\n   - Display inline diffs showing code changes\n   - Parse Edit tool args format: `{path, changes: [{type, diff}]}`\n   - Show syntax-highlighted before/after code\n   - Render diff format (lines starting with `-` for deletions, `+` for additions)\n\n2. **Diff Viewing for Write Tool Calls**\n   - Display new file content\n   - Show all content as additions (green highlighting)\n   - Include syntax highlighting based on file extension\n\n3. **UI Integration**\n   - Inline expansion below tool calls in trajectory\n   - Follow terminal-style aesthetic of ClaudeCodeTrajectory\n   - Use `∟` continuation character for consistency\n   - \"Show diff\" / \"Hide diff\" toggle buttons\n\n4. **Display Controls**\n   - Default collapsed view showing first 10-15 lines\n   - \"Expand full diff\" button for files exceeding line limit\n   - Graceful degradation for large files (500+ lines)\n\n5. **Syntax Highlighting**\n   - Detect language from file extension\n   - Support common languages: TypeScript, JavaScript, Python, JSON, YAML, CSS, HTML, etc.\n   - Use existing highlight.js infrastructure\n   - Fallback to plaintext for unknown extensions\n\n6. **Theme Support**\n   - Match light/dark theme from ThemeContext\n   - Terminal-friendly colors (subtle backgrounds for additions/deletions)\n   - Automatic theme switching\n\n### Non-Functional Requirements\n\n1. **Performance**\n   - Lazy render: only display diff when expanded\n   - Disable syntax highlighting for very large files (500+ lines)\n   - No performance regression with multiple diffs in trajectory\n\n2. **Reusability**\n   - Generic DiffViewer component for future agent types\n   - Adapter pattern for different tool arg formats\n\n3. **Error Handling**\n   - Graceful fallback for malformed JSON args\n   - Error messages for missing file paths\n   - Don't break trajectory rendering on diff errors\n\n4. **Accessibility**\n   - Keyboard navigation support\n   - Screen reader friendly\n\n## Technical Constraints\n\n1. Use already-installed `@git-diff-view/react` library (v0.0.22)\n2. Integrate with existing ClaudeCodeTrajectory component\n3. Follow existing terminal-style UI patterns\n4. Use existing theming infrastructure (ThemeContext)\n5. Maintain bundle size (library adds ~50KB)\n\n## Example Tool Args Formats\n\n### Edit Tool\n```json\n{\n  \"path\": \"frontend/src/components/issues/IssuePanel.tsx\",\n  \"changes\": [{\n    \"type\": \"edit\",\n    \"diff\": \"- import { useState, useEffect, useRef } from 'react'\\n+ import { useState, useEffect, useRef, useMemo } from 'react'\"\n  }]\n}\n```\n\n### Write Tool\n```json\n{\n  \"file_path\": \"src/newFile.ts\",\n  \"content\": \"export const foo = 'bar'\\n\"\n}\n```\n\n## Visual Design\n\nTerminal-style rendering:\n```\n⏺ Edit (frontend/src/components/Example.tsx)          0.45s\n  ∟ File edited successfully\n  ∟ > Show changes\n     ┌────────────────────────────────────┐\n     │ frontend/src/components/Example.tsx│\n     │  1 | import { useState } from 'react'│\n     │  2 | -const value = 10;              │ (red bg)\n     │  3 | +const value = 20;              │ (green bg)\n     │  4 | +console.log(value);            │ (green bg)\n     │  5 | return <div>{value}</div>       │\n     └────────────────────────────────────┘\n     > Expand full diff (45 lines)\n     > Hide changes\n```\n\n## Success Criteria\n\n- [ ] Diffs display inline for Edit and Write tool calls\n- [ ] Syntax highlighting works for TS, JS, Python, JSON\n- [ ] Theme switching works correctly\n- [ ] Expand/collapse works for diffs >15 lines\n- [ ] Error handling gracefully degrades\n- [ ] Terminal aesthetic matches ClaudeCodeTrajectory\n- [ ] No performance regression\n- [ ] Generic component reusable for other agents\n\n## Out of Scope\n\n- Split view mode (unified view only)\n- Inline commenting on diff lines\n- Copy diff to clipboard\n- Download as .patch file\n- Adapter logic for non-Claude agents (future work)","priority":2,"archived":1,"archived_at":"2025-11-27T08:02:10.684Z","created_at":"2025-11-27 02:20:10","updated_at":"2025-11-27 08:02:10","parent_id":null,"parent_uuid":null,"relationships":[],"tags":["diff-viewer","frontend","trajectory","ui"]}
{"id":"s-4mgr","uuid":"8c8bc6ab-41e3-42a9-a63f-c8d170bd7bbc","title":"Worktree Sync: Integrate Agent Execution Changes","file_path":"specs/s-4mgr_worktree_sync_integrate_agent_execution_changes.md","content":"# Worktree Sync: Integrate Agent Execution Changes\n\n## Overview\n\nEnable users to sync changes from agent execution worktrees back to their local working tree. This allows users to review agent-generated code in isolation (worktree) and then selectively integrate those changes into their main development environment.\n\n## Problem Statement\n\nCurrently, agent executions run in isolated git worktrees with their own branches. While this provides excellent isolation during execution, there's no built-in way to:\n\n1. **Preview changes** made by the agent before integrating them\n1. **Detect merge conflicts** between worktree changes and local changes\n1. **Integrate worktree changes** into the local tree in a controlled manner\n1. **Choose integration strategy** (squash all changes vs. preserve individual commits)\n\nUsers must manually use git commands to merge worktree branches, which is error-prone and doesn't handle sudocode-specific concerns (JSONL merge conflicts, isolated database state, etc.).\n\n## Requirements\n\n### Functional Requirements\n\n#### FR1: Conflict Detection\n\n- **FR1.1** Detect file-level merge conflicts between worktree branch and local branch\n- **FR1.2** Detect JSONL merge conflicts in `.sudocode/issues.jsonl` and `.sudocode/specs.jsonl`\n- **FR1.3** Check branch compatibility (worktree and local share compatible base)\n- **FR1.4** Provide detailed conflict report with file paths and conflict types\n\n#### FR2: Sync Preview\n\n- **FR2.1** Show diff between worktree current state and local HEAD (regardless of execution status)\n- **FR2.2** Display list of files changed in worktree\n- **FR2.3** Show commit history from worktree (for preserve-commits mode)\n- **FR2.4** Calculate and display merge base commit\n- **FR2.5** Preview resulting JSONL after merge (with conflict resolution applied)\n- **FR2.6** Include uncommitted JSONL changes in preview\n\n#### FR3: Squash Sync Mode\n\n- **FR3.1** Combine all worktree changes into a single commit\n- **FR3.2** Apply squashed commit to current local branch\n- **FR3.3** Use automatic JSONL merge resolution (existing UUID-based deduplication)\n- **FR3.4** Include uncommitted JSONL changes from worktree in sync\n- **FR3.5** Allow user to provide custom commit message\n- **FR3.6** Default commit message includes execution ID and issue reference\n\n#### FR4: Preserve Commits Sync Mode\n\n- **FR4.1** Cherry-pick all commits from worktree branch to local branch\n- **FR4.2** Preserve commit messages, authors, and timestamps\n- **FR4.3** Stop on first merge conflict and allow user intervention\n- **FR4.4** Use automatic JSONL merge resolution for each commit\n- **FR4.5** Include uncommitted JSONL changes from worktree as final commit\n- **FR4.6** Support resuming after manual conflict resolution\n\n#### FR5: JSONL Conflict Resolution\n\n- **FR5.1** Automatically resolve JSONL conflicts using existing merge-resolver logic\n- **FR5.2** UUID-based deduplication for issues and specs\n- **FR5.3** Timestamp-based prioritization for same UUID conflicts\n- **FR5.4** Metadata merging (relationships, tags, feedback)\n\n#### FR6: Code Conflict Detection & Handling\n\n- **FR6.1** Detect merge conflicts in regular code files (non-JSONL)\n- **FR6.2** Report conflicting files with line-level conflict information\n- **FR6.3** Provide options: abort sync or manual resolution in IDE\n- **FR6.4** For manual resolution: pause sync, offer \"Open in IDE\" button, allow user to resolve and resume\n- **FR6.5** Track conflict resolution state across sync retries\n\n#### FR7: UI Integration\n\n- **FR7.1** Add \"Sync Worktree to Local\" action button on execution view (available for all execution states)\n- **FR7.2** Display sync preview dialog with change summary\n- **FR7.3** Show conflict warnings before sync\n- **FR7.4** Provide mode selector (squash vs. preserve commits)\n- **FR7.5** Show sync progress and status updates\n- **FR7.6** Display sync result summary (files changed, conflicts resolved)\n- **FR7.7** Add \"Open Worktree in IDE\" button to allow users to inspect/modify worktree changes before syncing\n- **FR7.8** Offer worktree cleanup option after successful sync (for manual cleanup mode only)\n\n#### FR8: Safety & Validation\n\n- **FR8.1** Validate local working tree is clean before sync (no uncommitted changes)\n- **FR8.2** Validate worktree still exists and is accessible\n- **FR8.3** Create safety branch/tag before sync for rollback\n- **FR8.4** Allow sync from any execution state (running, paused, stopped, cancelled, completed) - snapshot current worktree state\n- **FR8.5** Validate branch compatibility before proceeding\n\n### Non-Functional Requirements\n\n#### NFR1: Performance\n\n- Preview generation should complete in < 2 seconds for typical changes\n- Conflict detection should complete in < 3 seconds for typical changes\n\n#### NFR2: Data Integrity\n\n- JSONL merge must never lose data (use merge-resolver guarantees)\n- All git operations must be atomic (rollback on failure)\n- Database state must remain consistent with JSONL after sync\n\n#### NFR3: Usability\n\n- Clear error messages for all failure scenarios\n- Conflict reports should be actionable (show what user needs to do)\n- Default to safest option (squash mode with preview)\n\n## Implementation Strategy\n\n### Architecture Overview\n\n```\n┌─────────────────────────────────────────────────────────────────┐\n│                         Frontend (React)                        │\n│  - ExecutionView with \"Sync\" button                            │\n│  - SyncPreviewDialog (shows diff, conflicts, mode selector)    │\n│  - SyncProgressDialog (shows real-time sync status)            │\n└────────────────────┬────────────────────────────────────────────┘\n                     │ HTTP API\n┌────────────────────▼────────────────────────────────────────────┐\n│                    Server (Express Routes)                      │\n│  POST /executions/:id/sync/preview                             │\n│  POST /executions/:id/sync/squash                              │\n│  POST /executions/:id/sync/preserve                            │\n│  GET  /executions/:id/sync/status                              │\n└────────────────────┬────────────────────────────────────────────┘\n                     │\n┌────────────────────▼────────────────────────────────────────────┐\n│                  WorktreeSync Service                           │\n│  - previewSync()    - detectConflicts()                        │\n│  - squashSync()     - preserveCommitsSync()                    │\n│  - resolveJSONLConflicts()                                     │\n│  - detectCodeConflicts()                                       │\n└────────────────────┬────────────────────────────────────────────┘\n                     │\n        ┌────────────┴──────────────┐\n        │                           │\n┌───────▼────────┐       ┌──────────▼──────────┐\n│  GitSyncCli    │       │  ConflictDetector   │\n│  - getMergeBase│       │  - checkMerge       │\n│  - getDiff     │       │  - parseConflicts   │\n│  - squashMerge │       │  - classifyConflict │\n│  - cherryPick  │       │  - suggestResolution│\n└────────────────┘       └─────────────────────┘\n```\n\n### Component Design\n\n#### 1\\. GitSyncCli (New: `server/src/execution/worktree/git-sync-cli.ts`)\n\nExtends existing `git-cli.ts` with sync-specific git operations:\n\n```typescript\nexport class GitSyncCli {\n  /**\n   * Find common ancestor between two branches\n   */\n  getMergeBase(branch1: string, branch2: string): string;\n  \n  /**\n   * Get diff between two commits\n   * Returns: { files: string[], additions: number, deletions: number }\n   */\n  getDiff(fromCommit: string, toCommit: string): DiffResult;\n  \n  /**\n   * Check if merge would conflict\n   * Returns: { hasConflicts: boolean, conflictingFiles: string[] }\n   */\n  checkMergeConflicts(sourceBranch: string, targetBranch: string): ConflictCheckResult;\n  \n  /**\n   * Perform squash merge\n   */\n  squashMerge(sourceBranch: string, targetBranch: string, message: string): void;\n  \n  /**\n   * Cherry-pick range of commits\n   */\n  cherryPickRange(startCommit: string, endCommit: string): CherryPickResult;\n  \n  /**\n   * Get list of commits between two refs\n   */\n  getCommitList(baseRef: string, headRef: string): Commit[];\n  \n  /**\n   * Check if working tree is clean\n   */\n  isWorkingTreeClean(): boolean;\n  \n  /**\n   * Create safety tag for rollback\n   */\n  createSafetyTag(tagName: string, ref: string): void;\n}\n```\n\n**Implementation Notes:**\n\n- Use `git merge-tree` for conflict detection without modifying working tree\n- Use `git diff --name-status` for file listing\n- Use `execSync` with proper error handling\n- Parse git output using regex patterns (similar to existing `worktreeList()`)\n\n#### 2\\. ConflictDetector (New: `server/src/execution/worktree/conflict-detector.ts`)\n\nDetects and classifies merge conflicts:\n\n```typescript\nexport interface ConflictReport {\n  hasConflicts: boolean;\n  codeConflicts: CodeConflict[];\n  jsonlConflicts: JSONLConflict[];\n  totalFiles: number;\n  summary: string;\n}\n\nexport interface CodeConflict {\n  filePath: string;\n  conflictType: 'content' | 'delete' | 'rename' | 'mode';\n  description: string;\n  canAutoResolve: boolean;\n  resolutionStrategy?: string;\n}\n\nexport interface JSONLConflict {\n  filePath: string;\n  entityType: 'issue' | 'spec';\n  conflictCount: number;\n  canAutoResolve: boolean; // Always true for JSONL\n}\n\nexport class ConflictDetector {\n  /**\n   * Detect all conflicts between branches\n   */\n  detectConflicts(\n    repoPath: string,\n    sourceBranch: string,\n    targetBranch: string\n  ): ConflictReport;\n  \n  /**\n   * Check if file has git conflict markers\n   */\n  private hasConflictMarkers(content: string): boolean;\n  \n  /**\n   * Parse git merge-tree output\n   */\n  private parseMergeTreeOutput(output: string): ConflictInfo[];\n  \n  /**\n   * Classify conflict type\n   */\n  private classifyConflict(conflict: ConflictInfo): CodeConflict | JSONLConflict;\n}\n```\n\n**Conflict Detection Strategy:**\n\n1. **Use** `git merge-tree` **for dry-run merge:**\n\n```bash\ngit merge-tree $(git merge-base branch1 branch2) branch1 branch2\n```\n\n- No working tree modification\n- Returns merge result with conflict markers\n- Parse output to identify conflicting files\n\n1. **Classify conflicts:**\n\n- JSONL files (`.sudocode/*.jsonl`) → JSONLConflict (auto-resolvable)\n- Other files → CodeConflict (needs inspection)\n\n1. **For code conflicts, detect type:**\n\n- Content conflict: Both branches modified same lines\n- Delete conflict: One deleted, one modified\n- Rename conflict: Both renamed same file differently\n- Mode conflict: File mode changed differently\n\n1. **Auto-resolution capabilities:**\n\n- JSONL: Always auto-resolve using merge-resolver\n- Code: Limited auto-resolution (e.g., non-overlapping changes)\n- Most code conflicts require manual resolution\n\n#### 3\\. WorktreeSync Service (New: `server/src/services/worktree-sync-service.ts`)\n\nOrchestrates the sync workflow:\n\n```typescript\nexport interface SyncPreviewResult {\n  canSync: boolean;\n  conflicts: ConflictReport;\n  diff: DiffSummary;\n  commits: Commit[];\n  mergeBase: string;\n  uncommittedJSONLChanges: boolean;\n  executionStatus: ExecutionStatus; // Warn if running/paused\n  warnings: string[];\n}\n\nexport interface SyncResult {\n  success: boolean;\n  finalCommit?: string;\n  filesChanged: number;\n  conflictsResolved: number;\n  uncommittedJSONLIncluded: boolean;\n  error?: string;\n  cleanupOffered?: boolean; // True if cleanup mode is 'manual'\n}\n\nexport class WorktreeSyncService {\n  /**\n   * Preview sync without making changes\n   */\n  async previewSync(executionId: string): Promise<SyncPreviewResult>;\n  \n  /**\n   * Perform squash sync\n   */\n  async squashSync(\n    executionId: string,\n    commitMessage?: string\n  ): Promise<SyncResult>;\n  \n  /**\n   * Perform preserve-commits sync\n   */\n  async preserveCommitsSync(executionId: string): Promise<SyncResult>;\n  \n  /**\n   * Validate preconditions for sync\n   */\n  private async validateSyncPreconditions(execution: Execution): Promise<void>;\n  \n  /**\n   * Resolve JSONL conflicts using merge-resolver\n   */\n  private async resolveJSONLConflicts(\n    repoPath: string,\n    jsonlFiles: string[]\n  ): Promise<void>;\n  \n  /**\n   * Create safety snapshot before sync\n   */\n  private async createSafetySnapshot(\n    repoPath: string,\n    executionId: string\n  ): Promise<string>;\n}\n```\n\n**Sync Workflow (Squash Mode):**\n\n```\n1. Load execution from database\n2. Validate preconditions:\n   - Worktree still exists\n   - Local working tree is clean\n   - Worktree branch exists\n   - (Execution can be in any state - just snapshot current worktree state)\n3. Create safety tag: `sudocode-sync-before-{execution-id}`\n4. Get current worktree HEAD commit (may include uncommitted JSONL changes)\n5. Detect conflicts using ConflictDetector\n6. If code conflicts exist:\n   - Pause sync, notify user, offer \"Open in IDE\" to resolve\n   - Return error if user aborts\n7. Checkout local target branch\n8. Perform git merge --squash worktree-branch\n9. Resolve JSONL conflicts:\n   - Extract issues.jsonl and specs.jsonl (including uncommitted changes)\n   - Run merge-resolver on each\n   - Stage resolved files\n10. Create commit with message\n11. Sync worktree JSONL/DB to local:\n    - Copy resolved JSONL to .sudocode/\n    - Re-import to local database\n12. Offer worktree cleanup (if cleanup mode is 'manual')\n13. Return success result\n```\n\n**Sync Workflow (Preserve Commits Mode):**\n\n```\n1-6. Same as squash mode\n7. Get commit list from merge-base to worktree HEAD\n8. For each commit in order:\n   a. Cherry-pick commit\n   b. If JSONL conflicts:\n      - Resolve using merge-resolver\n      - Continue cherry-pick\n   c. If code conflicts:\n      - Pause and report to user\n      - Offer \"Open in IDE\" for manual resolution\n      - Wait for user to resolve and confirm\n      - Resume cherry-pick on user command\n9. If worktree has uncommitted JSONL changes:\n   - Create final commit with those changes\n10. Sync final state (same as squash #11)\n11. Offer worktree cleanup (if cleanup mode is 'manual')\n12. Return success result\n```\n\n#### 4\\. API Routes (Add to `server/src/routes/executions.ts`)\n\n```typescript\n/**\n * Preview sync changes and detect conflicts\n * GET /api/executions/:id/sync/preview\n */\nrouter.get('/:id/sync/preview', async (req, res) => {\n  const { id } = req.params;\n  const result = await worktreeSyncService.previewSync(id);\n  res.json(result);\n});\n\n/**\n * Perform squash sync\n * POST /api/executions/:id/sync/squash\n * Body: { commitMessage?: string }\n */\nrouter.post('/:id/sync/squash', async (req, res) => {\n  const { id } = req.params;\n  const { commitMessage } = req.body;\n  const result = await worktreeSyncService.squashSync(id, commitMessage);\n  res.json(result);\n});\n\n/**\n * Perform preserve-commits sync\n * POST /api/executions/:id/sync/preserve\n */\nrouter.post('/:id/sync/preserve', async (req, res) => {\n  const { id } = req.params;\n  const result = await worktreeSyncService.preserveCommitsSync(id);\n  res.json(result);\n});\n```\n\n#### 5\\. Frontend Components\n\n**a. Add Sync and IDE Buttons to ExecutionView**\n\nLocation: `frontend/src/components/executions/ExecutionView.tsx`\n\n```typescript\n// Add sync and IDE buttons next to other execution actions\n// Available for all execution states (not just completed)\n{execution.worktree_path && (\n  <>\n    <Button\n      onClick={handleOpenInIDE}\n      variant=\"secondary\"\n    >\n      Open Worktree in IDE\n    </Button>\n    <Button\n      onClick={handleSyncClick}\n    >\n      Sync Worktree to Local\n    </Button>\n  </>\n)}\n```\n\n**b. SyncPreviewDialog (New component)**\n\n```typescript\ninterface SyncPreviewDialogProps {\n  execution: Execution;\n  preview: SyncPreviewResult;\n  onConfirm: (mode: 'squash' | 'preserve', message?: string) => void;\n  onCancel: () => void;\n  onOpenIDE: () => void;\n}\n\n// Shows:\n// - Execution status indicator (if running/paused, warn that state may change)\n// - Diff summary (files changed, +/- lines)\n// - Conflict warnings (if any) with \"Open in IDE\" button\n// - Uncommitted JSONL changes indicator\n// - Mode selector (squash vs preserve)\n// - Commit message input (for squash)\n// - Confirm/Cancel buttons\n```\n\n**c. SyncProgressDialog (New component)**\n\n```typescript\ninterface SyncProgressDialogProps {\n  syncStatus: SyncResult | null;\n  onClose: () => void;\n  onCleanupWorktree?: () => void;\n  showCleanupOption: boolean;\n}\n\n// Shows:\n// - Progress indicator\n// - Status messages (cherry-picking commits, resolving conflicts, etc.)\n// - Conflict resolution prompt with \"Open in IDE\" button (if conflicts detected)\n// - Success/error summary\n// - Files changed count\n// - Worktree cleanup option (if cleanup mode is 'manual' and sync succeeded)\n```\n\n### Implementation Phases\n\n#### Phase 1: Git Operations & Conflict Detection (Foundation)\n\n- Implement `GitSyncCli` with all git operations\n- Implement `ConflictDetector` for dry-run conflict detection\n- Add unit tests for git operations\n- Add integration tests for conflict detection scenarios\n\n#### Phase 2: Squash Sync (Core Feature)\n\n- Implement `WorktreeSyncService.previewSync()`\n- Implement `WorktreeSyncService.squashSync()`\n- Integrate with existing merge-resolver for JSONL\n- Add API routes for preview and squash\n- Add tests for squash sync workflow\n\n#### Phase 3: UI Integration (User-Facing)\n\n- Add \"Sync Worktree to Local\" button to ExecutionView\n- Create `SyncPreviewDialog` component\n- Create `SyncProgressDialog` component\n- Add sync state management to execution context\n- Add user-facing error handling and messaging\n\n#### Phase 4: Preserve Commits Sync (Advanced Feature)\n\n- Implement `WorktreeSyncService.preserveCommitsSync()`\n- Add cherry-pick logic with conflict handling\n- Add pause/resume functionality for manual conflict resolution\n- Add API route for preserve sync\n- Update UI to support mode selection\n\n#### Phase 5: Code Conflict Resolution (Future Enhancement)\n\n- Add conflict resolution strategies for common code patterns\n- Implement semi-automatic conflict resolution\n- Add conflict resolution UI (inline diff editor)\n- Support manual conflict resolution workflow\n- Add rollback/undo functionality\n\n## Edge Cases & Considerations\n\n### 1\\. Worktree No Longer Exists\n\n- **Scenario:** User deleted worktree directory manually\n- **Handling:** Check worktree existence in preview, show error, disable sync\n- **Recovery:** No sync possible, user must re-run execution\n\n### 2\\. Local Working Tree Dirty\n\n- **Scenario:** User has uncommitted changes in local tree\n- **Handling:** Block sync, show warning, suggest stash or commit\n- **Recovery:** User cleans working tree, retries sync\n\n### 3\\. Diverged Branches (No Common Base)\n\n- **Scenario:** Worktree branch and local branch have completely different histories\n- **Handling:** Detect in preview, show error, explain incompatibility\n- **Recovery:** User must manually reconcile or abandon sync\n\n### 4\\. Execution In Progress\n\n- **Scenario:** User wants to sync while agent is still executing (running/paused state)\n- **Handling:** Allow sync of current worktree state, warn user that execution may continue making changes after sync\n- **Impact:** Synced state may not reflect final execution result; user may need to sync again after completion\n\n### 5\\. JSONL Conflicts with UUID Collisions\n\n- **Scenario:** Worktree and local both have different entities with same ID hash\n- **Handling:** Merge-resolver renames duplicates with `.1`, `.2` suffixes\n- **Impact:** Users may need to manually reconcile entity references\n\n### 6\\. Binary File Conflicts\n\n- **Scenario:** Agent modified images/binaries that also changed locally\n- **Handling:** Git shows binary conflict, cannot auto-resolve\n- **Recovery:** Manual resolution required (choose ours/theirs or manual merge)\n\n### 7\\. Database State Inconsistency\n\n- **Scenario:** JSONL sync succeeds but database import fails\n- **Handling:** Rollback git changes, report error, maintain consistency\n- **Recovery:** Fix database issue, retry sync\n\n### 8\\. Partial Sync Failure (Preserve Mode)\n\n- **Scenario:** Cherry-pick succeeds for some commits, fails on later commit\n- **Handling:** Leave partial changes, report failure point, offer rollback\n- **Recovery:** User resolves conflict, continues cherry-pick, or rolls back\n\n## Security Considerations\n\n1. **Path Traversal:** Validate all file paths are within repo boundaries\n1. **Command Injection:** Sanitize all git command arguments (use existing execSync wrapper)\n1. **Data Loss Prevention:** Always create safety tags before destructive operations\n1. **Access Control:** Validate user has permission to modify target branch\n1. **Rollback Safety:** Ensure rollback is always possible (safety tags + clean state validation)\n\n## Testing Strategy\n\n### Unit Tests\n\n- Git operations (getMergeBase, getDiff, etc.)\n- Conflict detection logic\n- JSONL merge resolution\n- Validation checks\n\n### Integration Tests\n\n- Full squash sync workflow\n- Full preserve-commits sync workflow\n- Conflict detection scenarios\n- JSONL conflict resolution\n- Database sync after merge\n\n### E2E Tests\n\n- User creates execution, makes changes, syncs back (squash)\n- User creates execution, makes changes, syncs back (preserve)\n- User encounters conflict, resolves, completes sync\n- User cancels sync, no changes applied\n\n### Manual Testing Scenarios\n\n- Real-world agent execution with complex changes\n- Multiple JSONL conflicts (issues + specs)\n- Code conflicts requiring manual resolution\n- Large diffs (100+ files)\n- Binary file modifications\n\n## Design Decisions\n\n### 1\\. Syncing from Any Execution State\n\n**Decision:** Allow syncing from executions in any state (running, paused, stopped, cancelled, completed, blocked).\n\n**Rationale:** Users may want to preview or integrate partial work from an in-progress execution. The sync operation captures the current state of the worktree at the time of sync request.\n\n**Implications:**\n\n- Sync takes a snapshot of current worktree HEAD commit\n- For running/paused executions, warn user that execution may continue making changes\n- User can sync again after execution completes to get final state\n\n### 2\\. Worktree Cleanup After Sync\n\n**Decision:** Use configured cleanup mode from execution settings. For manual cleanup mode, offer cleanup option after successful sync.\n\n**Rationale:** Respects existing user preferences while providing explicit control for manual cleanup scenarios.\n\n**Behavior:**\n\n- **Auto cleanup:** Automatically clean up worktree after sync (follows existing execution cleanup config)\n- **Manual cleanup:** Show \"Clean up worktree?\" prompt after successful sync\n- **Never cleanup:** Keep worktree intact (allows follow-up executions)\n\n### 3\\. Selective File Sync\n\n**Decision:** Not supported in initial implementation. Sync all changes or none.\n\n**Rationale:** Simplifies implementation and UX. Users who need fine-grained control can:\n\n- Use \"Open Worktree in IDE\" to make selective changes before syncing\n- Manually use git commands for advanced workflows\n\n**Future Enhancement:** May add selective file sync in Phase 5+ based on user feedback.\n\n### 4\\. Uncommitted JSONL Changes\n\n**Decision:** Include uncommitted JSONL changes from worktree in sync.\n\n**Rationale:** Worktree may have uncommitted spec/issue updates that represent important work state. These should be preserved during sync.\n\n**Implementation:** Before sync, check for uncommitted changes in `.sudocode/*.jsonl`, include them in merge resolution.\n\n### 5\\. Bi-directional Sync (Local → Worktree)\n\n**Decision:** Not implemented in this version, but design is future-proofed to support it.\n\n**Rationale:** Current use case is primarily worktree→local (integrating agent work). Local→worktree (updating agent context) is a different workflow that requires additional UX design.\n\n**Future-Proofing:**\n\n- `WorktreeSyncService` interface designed to be symmetric (can add `syncToWorktree()` method)\n- API routes structured to support bidirectional operations (`/sync/to-worktree` endpoint can be added)\n- Conflict detection logic is branch-agnostic (works for either direction)\n\n**Future Implementation Notes:**\n\n- When implemented, local→worktree sync would allow users to:\n  - Push hotfixes to running executions\n  - Update specs/issues that agent is working on\n  - Share local work with paused execution for agent to continue\n- Would need careful handling of running executions (notify/pause agent during sync)\n\n### 6\\. Manual Code Conflict Resolution UX\n\n**Decision:** Pause sync, notify user of conflicts, provide \"Open in IDE\" button for manual resolution.\n\n**Rationale:**\n\n- Most code conflicts require developer judgment and context\n- IDE provides familiar, powerful tools for conflict resolution\n- Simpler than building custom conflict resolution UI\n\n**Workflow:**\n\n1. Conflict detected during sync\n1. Sync pauses, shows conflict report with file list\n1. User clicks \"Open in IDE\" button\n1. System opens worktree in configured IDE with conflict markers visible\n1. User resolves conflicts in IDE, saves files\n1. User returns to sync dialog, clicks \"Continue\"\n1. System validates conflicts are resolved, continues sync\n\n**Future Enhancement:** In-app conflict visualization and resolution (Phase 5) for users who prefer not to context-switch to IDE.\n\n## Success Metrics\n\n- **Adoption:** % of completed executions that get synced\n- **Success Rate:** % of sync attempts that complete without error\n- **Conflict Rate:** % of syncs that encounter conflicts (target: < 20%)\n- **Auto-Resolution Rate:** % of conflicts resolved automatically (target: > 80% for JSONL)\n- **User Satisfaction:** Feedback from users on sync experience\n\n## Future Enhancements\n\n1. **Bi-directional Sync (Local → Worktree):** Push changes from local tree to worktree\n\n- Use cases: Update running execution context, share hotfixes with agent\n- API: `POST /executions/:id/sync/to-worktree`\n- Requires coordination with running agent processes\n\n1. **Smart Conflict Resolution:** ML-based suggestions for code conflict resolution\n1. **Partial File Sync:** Select specific files/changes to sync\n1. **Sync Templates:** Pre-configured sync strategies for common patterns\n1. **Batch Sync:** Sync multiple executions at once\n1. **Sync History:** Track all syncs performed, allow rollback to previous state\n1. **Async Sync:** Long-running syncs don't block UI\n1. **Conflict Visualization:** Visual diff tool for reviewing conflicts (in-app alternative to IDE)\n1. **Auto-sync:** Optional auto-sync on execution completion\n1. **IDE Integration Protocol:** Standardized way to open specific files at conflict locations across different IDEs","priority":1,"archived":0,"archived_at":null,"created_at":"2025-11-28 20:27:12","updated_at":"2025-11-28 20:49:51","parent_id":null,"parent_uuid":null,"relationships":[],"tags":["agent-execution","feature","git","sync","worktree"]}
{"id":"s-6u9w","uuid":"99956c8a-3d04-4edb-8d6f-c295c167f75a","title":"Worktree Management Page","file_path":"specs/s-6u9w_worktree_management_page.md","content":"# Overview\n\nA dedicated page at `/worktrees` that provides centralized management of git worktrees created for agent executions, enabling users to view, sync, and manage multiple worktrees efficiently.\n\n## User Requirements\n\n### Workflow Context\n- Worktrees exist as standalone entities but are interacted with through executions\n- Users can create standalone worktrees and bind issue executions to them\n- Users can create new worktrees through new executions\n- Users need visibility into all worktrees to enable reuse across multiple executions\n\n### Core Features (MVP)\n1. **List all worktrees** with status visibility\n2. **Quick actions**: Sync to local, Delete worktree, Open in IDE\n3. **Detailed change preview**: View commits, file changes, conflicts inline\n4. **Search and filtering**: Find worktrees by execution ID, branch name, issue\n5. **Issue association**: Clear visibility of which issue each worktree relates to\n6. **Worktree reusability**: See all existing worktrees to identify candidates for new executions\n\n## Technical Architecture\n\n### Data Model\n\n**Foundation Principle**: Worktrees ARE Executions\n- Query executions where `worktree_path IS NOT NULL`\n- Reuse existing `Execution` type from `types/src/schema.ts`\n- No new database schema changes required\n\n**Key Execution Fields**:\n```typescript\n{\n  id: string                    // Execution identifier\n  issue_id: string              // Associated issue\n  worktree_path: string         // File system path to worktree\n  branch_name: string           // Git branch for this worktree\n  target_branch: string         // Base branch (where changes will merge)\n  status: ExecutionStatus       // running | paused | completed | failed\n  files_changed: string[]       // List of modified files\n  before_commit: string         // HEAD before execution\n  after_commit: string          // Latest commit in worktree\n  created_at: Date\n  updated_at: Date\n}\n```\n\n### Backend API\n\n**New Endpoint**:\n```\nGET /api/executions/worktrees\n```\n\n**Response**:\n```typescript\n{\n  success: boolean\n  data: Execution[]  // Executions filtered by worktree_path != null\n}\n```\n\n**Implementation** (server/src/routes/executions.ts):\n- Use existing ExecutionService.listAllExecutions()\n- Filter results where worktree_path is not null\n- Return as standard execution array\n\n**Reused Endpoints**:\n- `GET /api/executions/:id/sync/preview` - Preview sync changes\n- `POST /api/executions/:id/sync/squash` - Perform squash sync\n- `POST /api/executions/:id/sync/preserve` - Perform preserve-commits sync\n- `DELETE /api/executions/:id/worktree` - Delete worktree\n\n### Frontend Architecture\n\n#### Page Structure (follows IssuesPage pattern)\n\n**Route**: `/worktrees`\n\n**Layout**:\n```\n┌─────────────────────────────────────────────────────────┐\n│ Header (Title, Search, Filters, Sort)                  │\n├─────────────────────────────────────────────────────────┤\n│ ┌──────────────────────┬──────────────────────────────┐ │\n│ │ WorktreeList (66%)   │ WorktreeDetailPanel (34%)    │ │\n│ │                      │                              │ │\n│ │ Grid of Cards:       │ Selected Worktree Details:   │ │\n│ │ - WorktreeCard       │ - Overview                   │ │\n│ │ - WorktreeCard       │ - Commits                    │ │\n│ │ - WorktreeCard       │ - Files Changed              │ │\n│ │ ...                  │ - Conflicts                  │ │\n│ │                      │ - Action Buttons             │ │\n│ └──────────────────────┴──────────────────────────────┘ │\n└─────────────────────────────────────────────────────────┘\n```\n\n**Resizable Panels**:\n- Uses `react-resizable-panels`\n- Panel sizes persist to localStorage\n- Collapsible right panel\n\n**State Management**:\n- URL hash for selected worktree (#execution-id)\n- localStorage for sort/filter preferences (key: `sudocode:worktrees:sortOption`)\n- React Query for data fetching and caching\n\n#### Component Hierarchy\n\n```\nWorktreesPage\n├── Header\n│   ├── Title with count badge\n│   ├── Project info (repo name, branch)\n│   ├── Search input\n│   ├── Sort dropdown (newest, last-updated, status)\n│   └── Filter dropdown (all, active, completed, with-conflicts)\n├── PanelGroup\n│   ├── Panel (Left - List View)\n│   │   └── WorktreeList\n│   │       └── WorktreeCard[] (grid layout)\n│   ├── PanelResizeHandle\n│   └── Panel (Right - Detail View)\n│       └── WorktreeDetailPanel\n│           ├── Overview section\n│           ├── Commits section\n│           ├── Files changed section\n│           ├── Conflicts section\n│           └── Action bar\n└── Dialogs (from useExecutionSync)\n    ├── SyncPreviewDialog\n    ├── SyncProgressDialog\n    └── DeleteWorktreeDialog\n```\n\n#### Component Specifications\n\n**WorktreeCard** (frontend/src/components/worktrees/WorktreeCard.tsx):\n- Displays per worktree:\n  - Execution ID (truncated, copyable tooltip)\n  - Branch name with GitBranch icon\n  - Status badge (colored by status)\n  - Issue reference (clickable → navigate to `/issues/:id`)\n  - File count badge (from files_changed.length)\n  - Conflict indicator (red badge if conflicts detected)\n  - Last updated timestamp (relative time)\n- Hover actions:\n  - View Details (navigate to execution detail)\n  - Sync to Local (trigger sync preview)\n  - Open in IDE (copy path to clipboard)\n  - Delete (confirmation dialog)\n- Visual states: default, hover, selected\n\n**WorktreeList** (frontend/src/components/worktrees/WorktreeList.tsx):\n- Grid layout: `md:grid-cols-2 lg:grid-cols-3`\n- Loading state: Skeleton cards\n- Empty state: \"No worktrees found. Create an execution with worktree mode to get started.\"\n- Maps filtered/sorted worktrees to WorktreeCard\n- Click handler to update URL hash and select worktree\n\n**WorktreeDetailPanel** (frontend/src/components/worktrees/WorktreeDetailPanel.tsx):\n\n**Overview Section**:\n- Execution ID (copyable)\n- Issue link (navigate to issue)\n- Branch name\n- Status badge\n- Created/Updated timestamps\n- Worktree path (copyable)\n\n**Commits Section**:\n- Fetches via `executionsApi.syncPreview(executionId)`\n- Displays commit list from preview result:\n  - SHA (short form, copyable)\n  - Commit message\n  - Author\n  - Date (relative time)\n- Shows merge base reference\n- Link to view full execution details\n\n**Files Changed Section**:\n- From sync preview `diff.files` array\n- File list showing:\n  - File path\n  - +/- line counts\n  - Change type (modified, added, deleted)\n- Summary: Total additions/deletions\n\n**Conflicts Section**:\n- Displayed only if conflicts detected\n- Code conflicts:\n  - File path\n  - Conflict type (content, delete, rename, mode)\n  - \"Requires manual resolution\" indicator\n- JSONL conflicts:\n  - File path\n  - \"Auto-resolvable\" indicator\n- Total conflict count badge\n\n**Action Bar**:\n- Primary button: \"Sync to Local\" → calls `fetchSyncPreview(executionId)`\n- Secondary button: \"Open in IDE\" → calls `openWorktreeInIDE(execution)`\n- Danger button: \"Delete Worktree\" → shows DeleteWorktreeDialog\n- Tertiary link: \"View Full Details\" → navigate to `/executions/:id`\n\n**WorktreesPage** (frontend/src/pages/WorktreesPage.tsx):\n\n**Header**:\n- Title: \"Worktrees\" with count badge\n- Project context: Repository name, current branch (from useRepositoryInfo)\n- Search input: Filter by execution ID, branch name, issue ID\n- Sort dropdown:\n  - Newest first (created_at DESC)\n  - Last updated (updated_at DESC)\n  - Status (running → paused → completed → failed)\n- Filter dropdown:\n  - All worktrees\n  - Active only (status = running or paused)\n  - Completed only (status = completed)\n  - With conflicts (requires sync preview check)\n\n**State Management**:\n```typescript\nconst [selectedWorktree, setSelectedWorktree] = useState<Execution | undefined>()\nconst [filterText, setFilterText] = useState('')\nconst [sortOption, setSortOption] = useState<SortOption>('newest')\nconst [statusFilter, setStatusFilter] = useState<'all' | 'active' | 'completed'>('all')\n```\n\n**URL Hash Selection**:\n- Parse `location.hash` on mount → select initial worktree\n- Update hash when worktree selected\n- Listen to hash changes for browser back/forward\n\n**Filtering Logic**:\n```typescript\nconst filtered = useMemo(() => {\n  return worktrees.filter(wt => \n    (filterText === '' || \n     wt.id.includes(filterText) ||\n     wt.branch_name.includes(filterText) ||\n     wt.issue_id.includes(filterText)) &&\n    (statusFilter === 'all' || \n     statusFilter === 'active' && ['running', 'paused'].includes(wt.status) ||\n     statusFilter === 'completed' && wt.status === 'completed')\n  )\n}, [worktrees, filterText, statusFilter])\n```\n\n**Sorting Logic**:\n```typescript\nconst sorted = useMemo(() => {\n  const items = [...filtered]\n  switch (sortOption) {\n    case 'newest':\n      return items.sort((a, b) => new Date(b.created_at) - new Date(a.created_at))\n    case 'last-updated':\n      return items.sort((a, b) => new Date(b.updated_at) - new Date(a.updated_at))\n    case 'status':\n      const statusOrder = { running: 0, paused: 1, completed: 2, failed: 3 }\n      return items.sort((a, b) => statusOrder[a.status] - statusOrder[b.status])\n  }\n}, [filtered, sortOption])\n```\n\n#### Data Hook\n\n**useWorktrees** (frontend/src/hooks/useWorktrees.ts):\n\nPattern: Follow useIssues.ts structure\n\n```typescript\nexport function useWorktrees() {\n  const queryClient = useQueryClient()\n  const { currentProjectId } = useProject()\n  \n  const queryKey = ['worktrees', currentProjectId]\n  \n  const query = useQuery({\n    queryKey,\n    queryFn: () => executionsApi.listWorktrees(),\n    enabled: !!currentProjectId\n  })\n  \n  // Optional: WebSocket subscription for real-time updates\n  const { connected, subscribe, addMessageHandler } = useWebSocketContext()\n  \n  useEffect(() => {\n    const handleMessage = (message: WebSocketMessage) => {\n      if (message.type === 'execution_updated' || \n          message.type === 'execution_completed') {\n        queryClient.invalidateQueries({ queryKey: ['worktrees', currentProjectId] })\n      }\n    }\n    \n    addMessageHandler('useWorktrees', handleMessage)\n    if (connected) subscribe('execution')\n    \n    return () => {\n      removeMessageHandler('useWorktrees')\n      unsubscribe('execution')\n    }\n  }, [connected])\n  \n  return {\n    worktrees: query.data ?? [],\n    isLoading: query.isLoading,\n    isError: query.isError,\n    error: query.error\n  }\n}\n```\n\n### Component Reuse Strategy\n\n**100% Reuse (No modifications needed)**:\n1. `useExecutionSync` hook - All sync state management\n2. `SyncPreviewDialog` - Preview changes before sync\n3. `SyncProgressDialog` - Show sync progress and results\n4. `DeleteWorktreeDialog` - Delete confirmation\n5. All UI primitives from shadcn/ui:\n   - Badge, Button, Card, Input, Select\n   - Tooltip, AlertDialog\n   - PanelGroup, Panel, PanelResizeHandle\n\n**Pattern Reuse**:\n- Page structure from `IssuesPage.tsx`\n- Data hook pattern from `useIssues.ts`\n- Status badges from `ExecutionView.tsx`\n\n### Navigation Integration\n\n**App.tsx** modification:\n```typescript\n<Route\n  path=\"worktrees\"\n  element={\n    <ProtectedRoute>\n      <WorktreesPage />\n    </ProtectedRoute>\n  }\n/>\n```\n\n**Sidebar.tsx** modification:\n```typescript\nconst navItems = [\n  { path: '/issues', label: 'Issues', icon: ListTodo },\n  { path: '/specs', label: 'Specs', icon: FileText },\n  { path: '/worktrees', label: 'Worktrees', icon: GitBranch }, // NEW\n]\n```\n\n## User Workflows\n\n### View All Worktrees\n1. User clicks \"Worktrees\" in sidebar\n2. Page loads, fetches all executions with worktree_path\n3. Displays grid of worktree cards\n4. User can search/filter/sort as needed\n\n### Inspect Worktree Details\n1. User clicks on a worktree card\n2. URL hash updates to `#execution-id`\n3. Detail panel loads sync preview\n4. Shows commits, files, conflicts\n5. User can see all changes before syncing\n\n### Sync Worktree to Local\n1. User clicks \"Sync to Local\" in detail panel\n2. `fetchSyncPreview()` called → opens SyncPreviewDialog\n3. User reviews changes, conflicts, warnings\n4. User selects sync mode (squash or preserve)\n5. User optionally customizes commit message\n6. User clicks \"Sync\" → opens SyncProgressDialog\n7. Backend performs sync with conflict resolution\n8. Success: Shows summary with option to delete worktree\n9. Failure: Shows error with recovery options\n\n### Open Worktree in IDE\n1. User clicks \"Open in IDE\"\n2. Worktree path copied to clipboard\n3. Toast notification: \"Path copied to clipboard\"\n4. User manually opens path in IDE\n\n### Delete Worktree\n1. User clicks \"Delete Worktree\"\n2. DeleteWorktreeDialog appears with confirmation\n3. User confirms deletion\n4. Backend deletes worktree and branch\n5. Worktree removed from list\n6. If worktree was selected, detail panel shows empty state\n\n### Reuse Existing Worktree\n1. User views worktree list\n2. User identifies worktree with desired context\n3. User can see worktree path, branch, and current state\n4. User creates new execution targeting that worktree (future feature)\n\n## Implementation Phases\n\n### Phase 1: Data Layer (30 min)\n- Add `GET /executions/worktrees` backend endpoint\n- Add `executionsApi.listWorktrees()` to API client\n- Create `useWorktrees` hook with React Query\n\n### Phase 2: Components (2-2.5 hours)\n- Create WorktreeCard component\n- Create WorktreeList component\n- Create WorktreeDetailPanel component\n- Create WorktreesPage component\n- Wire up useExecutionSync for all sync operations\n\n### Phase 3: Navigation (15 min)\n- Add /worktrees route to App.tsx\n- Add Worktrees nav item to Sidebar.tsx\n- Test navigation and URL hash selection\n\n### Phase 4: Polish (30-45 min)\n- Add loading states (skeleton cards)\n- Add empty states (no worktrees, no selection)\n- Error handling (failed to load, sync errors)\n- Test all actions\n- Verify responsive layout\n\n**Total Implementation Time: 3.5-4 hours**\n\n## Success Criteria\n\n- [ ] User can navigate to /worktrees\n- [ ] User can see all worktrees in a grid layout\n- [ ] User can search/filter worktrees by execution ID, branch, issue\n- [ ] User can sort worktrees by date, status\n- [ ] User can select a worktree to see details\n- [ ] User can see commits, file changes, and conflicts for selected worktree\n- [ ] User can preview sync changes before executing\n- [ ] User can sync worktree to local (squash or preserve modes)\n- [ ] User can delete worktree with confirmation\n- [ ] User can open worktree path in IDE (via clipboard)\n- [ ] User can identify which issue a worktree relates to\n- [ ] User can view full execution details for any worktree\n- [ ] User can navigate via URL hash (shareable links, browser back/forward)\n- [ ] Page handles loading, empty, and error states gracefully\n\n## Future Enhancements (Post-MVP)\n\n- Real-time WebSocket updates for worktree status changes\n- Batch operations (select multiple worktrees, bulk sync/delete)\n- Inline sync preview in card hover (without opening full dialog)\n- Advanced filters (by base branch, file count range, conflict status)\n- Worktree health checks (verify directory still exists on disk)\n- Auto-cleanup policies (delete worktrees older than X days)\n- Disk usage statistics and warnings\n- Branch divergence visualization\n- Quick actions: Create PR from worktree\n- Execution binding: Attach new execution to existing worktree\n\n## Technical Dependencies\n\n**Frontend**:\n- React 18+\n- React Router v6 (for routing)\n- TanStack Query v4 (for data fetching)\n- react-resizable-panels (for layout)\n- lucide-react (for icons)\n- shadcn/ui components\n- Tailwind CSS\n\n**Backend**:\n- Existing ExecutionService\n- Existing WorktreeSyncService\n- Existing worktree endpoints\n\n**No new dependencies required**","priority":1,"archived":0,"archived_at":null,"created_at":"2025-11-30 02:08:36","updated_at":"2025-11-30 02:08:36","parent_id":null,"parent_uuid":null,"relationships":[],"tags":["execution","frontend","ui","worktree"]}
{"id":"s-65lm","uuid":"c5a5a0dc-3dfa-4aca-9ae9-0474c5e05834","title":"Executions Page - Multi-Execution Monitoring","file_path":"specs/s-65lm_executions_page_multi_execution_monitoring.md","content":"# Executions Page - Multi-Execution Monitoring\n\n## Overview\n\nBuild an \"Executions Page\" that allows users to monitor and interact with multiple executions simultaneously through a grid-based layout with an intelligent sidebar for execution management.\n\n## User Requirements\n\n### Core Features\n1. **Grid of Multiple Execution Views**: Display multiple executions in a configurable grid layout, each with its own execution monitor and agent config panel\n2. **Sidebar with Execution List**: Show all executions with metadata (issue, branch, status, timestamp) and checkbox-based visibility controls\n3. **Rapid Context Switching**: Allow users to quickly toggle which executions are displayed and interact with different agent config panels\n4. **Configurable Grid Layouts**: Support 2-column, 3-column, and 4-column grid layouts based on user preference\n\n### User Workflow\n- Users can view a list of all executions in the sidebar\n- Check/uncheck executions to show/hide them in the grid\n- Monitor multiple executions simultaneously with real-time updates\n- Submit follow-ups to any execution directly from its grid tile\n- Change grid density (2/3/4 columns) based on screen size and preference\n\n## Architecture\n\n### Component Structure\n\n#### ExecutionsPage (Main Container)\n- **Location**: `/frontend/src/pages/ExecutionsPage.tsx`\n- **Layout**: PanelGroup with resizable sidebar + grid area (following IssuesPage pattern)\n- **State Management**:\n  - `gridLayout`: '2col' | '3col' | '4col' (persisted to localStorage)\n  - `visibleExecutionIds`: Set<string> (sessionStorage, resets on reload)\n  - `searchText`: string (optional filter)\n  - `statusFilter`: ExecutionStatus | 'all'\n- **Header Controls**: Grid layout toggle, filters, search\n- **Persistence**: Layout preferences saved to localStorage, panel sizes saved\n\n#### ExecutionsSidebar\n- **Location**: `/frontend/src/components/executions/ExecutionsSidebar.tsx`\n- **Features**:\n  - List of all executions with metadata display\n  - Checkbox for each execution to toggle visibility in grid\n  - Status badges with color coding (running=blue, completed=green, failed=red)\n  - Relative timestamps (\"3m ago\")\n  - Real-time WebSocket updates for status changes\n  - Collapsible (60px collapsed, 280-320px expanded)\n\n#### ExecutionsGrid\n- **Location**: `/frontend/src/components/executions/ExecutionsGrid.tsx`\n- **Implementation**: CSS Grid with dynamic column count\n  - 2-column: `grid-template-columns: repeat(2, 1fr)`\n  - 3-column: `grid-template-columns: repeat(3, 1fr)` (default)\n  - 4-column: `grid-template-columns: repeat(4, 1fr)`\n- **Responsive Behavior**:\n  - < 1024px: Force 1 column\n  - 1024-1440px: Max 2 columns\n  - 1440+px: Allow all layouts\n- **Empty State**: \"Check executions in sidebar to display\"\n\n#### ExecutionGridTile\n- **Location**: `/frontend/src/components/executions/ExecutionGridTile.tsx`\n- **Structure**:\n  - Sticky Header: Execution ID, status badge, quick actions\n  - Scrollable Middle: ExecutionMonitor (compact mode)\n  - Sticky Footer: AgentConfigPanel (follow-up mode)\n- **Integration**:\n  - Reuses `ExecutionMonitor` with `compact={true}` prop\n  - Reuses `AgentConfigPanel` with `isFollowUp={true}` for follow-ups\n  - Focus indicators (2px border) when active\n\n### Backend API\n\n#### New Endpoint: GET /api/executions\n- **Purpose**: List all executions across all issues with filtering and pagination\n- **Query Parameters**:\n  - `limit?: number` (default: 50)\n  - `offset?: number` (default: 0)\n  - `status?: ExecutionStatus | ExecutionStatus[]`\n  - `issueId?: string`\n  - `sortBy?: 'created_at' | 'updated_at'` (default: 'created_at')\n  - `order?: 'asc' | 'desc'` (default: 'desc')\n- **Response**:\n  ```typescript\n  {\n    executions: Execution[]\n    total: number\n    hasMore: boolean\n  }\n  ```\n- **Location**: `/server/src/routes/executions.ts`\n\n#### Frontend API Client\n- **Location**: `/frontend/src/lib/api.ts`\n- **Method**: `executionsApi.listAll(params?)`\n- **React Query Hook**: `useExecutions()` for data fetching with caching\n\n### Data Flow\n\n#### Initial Load\n1. ExecutionsPage mounts\n2. Fetch executions via `executionsApi.listAll()`\n3. Display all in sidebar (none checked initially)\n4. Grid shows empty state\n\n#### Show/Hide Executions\n1. User checks execution in sidebar\n2. Add `execution.id` to `visibleExecutionIds` Set\n3. Grid re-renders with new ExecutionGridTile\n4. ExecutionMonitor connects to SSE stream (if execution is running)\n5. AgentConfigPanel ready for follow-up submission\n\n#### Real-time Updates\n1. WebSocket receives `execution_status_changed` event\n2. Update execution in sidebar (status badge changes)\n3. If execution visible in grid → ExecutionMonitor updates via SSE\n\n#### Follow-up Submission\n1. User submits prompt in AgentConfigPanel\n2. Call `executionsApi.createFollowUp(executionId, { feedback })`\n3. New execution created\n4. WebSocket broadcasts `execution_created`\n5. Sidebar adds new execution to list\n6. User can check it to show in grid\n\n### WebSocket Integration\n- Subscribe to 'execution' entity type on page mount\n- Handle events:\n  - `execution_created`: Add to sidebar list\n  - `execution_updated`: Update execution metadata\n  - `execution_status_changed`: Update status badges\n  - `execution_deleted`: Remove from sidebar and grid\n- Unsubscribe on page unmount\n\n## Implementation Phases\n\n### Phase 1: Backend (1.5 hours)\n1. Add GET /api/executions endpoint to `/server/src/routes/executions.ts`\n2. Implement ExecutionService.listAll() method with filtering/pagination\n3. Test endpoint with various filters and pagination\n\n### Phase 2: Frontend Components (3 hours)\n1. Create ExecutionGridTile component\n   - Sticky header/footer with scrollable ExecutionMonitor\n   - Test with single execution\n2. Create ExecutionsGrid component\n   - CSS Grid with dynamic columns (2/3/4)\n   - Empty state handling\n3. Create ExecutionsSidebar component\n   - Execution list with checkboxes\n   - Metadata display (issue, branch, status, time)\n   - WebSocket subscription for updates\n4. Create ExecutionsPage component\n   - PanelGroup layout\n   - State management\n   - Grid layout controls\n\n### Phase 3: Integration (1.5 hours)\n1. Add route `/executions` to `/frontend/src/App.tsx`\n2. Add navigation link to MainLayout\n3. Add `executionsApi.listAll()` to API client\n4. Create `useExecutions()` React Query hook\n5. WebSocket integration for real-time updates\n6. Polish: empty states, loading states, error handling\n\n### Phase 4: Testing & Refinement (2 hours)\n1. Manual testing with multiple executions\n2. Test grid layout switches\n3. Test WebSocket real-time updates\n4. Test follow-up submissions\n5. Bug fixes and edge cases\n6. Responsive behavior testing\n\n**Total Estimated Time: 7 hours**\n\n## Success Criteria\n\nMVP is successful if:\n- ✅ Users can view multiple executions simultaneously in a grid\n- ✅ Users can show/hide executions via sidebar checkboxes\n- ✅ Users can interact with agent config panels for each execution\n- ✅ Grid layout can be changed between 2/3/4 columns\n- ✅ Real-time updates work via WebSocket\n- ✅ No performance issues with 10 concurrent executions\n- ✅ Implementation completed in 6-8 hours\n\n## Deferred Features (Future Versions)\n\n### v1.1 Enhancements\n- Keyboard shortcuts (Tab to cycle, Cmd+K quick switcher)\n- Search/filter in sidebar\n- Sort options (newest, status, priority)\n- Drag-and-drop to reorder grid tiles\n\n### v1.2 Performance\n- Virtualization for sidebar (when 100+ executions)\n- Smart SSE connection management (limit to 5 concurrent streams)\n- Memory optimization with ring buffers\n\n### v1.3 Advanced UX\n- Custom grid layouts (adjustable tile sizes)\n- Execution comparison view\n- Execution grouping/workspaces\n- Pin favorite executions\n\n## Testing Checklist\n\n### Manual Testing\n- [ ] Create 3 executions on different issues\n- [ ] Check all 3 in sidebar → verify grid shows 3 tiles\n- [ ] Uncheck 1 → verify it disappears from grid\n- [ ] Submit follow-up from one tile → verify new execution appears in sidebar\n- [ ] Change grid layout (2/3/4 col) → verify tiles reflow correctly\n- [ ] Reload page → verify grid layout preference persists\n- [ ] Cancel a running execution → verify status updates in sidebar and grid\n- [ ] Test on mobile (< 1024px) → verify forces 1 column\n\n### Edge Cases\n- [ ] Empty state when no executions exist\n- [ ] Empty state when executions exist but none checked\n- [ ] Handle execution deletion (remove from sidebar and grid)\n- [ ] Handle execution error states\n- [ ] Handle SSE disconnection and reconnection\n\n## Technical Constraints\n\n- Reuse ExecutionMonitor component (no modifications needed)\n- Reuse AgentConfigPanel component (no modifications needed)\n- Follow IssuesPage PanelGroup pattern for layout consistency\n- Use existing WebSocket infrastructure\n- No virtualization in MVP (defer to v1.2 if needed)\n- Grid layout preference persists via localStorage\n- Visible executions reset on page reload (sessionStorage)\n\n## Files Affected\n\n### New Files (4)\n1. `/frontend/src/pages/ExecutionsPage.tsx` (~350 lines)\n2. `/frontend/src/components/executions/ExecutionGridTile.tsx` (~200 lines)\n3. `/frontend/src/components/executions/ExecutionsGrid.tsx` (~80 lines)\n4. `/frontend/src/components/executions/ExecutionsSidebar.tsx` (~250 lines)\n\n### Modified Files (3)\n1. `/frontend/src/App.tsx` - Add route (~8 lines)\n2. `/frontend/src/lib/api.ts` - Add listAll method (~15 lines)\n3. `/server/src/routes/executions.ts` - Add GET /executions endpoint (~60 lines)\n\n### Reference Files (No Changes)\n1. `/frontend/src/pages/IssuesPage.tsx` - PanelGroup layout pattern\n2. `/frontend/src/components/executions/ExecutionMonitor.tsx` - Compact mode\n3. `/frontend/src/components/executions/AgentConfigPanel.tsx` - Follow-up mode\n4. `/frontend/src/components/executions/ExecutionView.tsx` - Structure reference","priority":1,"archived":0,"archived_at":null,"created_at":"2025-11-30 10:55:34","updated_at":"2025-11-30 10:55:34","parent_id":null,"parent_uuid":null,"relationships":[],"tags":["executions","feature","monitoring","ui"]}
{"id":"s-6h0o","uuid":"f6ea3c72-123d-4220-9c6b-8fa8989918da","title":"Execution Code Changes Extraction","file_path":"specs/s-6h0o_execution_code_changes_extraction.md","content":"# Execution Code Changes Extraction\n\n## Overview\n\nAdd functionality to extract and display code changes (file lists + diff statistics) from executions. This allows users to see what files were modified during an agent execution and view statistics about the changes.\n\n## Requirements\n\n### Functional Requirements\n\n1. **Data to Extract**\n   - List of changed files with paths\n   - Diff statistics per file (lines added/deleted)\n   - File status indicators (A=Added, M=Modified, D=Deleted, R=Renamed)\n   - Summary statistics (total files, total additions, total deletions)\n\n2. **Capture Timing**\n   - Capture when execution completes (status: 'completed')\n   - Capture when execution is stopped/cancelled (status: 'stopped')\n   - Do NOT capture for failed executions (inconsistent state)\n\n3. **Execution Modes Support**\n   - **Worktree mode**: Track changes in isolated worktree\n   - **Local mode**: Track changes in main repository working tree\n\n4. **Commit Scenarios**\n   - **Committed changes**: Agent commits changes during execution\n   - **Uncommitted changes**: Agent makes changes without committing (auto-commit disabled)\n   - Handle both scenarios transparently\n\n### Non-Functional Requirements\n\n1. **Minimal Storage**: Store only commit SHAs (80 bytes per execution), not full diffs\n2. **Recalculatable**: Changes can be re-computed at any time from git history\n3. **Fast UI**: Changes available within 50-200ms for typical executions\n4. **Clear Errors**: Show explicit error messages when changes unavailable\n5. **Simplicity**: Leverage existing git infrastructure, minimal new code\n\n## Design Approach\n\n### Core Strategy\n\n**On-demand calculation with commit SHA tracking**:\n- Store `before_commit` and `after_commit` SHAs in database (existing fields)\n- Calculate changes on-demand when UI requests them via new API endpoint\n- Use existing git CLI infrastructure for diff operations\n- Support both committed and uncommitted changes\n\n### Why This Approach?\n\n- ✅ Minimal storage overhead (just 2 commit SHAs)\n- ✅ Recalculatable anytime (not locked into initial calculation)\n- ✅ Simple implementation (reuse existing git utilities)\n- ✅ Works after worktree deletion (for committed changes)\n- ✅ No lifecycle complexity (just capture commits)\n\n## Architecture\n\n### Database Schema\n\n**No schema changes required** - use existing fields:\n```sql\nexecutions table:\n  - before_commit TEXT    -- Existing field\n  - after_commit TEXT     -- Existing field\n```\n\n### New Components\n\n1. **ExecutionChangesService** (`/server/src/services/execution-changes-service.ts`)\n   - Calculate diff statistics from commit SHAs\n   - Handle 3 diff scenarios (committed/uncommitted/none)\n   - Parse git numstat output\n   - Validate execution status and commit availability\n\n2. **API Endpoint** (`GET /api/executions/:executionId/changes`)\n   - Expose changes calculation to frontend\n   - Return structured diff data or unavailable reason\n\n3. **CodeChangesPanel** (`/frontend/src/components/executions/CodeChangesPanel.tsx`)\n   - UI component to display file changes\n   - Show file list with +/- statistics\n   - Badge for uncommitted changes\n   - Error states for unavailable changes\n\n4. **useExecutionChanges** (`/frontend/src/hooks/useExecutionChanges.ts`)\n   - React hook to fetch execution changes\n   - Handle loading/error states\n\n### Commit Capture Strategy\n\n#### before_commit Capture\n\n**Worktree mode**: Already captured during worktree creation (no changes needed)\n\n**Local mode**: Capture at execution creation\n```typescript\n// In ExecutionService.createExecution()\nif (mode === 'local') {\n  const beforeCommit = execSync('git rev-parse HEAD', { cwd: repoPath }).trim();\n  await updateExecution(db, executionId, { before_commit: beforeCommit });\n}\n```\n\n#### after_commit Capture\n\n**All modes**: Capture at execution completion/stop\n```typescript\n// In AgentExecutorWrapper.handleSuccess() and cancel()\nconst repoPath = execution.worktree_path || this.repoPath;\nconst afterCommit = execSync('git rev-parse HEAD', { cwd: repoPath }).trim();\nawait updateExecution(db, executionId, { after_commit: afterCommit });\n```\n\n### 3-Scenario Diff Strategy\n\nThe system automatically detects which scenario applies:\n\n#### Scenario A: Committed Changes\n**Condition**: `after_commit` exists and differs from `before_commit`\n\n**Git Command**:\n```bash\ngit diff --numstat --name-status --find-renames <before>..<after>\n```\n\n**Characteristics**:\n- Standard commit-to-commit diff\n- Works even after worktree deletion (git objects persist)\n- Most reliable scenario\n\n#### Scenario B: Uncommitted Changes\n**Condition**: `after_commit` is null OR equals `before_commit`\n\n**Git Command**:\n```bash\n# In worktree mode: use worktree_path if it exists\n# In local mode: use main repo path\ngit diff --numstat --name-status --find-renames HEAD\n```\n\n**Characteristics**:\n- Captures working tree changes relative to HEAD\n- Critical for executions without auto-commit enabled\n- Only works if worktree/working tree still exists\n- Set `uncommitted: true` in response\n\n#### Scenario C: No Changes\n**Condition**: No commits AND no working tree changes\n\n**Response**: Empty files array with zero summary stats\n\n### API Interface\n\n#### Request\n```\nGET /api/executions/:executionId/changes\n```\n\n#### Success Response (Committed Changes)\n```json\n{\n  \"success\": true,\n  \"data\": {\n    \"available\": true,\n    \"uncommitted\": false,\n    \"commitRange\": {\n      \"before\": \"abc123...\",\n      \"after\": \"def456...\"\n    },\n    \"changes\": {\n      \"files\": [\n        {\n          \"path\": \"frontend/src/App.tsx\",\n          \"additions\": 5,\n          \"deletions\": 2,\n          \"status\": \"M\"\n        },\n        {\n          \"path\": \"server/src/new-file.ts\",\n          \"additions\": 20,\n          \"deletions\": 0,\n          \"status\": \"A\"\n        }\n      ],\n      \"summary\": {\n        \"totalFiles\": 2,\n        \"totalAdditions\": 25,\n        \"totalDeletions\": 2\n      }\n    }\n  }\n}\n```\n\n#### Success Response (Uncommitted Changes)\n```json\n{\n  \"success\": true,\n  \"data\": {\n    \"available\": true,\n    \"uncommitted\": true,\n    \"commitRange\": null,\n    \"changes\": {\n      \"files\": [...],\n      \"summary\": {...}\n    }\n  }\n}\n```\n\n#### Error Response (Unavailable)\n```json\n{\n  \"success\": true,\n  \"data\": {\n    \"available\": false,\n    \"reason\": \"worktree_deleted_with_uncommitted_changes\"\n  }\n}\n```\n\n**Unavailability Reasons**:\n- `missing_commits`: before_commit not captured\n- `commits_not_found`: Commits garbage collected\n- `incomplete_execution`: Execution status not completed/stopped\n- `git_error`: Git command failed\n- `worktree_deleted_with_uncommitted_changes`: Uncommitted changes lost\n\n## Edge Cases\n\n| Scenario | Handling |\n|----------|----------|\n| Uncommitted changes (no auto-commit) | Use `git diff HEAD` to capture working tree changes, set `uncommitted: true` |\n| Uncommitted + worktree deleted | Return `available: false, reason: 'worktree_deleted_with_uncommitted_changes'` |\n| Committed changes + worktree deleted | Git objects persist in main repo - diff still works |\n| Commits garbage collected | Return `available: false, reason: 'commits_not_found'` |\n| Execution failed early | Return `available: false, reason: 'incomplete_execution'` |\n| Local mode (no isolation) | Capture before_commit at creation, check uncommitted or committed changes |\n| after_commit == before_commit | Treat as uncommitted changes, use `git diff HEAD` |\n| Binary files | Git numstat shows `-` for binary, parse as 0 changes |\n| Empty diff | Return empty files array with 0 summary stats |\n| Large diffs (1000+ files) | Return all files (UI can paginate if needed) |\n| Missing before commit | Return `available: false, reason: 'missing_commits'` |\n\n## UI Design\n\n### Display Location\nIntegrate `CodeChangesPanel` into `ExecutionView` for completed/stopped executions.\n\n### Component Features\n- File list with status badges (A/M/D/R)\n- Per-file statistics (+5 -2 format)\n- Summary header (X files changed, +Y -Z)\n- \"Uncommitted Changes\" badge when applicable\n- Warning message for uncommitted changes\n- Error state for unavailable changes with reason\n\n### Optional Caching\nSimple in-memory cache with 5-minute TTL for performance optimization (can be added later if needed).\n\n## Performance Characteristics\n\n### Computation Time\n- Git diff command: 50-200ms for typical changes (10-100 files)\n- Large diffs (1000+ files): 500ms-2s\n- On-demand calculation: Acceptable for UI\n- With cache: <1ms for repeated requests\n\n### Storage Impact\n- Per execution: 80 bytes (2 commit SHAs)\n- No permanent diff storage: Zero overhead\n- Cache memory: ~5KB per execution × active requests only\n\n### Network Impact\n- API response: 2-10KB for typical changes (50 files)\n- Large diffs: 50KB (500 files)\n- Gzip compression: ~5x reduction\n\n## Implementation Files\n\n### Backend (New)\n- `/server/src/services/execution-changes-service.ts` - Core diff calculation service\n- `/server/tests/unit/services/execution-changes-service.test.ts` - Unit tests\n- `/server/tests/integration/execution-changes.test.ts` - Integration tests\n\n### Backend (Modified)\n- `/server/src/services/execution-service.ts` - Add before_commit capture for local mode\n- `/server/src/execution/executors/agent-executor-wrapper.ts` - Add after_commit capture\n- `/server/src/routes/executions.ts` - Add changes API endpoint\n\n### Frontend (New)\n- `/frontend/src/hooks/useExecutionChanges.ts` - React hook\n- `/frontend/src/components/executions/CodeChangesPanel.tsx` - UI component\n- `/frontend/tests/components/executions/CodeChangesPanel.test.tsx` - Component tests\n\n### Frontend (Modified)\n- `/frontend/src/lib/api.ts` - Add getChanges() API client method\n- `/frontend/src/components/executions/ExecutionView.tsx` - Integrate CodeChangesPanel\n\n## Testing Strategy\n\n### Unit Tests\n- Parse numstat output correctly\n- Handle binary files (- -)\n- Detect file status (A/M/D/R)\n- Calculate summary statistics\n- Return unavailable when commits missing\n- Return unavailable when status not completed/stopped\n- Handle git command errors gracefully\n- Detect uncommitted changes (after_commit == before_commit)\n- Use git diff HEAD for uncommitted changes\n- Handle worktree deleted with uncommitted changes\n\n### Integration Tests\n- End-to-end: create execution → complete → get changes (committed)\n- End-to-end: create execution → complete → get changes (uncommitted)\n- Worktree mode with real git operations\n- Local mode with real git operations\n- Cancelled execution captures changes\n- Changes calculated after worktree cleanup (committed changes)\n- Uncommitted changes not available after worktree cleanup\n\n### Frontend Tests\n- Display file list correctly\n- Show summary statistics\n- Handle unavailable state with error message\n- Handle loading state\n- Handle fetch errors\n- Display uncommitted badge when appropriate\n\n## Migration & Rollout\n\n### Backward Compatibility\n- Old executions: May have null `before_commit` or `after_commit`\n- Handling: Return `available: false, reason: 'missing_commits'`\n- No database migration needed: Additive-only changes\n\n### Rollout Strategy\n1. Deploy backend changes (commit capture + API endpoint)\n2. Monitor that commits are being captured correctly\n3. Deploy frontend changes (UI components)\n4. Verify in production with real executions\n\n## Success Criteria\n\n1. ✅ Users can view code changes for completed executions\n2. ✅ Changes display within 200ms for typical executions\n3. ✅ Both committed and uncommitted changes are tracked\n4. ✅ Clear error messages when changes unavailable\n5. ✅ Works for both worktree and local mode executions\n6. ✅ No storage bloat (only commit SHAs stored)\n7. ✅ Changes recalculatable at any time\n\n## Estimated Effort\n\n**5-7 hours** total implementation time","priority":2,"archived":0,"archived_at":null,"created_at":"2025-11-30 10:59:23","updated_at":"2025-11-30 10:59:23","parent_id":null,"parent_uuid":null,"relationships":[],"tags":["executions","feature","git","ui"]}
{"id":"s-2s2l","uuid":"98c9a2dc-9607-40cf-9d46-46396d3f38d0","title":"IDE Opening for Execution Worktrees","file_path":"specs/s-2s2l_ide_opening_for_execution_worktrees.md","content":"# IDE Opening for Execution Worktrees\n\n## Overview\n\nEnable users to open execution worktrees directly in their configured IDE from the web UI, replacing the current clipboard-copy workflow with seamless IDE integration.\n\n## Background\n\n**Current State:**\n\n- When users want to inspect or modify execution worktrees, they must:\n  1. Click \"Open in IDE\" button\n  1. Path is copied to clipboard with alert dialog\n  1. Manually open their IDE and navigate to the path\n- This creates friction and interrupts the workflow\n\n**Desired State:**\n\n- Single click opens the worktree directly in the user's preferred IDE\n- Supports multiple popular editors (VS Code, Cursor, Windsurf, IntelliJ, Zed, Xcode, custom)\n- Per-user configuration (not project-wide)\n- Local IDE opening only (no remote SSH in initial version)\n\n## Requirements\n\n### Functional Requirements\n\n**FR1: IDE Opening**\n\n- Users can open execution worktrees in their configured IDE with a single click\n- System spawns the IDE process with the worktree path as an argument\n- Works for any execution that has a valid worktree\n\n**FR2: Multiple Editor Support**\n\n- Support popular editors:\n  - VS Code (`code` command)\n  - Cursor (`cursor` command)\n  - Windsurf (`windsurf` command)\n  - IntelliJ IDEA (`idea` command)\n  - Zed (`zed` command)\n  - Xcode (`xed` command)\n  - Custom command (user-specified)\n\n**FR3: Per-User Configuration**\n\n- Each user can configure their preferred editor\n- Configuration stored in `.sudocode/config.local.json` (gitignored)\n- Default: VS Code if available, otherwise first available editor\n- Falls back gracefully if configured editor not available\n\n**FR4: Editor Availability Detection**\n\n- System detects which editors are installed/available\n- Settings UI shows only available editors\n- Helpful error messages when configured editor is unavailable\n\n**FR5: User Feedback**\n\n- Toast notifications for success/failure\n- Clear error messages with actionable guidance\n- Replace current alert() dialogs with modern toast notifications\n\n### Non-Functional Requirements\n\n**NFR1: Security**\n\n- All command execution happens server-side\n- Frontend cannot inject arbitrary commands\n- Command validation and sanitization\n\n**NFR2: Cross-Platform Compatibility**\n\n- Works on macOS, Linux, and Windows\n- Platform-specific command resolution using Node.js `which` package\n\n**NFR3: Performance**\n\n- Editor availability checks cached (5-minute TTL)\n- Non-blocking editor spawning (detached processes)\n- No impact on execution performance\n\n**NFR4: Extensibility**\n\n- Architecture supports future enhancements:\n  - Remote SSH editor support\n  - File-specific opening (not just worktree root)\n  - Multi-file opening\n  - Editor-specific arguments\n\n## Design\n\n### Architecture\n\nBased on vibe-kanban's clean implementation pattern:\n\n```\nFrontend (ExecutionView)\n    ↓ HTTP POST /api/executions/:id/open-in-ide\nAPI Routes (executions.ts)\n    ↓\nEditorService\n├── getCommand() - Map editor type to command string\n├── checkAvailability() - Use 'which' to verify installation\n└── spawnEditor() - Launch detached process\n    ↓\nNode.js child_process.spawn() + which package\n```\n\n### Implementation Approach (from vibe-kanban)\n\n**Command Resolution Pattern:**\n\n```typescript\nclass EditorService {\n  // Simple string mapping (vibe-kanban's approach)\n  getCommand(editorType: EditorType): string {\n    const commands = {\n      'vs-code': 'code',\n      'cursor': 'cursor',\n      'windsurf': 'windsurf',\n      'intellij': 'idea',\n      'zed': 'zed',\n      'xcode': 'xed'\n    }\n    return commands[editorType] || 'code'\n  }\n\n  // Availability check using which\n  async checkAvailability(command: string): Promise<boolean> {\n    try {\n      await which(command)\n      return true\n    } catch {\n      return false\n    }\n  }\n\n  // Non-blocking spawn (vibe-kanban's approach)\n  async spawnEditor(path: string, command: string): Promise<void> {\n    spawn(command, [path], {\n      detached: true,\n      stdio: 'ignore'\n    })\n  }\n}\n```\n\n**Key Simplifications for Phase 1:**\n\n- Use `which` npm package instead of complex PATH refresh (simpler than vibe-kanban's Rust version)\n- Direct command mapping without CommandBuilder abstraction\n- Node.js handles cross-platform differences automatically\n\n**Future Enhancement (Phase 2+):**\n\n- Could add PATH refresh logic like vibe-kanban if needed (spawning login shell)\n- For now, simple `which` lookup is sufficient\n\n### Data Model\n\n**EditorType Enum:**\n\n```typescript\nenum EditorType {\n  VS_CODE = 'vs-code',\n  CURSOR = 'cursor',\n  WINDSURF = 'windsurf',\n  INTELLIJ = 'intellij',\n  ZED = 'zed',\n  XCODE = 'xcode',\n  CUSTOM = 'custom'\n}\n```\n\n**EditorConfig Interface:**\n\n```typescript\ninterface EditorConfig {\n  editorType: EditorType\n  customCommand?: string  // Required if editorType === 'custom'\n}\n```\n\n**Configuration File (**`.sudocode/config.local.json`**):**\n\n```json\n{\n  \"editor\": {\n    \"editorType\": \"vs-code\",\n    \"customCommand\": null\n  }\n}\n```\n\n### API Design\n\n**Endpoint 1: Open Worktree in IDE**\n\n```\nPOST /api/executions/:executionId/open-in-ide\n\nRequest:\n{\n  editorType?: string  // Optional override for this execution\n}\n\nResponse:\n{\n  success: boolean\n  message?: string\n  error?: {\n    code: 'EDITOR_NOT_FOUND' | 'WORKTREE_MISSING' | 'SPAWN_FAILED'\n    details: string\n  }\n}\n```\n\n**Endpoint 2: Get Editor Configuration (Phase 2)**\n\n```\nGET /api/config/editor\n\nResponse:\n{\n  editorType: string\n  customCommand?: string\n}\n```\n\n**Endpoint 3: Update Editor Configuration (Phase 2)**\n\n```\nPUT /api/config/editor\n\nRequest:\n{\n  editorType: string\n  customCommand?: string\n}\n\nResponse:\n{\n  success: boolean\n  config: EditorConfig\n}\n```\n\n**Endpoint 4: Check Editor Availability (Phase 2)**\n\n```\nGET /api/config/editor/available\n\nResponse:\n{\n  available: {\n    'vs-code': boolean,\n    'cursor': boolean,\n    'windsurf': boolean,\n    'intellij': boolean,\n    'zed': boolean,\n    'xcode': boolean\n  },\n  current: EditorConfig\n}\n```\n\n### Component Design\n\n**EditorService (Backend)**\n\n```typescript\nclass EditorService {\n  /**\n   * Load editor configuration from .sudocode/config.local.json\n   * Falls back to default (VS Code) if file doesn't exist\n   */\n  loadConfig(): EditorConfig\n  \n  /**\n   * Get command name for editor type\n   * Examples: 'vs-code' → 'code', 'cursor' → 'cursor'\n   * Based on vibe-kanban's simple string mapping\n   */\n  getCommand(editorType: EditorType): string\n  \n  /**\n   * Check if editor command is available using 'which' package\n   * Simpler than vibe-kanban's PATH refresh approach\n   */\n  async checkAvailability(command: string): Promise<boolean>\n  \n  /**\n   * Spawn editor process with worktree path\n   * Detached mode for non-blocking execution (vibe-kanban pattern)\n   * Returns immediately after spawn\n   */\n  async spawnEditor(path: string, config: EditorConfig): Promise<void>\n  \n  /**\n   * Check availability of all supported editors (Phase 2)\n   */\n  async checkAllAvailability(): Promise<Record<EditorType, boolean>>\n}\n```\n\n**useExecutionSync Hook (Frontend)**\n\n```typescript\n// Update existing openWorktreeInIDE function\nconst openWorktreeInIDE = useCallback(async (execution: Execution) => {\n  if (!execution.worktree_path) {\n    toast.error('No worktree path available')\n    return\n  }\n\n  try {\n    await executionsApi.openInIde(execution.id)\n    toast.success('Opening worktree in IDE...')\n  } catch (error) {\n    const message = error instanceof Error ? error.message : 'Failed to open IDE'\n    toast.error(message)\n  }\n}, [])\n```\n\n### Error Handling\n\n**Error Types (based on vibe-kanban's pattern):**\n\n```typescript\nclass EditorOpenError extends Error {\n  code: 'EDITOR_NOT_FOUND' | 'WORKTREE_MISSING' | 'SPAWN_FAILED'\n  editorType: EditorType\n  details?: string\n}\n```\n\n**Error Messages:**\n\n1. **EDITOR\\_NOT\\_FOUND**: Configured editor command not in PATH\n\n- Message: \"Editor not found. Please install \\[editor name\\] or configure a different editor in Settings.\"\n\n1. **WORKTREE\\_MISSING**: Execution has no worktree path\n\n- Message: \"No worktree available for this execution.\"\n\n1. **SPAWN\\_FAILED**: Process launch failed\n\n- Message: \"Failed to launch editor. Check that \\[editor name\\] is properly installed.\"\n\n**Fallback Strategy:**\n\n- Log detailed error server-side\n- Return user-friendly error message to frontend\n- Toast notification with error and guidance\n- No fallback to clipboard copy (clean separation of concerns)\n\n### User Experience Flow\n\n**Basic Flow (Phase 1):**\n\n1. User completes execution (has worktree)\n1. User clicks \"Open in IDE\" button in ExecutionView\n1. Frontend calls `POST /api/executions/:id/open-in-ide`\n1. Backend loads editor config (default: VS Code)\n1. Backend spawns editor process: `code /path/to/worktree` (detached)\n1. Toast shows \"Opening worktree in IDE...\"\n1. IDE launches with worktree open\n\n**Configuration Flow (Phase 2):**\n\n1. User navigates to Settings page\n1. System checks which editors are available\n1. User sees dropdown with available editors (checkmarks)\n1. User selects preferred editor\n1. User clicks \"Save\"\n1. Configuration saved to `.sudocode/config.local.json`\n1. Toast shows \"Editor configuration saved\"\n\n**Error Flow:**\n\n1. User clicks \"Open in IDE\"\n1. Backend attempts to spawn editor\n1. Editor not found (not in PATH)\n1. Error response returned\n1. Toast shows: \"VS Code not found. Please install VS Code or configure a different editor in Settings.\"\n\n## Implementation Phases\n\n### Phase 1: Basic IDE Opening (MVP)\n\n**Goal:** Replace clipboard copy with actual IDE opening\n\n**Scope:**\n\n- Backend EditorService with all editor type support\n- API endpoint for opening worktrees\n- Frontend hook integration\n- Toast notifications\n- Default to VS Code, fall back gracefully\n\n**Implementation Details:**\n\n- Use vibe-kanban's simple command mapping approach\n- Use Node.js `which` package for availability checking\n- Use `child_process.spawn()` with detached mode (vibe-kanban pattern)\n- Install `which` npm package: `npm install which @types/which`\n\n**Timeline:** 2-3 days\n\n**Success Criteria:**\n\n- ✓ Clicking \"Open in IDE\" launches VS Code with worktree\n- ✓ Error handling for editor not installed\n- ✓ Toast notifications replace alert dialogs\n- ✓ No regression in worktree functionality\n\n### Phase 2: Configuration UI\n\n**Goal:** Allow users to configure preferred editor\n\n**Scope:**\n\n- Settings page with editor selector\n- Editor availability detection\n- Configuration API endpoints\n- Editor icons in UI\n- Per-user configuration persistence\n\n**Timeline:** 3-5 days\n\n**Success Criteria:**\n\n- ✓ Settings page shows available editors\n- ✓ User can select and save preferred editor\n- ✓ Configuration persists across sessions\n- ✓ Each editor type works when installed\n- ✓ Custom command support\n\n### Phase 3: File-Specific Opening (Future)\n\n**Goal:** Open specific files that changed during execution\n\n**Scope:** Deferred - focusing on worktree root first\n\n**Future Requirements:**\n\n- Track changed files during execution\n- API to retrieve changed files list\n- UI to select files to open\n- Pass file paths to editor command\n\n## Technical Considerations\n\n### Command Resolution Strategy\n\n**Editor → Command Mapping (vibe-kanban approach):**\n\n```typescript\nconst EDITOR_COMMANDS: Record<EditorType, string> = {\n  'vs-code': 'code',\n  'cursor': 'cursor',\n  'windsurf': 'windsurf',\n  'intellij': 'idea',\n  'zed': 'zed',\n  'xcode': 'xed'\n}\n```\n\n**Availability Detection:**\n\n```typescript\nimport which from 'which'\n\nasync function checkAvailability(command: string): Promise<boolean> {\n  try {\n    await which(command)\n    return true\n  } catch {\n    return false\n  }\n}\n```\n\n### Process Spawning Strategy\n\n**Detached Mode (vibe-kanban pattern):**\n\n```typescript\nimport { spawn } from 'child_process'\n\nfunction spawnEditor(command: string, worktreePath: string): void {\n  spawn(command, [worktreePath], {\n    detached: true,      // Don't wait for process to exit\n    stdio: 'ignore',     // Ignore stdout/stderr\n    cwd: worktreePath    // Set working directory\n  })\n}\n```\n\n**Benefits:**\n\n- Server doesn't block waiting for editor to close\n- Editor runs as independent process\n- API responds immediately\n\n### Configuration Management\n\n**File Location:** `.sudocode/config.local.json`\n\n**Why Local Config:**\n\n- Per-user preferences (different developers prefer different editors)\n- Gitignored (doesn't pollute repository)\n- Follows existing sudocode configuration patterns\n- Can provide `.sudocode/config.local.json.example` for teams\n\n**Default Behavior:**\n\n- If file doesn't exist, default to VS Code\n- If VS Code not available, check other editors in priority order\n- If no editors available, return helpful error\n\n### Security Considerations\n\n**Command Injection Prevention:**\n\n- All commands hardcoded in EditorService (vibe-kanban approach)\n- Only allow predefined editor types\n- Custom commands validated (no shell metacharacters)\n- Paths sanitized and validated\n\n**Server-Side Execution:**\n\n- Frontend cannot execute arbitrary commands\n- All spawning happens server-side with validation\n- Request validation and sanitization\n\n### Dependencies\n\n**New NPM Packages:**\n\n- `which` - Cross-platform command resolution\n- `@types/which` - TypeScript types\n\n**Installation:**\n\n```bash\nnpm install which @types/which\n```\n\n## Success Metrics\n\n**Phase 1:**\n\n- Users stop manually opening IDEs for worktree inspection\n- Reduction in time to start editing worktree code\n- Positive user feedback on workflow improvement\n\n**Phase 2:**\n\n- Multiple editor types being used\n- Users successfully configure custom editors\n- Zero support requests about editor configuration\n\n## Reference Implementation\n\nBased on vibe-kanban's implementation:\n\n- `/references/vibe-kanban/crates/services/src/services/config/editor/mod.rs` - Core patterns\n  - Lines 83-97: Simple command mapping\n  - Lines 127-129: Availability checking\n  - Lines 160-171: Non-blocking spawn pattern\n- `/references/vibe-kanban/crates/utils/src/shell.rs` - Command resolution\n  - Lines 32-53: Multi-stage executable resolution (simplified for Node.js)\n  - Lines 95-101: Using `which` crate\n\n**Key Adaptations:**\n\n- Rust → TypeScript translation\n- Use Node.js `which` package instead of Rust `which` crate\n- Simplify PATH refresh (not needed initially with `which` package)\n- Adapt to sudocode's configuration patterns\n- Integrate with existing execution infrastructure\n\n## Open Questions\n\nNone - requirements clarified with user:\n\n- ✓ Editor support: Multiple editors (not just VS Code)\n- ✓ Remote support: Local only (no SSH)\n- ✓ Target: Worktree root first, file-specific later\n- ✓ Configuration: `.sudocode/config.local.json` (gitignored)\n- ✓ Implementation approach: Use vibe-kanban's patterns\n\n## Dependencies\n\n**Technical:**\n\n- Node.js `child_process` module (built-in)\n- Node.js `path` module (built-in)\n- `which` npm package (new dependency)\n- Existing execution/worktree infrastructure\n\n**External:**\n\n- Users must have editor installed and in PATH\n- Editors must support command-line launching with directory argument\n\n## Future Enhancements\n\nNot in current scope, but architecture supports:\n\n1. **Remote SSH Support**\n\n- Generate `vscode://vscode-remote/ssh-remote+user@host/path` URLs\n- Support remote development workflows\n\n1. **File-Specific Opening**\n\n- Open specific files that changed during execution\n- Pass line/column numbers for precise navigation\n\n1. **Multi-File Opening**\n\n- Open multiple changed files simultaneously\n- Editor-specific multi-file arguments\n\n1. **Editor Arguments**\n\n- Custom flags per editor (e.g., `--new-window`, `--goto`)\n- User-configurable argument templates\n\n1. **PATH Refresh Enhancement**\n\n- Add vibe-kanban's login shell PATH refresh if simple `which` proves insufficient\n- Would help in GUI environments with limited PATH\n\n1. **Keyboard Shortcuts**\n\n- Hotkeys to open IDE from execution view\n- Quick actions menu integration\n\n1. **Integration with Follow-Ups**\n\n- \"Open in IDE and create follow-up\" workflow\n- Automatic follow-up after manual edits","priority":1,"archived":0,"archived_at":null,"created_at":"2025-11-30 11:04:27","updated_at":"2025-12-05 08:32:22","parent_id":null,"parent_uuid":null,"relationships":[],"tags":["developer-experience","feature","ide-integration","worktree"]}
{"id":"s-3g2y","uuid":"79b5905c-0146-406e-981f-61fa32e61f1e","title":"Workflow System","file_path":"specs/s-3g2y_workflow_system.md","content":"# Workflow System Specification\n\n## Overview\n\nAdd an automation layer to sudocode that enables running multiple issues as a coordinated workflow. The system provides a **flexible interface** that supports different execution strategies, from simple sequential execution to agent-managed orchestration.\n\n## Design Decisions\n\n- **Scope**: Design interface with both implementations in mind; create stubs to visualize how they work\n- **Parallelism**: Support optional parallel execution of independent steps\n- **MCP**: Create separate `sudocode-workflow` MCP server for orchestration tools\n- **Workflow Source**: Support spec, explicit issues, root issue, AND general goal (for agent-led orchestration)\n\n---\n\n## Architecture\n\n### Core Abstraction: Workflow Interface\n\n```\nIWorkflowEngine (interface)\n    ├── createWorkflow(source, config)     // From spec, issues, root issue, or goal\n    ├── startWorkflow(workflowId)          // Begin execution\n    ├── pauseWorkflow(workflowId)          // Stop after current step\n    ├── resumeWorkflow(workflowId)         // Continue from pause\n    ├── cancelWorkflow(workflowId)         // Abort\n    ├── retryStep(workflowId, stepId)      // Retry failed step\n    ├── skipStep(workflowId, stepId)       // Skip and unblock dependents\n    ├── on(eventType, handler)             // Subscribe to events\n    └── analyzeDependencies(issueIds)      // Get dependency graph\n```\n\n### Implementation Strategies\n\n**1\\. Naive Sequential Implementation**\n\n- Executes issues in topological order\n- Single shared worktree for entire workflow\n- Auto-commits after each successful step\n- Simple failure handling: pause, retry, skip, or abort\n- Supports parallel execution of independent steps\n\n**2\\. Agent-Managed Implementation**\n\n- Orchestrator agent manages workflow via MCP tools\n- Event-driven wakeups on step completion/failure\n- Dynamic decisions: agent selection, retry strategy, escalation\n- Supports goal-based workflows (empty initial steps, orchestrator creates issues)\n\n---\n\n## Data Model\n\n### Core Types\n\n```typescript\ntype WorkflowStatus =\n  | \"pending\" | \"planning\" | \"running\" | \"paused\"\n  | \"completed\" | \"failed\" | \"cancelled\";\n\ntype WorkflowStepStatus =\n  | \"pending\" | \"ready\" | \"running\"\n  | \"completed\" | \"failed\" | \"skipped\" | \"blocked\";\n\n// How the workflow scope is defined\ntype WorkflowSource =\n  | { type: \"spec\"; specId: string }           // Issues implementing a spec\n  | { type: \"issues\"; issueIds: string[] }     // Explicit issue list\n  | { type: \"root_issue\"; issueId: string }    // Issue + all its blockers\n  | { type: \"goal\"; goal: string };            // General goal (agent-led)\n\ninterface WorkflowStep {\n  id: string;\n  issueId: string;\n  index: number;\n  dependencies: string[];      // Step IDs this depends on\n  status: WorkflowStepStatus;\n  executionId?: string;        // Linked execution\n  commitSha?: string;          // Commit after step\n  error?: string;\n  agentType?: AgentType;       // Override per-step\n  model?: string;\n}\n\ninterface Workflow {\n  id: string;\n  title: string;\n  source: WorkflowSource;\n  status: WorkflowStatus;\n  steps: WorkflowStep[];       // Empty initially for \"goal\" source\n\n  // Worktree (shared across steps)\n  worktreePath?: string;\n  branchName?: string;\n  baseBranch: string;\n\n  // Progress\n  currentStepIndex: number;\n\n  // Orchestrator (for agent-managed)\n  orchestratorExecutionId?: string;\n  orchestratorSessionId?: string;\n\n  // Escalation (for HITL)\n  escalationStatus?: EscalationStatus;\n  escalationData?: EscalationData;\n  escalationRequestedAt?: string;\n  escalationResolvedAt?: string;\n\n  // Config\n  config: WorkflowConfig;\n}\n\ninterface WorkflowConfig {\n  // === For Sequential Engine ===\n  parallelism: \"sequential\" | \"parallel\";\n  maxConcurrency?: number;\n  onFailure: \"stop\" | \"pause\" | \"skip_dependents\" | \"continue\";\n  autoCommitAfterStep: boolean;\n  defaultAgentType: AgentType;\n\n  // === For Orchestrator Engine ===\n  orchestratorAgentType?: AgentType;\n  orchestratorModel?: string;\n  autonomyLevel: \"full_auto\" | \"human_in_the_loop\";\n\n  // === Timeouts ===\n  executionTimeoutMs?: number;    // Cancel stuck executions\n  idleTimeoutMs?: number;         // Wake orchestrator if nothing happens\n  wakeupBatchWindowMs?: number;   // Batch events within this window\n}\n\n// Escalation types (for HITL)\ntype EscalationStatus = 'pending' | 'resolved' | 'bypassed';\n\ninterface EscalationData {\n  requestId: string;\n  message: string;\n  options?: string[];\n  context?: Record<string, unknown>;\n  response?: {\n    action: 'approve' | 'reject' | 'custom';\n    message?: string;\n    respondedAt: string;\n  };\n}\n```\n\n### Database Schema\n\n```sql\nCREATE TABLE workflows (\n  id TEXT PRIMARY KEY,\n  title TEXT NOT NULL,\n  source TEXT NOT NULL,          -- JSON\n  status TEXT NOT NULL DEFAULT 'pending',\n  steps TEXT NOT NULL,           -- JSON array\n  worktree_path TEXT,\n  branch_name TEXT,\n  base_branch TEXT NOT NULL,\n  current_step_index INTEGER DEFAULT 0,\n  orchestrator_execution_id TEXT,\n  orchestrator_session_id TEXT,\n  escalation_status TEXT CHECK(escalation_status IN (NULL, 'pending', 'resolved', 'bypassed')),\n  escalation_data TEXT,\n  escalation_requested_at DATETIME,\n  escalation_resolved_at DATETIME,\n  config TEXT NOT NULL,          -- JSON\n  created_at DATETIME,\n  updated_at DATETIME,\n  started_at DATETIME,\n  completed_at DATETIME\n);\n\nCREATE TABLE workflow_events (\n  id TEXT PRIMARY KEY,\n  workflow_id TEXT NOT NULL,\n  type TEXT NOT NULL,            -- step_completed, step_failed, etc.\n  step_id TEXT,\n  execution_id TEXT,\n  payload TEXT NOT NULL,         -- JSON\n  created_at DATETIME,\n  processed_at DATETIME,\n  FOREIGN KEY (workflow_id) REFERENCES workflows(id)\n);\n```\n\n---\n\n## Dependency Graph Analysis\n\nUsing Kahn's algorithm for topological sort with cycle detection:\n\n1. Build adjacency list from `blocks`/`depends-on` relationships\n1. Compute in-degree for each node\n1. Process nodes with in-degree 0, reducing neighbors' in-degrees\n1. If not all nodes processed → cycle exists\n1. Group nodes by topological level for parallel groups\n\n---\n\n## Naive Implementation\n\n### Worktree Strategy\n\n- **Single shared worktree** for entire workflow\n- First step creates worktree; subsequent steps reuse via `reuseWorktreeId`\n- Each step commits changes before next step starts\n- On failure: preserve worktree for inspection\n\n### Git Commit Strategy\n\n- Auto-commit after each successful step (configurable)\n- Message template: `[Workflow Step {n}] {issueId}: {issueTitle}`\n- On failure: uncommitted changes preserved in working directory\n\n### Parallel Execution\n\n- Group steps by dependency level (parallel groups)\n- Run all steps in group concurrently (respecting maxConcurrency)\n- Wait for group to complete before starting next group\n\n---\n\n## Agent-Managed Implementation\n\nThe agent-managed workflow is designed for **maximum flexibility**. The orchestrator agent is in full control of all decisions - parallelism, worktree strategy, agent selection, error handling, and workflow adaptation. The system provides tools and tracks state; the agent decides everything else.\n\n### Core Concept: Orchestrator as Execution\n\nThe orchestrator is itself an execution with its own session. When a workflow starts:\n\n1. An execution is created for the orchestrator agent\n1. The orchestrator receives initial context (workflow source, config)\n1. The orchestrator uses MCP tools to execute issues, monitor progress, adapt the plan\n1. The orchestrator session is maintained across all wakeups (conversation history preserved)\n\nThe `Workflow` entity is a lightweight wrapper that tracks:\n\n- Which orchestrator execution is managing it\n- High-level status for UI display\n- Configuration (autonomy level, timeouts)\n- List of executions spawned by this workflow\n\n### MCP Tools for Orchestrator\n\nThe orchestrator has access to two tool sets:\n\n**Workflow Orchestration Tools** (new MCP server: `sudocode-workflow`):\n\n| Tool | Description |\n| --- | --- |\n| `workflow_status` | Get current workflow state, active executions, recent events |\n| `execute_issue` | Start execution for an issue with full config (agent, model, worktree strategy) |\n| `execution_status` | Check status of a running/completed execution |\n| `execution_cancel` | Cancel a running execution |\n| `execution_trajectory` | Get summarized trajectory of an execution (tool calls, key decisions) |\n| `execution_changes` | Get file changes from an execution (diff summary or full) |\n| `escalate_to_user` | Request user input (async - returns pending, response via wakeup) |\n| `notify_user` | Send notification to user without blocking |\n| `workflow_complete` | Mark workflow as complete with summary |\n\n**Existing Sudocode Tools** (available via `sudocode` MCP server):\n\n| Tool | Description |\n| --- | --- |\n| `ready` | See what issues are ready to work on |\n| `show_spec`, `show_issue` | View spec/issue details |\n| `list_specs`, `list_issues` | Browse specs and issues |\n| `upsert_issue`, `upsert_spec` | Create or modify issues/specs |\n| `link` | Create relationships between entities |\n| `add_feedback` | Add feedback comments to specs/issues |\n\n### execute\\_issue Tool\n\nThe core tool for spawning agent executions:\n\n```typescript\ninterface ExecuteIssueParams {\n  issue_id: string;\n\n  // Agent configuration (vanilla coding agents for now)\n  agent_type?: AgentType;        // Default: claude-code\n  model?: string;                // Default: claude-sonnet-4\n\n  // Worktree strategy (orchestrator decides)\n  worktree_mode: \"create_root\" | \"use_root\" | \"create_branch\" | \"use_branch\";\n  base_branch?: string;          // For create_branch: which branch to base off\n  branch_name?: string;          // For use_branch: specific branch to use\n\n  // Execution config\n  timeout_ms?: number;\n  prompt_additions?: string;     // Additional context for the agent\n}\n```\n\n**Worktree Modes**:\n\n- `create_root`: Create a new root worktree for the workflow (first execution)\n- `use_root`: Use the existing root worktree (sequential execution)\n- `create_branch`: Create a new branch off base\\_branch (parallel execution)\n- `use_branch`: Use an existing branch (continue work on a branch)\n\nThe orchestrator decides the strategy based on parallelism needs:\n\n- Single-threaded: `use_root` for all executions\n- Parallel: `create_branch` for each parallel execution, then merge\n\n### Wakeup Mechanism\n\nThe orchestrator session is maintained across the workflow. On events, the orchestrator receives an automated follow-up message:\n\n```\n[Workflow Event]\n\nExecutions changed since last update:\n- i-abc1 (Add auth endpoint): COMPLETED\n  - Duration: 3m 42s\n  - Files changed: 4\n  - Summary: \"Implemented OAuth token endpoint with JWT validation...\"\n\n- i-xyz2 (Add tests): FAILED\n  - Duration: 1m 15s\n  - Exit code: 1\n  - Error: \"Test suite failed with 3 errors...\"\n\nUse execution_trajectory or execution_changes tools to inspect details.\nWhat would you like to do next?\n```\n\n**Wakeup Triggers**:\n\n1. Execution completed/failed\n1. Configurable timeout (execution taking too long)\n1. User responded to escalation\n1. Scheduled check-in (optional)\n\n**Batching**: Multiple events that occur close together are batched into a single wakeup message (configurable window, default 5s).\n\n### Autonomy Levels\n\n```typescript\ntype AutonomyLevel = \"full_auto\" | \"human_in_the_loop\";\n\ninterface WorkflowConfig {\n  // ...existing...\n  autonomyLevel: AutonomyLevel;\n\n  // Timeout config\n  executionTimeoutMs?: number;    // Cancel stuck executions\n  idleTimeoutMs?: number;         // Wake if nothing happens\n}\n```\n\n**Full Auto Mode**:\n\n- `escalate_to_user` returns `{ status: 'auto_approved' }` immediately\n- Orchestrator runs to completion without user intervention\n- User can still pause/cancel via UI\n\n**Human-in-the-Loop Mode**:\n\n- `escalate_to_user` returns `{ status: 'pending', escalation_id }` immediately\n- Orchestrator session ends naturally (no blocking)\n- Workflow status shows \"awaiting\\_input\"\n- User responds via UI → response delivered in wakeup follow-up\n- Orchestrator continues with full context\n\n### Verification Pattern (No Special Tools)\n\nVerification is just a pattern the orchestrator can follow, not a special system feature:\n\n1. After an issue completes, orchestrator creates a sub-issue: \"Verify: Review auth endpoint changes\"\n1. Orchestrator executes the verification issue (can use different agent/prompt)\n1. Verification agent examines changes, runs tests, adds feedback to original issue\n1. Orchestrator peeks at trajectory/feedback to determine if changes are acceptable\n1. If issues found, orchestrator can create fix issues or retry\n\nThis keeps the system simple - verification is just more issues executed in sequence.\n\n### Dynamic Workflow Adaptation\n\nThe orchestrator can adapt the workflow dynamically:\n\n- **Add issues**: Use `upsert_issue` to create new issues as needed\n- **Add relationships**: Use `link` to establish dependencies\n- **Skip/modify**: Simply don't execute certain issues, or modify them first\n- **Handle cycles**: Orchestrator identifies logical cycles and adapts (no rigid enforcement)\n- **Respond to failures**: Create fix issues, retry with different config, or escalate\n\nThe workflow doesn't have a rigid step list for agent-managed mode. Instead:\n\n- Orchestrator uses `ready` and `list_issues` to see what's available\n- Uses relationships to understand dependencies\n- Decides execution order based on its judgment\n- Tracks what's been done via execution history\n\n### Merge Strategy for Parallel Execution\n\nWhen parallel executions complete on separate branches:\n\n1. Orchestrator sees multiple executions completed\n1. Uses `execution_changes` to understand what each changed\n1. Decides merge order (or creates a merge issue)\n1. Can spawn a sub-agent to handle merge conflicts if needed\n1. Or handles merge directly using git tools\n\nThe system doesn't auto-merge - the orchestrator decides how to integrate parallel work.\n\n### Escalation UI Flow\n\nWhen `escalate_to_user` is called:\n\n1. Tool returns `{ status: 'pending', escalation_id }` immediately\n1. Orchestrator session ends naturally\n1. Workflow status updates to \"awaiting\\_input\"\n1. UI shows escalation with context and options\n1. User can: approve, reject, provide input, or dismiss\n1. User response recorded → wakeup triggered\n1. Orchestrator receives response in follow-up message\n1. Workflow continues based on orchestrator's next action\n\n---\n\n## Implementation Phases\n\n### Phase 1: Core Types and Schema ✅\n\n- Add workflow types to `types/src/workflows.d.ts`\n- Add workflows and workflow\\_events tables to schema\n\n### Phase 2: Dependency Analysis ✅\n\n- Implement `buildDependencyGraph()` using relationship operations\n- Implement `topologicalSort()` with cycle detection\n- Implement `findParallelGroups()` for parallel execution\n\n### Phase 3: Workflow Interface ✅\n\n- Create `IWorkflowEngine` interface\n- Create `WorkflowEventEmitter` for lifecycle events\n- Create base class with shared logic\n\n### Phase 4: Sequential Engine ✅\n\n- Implement source resolution (spec, issues, root\\_issue)\n- Implement sequential and parallel execution modes\n- Implement step execution with worktree reuse\n- Implement auto-commit and failure handling\n\n### Phase 5: Orchestrator Engine\n\nFull implementation of agent-managed workflow orchestration.\n\n#### Phase 5a: Core Orchestrator Engine\n\n**New Files:**\n\n- `server/src/workflow/engines/orchestrator-engine.ts`\n- `server/src/workflow/services/wakeup-service.ts`\n- `server/src/workflow/services/prompt-builder.ts`\n\n**OrchestratorWorkflowEngine** (extends BaseWorkflowEngine):\n\n- `createWorkflow(source, config)` - supports goal-based workflows\n- `startWorkflow(workflowId)` - spawns orchestrator execution\n- `pauseWorkflow(workflowId)` - sets pause flag\n- `resumeWorkflow(workflowId)` - triggers wakeup\n- `cancelWorkflow(workflowId)` - cancels orchestrator and all executions\n\n**WorkflowWakeupService**:\n\n- `recordEvent(workflowId, type, executionId?, payload?)` - record workflow events\n- `scheduleWakeup(workflowId)` - debounced wakeup scheduling\n- `triggerWakeup(workflowId, message)` - send follow-up to orchestrator\n\n**Key Patterns:**\n\n- Orchestrator execution stored in `workflow.orchestrator_execution_id`\n- Session ID stored in `workflow.orchestrator_session_id`\n- Wakeups use `ExecutionService.createFollowUp()` with event summary\n- Events batched within configurable window (default 5s)\n\n#### Phase 5b: Workflow MCP Server\n\n**New Files:**\n\n```\nserver/src/workflow/mcp/\n├── index.ts              # Entry point (stdio transport)\n├── server.ts             # WorkflowMCPServer class\n├── types.ts              # Tool parameter types\n└── tools/\n    ├── workflow.ts       # workflow_status, workflow_complete\n    ├── execution.ts      # execute_issue, execution_status, execution_cancel\n    └── inspection.ts     # execution_trajectory, execution_changes\n```\n\n**Entry Point:**\n\n```bash\nnode server/dist/workflow/mcp/index.js \\\n  --workflow-id wf-abc123 \\\n  --db-path .sudocode/cache.db \\\n  --repo-path /path/to/repo\n```\n\nThe MCP server calls services **directly** (not via CLI) for efficiency.\n\n#### Phase 5c: Escalation System\n\n**Schema Updates** (add to workflows table):\n\n- `escalation_status` - pending/resolved/bypassed\n- `escalation_data` - JSON with request details\n- `escalation_requested_at`, `escalation_resolved_at` - timestamps\n\n**New Files:**\n\n- `server/src/workflow/mcp/tools/escalation.ts`\n\n**Escalation Tools:**\n\n- `escalate_to_user` - Returns `{ status: 'pending' }` immediately; response via wakeup\n- `notify_user` - Non-blocking notification\n\n**API Endpoint:**\n\n```\nPOST /api/workflows/:id/escalation/respond\nBody: { action: 'approve'|'reject'|'custom', message?: string }\n```\n\n**Async Wakeup Flow:**\n\n1. Orchestrator calls `escalate_to_user` → returns `{ status: 'pending' }`\n1. Orchestrator session ends naturally (no blocking)\n1. Workflow status → `awaiting_input`, broadcast to UI\n1. User responds via API → records event\n1. Wakeup triggered with response in follow-up message\n\n#### Phase 5d: Integration & Polish\n\n**Integration Points:**\n\n- Hook `ExecutionService.handleComplete/handleError` to record workflow events\n- Add `workflow_execution_id` tracking on spawned executions\n- WebSocket broadcasts for workflow updates\n\n**Error Handling:**\n\n- Orchestrator crash recovery (resume from last checkpoint)\n- Execution timeout detection and wakeup\n- Graceful degradation on MCP errors\n\n### Phase 6: Workflow MCP Server (covered by 5b)\n\n- Create `mcp-workflow/` package (optional separate package)\n- Implement workflow MCP tools\n\n### Phase 7: API and Events\n\n- Create REST endpoints for workflow management\n- Add WebSocket broadcasting for real-time updates\n\n---\n\n## File Structure\n\n```\nserver/src/workflow/\n├── index.ts                        # Public exports\n├── workflow-engine.ts              # IWorkflowEngine interface\n├── workflow-event-emitter.ts       # Event system\n├── dependency-analyzer.ts          # Graph analysis\n├── base-workflow-engine.ts         # Shared implementation logic\n├── engines/\n│   ├── sequential-engine.ts        # Naive implementation\n│   └── orchestrator-engine.ts      # Agent-managed implementation\n├── services/\n│   ├── wakeup-service.ts           # Event watching and wakeup triggering\n│   └── prompt-builder.ts           # Orchestrator prompt construction\n└── mcp/\n    ├── index.ts                    # Entry point (stdio transport)\n    ├── server.ts                   # WorkflowMCPServer class\n    ├── types.ts                    # Tool parameter types\n    └── tools/\n        ├── workflow.ts             # workflow_status, workflow_complete\n        ├── execution.ts            # execute_issue, execution_status, execution_cancel\n        ├── inspection.ts           # execution_trajectory, execution_changes\n        └── escalation.ts           # escalate_to_user, notify_user\n```","priority":0,"archived":0,"archived_at":null,"created_at":"2025-12-03 04:39:10","updated_at":"2025-12-03 21:06:00","parent_id":null,"parent_uuid":null,"relationships":[],"tags":["agent-orchestration","architecture","automation","workflow"]}
{"id":"s-3i40","uuid":"c5a531e2-38e7-4584-948d-04e86a0008ea","title":"Workflow Management UI","file_path":"specs/s-3i40_workflow_management_ui.md","content":"# Workflow Management UI Specification\n\n## Overview\n\nDesign and implementation requirements for the workflow management user interface. This spec covers integration with existing pages, a dedicated workflows page, and visualization of workflow execution including DAG-based step visualization.\n\n**Parent Spec:** [[s-3g2y]] (Workflow System)\n\n---\n\n## Design Decisions\n\n| Decision | Choice | Rationale |\n| --- | --- | --- |\n| DAG Visualization | React Flow | Rich node/edge library, good React integration, supports custom nodes |\n| Graph Orientation | Vertical | Easier to scroll through, natural top-to-bottom flow |\n| Real-time Updates | WebSocket | Consistent with existing execution infrastructure |\n| Orchestrator UI | Full Trajectory | Reuse existing AgentTrajectory component for orchestrator visibility |\n\n---\n\n## Phase 1: API-Independent Implementation\n\nThis section covers frontend work that can be completed before the backend workflow API is ready. All components use mock data and placeholder handlers.\n\n### 1\\. React Flow Setup & Base DAG Component\n\n**Install Dependencies:**\n\n```bash\nnpm --prefix frontend install @xyflow/react dagre @types/dagre\n```\n\n**Create** `WorkflowDAG` **Component:**\n\nLocation: `frontend/src/components/workflows/WorkflowDAG.tsx`\n\n```typescript\ninterface WorkflowDAGProps {\n  steps: WorkflowStep[];\n  selectedStepId?: string;\n  onStepSelect?: (stepId: string) => void;\n  onStepAction?: (stepId: string, action: 'retry' | 'skip' | 'cancel') => void;\n  interactive?: boolean;  // false for preview mode\n}\n```\n\n**Implementation Details:**\n\n- Use `@xyflow/react` (React Flow v12) with `ReactFlow`, `Background`, `Controls`, `MiniMap`\n- Auto-layout with dagre: `rankdir: 'TB'` (top-to-bottom), `nodesep: 50`, `ranksep: 80`\n- Convert `WorkflowStep[]` to React Flow nodes and edges\n- Edges derived from `step.dependencies` array\n- Fit view on mount and when steps change\n\n**Mock Data Generator:**\n\n```typescript\n// frontend/src/lib/mock/workflows.ts\nexport function generateMockWorkflow(stepCount: number): Workflow {\n  // Generate workflow with random dependency structure\n  // Mix of sequential and parallel steps\n}\n\nexport function generateMockSteps(): WorkflowStep[] {\n  // Return realistic step configurations\n  // Include various status states for testing\n}\n```\n\n---\n\n### 2\\. WorkflowStepNode Component\n\n**Custom React Flow Node:**\n\nLocation: `frontend/src/components/workflows/WorkflowStepNode.tsx`\n\n```typescript\ninterface WorkflowStepNodeData {\n  step: WorkflowStep;\n  issue?: Issue;  // Enriched issue data\n  isSelected?: boolean;\n  onSelect?: () => void;\n}\n```\n\n**Visual Design:**\n\n```\n┌──────────────────────────────┐\n│ ● i-abc1                     │  ← Status icon + Issue ID\n│ ─────────────────────────────│\n│ Add authentication endpoint  │  ← Issue title (truncated)\n│ claude-code • 3m 42s         │  ← Agent + duration (if running/completed)\n└──────────────────────────────┘\n```\n\n**Status Styling:**\n\n| Status | Border | Background | Icon |\n| --- | --- | --- | --- |\n| pending | `border-muted` | `bg-muted/20` | `Clock` (gray) |\n| ready | `border-blue-500` | `bg-blue-500/10` | `Circle` (blue outline) |\n| running | `border-blue-500` | `bg-blue-500/20` | `Loader2` (animated) |\n| completed | `border-green-500` | `bg-green-500/10` | `CheckCircle2` (green) |\n| failed | `border-destructive` | `bg-destructive/10` | `XCircle` (red) |\n| skipped | `border-muted` | `bg-muted/10` | `MinusCircle` (gray, strikethrough text) |\n| blocked | `border-yellow-500` | `bg-yellow-500/10` | `AlertCircle` (yellow) |\n\n**Interactions:**\n\n- Click: Select node (calls `onSelect`)\n- Hover: Show full title in tooltip\n- Selected state: Ring highlight (`ring-2 ring-primary`)\n\n---\n\n### 3\\. WorkflowCard Component\n\n**Card for List View:**\n\nLocation: `frontend/src/components/workflows/WorkflowCard.tsx`\n\n```typescript\ninterface WorkflowCardProps {\n  workflow: Workflow;\n  onSelect?: () => void;\n  onPause?: () => void;\n  onResume?: () => void;\n  onCancel?: () => void;\n}\n```\n\n**Visual Design:**\n\n```\n┌─────────────────────────────────────┐\n│ Auth Implementation          ◐ Running │  ← Title + Status badge\n│ Source: s-3g2y (Workflow System)     │  ← Source with link\n├─────────────────────────────────────┤\n│ ●●●○○○  3/6 steps                   │  ← Progress dots + text\n│ ─────────────────────────────────────│\n│ Agent: claude-code                  │\n│ Started: 15 minutes ago             │\n├─────────────────────────────────────┤\n│            [⏸ Pause]  [■ Cancel]    │  ← Action buttons\n└─────────────────────────────────────┘\n```\n\n**Progress Indicator Options:**\n\n- Dots: `●●●○○○` (filled = completed, hollow = remaining)\n- Bar: Horizontal progress bar with percentage\n- Compact: `3/6` with small progress ring\n\n**Status Badge Colors:**\n\n- pending: `bg-muted text-muted-foreground`\n- running: `bg-blue-500 text-white`\n- paused: `bg-yellow-500 text-white`\n- completed: `bg-green-500 text-white`\n- failed: `bg-destructive text-destructive-foreground`\n- cancelled: `bg-muted text-muted-foreground`\n\n---\n\n### 4\\. WorkflowStepPanel Component\n\n**Side Panel for Step Details:**\n\nLocation: `frontend/src/components/workflows/WorkflowStepPanel.tsx`\n\n```typescript\ninterface WorkflowStepPanelProps {\n  step: WorkflowStep;\n  issue?: Issue;\n  onClose?: () => void;\n  onRetry?: () => void;\n  onSkip?: () => void;\n  onViewExecution?: () => void;\n}\n```\n\n**Layout:**\n\n```\n┌─────────────────────────────────────┐\n│ Step Details                    [X] │\n├─────────────────────────────────────┤\n│ i-abc1: Add authentication endpoint │\n│ Status: ● Running                   │\n│ Duration: 3m 42s                    │\n├─────────────────────────────────────┤\n│ Description:                        │\n│ Implement OAuth2 authentication...  │\n│ [Read more →]                       │\n├─────────────────────────────────────┤\n│ Dependencies: (2)                   │\n│  • i-xyz1: Setup database schema    │\n│  • i-xyz2: Configure OAuth provider │\n├─────────────────────────────────────┤\n│ Execution:                          │\n│ [View Execution →]                  │\n├─────────────────────────────────────┤\n│ Error: (if failed)                  │\n│ Test suite failed with 3 errors...  │\n├─────────────────────────────────────┤\n│ [Retry]  [Skip]  [Cancel]           │\n└─────────────────────────────────────┘\n```\n\n---\n\n### 5\\. CreateWorkflowDialog Component\n\n**Workflow Creation Dialog:**\n\nLocation: `frontend/src/components/workflows/CreateWorkflowDialog.tsx`\n\n```typescript\ninterface CreateWorkflowDialogProps {\n  open: boolean;\n  onOpenChange: (open: boolean) => void;\n  onCreate?: (options: CreateWorkflowOptions) => void;\n  defaultSource?: WorkflowSource;  // Pre-fill when opened from spec page\n}\n```\n\n**Form State:**\n\n```typescript\ninterface WorkflowFormState {\n  title: string;\n  sourceType: 'spec' | 'issues' | 'root_issue' | 'goal';\n  specId?: string;\n  issueIds?: string[];\n  rootIssueId?: string;\n  goal?: string;\n  config: Partial<WorkflowConfig>;\n}\n```\n\n**Source Type Tabs:**\n\n- Use existing `RadioGroup` component for source type selection\n- Conditional rendering of source-specific inputs\n\n**Entity Selection:**\n\n- Reuse `EntityCombobox` for spec/issue selection\n- Multi-select mode for \"From Issues\" source\n\n**Configuration Section:**\n\n- Collapsible \"Advanced Configuration\" section\n- Form controls for `WorkflowConfig` fields\n- Sensible defaults pre-filled\n\n**Preview Section:**\n\n- Show count of issues that will be included\n- \"Preview DAG\" button opens `WorkflowDAG` in read-only mode in a sub-dialog\n\n---\n\n### 6\\. Frontend Types & Mock Data\n\n**Frontend Workflow Types:**\n\nLocation: `frontend/src/types/workflow.ts`\n\n```typescript\nimport type {\n  Workflow,\n  WorkflowStep,\n  WorkflowStatus,\n  WorkflowStepStatus,\n  WorkflowSource,\n  WorkflowConfig,\n  CreateWorkflowOptions\n} from '@sudocode-ai/types';\n\n// Re-export for convenience\nexport type {\n  Workflow,\n  WorkflowStep,\n  WorkflowStatus,\n  WorkflowStepStatus,\n  WorkflowSource,\n  WorkflowConfig,\n  CreateWorkflowOptions\n};\n\n// Frontend-specific extensions\nexport interface WorkflowWithIssues extends Workflow {\n  /** Enriched issue data for each step */\n  stepIssues: Record<string, Issue>;\n}\n\n// DAG node/edge types for React Flow\nexport interface WorkflowNode {\n  id: string;\n  type: 'workflowStep';\n  position: { x: number; y: number };\n  data: {\n    step: WorkflowStep;\n    issue?: Issue;\n  };\n}\n\nexport interface WorkflowEdge {\n  id: string;\n  source: string;\n  target: string;\n  animated?: boolean;\n  style?: React.CSSProperties;\n}\n```\n\n**Mock Data Module:**\n\nLocation: `frontend/src/lib/mock/workflows.ts`\n\n```typescript\nexport const MOCK_WORKFLOWS: Workflow[] = [\n  // Various workflows in different states\n  // - Running workflow with mixed step statuses\n  // - Completed workflow\n  // - Failed workflow with error message\n  // - Paused workflow awaiting input\n];\n\nexport const MOCK_WORKFLOW_STEPS: Record<string, WorkflowStep[]> = {\n  // Step configurations for each mock workflow\n};\n\nexport function createMockWorkflow(overrides?: Partial<Workflow>): Workflow;\nexport function createMockStep(overrides?: Partial<WorkflowStep>): WorkflowStep;\n```\n\n---\n\n### 7\\. Placeholder Hooks\n\n**Hook Interfaces (with mock implementations):**\n\nLocation: `frontend/src/hooks/useWorkflows.ts`\n\n```typescript\nexport function useWorkflows() {\n  // Returns mock data for now\n  // Will be replaced with React Query when API is ready\n  return {\n    workflows: MOCK_WORKFLOWS,\n    isLoading: false,\n    error: null,\n  };\n}\n\nexport function useWorkflow(id: string) {\n  // Returns single mock workflow\n  return {\n    workflow: MOCK_WORKFLOWS.find(w => w.id === id),\n    isLoading: false,\n    error: null,\n  };\n}\n\nexport function useWorkflowMutations() {\n  // Placeholder handlers that log to console\n  return {\n    create: async (options: CreateWorkflowOptions) => {\n      console.log('Create workflow:', options);\n    },\n    pause: async (id: string) => {\n      console.log('Pause workflow:', id);\n    },\n    resume: async (id: string) => {\n      console.log('Resume workflow:', id);\n    },\n    cancel: async (id: string) => {\n      console.log('Cancel workflow:', id);\n    },\n  };\n}\n```\n\n---\n\n### 8\\. Storybook Stories (Optional)\n\nIf Storybook is available, create stories for visual development:\n\n```typescript\n// WorkflowStepNode.stories.tsx\nexport const Pending: Story = { args: { data: { step: pendingStep } } };\nexport const Running: Story = { args: { data: { step: runningStep } } };\nexport const Completed: Story = { args: { data: { step: completedStep } } };\nexport const Failed: Story = { args: { data: { step: failedStep } } };\n\n// WorkflowCard.stories.tsx\nexport const Running: Story = { args: { workflow: runningWorkflow } };\nexport const Completed: Story = { args: { workflow: completedWorkflow } };\n\n// WorkflowDAG.stories.tsx\nexport const LinearWorkflow: Story = { args: { steps: linearSteps } };\nexport const ParallelWorkflow: Story = { args: { steps: parallelSteps } };\nexport const ComplexWorkflow: Story = { args: { steps: complexSteps } };\n```\n\n---\n\n### Implementation Order\n\nRecommended sequence for implementation:\n\n1. **Types & Mocks** - Foundation for all other work\n1. **React Flow Setup + WorkflowDAG** - Core visualization\n1. **WorkflowStepNode** - Custom node for DAG\n1. **WorkflowCard** - List view component\n1. **WorkflowStepPanel** - Detail panel\n1. **CreateWorkflowDialog** - Creation flow\n1. **Placeholder hooks** - Wire up components\n\nEach can be developed and tested independently with mock data.\n\n---\n\n## Phase 2: Pages & Integration ✅ COMPLETED\n\nThis phase covers routing, navigation, and integration with existing pages.\n\n### 1\\. Workflow Routes\n\n**Files Modified:**\n\n- `frontend/src/App.tsx` - Added protected routes\n\n```typescript\n// Routes added\n<Route path=\"/workflows\" element={<WorkflowsPage />} />\n<Route path=\"/workflows/:id\" element={<WorkflowDetailPage />} />\n```\n\n### 2\\. WorkflowsPage\n\n**Location:** `frontend/src/pages/WorkflowsPage.tsx`\n\nFeatures implemented:\n\n- Grid layout of `WorkflowCard` components\n- Status filter dropdown (pending, running, paused, completed, failed, cancelled)\n- Search by title/source\n- \"Create Workflow\" button opens `CreateWorkflowDialog`\n- Empty states for no workflows vs no matches\n- Active workflow count in header\n\n### 3\\. WorkflowDetailPage\n\n**Location:** `frontend/src/pages/WorkflowDetailPage.tsx`\n\nFeatures implemented:\n\n- Split layout: DAG on left, step panel on right\n- Header with title, status badge, progress indicator\n- `WorkflowControls` for pause/resume/cancel\n- Step selection updates side panel\n- Back navigation to `/workflows`\n- 404 handling for invalid IDs\n\n### 4\\. Navigation Integration\n\n**File Modified:** `frontend/src/components/layout/Sidebar.tsx`\n\n- Added \"Workflows\" nav item with `Network` icon\n- Position: between \"Agent Executions\" and \"Worktrees\"\n\n### 5\\. Specs Page Integration\n\n**Files Modified:**\n\n- `frontend/src/components/specs/SpecCard.tsx` - Added workflow button and indicator\n- `frontend/src/components/specs/SpecList.tsx` - Pass workflow props\n- `frontend/src/pages/SpecsPage.tsx` - CreateWorkflowDialog integration\n- `frontend/src/pages/SpecDetailPage.tsx` - Header workflow button\n\nFeatures:\n\n- \"Run as Workflow\" button on spec cards and detail page\n- Active workflow indicator badge (running/paused)\n- Click badge to navigate to workflow\n\n### 6\\. Issues Page Integration\n\n**Files Created:**\n\n- `frontend/src/components/issues/WorkflowIndicator.tsx`\n\n**Files Modified:**\n\n- `frontend/src/components/issues/IssueCard.tsx` - Added `workflowInfo` prop\n- `frontend/src/components/issues/IssueKanbanBoard.tsx` - Pass workflow info map\n- `frontend/src/pages/IssuesPage.tsx` - Compute `issueWorkflows` from active workflows\n\nFeatures:\n\n- `WorkflowIndicator` badge on issue cards when in active workflow\n- Color-coded step status (pending, running, completed, failed, etc.)\n- Tooltip with workflow title and step status\n- Click to navigate to workflow detail\n\n---\n\n## Phase 3: API Integration\n\nThis phase connects the UI to the backend workflow API ([[s-7gje]]). Replaces mock data with real API calls using React Query.\n\n### Prerequisites\n\nBackend workflow API must be available:\n\n- `GET /api/workflows` - List workflows\n- `POST /api/workflows` - Create workflow\n- `GET /api/workflows/:id` - Get workflow details\n- `DELETE /api/workflows/:id` - Delete workflow\n- `POST /api/workflows/:id/start` - Start workflow\n- `POST /api/workflows/:id/pause` - Pause workflow\n- `POST /api/workflows/:id/resume` - Resume workflow\n- `POST /api/workflows/:id/cancel` - Cancel workflow\n- `POST /api/workflows/:id/steps/:stepId/retry` - Retry step\n- `POST /api/workflows/:id/steps/:stepId/skip` - Skip step\n- `GET /api/workflows/:id/events` - Get event history\n\n### 1\\. Workflow API Client\n\n**File:** `frontend/src/lib/api.ts`\n\nAdd workflow endpoint functions:\n\n```typescript\n// Workflow API endpoints\nexport const workflowApi = {\n  // List workflows with optional filters\n  list: (params?: {\n    status?: WorkflowStatus | WorkflowStatus[];\n    limit?: number;\n    offset?: number;\n    sortBy?: 'created_at' | 'updated_at';\n    order?: 'asc' | 'desc';\n  }) => api.get<Workflow[]>('/api/workflows', { params }),\n\n  // Create workflow from source\n  create: (options: CreateWorkflowOptions) =>\n    api.post<Workflow>('/api/workflows', options),\n\n  // Get single workflow\n  get: (id: string) => api.get<Workflow>(`/api/workflows/${id}`),\n\n  // Delete workflow\n  delete: (id: string) => api.delete(`/api/workflows/${id}`),\n\n  // Lifecycle actions\n  start: (id: string) => api.post<Workflow>(`/api/workflows/${id}/start`),\n  pause: (id: string) => api.post<Workflow>(`/api/workflows/${id}/pause`),\n  resume: (id: string) => api.post<Workflow>(`/api/workflows/${id}/resume`),\n  cancel: (id: string) => api.post<Workflow>(`/api/workflows/${id}/cancel`),\n\n  // Step actions\n  retryStep: (workflowId: string, stepId: string) =>\n    api.post<Workflow>(`/api/workflows/${workflowId}/steps/${stepId}/retry`),\n  skipStep: (workflowId: string, stepId: string, reason?: string) =>\n    api.post<Workflow>(`/api/workflows/${workflowId}/steps/${stepId}/skip`, { reason }),\n\n  // Event history\n  getEvents: (id: string) =>\n    api.get<WorkflowEvent[]>(`/api/workflows/${id}/events`),\n};\n```\n\n### 2\\. Convert useWorkflows Hook\n\n**File:** `frontend/src/hooks/useWorkflows.ts`\n\nReplace mock data with React Query:\n\n```typescript\nimport { useQuery } from '@tanstack/react-query';\nimport { workflowApi } from '@/lib/api';\n\nexport function useWorkflows(params?: WorkflowListParams) {\n  return useQuery({\n    queryKey: ['workflows', params],\n    queryFn: () => workflowApi.list(params),\n    staleTime: 30_000, // 30 seconds\n  });\n}\n```\n\n**Query Key Convention:**\n\n- `['workflows']` - All workflows\n- `['workflows', { status: 'running' }]` - Filtered list\n- `['workflow', id]` - Single workflow\n- `['workflow', id, 'events']` - Workflow events\n\n### 3\\. Convert useWorkflow Hook\n\nFetch single workflow with issue enrichment:\n\n```typescript\nexport function useWorkflow(id: string) {\n  const workflowQuery = useQuery({\n    queryKey: ['workflow', id],\n    queryFn: () => workflowApi.get(id),\n    enabled: !!id,\n  });\n\n  // Fetch issues for all steps\n  const issueIds = workflowQuery.data?.steps.map(s => s.issueId) ?? [];\n  const issuesQuery = useQuery({\n    queryKey: ['issues', issueIds],\n    queryFn: () => issueApi.getMany(issueIds),\n    enabled: issueIds.length > 0,\n  });\n\n  return {\n    workflow: workflowQuery.data,\n    issues: issuesQuery.data,\n    isLoading: workflowQuery.isLoading || issuesQuery.isLoading,\n    error: workflowQuery.error || issuesQuery.error,\n  };\n}\n```\n\n### 4\\. Implement useWorkflowMutations\n\nWire up mutations with React Query:\n\n```typescript\nimport { useMutation, useQueryClient } from '@tanstack/react-query';\n\nexport function useWorkflowMutations() {\n  const queryClient = useQueryClient();\n\n  const invalidateWorkflows = () => {\n    queryClient.invalidateQueries({ queryKey: ['workflows'] });\n  };\n\n  const create = useMutation({\n    mutationFn: workflowApi.create,\n    onSuccess: invalidateWorkflows,\n  });\n\n  const pause = useMutation({\n    mutationFn: workflowApi.pause,\n    onSuccess: (_, id) => {\n      queryClient.invalidateQueries({ queryKey: ['workflow', id] });\n      invalidateWorkflows();\n    },\n  });\n\n  const resume = useMutation({\n    mutationFn: workflowApi.resume,\n    onSuccess: (_, id) => {\n      queryClient.invalidateQueries({ queryKey: ['workflow', id] });\n      invalidateWorkflows();\n    },\n  });\n\n  const cancel = useMutation({\n    mutationFn: workflowApi.cancel,\n    onSuccess: (_, id) => {\n      queryClient.invalidateQueries({ queryKey: ['workflow', id] });\n      invalidateWorkflows();\n    },\n  });\n\n  return { create, pause, resume, cancel };\n}\n```\n\n### 5\\. Implement useWorkflowStepActions\n\nStep-level mutations:\n\n```typescript\nexport function useWorkflowStepActions(workflowId: string) {\n  const queryClient = useQueryClient();\n\n  const invalidate = () => {\n    queryClient.invalidateQueries({ queryKey: ['workflow', workflowId] });\n    queryClient.invalidateQueries({ queryKey: ['workflows'] });\n  };\n\n  const retry = useMutation({\n    mutationFn: (stepId: string) => workflowApi.retryStep(workflowId, stepId),\n    onSuccess: invalidate,\n  });\n\n  const skip = useMutation({\n    mutationFn: ({ stepId, reason }: { stepId: string; reason?: string }) =>\n      workflowApi.skipStep(workflowId, stepId, reason),\n    onSuccess: invalidate,\n  });\n\n  return { retry, skip };\n}\n```\n\n### 6\\. WebSocket Subscription\n\n**File:** `frontend/src/contexts/WebSocketContext.tsx`\n\nAdd workflow event subscription:\n\n```typescript\n// New workflow event types to handle\ntype WorkflowEventType =\n  | 'workflow_created'\n  | 'workflow_updated'\n  | 'workflow_deleted'\n  | 'workflow_started'\n  | 'workflow_paused'\n  | 'workflow_resumed'\n  | 'workflow_completed'\n  | 'workflow_failed'\n  | 'workflow_cancelled'\n  | 'workflow_step_started'\n  | 'workflow_step_completed'\n  | 'workflow_step_failed'\n  | 'workflow_step_skipped';\n\n// Subscribe to workflow events\nsubscribe(`${projectId}:workflow:*`, handleWorkflowEvent);\n```\n\n### 7\\. Query Invalidation on WebSocket Events\n\nInvalidate React Query caches when workflow events arrive:\n\n```typescript\nfunction handleWorkflowEvent(event: ServerMessage) {\n  const queryClient = useQueryClient();\n\n  // Extract workflow ID from event\n  const workflowId = event.data?.workflowId;\n\n  // Invalidate relevant queries\n  queryClient.invalidateQueries({ queryKey: ['workflows'] });\n\n  if (workflowId) {\n    queryClient.invalidateQueries({ queryKey: ['workflow', workflowId] });\n  }\n\n  // For step events, also update the workflow detail\n  if (event.type.startsWith('workflow_step_')) {\n    queryClient.invalidateQueries({ queryKey: ['workflow', workflowId] });\n  }\n}\n```\n\n### 8\\. Optimistic Updates (Optional)\n\nFor better UX, implement optimistic updates for common actions:\n\n```typescript\nconst pause = useMutation({\n  mutationFn: workflowApi.pause,\n  onMutate: async (id) => {\n    await queryClient.cancelQueries({ queryKey: ['workflow', id] });\n    const previous = queryClient.getQueryData(['workflow', id]);\n\n    // Optimistically update to paused state\n    queryClient.setQueryData(['workflow', id], (old: Workflow) => ({\n      ...old,\n      status: 'paused',\n    }));\n\n    return { previous };\n  },\n  onError: (err, id, context) => {\n    // Rollback on error\n    queryClient.setQueryData(['workflow', id], context?.previous);\n  },\n  onSettled: (_, __, id) => {\n    queryClient.invalidateQueries({ queryKey: ['workflow', id] });\n  },\n});\n```\n\n### Implementation Order\n\n1. **API Client** - Add endpoints to `lib/api.ts`\n1. **useWorkflows** - Convert list hook to React Query\n1. **useWorkflow** - Convert detail hook with issue enrichment\n1. **useWorkflowMutations** - Implement lifecycle actions\n1. **useWorkflowStepActions** - Implement step actions\n1. **WebSocket Integration** - Subscribe to workflow events\n1. **Query Invalidation** - Auto-refresh on events\n1. **Testing** - Verify all flows work end-to-end\n\n### Files to Modify\n\n| File | Changes |\n| --- | --- |\n| `frontend/src/lib/api.ts` | Add `workflowApi` object with all endpoints |\n| `frontend/src/hooks/useWorkflows.ts` | Replace mock with React Query |\n| `frontend/src/contexts/WebSocketContext.tsx` | Add workflow event handling |\n| `frontend/src/pages/WorkflowsPage.tsx` | Update to use new hook signatures |\n| `frontend/src/pages/WorkflowDetailPage.tsx` | Update to use new hook signatures |\n| `frontend/src/components/workflows/CreateWorkflowDialog.tsx` | Wire up create mutation |\n\n### Remove After Integration\n\nAfter Phase 3 is complete, the following can be removed:\n\n- `frontend/src/lib/mock/workflows.ts` - Mock data no longer needed\n- Console.log statements in hooks\n\n---\n\n## Integration with Existing Pages\n\n### Specs Page\n\n**Run Workflow Action:**\n\n- Add \"Run as Workflow\" button/action on spec cards and spec detail page\n- Only enabled when spec has implementing issues (via `implements` relationships)\n- Opens workflow creation dialog with spec pre-selected as source\n\n**Workflow Status Indicator:**\n\n- Show badge/indicator on spec cards when an active workflow exists for that spec\n- Status colors: running (blue), paused (yellow), failed (red)\n\n### Issues Page\n\n**Workflow Membership Indicator:**\n\n- Visual indicator on issue cards when issue is part of an active workflow\n- Color-coded border or badge matching the workflow's assigned color\n- Tooltip showing workflow name and step status\n\n**Visual Grouping:**\n\n- Issues in the same workflow share a color code\n- Color palette for distinguishing multiple concurrent workflows\n- Subtle background tint or left border stripe on kanban cards\n\n**Future Work:**\n\n- Multi-select issues → \"Run as Workflow\" action\n- Integration with `ready` command output for quick workflow creation\n\n---\n\n## Workflows Page\n\nNew top-level page at `/workflows` for workflow management.\n\n### List View\n\nSimilar pattern to ExecutionsPage with cards/tiles:\n\n```\n┌─────────────────────────────────────────────────────────────┐\n│ Workflows                     [Filter ▼]  [+ Create Workflow]│\n├─────────────────────────────────────────────────────────────┤\n│ ┌────────────────────────┐  ┌────────────────────────────┐  │\n│ │ Auth Implementation    │  │ API v2 Migration           │  │\n│ │ Source: s-abc1         │  │ Source: 5 issues           │  │\n│ │ ●●●○○ 3/5 steps        │  │ ●●●●● Complete             │  │\n│ │ ◐ Running   [▶ ⏸ ■]    │  │ ● Completed  2h ago        │  │\n│ │ Agent: claude-code     │  │ Agent: claude-code         │  │\n│ └────────────────────────┘  └────────────────────────────┘  │\n└─────────────────────────────────────────────────────────────┘\n```\n\n**Card Contents:**\n\n- Workflow title\n- Source indicator (spec ID, issue count, or goal preview)\n- Step progress (completed/total with visual dots or bar)\n- Status badge with color\n- Quick actions: pause, resume, cancel\n- Agent type indicator\n- Timestamp (started, completed, or duration)\n\n**Filtering:**\n\n- By status: pending, planning, running, paused, completed, failed, cancelled\n- By source type: spec, issues, root\\_issue, goal\n- Search by title\n\n---\n\n## Workflow Detail Page\n\nRoute: `/workflows/:id`\n\n### Layout\n\n```\n┌─────────────────────────────────────────────────────────────┐\n│ ← Back   Auth Implementation              [⏸ Pause] [■ Stop]│\n│ Status: Running • Step 3/5 • Started 15m ago                │\n├─────────────────────────────────────────────────────────────┤\n│                                                             │\n│  ┌─────────────────────┐   ┌──────────────────────────────┐│\n│  │                     │   │ Step Details                 ││\n│  │   DAG Visualization │   │ ─────────────────────────────││\n│  │   (React Flow)      │   │ Issue: i-xyz2                ││\n│  │                     │   │ Status: Running              ││\n│  │   [i-abc1] ●        │   │ Agent: claude-code           ││\n│  │      ↓              │   │ Duration: 3m 42s             ││\n│  │   [i-xyz2] ◐ ←      │   │                              ││\n│  │      ↓              │   │ [View Execution →]           ││\n│  │   [i-def3] ○        │   │                              ││\n│  │                     │   │ Actions:                     ││\n│  │                     │   │ [Retry] [Skip] [Cancel]      ││\n│  └─────────────────────┘   └──────────────────────────────┘│\n└─────────────────────────────────────────────────────────────┘\n```\n\n### DAG Visualization (React Flow)\n\n**Node Design:**\n\n- Custom node component for workflow steps\n- Shows: issue ID, issue title (truncated), status icon\n- Color-coded by status:\n  - Pending: gray\n  - Ready: blue outline\n  - Running: blue with pulse animation\n  - Completed: green\n  - Failed: red\n  - Skipped: gray with strikethrough\n\n**Edge Design:**\n\n- Directed edges showing dependency flow\n- Animate edges leading to running node\n- Dim edges for completed paths\n\n**Interactions:**\n\n- Click node → show step details in side panel\n- Right-click node → context menu (retry, skip, view execution)\n- Zoom and pan controls\n- Fit-to-view button\n- Minimap for large workflows\n\n**Layout:**\n\n- Vertical orientation (top-to-bottom)\n- Auto-layout using dagre algorithm\n- Parallel steps arranged horizontally at same level\n\n### Step Details Panel\n\nCollapsible side panel showing:\n\n- Issue details (title, description preview)\n- Step status and timing\n- Execution link (if execution exists)\n- Error message (if failed)\n- Actions: retry, skip, cancel\n\n---\n\n## Orchestrator Workflow View\n\nFor agent-managed workflows (orchestratorAgentType set):\n\n### Orchestrator Trajectory\n\nReuse existing `AgentTrajectory` component to visualize orchestrator's actions:\n\n- Tool calls (execute\\_issue, workflow\\_status, etc.)\n- Decision points\n- Escalation requests\n\n```\n┌─────────────────────────────────────────────────────────────┐\n│ Orchestrator Activity                                       │\n├─────────────────────────────────────────────────────────────┤\n│ ▼ execute_issue(i-abc1)                          2m ago    │\n│   Started execution for \"Add auth endpoint\"                 │\n│                                                             │\n│ ▼ execution_status(i-abc1)                       1m ago    │\n│   Execution completed successfully                          │\n│                                                             │\n│ ▶ escalate_to_user                               now       │\n│   \"The tests are failing. Should I proceed?\"               │\n│   ┌─────────────────────────────────────────────┐          │\n│   │ [Approve] [Reject] [Provide Input...]       │          │\n│   └─────────────────────────────────────────────┘          │\n└─────────────────────────────────────────────────────────────┘\n```\n\n### Escalation Interface\n\nWhen `escalate_to_user` is called (human-in-the-loop mode):\n\n- Workflow status shows \"Awaiting Input\"\n- Prominent UI element showing escalation context\n- Action buttons: Approve, Reject, Custom Input\n- Text area for providing detailed feedback\n- Notification/toast when escalation occurs\n\n### Wakeup Event Visualization\n\nShow orchestrator wakeup events in the trajectory:\n\n- Execution completed/failed notifications\n- Batched events displayed together\n- Clear indication of what triggered the wakeup\n\n---\n\n## Workflow Creation Dialog\n\n### Dialog Flow\n\n```\n┌─────────────────────────────────────────────────────────────┐\n│ Create Workflow                                         [X] │\n├─────────────────────────────────────────────────────────────┤\n│ Source Type:                                                │\n│  ◉ From Spec   - Run all issues implementing a spec        │\n│  ○ From Issues - Select specific issues to run             │\n│  ○ From Root   - Run issue with all its blockers           │\n│  ○ From Goal   - AI orchestrator plans and executes        │\n├─────────────────────────────────────────────────────────────┤\n│ Select Spec:                                                │\n│  ┌─────────────────────────────────────────────────────┐   │\n│  │ [Search specs...]                                    │   │\n│  │ ○ s-3g2y: Workflow System (5 implementing issues)   │   │\n│  │ ○ s-abc1: Authentication (3 implementing issues)    │   │\n│  └─────────────────────────────────────────────────────┘   │\n├─────────────────────────────────────────────────────────────┤\n│ ▶ Advanced Configuration                                    │\n│   Execution Mode: ○ Sequential  ◉ Parallel (max: 3)        │\n│   On Failure: [Pause workflow ▼]                           │\n│   Default Agent: [Claude Code ▼]                           │\n│   Auto-commit after each step: [✓]                         │\n├─────────────────────────────────────────────────────────────┤\n│                                                             │\n│ Preview: 5 issues will be executed                          │\n│ Estimated dependency levels: 3                              │\n│                                                             │\n│                    [Cancel]  [Preview DAG]  [Create & Run]  │\n└─────────────────────────────────────────────────────────────┘\n```\n\n### Source-Specific UI\n\n**From Spec:**\n\n- Spec search/select dropdown\n- Shows count of implementing issues\n- Preview shows issues that will be included\n\n**From Issues:**\n\n- Multi-select issue picker\n- Shows dependency warnings if cycles detected\n- Can reorder manually or auto-sort by dependencies\n\n**From Root Issue:**\n\n- Single issue selector\n- Shows dependency tree preview\n- Indicates how many blocking issues will be included\n\n**From Goal (Agent-Managed):**\n\n- Text area for goal description\n- Orchestrator agent selector\n- Autonomy level toggle: Full Auto / Human-in-the-Loop\n- Model selector for orchestrator\n\n### Preview DAG\n\nButton to show a preview of the dependency graph before creating:\n\n- Same React Flow visualization as detail view\n- Read-only preview\n- Helps user understand execution order\n\n---\n\n## Real-time Updates\n\n### WebSocket Events\n\nNew event types for workflow updates:\n\n- `workflow_created` - New workflow started\n- `workflow_updated` - Status or progress changed\n- `workflow_step_changed` - Individual step status changed\n- `workflow_escalation` - Escalation requires user input\n\n### Update Handling\n\n- WorkflowsPage: Invalidate query on workflow events\n- WorkflowDetailPage: Live update DAG node states\n- IssuesPage: Update workflow indicators on step changes\n- SpecsPage: Update workflow badges\n\n---\n\n## Components to Create\n\n### New Components\n\n| Component | Location | Purpose |\n| --- | --- | --- |\n| `WorkflowCard` | `components/workflows/` | Card for workflow list view |\n| `WorkflowDAG` | `components/workflows/` | React Flow DAG visualization |\n| `WorkflowStepNode` | `components/workflows/` | Custom React Flow node for steps |\n| `WorkflowStepPanel` | `components/workflows/` | Side panel for step details |\n| `CreateWorkflowDialog` | `components/workflows/` | Workflow creation dialog |\n| `WorkflowControls` | `components/workflows/` | Pause/resume/cancel buttons |\n| `EscalationPanel` | `components/workflows/` | Escalation response interface |\n| `WorkflowIndicator` | `components/issues/` | Badge for issue cards in workflows |\n\n### New Pages\n\n| Page | Route | Purpose |\n| --- | --- | --- |\n| `WorkflowsPage` | `/workflows` | List all workflows |\n| `WorkflowDetailPage` | `/workflows/:id` | Single workflow view |\n\n### Hooks\n\n| Hook | Purpose |\n| --- | --- |\n| `useWorkflows` | Fetch workflow list with React Query |\n| `useWorkflow` | Fetch single workflow details |\n| `useWorkflowMutations` | Create, pause, resume, cancel workflows |\n| `useWorkflowStepActions` | Retry, skip step actions |\n\n---\n\n## Navigation Updates\n\nAdd to main navigation:\n\n- New \"Workflows\" nav item between \"Executions\" and \"Worktrees\"\n- Badge showing count of active (running/paused) workflows\n\n---\n\n## Future Work\n\nCaptured for later implementation:\n\n1. **Issues Page Multi-Select**: Select multiple issues → \"Run as Workflow\"\n1. **Ready List Integration**: Quick workflow creation from `ready` command output\n1. **Workflow Templates**: Save workflow configurations for reuse\n1. **Workflow Comparison**: Compare code changes across workflow runs\n1. **Workflow Analytics**: Execution time trends, success rates","priority":1,"archived":0,"archived_at":null,"created_at":"2025-12-03 08:35:35","updated_at":"2026-01-07 00:56:12","parent_id":"s-3g2y","parent_uuid":null,"relationships":[],"tags":["design","frontend","react-flow","ui","workflow"]}
{"id":"s-7gje","uuid":"e2467795-a7f1-4f77-8bfb-d92a9d6c6cb7","title":"Workflow API and Events (Phase 7)","file_path":"specs/s-7gje_workflow_api_and_events_phase_7.md","content":"# Workflow API and Events\n\n## Overview\n\nREST API endpoints and WebSocket event broadcasting for workflow management. Built against the stable `IWorkflowEngine` interface - works for both Sequential and future Orchestrator engines.\n\n**Parent Spec:** [[s-3g2y]]\n\n---\n\n## REST API Endpoints\n\n### Base Path: `/api/workflows`\n\nAll endpoints require `X-Project-ID` header via `requireProject()` middleware.\n\n| Method | Endpoint | Description |\n|--------|----------|-------------|\n| `GET` | `/api/workflows` | List workflows with filtering |\n| `POST` | `/api/workflows` | Create workflow from source |\n| `GET` | `/api/workflows/:id` | Get workflow details |\n| `DELETE` | `/api/workflows/:id` | Delete workflow |\n| `POST` | `/api/workflows/:id/start` | Start pending workflow |\n| `POST` | `/api/workflows/:id/pause` | Pause running workflow |\n| `POST` | `/api/workflows/:id/resume` | Resume paused workflow |\n| `POST` | `/api/workflows/:id/cancel` | Cancel workflow |\n| `POST` | `/api/workflows/:id/steps/:stepId/retry` | Retry failed step |\n| `POST` | `/api/workflows/:id/steps/:stepId/skip` | Skip step |\n| `GET` | `/api/workflows/:id/events` | Get workflow event history |\n\n---\n\n## Request/Response Contracts\n\n### GET /api/workflows\n\n**Query Parameters:**\n```typescript\n{\n  limit?: number;      // Default: 50\n  offset?: number;     // Default: 0\n  status?: WorkflowStatus | WorkflowStatus[];  // Comma-separated\n  sortBy?: 'created_at' | 'updated_at';\n  order?: 'asc' | 'desc';\n}\n```\n\n**Response:** `{ success: true, data: Workflow[] }`\n\n### POST /api/workflows\n\n**Request Body:**\n```typescript\n{\n  source: WorkflowSource;  // Required\n  config?: Partial<WorkflowConfig>;\n  title?: string;  // Optional override\n}\n```\n\n**Response:** `{ success: true, data: Workflow }` (201)\n\n### POST /api/workflows/:id/steps/:stepId/skip\n\n**Request Body:**\n```typescript\n{\n  reason?: string;  // Optional skip reason\n}\n```\n\n### Response Format\n\n```typescript\n// Success\n{ success: true, data: T }\n\n// Error\n{ success: false, data: null, message: string }\n```\n\n### Error Mapping\n\n| Error Class | HTTP Status |\n|-------------|-------------|\n| `WorkflowNotFoundError` | 404 |\n| `WorkflowStepNotFoundError` | 404 |\n| `WorkflowStateError` | 400 |\n| `WorkflowCycleError` | 400 |\n| Generic errors | 500 |\n\n---\n\n## WebSocket Events\n\n### New ServerMessage Types\n\n```typescript\n// Workflow lifecycle events\n| \"workflow_created\"\n| \"workflow_updated\"\n| \"workflow_deleted\"\n| \"workflow_started\"\n| \"workflow_paused\"\n| \"workflow_resumed\"\n| \"workflow_completed\"\n| \"workflow_failed\"\n| \"workflow_cancelled\"\n\n// Step events\n| \"workflow_step_started\"\n| \"workflow_step_completed\"\n| \"workflow_step_failed\"\n| \"workflow_step_skipped\"\n```\n\n### Subscription Patterns\n\n```\n{projectId}:workflow:*              // All workflow events\n{projectId}:workflow:{workflowId}   // Specific workflow\n{projectId}:all                     // All events including workflows\n```\n\n### Broadcast Helpers\n\n```typescript\n// Workflow-level events\nbroadcastWorkflowUpdate(\n  projectId: string,\n  workflowId: string,\n  action: \"created\" | \"updated\" | \"deleted\" | \"started\" | \n          \"paused\" | \"resumed\" | \"completed\" | \"failed\" | \"cancelled\",\n  data?: any\n): void\n\n// Step-level events\nbroadcastWorkflowStepUpdate(\n  projectId: string,\n  workflowId: string,\n  action: \"started\" | \"completed\" | \"failed\" | \"skipped\",\n  data?: any\n): void\n```\n\n---\n\n## Event Bridge Service\n\nConnects `WorkflowEventEmitter` to WebSocket broadcasts.\n\n**File:** `server/src/services/workflow-broadcast-service.ts`\n\n```typescript\nclass WorkflowBroadcastService {\n  constructor(\n    eventEmitter: WorkflowEventEmitter,\n    getProjectId: (workflowId: string) => string | null\n  )\n}\n```\n\n**Event Mapping:**\n\n| WorkflowEventPayload.type | WebSocket Event |\n|---------------------------|-----------------|\n| `workflow_started` | `workflow_started` |\n| `workflow_paused` | `workflow_paused` |\n| `workflow_resumed` | `workflow_resumed` |\n| `workflow_completed` | `workflow_completed` |\n| `workflow_failed` | `workflow_failed` |\n| `workflow_cancelled` | `workflow_cancelled` |\n| `step_started` | `workflow_step_started` |\n| `step_completed` | `workflow_step_completed` |\n| `step_failed` | `workflow_step_failed` |\n| `step_skipped` | `workflow_step_skipped` |\n\n---\n\n## Integration\n\n### Engine Lifecycle (Per-Project)\n\nAdd `workflowEngine` to `ProjectContext`:\n\n```typescript\ninterface ProjectContext {\n  // ... existing\n  workflowEngine?: SequentialWorkflowEngine;\n}\n```\n\nInitialize when project opens:\n```typescript\nconst eventEmitter = new WorkflowEventEmitter();\nconst workflowEngine = new SequentialWorkflowEngine(db, executionService, eventEmitter);\nnew WorkflowBroadcastService(eventEmitter, () => projectId);\n```\n\n### Router Registration\n\n```typescript\napp.use(\"/api/workflows\", requireProject(projectManager), createWorkflowsRouter());\n```\n\n---\n\n## Files\n\n### Create\n- `server/src/routes/workflows.ts` - REST endpoints\n- `server/src/services/workflow-broadcast-service.ts` - Event bridge\n- `server/tests/unit/routes/workflows.test.ts` - Tests\n\n### Modify\n- `server/src/services/websocket.ts` - Add event types + helpers\n- `server/src/index.ts` - Register router\n- `server/src/services/project-manager.ts` - Initialize engine\n\n---\n\n## Future: Orchestrator Extension\n\nWhen Phase 5 (Orchestrator) is implemented, add:\n\n```typescript\n// Escalation endpoint\nPOST /api/workflows/:id/escalation/respond\nBody: { action: 'approve' | 'reject' | 'custom', message?: string }\n\n// Escalation events\n| \"workflow_escalation_requested\"\n| \"workflow_escalation_resolved\"\n```\n\nCore API remains unchanged - escalation is additive.","priority":1,"archived":0,"archived_at":null,"created_at":"2025-12-03 10:58:32","updated_at":"2025-12-03 10:58:32","parent_id":null,"parent_uuid":null,"relationships":[],"tags":["api","phase-7","websocket","workflow"]}
{"id":"s-6uh0","uuid":"b3d01f96-393c-4ad0-8937-3672cd2d8eb8","title":"Phase 5b: Workflow MCP Server","file_path":"specs/s-6uh0_phase_5b_workflow_mcp_server.md","content":"# Phase 5b: Workflow MCP Server\n\n## Overview\n\nThe Workflow MCP Server provides tools for the orchestrator agent to control workflow execution. It's spawned as a subprocess by the orchestrator execution and communicates via stdio.\n\n**Key Difference from Main MCP Server:**\n- Main MCP (`mcp/`) wraps CLI commands for general sudocode operations\n- Workflow MCP (`server/src/workflow/mcp/`) calls services directly for efficiency and has workflow-specific tools\n\n## Architecture\n\n```\nOrchestrator Execution (Claude Code)\n    ↓ MCP Protocol (stdio)\nWorkflow MCP Server (node process)\n    ↓ Direct calls\nExecutionService, Database, etc.\n```\n\n## Entry Point\n\n```bash\nnode server/dist/workflow/mcp/index.js \\\n  --workflow-id wf-abc123 \\\n  --db-path .sudocode/cache.db \\\n  --repo-path /path/to/repo\n```\n\n## Directory Structure\n\n```\nserver/src/workflow/mcp/\n├── index.ts              # Entry point (CLI args → stdio transport)\n├── server.ts             # WorkflowMCPServer class\n├── types.ts              # Tool parameter/result types\n└── tools/\n    ├── workflow.ts       # workflow_status, workflow_complete\n    ├── execution.ts      # execute_issue, execution_status, execution_cancel\n    └── inspection.ts     # execution_trajectory, execution_changes\n```\n\n## MCP Tools\n\n### Workflow Control Tools\n\n| Tool | Parameters | Returns | Purpose |\n|------|------------|---------|---------|\n| `workflow_status` | (none) | workflow, steps, activeExecutions, readyIssues | Get current workflow state |\n| `workflow_complete` | summary, status? | success, final_status | Mark workflow as complete/failed |\n\n### Execution Tools\n\n| Tool | Parameters | Returns | Purpose |\n|------|------------|---------|---------|\n| `execute_issue` | issue_id, agent_type?, model?, worktree_mode | execution_id, worktree_path, status | Start execution for an issue |\n| `execution_status` | execution_id | status, exit_code, error, summary, files_changed | Check execution status |\n| `execution_cancel` | execution_id, reason? | success, message | Cancel running execution |\n\n### Inspection Tools\n\n| Tool | Parameters | Returns | Purpose |\n|------|------------|---------|---------|\n| `execution_trajectory` | execution_id, max_entries? | entries[], summary | Get agent actions/tool calls |\n| `execution_changes` | execution_id, include_diff? | files[], summary, commits | Get code changes |\n\n## Worktree Modes\n\nThe orchestrator decides worktree isolation strategy:\n\n| Mode | Behavior | Use Case |\n|------|----------|----------|\n| `create_root` | Create new root worktree for entire workflow | First execution |\n| `use_root` | Use existing workflow worktree | Sequential execution |\n| `create_branch` | Create branch off base for parallel work | Parallel execution |\n| `use_branch` | Continue on existing branch | Follow-up execution |\n\n## Implementation Details\n\n### WorkflowMCPServer Class\n\n```typescript\nclass WorkflowMCPServer {\n  constructor(options: {\n    workflowId: string;\n    dbPath: string;\n    repoPath: string;\n  });\n\n  async start(): Promise<void>;  // Connect stdio transport\n  async stop(): Promise<void>;   // Cleanup\n}\n```\n\n### Tool Implementation Pattern\n\nEach tool file exports:\n```typescript\nexport const toolDefinitions: ToolDefinition[];\nexport function handleTool(\n  name: string,\n  args: Record<string, unknown>,\n  context: WorkflowMCPContext\n): Promise<ToolResult>;\n```\n\n### Context Object\n\n```typescript\ninterface WorkflowMCPContext {\n  workflowId: string;\n  db: Database.Database;\n  executionService: ExecutionService;\n  repoPath: string;\n}\n```\n\n## Integration with OrchestratorEngine\n\nThe orchestrator engine passes MCP config when spawning:\n\n```typescript\n// In orchestrator-engine.ts buildOrchestratorConfig()\nmcpServers: {\n  'sudocode-workflow': {\n    command: 'node',\n    args: [\n      path.join(__dirname, '../mcp/index.js'),\n      '--workflow-id', workflow.id,\n      '--db-path', this.config.dbPath,\n      '--repo-path', this.config.repoPath\n    ]\n  }\n}\n```\n\n## Error Handling\n\n- Invalid workflow ID → Return error, don't crash\n- Execution not found → Return descriptive error\n- Database errors → Log and return error to orchestrator\n- The MCP server should be resilient - errors in one tool shouldn't crash the server\n\n## Testing Strategy\n\nUnit tests for each tool:\n- `workflow.test.ts` - workflow_status, workflow_complete\n- `execution.test.ts` - execute_issue, execution_status, execution_cancel\n- `inspection.test.ts` - execution_trajectory, execution_changes\n\nIntegration test:\n- Full MCP protocol test with mock stdio\n\nParent spec: [[s-3g2y]]","priority":1,"archived":0,"archived_at":null,"created_at":"2025-12-03 11:23:50","updated_at":"2025-12-03 11:23:50","parent_id":null,"parent_uuid":null,"relationships":[],"tags":["mcp","phase-5b","workflow"]}
{"id":"s-12rm","uuid":"82c7c0a5-13a8-4551-88f8-639ee1c1b50d","title":"Orchestrator Workflow UI","file_path":"specs/s-12rm_orchestrator_workflow_ui.md","content":"# Orchestrator Workflow UI Specification\n\n## Overview\n\nDesign and implement the UI for agent-guided orchestrator workflows, enabling users to:\n1. **View** the orchestrator agent's trajectory (tool calls, decisions, wakeups)\n2. **Respond** to escalation requests (approve/reject/custom input)\n3. **Guide** the orchestrator through a chat-like interface\n\n**Parent Spec:** [[s-3i40]] (Workflow Management UI)\n\n---\n\n## Architecture\n\n### Data Flow\n\n```\nOrchestrator Agent (Claude Code execution)\n    ↓ (executes via MCP tools)\nWorkflowEventEmitter → WorkflowBroadcastService → WebSocket\n    ↓\nFrontend: WebSocketContext → useWorkflows → UI Components\n    ↓\nUser responds via EscalationPanel or GuidanceInput\n    ↓\nPOST /api/workflows/:id/escalation/respond\n    ↓\nWakeupService triggers orchestrator follow-up\n```\n\n### Key Backend Resources (Already Exist)\n- `orchestratorExecutionId` on Workflow - links to orchestrator's execution\n- `escalation_requested` / `escalation_resolved` workflow events\n- `POST /api/workflows/:id/escalation/respond` endpoint\n- Execution logs API for orchestrator trajectory\n\n### What's Missing\n1. `GET /api/workflows/:id/escalation` - fetch pending escalation\n2. Frontend components for escalation and orchestrator trajectory\n3. WebSocket event handling for `escalation_requested`\n\n---\n\n## Design Decisions\n\n| Decision | Choice | Rationale |\n|----------|--------|-----------|\n| Panel layout | Tab-based switching in right panel | Reuses existing split layout, allows quick switching between step details and orchestrator view |\n| Guidance availability | Always visible | Users can provide guidance anytime, not just on escalation |\n| Escalation notification | Toast with action button | Non-blocking notification that allows navigation to workflow |\n\n---\n\n## Components\n\n### OrchestratorTrajectory\n\nDisplay orchestrator execution logs with specialized formatting for workflow MCP tools.\n\n```typescript\ninterface OrchestratorTrajectoryProps {\n  executionId: string      // orchestratorExecutionId from workflow\n  workflowId: string\n  onEscalationResponse?: (response: EscalationResponse) => void\n}\n```\n\n**Features:**\n- Fetches logs via `useAgUiStream` (active) or `useExecutionLogs` (completed)\n- Specialized tool call formatting:\n  - `execute_issue` → \"Starting issue i-xxxx: Title\"\n  - `execution_status` → \"Checking execution...\"\n  - `escalate_to_user` → Highlighted escalation block\n  - `workflow_complete` → Summary display\n- Wakeup events as visual dividers\n- Inline escalation panel when pending\n\n### EscalationPanel\n\nRespond to orchestrator escalation requests.\n\n```typescript\ninterface EscalationPanelProps {\n  escalation: EscalationData\n  onRespond: (response: EscalationResponse) => void\n  isResponding?: boolean\n}\n```\n\n**Layout:**\n- Warning header \"Orchestrator Needs Input\"\n- Escalation message display\n- Radio options if provided\n- Custom feedback textarea\n- Action buttons: Approve, Reject, Send Response\n\n### OrchestratorGuidancePanel\n\nAlways-visible input for proactive user guidance.\n\n```typescript\ninterface OrchestratorGuidancePanelProps {\n  workflowId: string\n  orchestratorExecutionId: string\n  isOrchestratorRunning: boolean\n}\n```\n\n**Features:**\n- Sticky input at bottom of Orchestrator tab\n- Creates follow-up execution with user message\n- Visual status indicator (running vs waiting)\n\n---\n\n## WorkflowDetailPage Layout\n\n```\n┌─────────────────────────────────────────────────────────────┐\n│ Workflow: Auth Implementation                    [Controls] │\n├─────────────────────────────────────────────────────────────┤\n│  ┌─ DAG View ─────────────┐  ┌─[Step Details][Orchestrator]┐│\n│  │                        │  │                             ││\n│  │   [i-abc1] ●           │  │ ▶ execute_issue(i-abc1)     ││\n│  │      ↓                 │  │   Started \"Add auth...\"     ││\n│  │   [i-xyz2] ◐           │  │                             ││\n│  │      ↓                 │  │ ▶ escalate_to_user          ││\n│  │   [i-def3] ○           │  │   [EscalationPanel inline]  ││\n│  │                        │  ├─────────────────────────────┤│\n│  │                        │  │ [Guidance input - always]   ││\n│  └────────────────────────┘  └─────────────────────────────┘│\n└─────────────────────────────────────────────────────────────┘\n```\n\n**Tab behavior:**\n- \"Step Details\" tab: Shows WorkflowStepPanel when step selected\n- \"Orchestrator\" tab: Shows OrchestratorTrajectory + guidance input\n- Tab only visible when workflow has orchestratorExecutionId\n- Auto-switch to Orchestrator tab when escalation is pending\n\n---\n\n## API Additions\n\n### GET /api/workflows/:id/escalation\n\nFetch pending escalation for a workflow.\n\n```typescript\ninterface PendingEscalationResponse {\n  hasPendingEscalation: boolean\n  escalation?: EscalationData\n}\n```\n\n### Frontend API Methods\n\n```typescript\nworkflowsApi: {\n  getEscalation: (id: string) => Promise<PendingEscalationResponse>\n  respondToEscalation: (id: string, response: EscalationResponse) => Promise<void>\n}\n```\n\n---\n\n## Real-Time Updates\n\n### WebSocket Events\n\nHandle `workflow_escalation_requested` events:\n- Show toast notification with workflow title\n- Action button navigates to workflow detail\n- Auto-switch to Orchestrator tab\n\n### Query Invalidation\n\nInvalidate escalation query on:\n- `workflow_escalation_requested`\n- `workflow_escalation_resolved`\n","priority":1,"archived":0,"archived_at":null,"created_at":"2025-12-03 23:18:18","updated_at":"2026-01-07 00:56:12","parent_id":"s-3i40","parent_uuid":null,"relationships":[],"tags":["escalation","frontend","orchestrator","ui","workflow"]}
{"id":"s-3mdp","uuid":"bef878ef-66a0-4f0b-8977-b5e379b7ac35","title":"Safe Merge for Uncommitted Local Changes","file_path":"specs/s-3mdp_safe_merge_for_uncommitted_local_changes.md","content":"# Safe Merge for Uncommitted Local Changes\n\n## Problem\n\nWhen syncing worktree execution results back to the base branch, uncommitted local changes can be lost:\n\n1. **Squash/Preserve Sync**: Currently blocks if local working tree is dirty - user must stash/commit first\n2. **Stage Sync**: Allows dirty working tree but uses `fs.copyFileSync` for uncommitted worktree files, which **overwrites** local changes without any merge attempt\n\nThis creates a poor experience and potential data loss when users have local uncommitted work.\n\n## Solution\n\nImplement proper three-way merging for all file types when both local and worktree have uncommitted changes to the same file.\n\n### Merge Strategy by File Type\n\n| File Type | Merge Strategy |\n|-----------|----------------|\n| JSONL files (`.sudocode/*.jsonl`) | UUID-based merge via existing `merge-resolver` |\n| All other files | `git merge-file` three-way merge with conflict markers |\n\n### Behavior\n\n1. **No local changes to file** → Direct copy (current behavior, safe)\n2. **Local changes exist**:\n   - Check if file is JSONL → use merge-resolver (no conflict markers)\n   - Otherwise → use `git merge-file` for three-way merge\n   - If merge has conflicts → insert standard conflict markers, track file as conflicting\n3. **Return conflict info** → Include list of files with conflicts in result\n4. **User resolves** → Standard git conflict resolution workflow\n\n## Implementation\n\n### Backend Changes\n\n#### 1. Update `_copyUncommittedFiles` in `worktree-sync-service.ts`\n\n```typescript\nprivate async _copyUncommittedFiles(worktreePath: string): Promise<{\n  filesCopied: number;\n  filesWithConflicts: string[];\n}> {\n  const filesWithConflicts: string[] = [];\n  \n  for (const filePath of allFiles) {\n    const localHasChanges = this._hasLocalUncommittedChanges(filePath);\n    \n    if (!localHasChanges) {\n      // Safe to overwrite\n      fs.copyFileSync(srcPath, destPath);\n    } else if (this._isJSONLFile(filePath)) {\n      // JSONL merge\n      await this._mergeJSONLFiles(destPath, srcPath);\n    } else {\n      // Three-way merge for other files\n      const hasConflicts = await this._threeWayMergeFile(filePath, worktreeFilePath);\n      if (hasConflicts) {\n        filesWithConflicts.push(filePath);\n      }\n    }\n    \n    execSync(`git add ${filePath}`, ...);\n    filesCopied++;\n  }\n  \n  return { filesCopied, filesWithConflicts };\n}\n```\n\n#### 2. Add helper methods\n\n```typescript\n// Check if local file has uncommitted changes vs HEAD\nprivate _hasLocalUncommittedChanges(filePath: string): boolean {\n  try {\n    execSync(`git diff --quiet HEAD -- ${filePath}`, { cwd: this.repoPath });\n    return false; // No changes (exit 0)\n  } catch {\n    return true; // Has changes (exit 1)\n  }\n}\n\n// Three-way merge using git merge-file\nprivate async _threeWayMergeFile(\n  filePath: string, \n  worktreeFilePath: string\n): Promise<boolean> {\n  // 1. Get base content from HEAD\n  // 2. Write to temp file\n  // 3. Run: git merge-file <local> <base-temp> <worktree>\n  // 4. Return true if conflicts (exit code > 0)\n}\n\n// JSONL-specific merge using merge-resolver\nprivate async _mergeJSONLFiles(\n  localPath: string,\n  worktreePath: string\n): Promise<void> {\n  // 1. Read both files as JSONL entities\n  // 2. Use resolveEntities() to merge by UUID\n  // 3. Write merged result back to local path\n}\n```\n\n#### 3. Update `SyncResult` type\n\nAdd field to track which files have conflicts:\n```typescript\ninterface SyncResult {\n  // ... existing fields ...\n  filesWithConflicts?: string[];\n}\n```\n\n### Frontend Changes\n\n#### 1. Sync Preview Warning\n\nIn the sync preview UI, show a warning when:\n- Local working tree has uncommitted changes\n- Those changes overlap with files being synced from worktree\n\nWarning should be informational (yellow), not blocking:\n> \"Some files have local uncommitted changes that will be merged. Conflicts may require manual resolution.\"\n\n#### 2. Sync Result Display\n\nIf `filesWithConflicts.length > 0` after sync:\n- Show which files have conflicts\n- Provide guidance on resolution (edit files, remove markers, commit)\n\n## Files to Modify\n\n### Backend\n- `server/src/services/worktree-sync-service.ts` - Core merge logic\n- `@sudocode-ai/types` - Update `SyncResult` type if needed\n\n### Frontend\n- Sync preview component - Add warning for potential conflicts\n- Sync result display - Show files with conflicts\n\n## Testing\n\n1. **Unit tests** for `_threeWayMergeFile` and `_hasLocalUncommittedChanges`\n2. **Integration test**: Stage sync with overlapping uncommitted changes\n3. **Integration test**: JSONL merge with local uncommitted changes\n4. **Manual test**: Verify conflict markers are valid git format\n\n## Out of Scope\n\n- Auto-resolving non-JSONL conflicts (user must resolve manually)\n- Blocking sync on potential conflicts (warning only)\n- Changes to squash/preserve sync dirty-tree blocking (they create commits, so blocking is appropriate)","priority":2,"archived":0,"archived_at":null,"created_at":"2025-12-06 09:48:05","updated_at":"2025-12-06 09:48:05","parent_id":null,"parent_uuid":null,"relationships":[],"tags":["backend","frontend","merge","sync","worktree"]}
{"id":"s-5c0u","uuid":"5ef68036-be14-4479-91d2-7892ba18a193","title":"Workflow Resume/Persistence Without Schema Changes","file_path":"specs/s-5c0u_workflow_resume_persistence_without_schema_changes.md","content":"## Overview\n\nEnable workflows to survive server crashes and restarts by reconstructing in-memory state from existing database structures. This approach requires **zero schema changes** by leveraging existing tables and JSON payloads.\n\n## Problem Statement\n\nCurrently, both workflow engines lose critical in-memory state when the server crashes or restarts:\n\n### Sequential Engine (`activeWorkflows` Map)\n- `isPaused` / `isCancelled` flags\n- `currentExecutionId` for running step\n- The execution loop itself (Promise-based)\n\n### Orchestrator Engine (`WorkflowWakeupService`)\n- `pendingWakeups` Map (debounce timers)\n- `executionTimeouts` Map (timeout tracking)\n- `pendingAwaits` / `resolvedAwaits` Maps (await conditions)\n- `awaitTimeouts` Map (await timers)\n\n**Result:** Workflows get orphaned in \"running\" status with no way to resume automatically.\n\n## Key Insight\n\nAll in-memory state can be **derived from existing database structures**:\n\n| In-Memory State | Derivable From |\n|-----------------|----------------|\n| `isPaused` | `workflow.status === 'paused'` |\n| `isCancelled` | `workflow.status === 'cancelled'` |\n| `currentExecutionId` | `step.executionId` where `step.status === 'running'` |\n| Await conditions | `workflow_events.payload` with special markers |\n| Timeout deadlines | `workflow_events.payload.timeoutAt` |\n\n## Implementation Plan\n\n### 1. Sequential Engine Recovery\n\nAdd `recoverWorkflows()` method to `SequentialWorkflowEngine`:\n\n```typescript\nasync recoverWorkflows(): Promise<void> {\n  // 1. Query workflows WHERE status IN ('running', 'paused') \n  //    AND engineType = 'sequential'\n  \n  // 2. For each workflow:\n  //    a. Reconstruct activeWorkflows entry from DB state\n  //    b. Find step with status = 'running'\n  //    c. Check associated execution status:\n  //       - If execution 'running' but process dead → mark step failed\n  //       - If execution 'completed' → handle success (missed callback)\n  //       - If execution 'failed' → handle failure (missed callback)\n  //    d. Resume runExecutionLoop() if workflow.status = 'running'\n}\n```\n\n**Call site:** `ProjectManager.openProject()` after engine initialization.\n\n### 2. Await State Persistence (Wakeup Service)\n\nStore await conditions in `workflow_events.payload`:\n\n**On `registerAwait()`:**\n```typescript\n// Insert event with await metadata\nINSERT INTO workflow_events (id, workflow_id, type, payload, created_at)\nVALUES (awaitId, workflowId, 'orchestrator_wakeup', {\n  awaitType: 'pending',\n  eventTypes: [...],\n  executionIds: [...],\n  timeoutAt: 'ISO timestamp',\n  message: '...'\n}, now)\n```\n\n**On `resolveAwait()`:**\n```typescript\n// Mark event as processed\nUPDATE workflow_events SET processed_at = now WHERE id = awaitId\n```\n\n**On recovery:**\n```typescript\n// Query unprocessed await events\nSELECT * FROM workflow_events \nWHERE type = 'orchestrator_wakeup'\nAND processed_at IS NULL\nAND json_extract(payload, '$.awaitType') = 'pending'\n\n// Reconstruct pendingAwaits Map\n// Reschedule timeout timers (calculate remaining from timeoutAt)\n// Trigger immediate wakeup for expired awaits\n```\n\n### 3. Execution Timeout Persistence\n\nStore timeout deadline in `step_started` event payload:\n\n**On step start:**\n```typescript\nthis.recordEvent({\n  workflowId,\n  type: 'step_started',\n  stepId,\n  executionId,\n  payload: {\n    timeoutAt: new Date(Date.now() + timeoutMs).toISOString()\n  }\n});\n```\n\n**On recovery:**\n```typescript\n// Find running steps with timeout deadlines\nSELECT * FROM workflow_events \nWHERE type = 'step_started'\nAND processed_at IS NULL\nAND json_extract(payload, '$.timeoutAt') IS NOT NULL\n\n// For each:\n//   - Calculate remaining time\n//   - If positive: restart timeout timer\n//   - If expired: trigger timeout handler\n```\n\n### 4. Wakeup Debounce Recovery\n\nPending wakeups are stored as unprocessed `workflow_events`. On recovery:\n- Query all unprocessed events per workflow\n- If any exist, schedule a wakeup (respecting batch window)\n\n## Recovery Flow\n\n```\nServer Startup\n     │\n     ▼\nProjectManager.openProject()\n     │\n     ├──► markStaleExecutionsAsFailed() [existing]\n     │         └── Executions left in 'running' → 'failed'\n     │\n     ├──► SequentialWorkflowEngine.recoverWorkflows() [NEW]\n     │         ├── Reconstruct activeWorkflows from DB\n     │         ├── Handle interrupted steps\n     │         └── Resume execution loops\n     │\n     ├──► OrchestratorWorkflowEngine.recoverOrphanedWorkflows() [existing]\n     │\n     └──► WorkflowWakeupService.recoverState() [NEW]\n               ├── Reconstruct pendingAwaits from events\n               ├── Reschedule await timeouts\n               └── Reschedule execution timeouts\n```\n\n## Files to Modify\n\n1. **`server/src/workflow/engines/sequential-engine.ts`**\n   - Add `recoverWorkflows()` method\n   - Add helper to check if execution process is alive\n\n2. **`server/src/workflow/services/wakeup-service.ts`**\n   - Persist await registration to `workflow_events`\n   - Add `recoverState()` method\n   - Mark awaits processed on resolution\n\n3. **`server/src/services/project-manager.ts`**\n   - Call recovery methods during `openProject()`\n\n4. **`server/src/workflow/base-workflow-engine.ts`** (optional)\n   - Add shared recovery utilities\n\n## Edge Cases\n\n### Mid-Step Crash\n- Execution has `status = 'running'` but process is dead\n- **Detection:** Check if process/session exists\n- **Resolution:** Mark execution and step as failed, follow `onFailure` strategy\n\n### Worktree Consistency\n- Git operations may have been interrupted\n- **Detection:** Check for lock files, merge conflicts\n- **Resolution:** Clean up locks, reset to known state if needed\n\n### Duplicate Recovery Prevention\n- Multiple server instances could try to recover same workflow\n- **Solution:** Atomic \"claim\" via UPDATE...WHERE pattern or skip if already running\n\n### Expired Awaits on Recovery\n- Await timeout passed while server was down\n- **Resolution:** Trigger immediate wakeup with 'timeout' reason\n\n## Testing Strategy\n\n### Unit Tests\n- `recoverWorkflows()` with various step/execution states\n- `recoverState()` with pending awaits and timeouts\n- Timeout recalculation edge cases\n\n### Integration Tests\n- Simulate crash by killing server mid-workflow\n- Verify workflow resumes correctly on restart\n- Verify await conditions are honored after recovery\n\n### Chaos Tests (optional)\n- Random crashes during different workflow phases\n- Verify no data corruption or orphaned state\n\n## Success Criteria\n\n1. Sequential workflows resume after server restart\n2. Orchestrator awaits persist and fire correctly after restart\n3. Execution timeouts continue to work after restart\n4. No database schema changes required\n5. Backward compatible with existing workflows","priority":1,"archived":0,"archived_at":null,"created_at":"2025-12-06 09:54:40","updated_at":"2025-12-06 09:54:40","parent_id":null,"parent_uuid":null,"relationships":[],"tags":["recovery","resilience","server","workflow"]}
{"id":"s-411l","uuid":"1b410c54-2d79-4a7b-bd3c-a44796336093","title":"Integration Framework for Third-Party Data Sources","file_path":"specs/s-411l_integration_framework_for_third_party_data_sources.md","content":"# Integration Framework for Third-Party Data Sources\n\n## Overview\n\nDesign a generic linking and syncing framework for third-party data source integrations. This enables sudocode to connect with external systems like Jira, Beads, Spec-kit, and OpenSpec for bidirectional synchronization of specs and issues.\n\n## Goals\n\n1. **Unified linking model** - Store external references directly on Spec/Issue entities\n2. **Provider adapter pattern** - Standard interface for all integrations\n3. **Auto-sync by default** - File watchers and webhooks for real-time sync\n4. **Conflict resolution** - Timestamp-based resolution with audit trail\n\n## Target Integrations\n\n| Provider | Type | Sync Method | Entity Mapping |\n|----------|------|-------------|----------------|\n| **Jira** | REST API | Webhooks + polling | Jira Issue → sudocode Issue |\n| **Beads** | JSONL file | File watcher | Beads Issue → sudocode Issue |\n| **Spec-kit** | Markdown | Directory watcher | spec.md → Spec, tasks.md → Issues |\n| **OpenSpec** | Markdown | Directory watcher | specs/ → Specs, changes/ → Issues |\n\n---\n\n## Data Model\n\n### ExternalLink (on Spec/Issue)\n\n```typescript\ninterface ExternalLink {\n  provider: 'jira' | 'beads' | 'spec-kit' | 'openspec';\n  external_id: string;           // Provider-specific ID\n  external_url?: string;         // Optional URL for display\n  sync_enabled: boolean;\n  sync_direction: 'inbound' | 'outbound' | 'bidirectional';\n  last_synced_at?: string;       // ISO timestamp\n  external_updated_at?: string;  // For conflict detection\n  metadata?: Record<string, unknown>;\n}\n```\n\n### Integration Configuration\n\nExtend `.sudocode/config.json`:\n\n```json\n{\n  \"integrations\": {\n    \"jira\": {\n      \"enabled\": true,\n      \"instance_url\": \"https://example.atlassian.net\",\n      \"auth_type\": \"basic\",\n      \"credentials_env\": \"JIRA_API_TOKEN\",\n      \"default_sync_direction\": \"bidirectional\"\n    },\n    \"beads\": {\n      \"enabled\": true,\n      \"path\": \"../other-project/.beads\",\n      \"auto_sync\": true\n    }\n  }\n}\n```\n\n---\n\n## Provider Adapter Interface\n\n```typescript\ninterface IntegrationProvider {\n  readonly name: string;\n  readonly supportsWatch: boolean;\n  readonly supportsPolling: boolean;\n\n  // Lifecycle\n  initialize(config: IntegrationConfig): Promise<void>;\n  validate(): Promise<{ valid: boolean; errors: string[] }>;\n  dispose(): Promise<void>;\n\n  // Entity operations\n  fetchEntity(externalId: string): Promise<ExternalEntity | null>;\n  searchEntities(query?: string): Promise<ExternalEntity[]>;\n  createEntity(entity: Partial<Spec | Issue>): Promise<string>;\n  updateEntity(externalId: string, entity: Partial<Spec | Issue>): Promise<void>;\n\n  // Change detection\n  getChangesSince(timestamp: Date): Promise<ExternalChange[]>;\n  startWatching?(callback: (changes: ExternalChange[]) => void): void;\n  stopWatching?(): void;\n\n  // Field mapping\n  mapToSudocode(external: ExternalEntity): { spec?: Partial<Spec>; issue?: Partial<Issue> };\n  mapFromSudocode(entity: Spec | Issue): Partial<ExternalEntity>;\n}\n```\n\n---\n\n## Sync Coordinator\n\nOrchestrates sync across all providers:\n\n- Registers and initializes providers based on config\n- Starts file watchers / webhook listeners for auto-sync\n- Handles inbound changes (external → sudocode)\n- Handles outbound changes (sudocode → external)\n- Resolves conflicts using configured strategy (newest-wins default)\n\n---\n\n## MCP Tools\n\n| Tool | Description |\n|------|-------------|\n| `list_integrations` | List configured integrations and sync status |\n| `link_external` | Link sudocode entity to external entity |\n| `unlink_external` | Remove external link |\n| `search_external` | Search entities in external system |\n| `import_external` | Import external entity as new sudocode entity |\n| `sync_integrations` | Manual sync trigger |\n\n---\n\n## File Structure\n\n```\ncli/src/integrations/\n├── types.ts                    # Core interfaces\n├── base-provider.ts            # BaseIntegrationProvider class\n├── sync-coordinator.ts         # SyncCoordinator class\n├── providers/\n│   ├── jira.ts\n│   ├── beads.ts\n│   ├── spec-kit.ts\n│   └── openspec.ts\n└── utils/\n    ├── conflict-resolver.ts\n    └── field-mapper.ts\n\nserver/src/services/\n└── integration-sync-service.ts\n\ntypes/src/\n├── index.d.ts                  # ExternalLink type\n└── integrations.d.ts           # Provider config types\n```\n\n---\n\n## Implementation Phases\n\n### Phase 1: Core Framework\n- Add `ExternalLink` type to entities\n- Implement `IntegrationProvider` interface\n- Implement `SyncCoordinator`\n- Add basic MCP tools\n\n### Phase 2: Beads Provider\n- Implement `BeadsProvider` (simplest - same JSONL architecture)\n- File watcher on `issues.jsonl`\n- Test bidirectional sync\n\n### Phase 3: File-based Providers\n- Implement `SpecKitProvider` with markdown parsing\n- Implement `OpenSpecProvider` with markdown parsing\n- Directory watchers for auto-sync\n\n### Phase 4: Jira Provider\n- Implement `JiraProvider` with REST API\n- Webhook endpoint for real-time sync\n- OAuth2 authentication (optional)\n\n### Phase 5: Server Integration\n- `IntegrationSyncService` for auto-sync on startup\n- REST endpoints for manual triggers\n\n---\n\n## Success Criteria\n\n1. External links persist on specs/issues in JSONL\n2. Auto-sync detects changes within 5 seconds (file-based) or real-time (webhooks)\n3. Conflict resolution works correctly (newest-wins)\n4. MCP tools enable agents to link and sync entities\n5. All four providers implemented and tested","priority":1,"archived":0,"archived_at":null,"created_at":"2025-12-11 08:23:11","updated_at":"2025-12-11 08:23:11","parent_id":null,"parent_uuid":null,"relationships":[],"tags":["architecture","beads","integrations","jira","openspec","spec-kit","sync"]}
{"id":"s-3igd","uuid":"f6320f56-f16e-494c-8b23-3f51c051aa02","title":"Spec-Kit Integration Plugin","file_path":"specs/s-3igd_spec_kit_integration_plugin.md","content":"## Overview\n\nCreate an integration plugin for spec-kit that syncs its markdown-based specs, plans, and tasks to sudocode's specs and issues. Follows the established pattern from `plugins/integration-beads/`.\n\n## Requirements\n\n### Sync Direction\n- Configurable sync direction using existing `default_sync_direction` config option\n- Support bidirectional, one-way-in, and one-way-out modes\n\n### Entity Mapping\n\n| spec-kit | → | sudocode | Relationship |\n|----------|---|----------|--------------|\n| `spec.md` | → | Spec | Root feature spec |\n| `plan.md` | → | Spec | `implements` → spec.md |\n| Individual tasks in `tasks.md` | → | Issue | `implements` → plan.md |\n| `research.md` | → | Spec | `references` → plan.md |\n| `data-model.md` | → | Spec | `references` → plan.md |\n| `contracts/*.md` | → | Spec | `references` → plan.md |\n| `constitution.md` | → | Spec | Root project spec |\n\n### Parsing Requirements\n\n#### spec.md\n- Extract title from `# Feature Specification: [FEATURE NAME]`\n- Extract metadata: Feature Branch, Status, Created date\n- Store full markdown content\n\n#### plan.md\n- Extract title from `# Implementation Plan: [FEATURE]`\n- Extract metadata: Branch, Spec link\n- Create `implements` relationship to parent spec.md\n\n#### tasks.md\n- Parse individual checkbox items: `- [ ] T001 [P?] [US?] Description`\n- Each task becomes a separate Issue\n- Track: completed status (`[ ]`/`[x]`), parallelizable marker `[P]`, user story `[US1]`, phase\n- Create `implements` relationship to plan.md\n\n### ID Generation\n- Deterministic path-based IDs for stability across syncs\n- Spec prefix: `sk-` (e.g., `sk-001-spec`, `sk-001-plan`)\n- Task prefix: `skt-` (e.g., `skt-001-T001`)\n\n### File Watching\n- Watch `.specify/specs/**/*.md` for changes\n- Content-based change detection using hash comparison\n- Support both polling and real-time watching modes\n\n### Outbound Sync\n- Update checkbox status in tasks.md when issue status changes\n- Update spec.md title/status when spec changes in sudocode\n\n## Configuration\n\n```typescript\ninterface SpecKitOptions {\n  path: string;                        // \".specify\"\n  spec_prefix?: string;                // \"sk\"\n  task_prefix?: string;                // \"skt\"\n  include_supporting_docs?: boolean;   // true\n  include_constitution?: boolean;      // true\n}\n```\n\n## File Structure\n\n```\nplugins/integration-speckit/\n├── package.json\n├── tsconfig.json\n├── vitest.config.ts\n├── src/\n│   ├── index.ts                    # SpecKitPlugin + SpecKitProvider\n│   ├── parser/\n│   │   ├── spec-parser.ts\n│   │   ├── plan-parser.ts\n│   │   ├── tasks-parser.ts\n│   │   └── supporting-docs.ts\n│   ├── writer/\n│   │   ├── spec-writer.ts\n│   │   └── tasks-writer.ts\n│   ├── id-generator.ts\n│   ├── relationship-mapper.ts\n│   └── watcher.ts\n└── tests/\n```\n\n## Acceptance Criteria\n\n- [ ] Plugin implements `IntegrationPlugin` and `IntegrationProvider` interfaces\n- [ ] Correctly parses spec.md, plan.md, tasks.md formats\n- [ ] Individual tasks in tasks.md become separate sudocode issues\n- [ ] Relationships are correctly established (implements, references)\n- [ ] File watcher detects changes in .specify directory\n- [ ] Outbound sync updates task checkboxes when issues closed\n- [ ] Configuration options work as specified\n- [ ] Unit tests for parsers, writers, and ID generation\n- [ ] Integration tests for full sync flow","priority":2,"archived":0,"archived_at":null,"created_at":"2025-12-12 09:15:35","updated_at":"2025-12-12 09:15:35","parent_id":null,"parent_uuid":null,"relationships":[],"tags":["integration","plugin","spec-kit"]}
{"id":"s-455l","uuid":"aacdb856-8249-4093-b632-7450ba2994ff","title":"OpenSpec Integration Plugin","file_path":"specs/s-455l_openspec_integration_plugin.md","content":"## Overview\n\nCreate an integration plugin for OpenSpec that syncs its markdown-based specs and change proposals to sudocode's specs and issues. Follows the established pattern from `plugins/integration-speckit/` (preferred reference) and `plugins/integration-beads/`.\n\n## Implementation References\n\nThe spec-kit integration (`plugins/integration-speckit/`) provides a comprehensive template for this implementation. Key analogous components:\n\n| spec-kit Component | OpenSpec Equivalent | Notes |\n|-------------------|---------------------|-------|\n| `src/index.ts` | `src/index.ts` | Plugin + Provider pattern, ~1400 lines |\n| `src/parser/spec-parser.ts` | `src/parser/spec-parser.ts` | Parse spec.md format |\n| `src/parser/plan-parser.ts` | `src/parser/change-parser.ts` | Parse proposal.md (similar structure) |\n| `src/parser/tasks-parser.ts` | `src/parser/tasks-parser.ts` | Checkbox parsing reusable |\n| `src/id-generator.ts` | `src/id-generator.ts` | Path-based deterministic IDs |\n| `src/watcher.ts` | `src/watcher.ts` | Chokidar + hash-based change detection |\n| `src/relationship-mapper.ts` | N/A | OpenSpec uses delta directories instead |\n\n**Key patterns to copy from spec-kit:**\n- `SpecKitProvider` class structure (implements `IntegrationProvider`)\n- `validateConfig()` and `testConnection()` implementations\n- `searchEntities()` directory scanning pattern\n- `getChangesSince()` hash-based change detection\n- Entity conversion helpers (`specToExternalEntity`, `taskToExternalEntity`)\n- `ExternalEntity.relationships` for automatic relationship creation\n\n## Requirements\n\n### Sync Direction\n- **Inbound only** - OpenSpec is the source of truth\n- sudocode mirrors OpenSpec data for AI context and tracking\n\n### Entity Mapping\n\n| OpenSpec | → | sudocode | Relationship |\n|----------|---|----------|--------------| \n| `openspec/specs/[capability]/spec.md` | → | Spec | Root capability spec |\n| `openspec/changes/[name]/` (active) | → | Issue | `implements` → target spec |\n| `openspec/changes/archive/YYYY-MM-DD-[name]/` | → | Issue (closed, archived) | Status change on archive |\n\nTasks in `tasks.md` remain as markdown checklist in issue content (not separate issues).\n\n### Parsing Requirements\n\n#### specs/[capability]/spec.md\n- Extract title from `# Title` heading\n- Extract Purpose section (`## Purpose`)\n- Parse requirements: `### Requirement: Name` headings\n- Parse scenarios: `#### Scenario: Description` with GIVEN/WHEN/THEN format\n- Store full markdown content\n\n#### changes/[name]/\n- Scan directory for `proposal.md`, `tasks.md`, `design.md`\n- Extract from proposal.md: `## Why`, `## What Changes`, `## Impact` sections\n- Parse tasks.md checkboxes: `- [ ]` and `- [x]` items\n- Calculate task completion percentage\n- Detect affected specs from `changes/[name]/specs/[cap]/` delta directories\n\n### ID Generation\n- Deterministic path-based IDs for stability across syncs\n- Spec prefix: `os-` (e.g., `os-a1b2` from hash of \"openspec-spec-cli-init\")\n- Change prefix: `osc-` (e.g., `osc-c3d4` from hash of \"openspec-change-add-feature\")\n\n### Archive Detection\nWhen a change moves from `changes/[name]/` to `changes/archive/YYYY-MM-DD-[name]/`:\n- Detect as status change (open → closed), not delete + create\n- Set `status: closed` and `archived: true` on corresponding issue\n- Preserve `archived_at` timestamp from directory name\n\n### File Watching\n- Watch `openspec/specs/**/*.md` for spec changes\n- Watch `openspec/changes/*/` for change directory additions/modifications\n- Watch `openspec/changes/archive/*/` for archive detection\n- Hash-based change detection to avoid false positives\n- Support both polling and real-time watching modes\n\n### Relationships\n- Parse delta directories `changes/[name]/specs/[cap]/` to identify affected specs\n- Create `implements` relationship from issue (change) to spec (capability)\n\n## Configuration\n\n```typescript\ninterface OpenSpecOptions {\n  /** Path to openspec directory (relative to project root) */\n  path: string;\n  /** Prefix for spec IDs (default: \"os\") */\n  spec_prefix?: string;\n  /** Prefix for change/issue IDs (default: \"osc\") */\n  change_prefix?: string;\n  /** Whether to track archived changes (default: true) */\n  track_archived?: boolean;\n}\n```\n\nExample config.json:\n```json\n{\n  \"integrations\": {\n    \"openspec\": {\n      \"enabled\": true,\n      \"plugin\": \"@sudocode-ai/integration-openspec\",\n      \"auto_sync\": true,\n      \"default_sync_direction\": \"inbound\",\n      \"options\": {\n        \"path\": \"openspec\",\n        \"spec_prefix\": \"os\",\n        \"change_prefix\": \"osc\",\n        \"track_archived\": true\n      }\n    }\n  }\n}\n```\n\n## File Structure\n\n```\nplugins/integration-openspec/\n├── package.json                 # Copy from spec-kit, update names\n├── tsconfig.json                # Copy from spec-kit\n├── vitest.config.ts             # Copy from spec-kit\n├── src/\n│   ├── index.ts                 # OpenSpecPlugin + OpenSpecProvider (main file)\n│   ├── parser/\n│   │   ├── index.ts             # Re-export all parsers\n│   │   ├── spec-parser.ts       # Parse specs/[cap]/spec.md\n│   │   ├── change-parser.ts     # Parse changes/[name]/ directories\n│   │   ├── tasks-parser.ts      # Parse tasks.md checkboxes (reuse from spec-kit)\n│   │   └── markdown-utils.ts    # Copy from spec-kit (PATTERNS, extractTitle, etc.)\n│   ├── id-generator.ts          # Path-based deterministic IDs\n│   └── watcher.ts               # Directory watcher (adapt from spec-kit)\n└── tests/\n    ├── parser/\n    │   ├── spec-parser.test.ts\n    │   ├── change-parser.test.ts\n    │   └── tasks-parser.test.ts\n    ├── id-generator.test.ts\n    ├── watcher.test.ts\n    └── provider.test.ts         # Full provider lifecycle tests\n```\n\n**Files to copy/adapt from spec-kit:**\n- `package.json` - Update package name and description\n- `tsconfig.json` - Copy as-is\n- `vitest.config.ts` - Copy as-is\n- `src/parser/markdown-utils.ts` - Copy as-is (PATTERNS, extractTitle, etc.)\n- `src/parser/tasks-parser.ts` - Reuse checkbox parsing logic\n- `src/watcher.ts` - Adapt for OpenSpec directory structure\n\n## Field Mapping\n\n### OpenSpec Spec → sudocode Spec\n\n| OpenSpec | sudocode Spec |\n|----------|---------------|\n| capability dir name | Used in ID generation |\n| H1 title | `title` |\n| Full markdown | `content` |\n| \"specs/[cap]/spec.md\" | `external_links[].external_id` |\n\n### OpenSpec Change → sudocode Issue\n\n| OpenSpec | sudocode Issue |\n|----------|----------------|\n| change dir name | Used in ID generation |\n| proposal.md \"What Changes\" | `title` |\n| Combined proposal + tasks.md | `content` |\n| active vs archive | `status` (open/closed) |\n| archive date prefix | `archived_at` |\n\n## Acceptance Criteria\n\n- [ ] Plugin implements `IntegrationPlugin` and `IntegrationProvider` interfaces\n- [ ] Correctly parses OpenSpec spec.md format (requirements, scenarios)\n- [ ] Correctly parses change directories (proposal, tasks, delta specs)\n- [ ] Archive detection closes and archives corresponding issues\n- [ ] Deterministic IDs are stable across syncs\n- [ ] File watcher detects changes in openspec directory\n- [ ] Relationships created between changes and affected specs\n- [ ] Unit tests for parsers and ID generation\n- [ ] Integration tests for provider lifecycle\n","priority":2,"archived":0,"archived_at":null,"created_at":"2025-12-12 09:59:15","updated_at":"2025-12-16T21:47:16.533Z","parent_id":null,"parent_uuid":null,"relationships":[{"from":"s-455l","from_type":"spec","to":"s-411l","to_type":"spec","type":"references"}],"tags":["integration","openspec","plugin"]}
{"id":"s-guo4","uuid":"86be78b2-b10c-4784-ab61-74463053ae86","title":"YAML-Based Multi-Line Text Merging for JSONL","file_path":"specs/s-guo4_yaml_based_multi_line_text_merging_for_jsonl.md","content":"# YAML-Based Multi-Line Text Merging for JSONL\n\n[[s-3mdp]]{ related }\n\n## Problem Statement\n\nThe current JSONL merge resolver (`cli/src/merge-resolver.ts`) already handles entity-level merging with UUID-based deduplication and metadata merging. However, it has a **critical limitation with multi-line text fields**:\n\n### The Real Problem: Multi-Line Scalar Fields\n\nWhen two agents edit different parts of the same multi-line text field (e.g., spec `description` or `content`), the entire field is treated as a single atomic string, causing unnecessary conflicts.\n\n#### Example: Spec Description Conflict\n\n```jsonl\nBase:\n{\"id\":\"s-1\",\"description\":\"## Overview\\nThis is paragraph 1.\\n\\n## Details\\nThis is paragraph 2.\"}\n\nBranch A (Agent 1 edits Overview):\n{\"id\":\"s-1\",\"description\":\"## Overview\\nThis is paragraph 1 with changes from Agent 1.\\n\\n## Details\\nThis is paragraph 2.\"}\n\nBranch B (Agent 2 edits Details):\n{\"id\":\"s-1\",\"description\":\"## Overview\\nThis is paragraph 1.\\n\\n## Details\\nThis is paragraph 2 with changes from Agent 2.\"}\n```\n\n**Current Result:**\n\n```\n❌ Full conflict - entire description field conflicts\nUser must manually merge the two versions\n```\n\n**What we want:**\n\n```\n✅ Auto-merged description:\n\"## Overview\\nThis is paragraph 1 with changes from Agent 1.\\n\\n## Details\\nThis is paragraph 2 with changes from Agent 2.\"\n```\n\nBoth agents' changes preserved because they edited different lines!\n\n## Current Merge Resolver Capabilities\n\nThe existing `cli/src/merge-resolver.ts` already provides:\n\n1. ✅ **UUID-based deduplication** - Groups entities by UUID\n1. ✅ **Metadata merging** - Unions relationships, tags, feedback arrays\n1. ✅ **Timestamp prioritization** - Keeps most recent for identical UUID+ID\n1. ✅ **Hash collision handling** - Renames duplicate IDs from different UUIDs\n1. ✅ **Three-way merge support** - `mergeThreeWay(base, ours, theirs)`\n\n**Gap:** All text fields (title, description, content) are treated as **opaque strings**. No line-level merging within these fields.\n\n## Proposed Solution: YAML Multi-Line String Expansion\n\nUse **YAML's multi-line string syntax** as an intermediate representation to enable git's line-based three-way merge **within** text fields.\n\n### Core Insight\n\nYAML supports multi-line strings with explicit line breaks preserved:\n\n```yaml\n# Literal style (| preserves newlines)\ndescription: |\n  ## Overview\n  This is paragraph 1 with changes from Agent 1.\n\n  ## Details\n  This is paragraph 2 with changes from Agent 2.\n```\n\nWhen git performs three-way merge on YAML:\n\n- Line 2 (paragraph 1) changed by Agent 1 → use Agent 1's version\n- Line 5 (paragraph 2) changed by Agent 2 → use Agent 2's version\n- **Auto-merge successful!**\n\n### Universal Three-Way Merge Strategy\n\n**Key architectural decision:** ALL merge operations should use the same three-way merge approach, even when only two versions are available.\n\n**For true 3-way scenarios** (git merge driver, worktree sync):\n\n- base = merge base commit\n- ours = current branch version\n- theirs = incoming branch version\n\n**For 2-way scenarios** (merging local + worktree files, resolving conflict markers):\n\n- base = **empty array** (treat as if both versions started from nothing)\n- ours = first set of changes (e.g., local working copy)\n- theirs = second set of changes (e.g., worktree version)\n\n**Why this works:**\n\n- Git's three-way merge with empty base accepts all changes from both sides\n- Metadata (tags, relationships, feedback) gets unioned\n- Text field changes get merged line-by-line via YAML expansion\n- Same YAML expansion strategy works for both scenarios\n- Single code path = simpler, more maintainable\n\n**Eliminates the need for:**\n\n- Separate `resolveEntities` function for 2-way merges\n- Different merge logic paths\n- Manual conflict marker parsing without base version\n\n### High-Level Flow (Universal 3-Way Merge)\n\n```\nENTRY POINT: Any merge scenario (git driver, worktree sync, manual resolution)\n  ↓\nIdentify merge scenario:\n  - True 3-way: base from merge-base commit, ours from current branch, theirs from incoming branch\n  - Simulated 3-way: base = empty array [], ours = first version, theirs = second version\n  ↓\nLoad entities from all three versions (base, ours, theirs)\n  - For simulated 3-way, base = []\n  - Parse JSONL into entity arrays\n  ↓\n**METADATA MERGE FIRST** (critical step):\n  - For each UUID, merge metadata from base/ours/theirs\n  - Union of tags, relationships, feedback\n  - Apply merged metadata to all three versions\n  - Eliminates metadata conflicts before YAML conversion\n  ↓\nConvert each entity to YAML with multi-line text expansion:\n  - Multi-line fields (description, content) → literal style (|)\n  - Arrays (already merged) → block style (- items)\n  - Simple scalars (id, title, status) → plain style\n  ↓\nRun git merge-file (3-way merge) on YAML versions\n  - For simulated 3-way with empty base, git accepts all changes from both sides\n  ↓\nGit automatically resolves:\n  ✅ Different lines in multi-line text fields (arrays already merged)\n  ✅ Different simple field changes\n  ✅ All changes when base is empty (simulated 3-way)\n  ↓\nRemaining conflicts: same line/field changed differently\n  ↓\nApply \"latest-wins\" (by updated_at) to conflicts\n  ↓\nConvert YAML back to JSON\n  ↓\nWrite to JSONL (sorted by created_at)\n```\n\n**Key Improvements:**\n\n- **Single code path** for all merge scenarios\n- **Empty base simulation** enables 3-way merge for 2-way scenarios\n- **Metadata merged first** eliminates a whole class of conflicts\n- **YAML expansion** handles text field line-level merging\n\n## Key Abstractions\n\n### 1\\. **Metadata Merger (Applied First)**\n\n**Purpose:** Union metadata arrays from all versions before YAML processing.\n\n**Strategy:**\n\n- **Input:** base, ours, theirs entities\n- **Process:** Union relationships, tags, feedback (existing `mergeMetadata` function)\n- **Output:** Canonical metadata to apply to all three versions\n- **Effect:** Eliminates metadata conflicts, simplifies YAML merge\n\n### 2\\. **JSONL-to-YAML Converter with Multi-Line Support**\n\n**Purpose:** Transform JSONL entities to YAML format with proper multi-line text handling.\n\n**Text Field Strategy:**\n\n- **Single-line text** (< 80 chars, no newlines): Plain YAML string\n  ```yaml\n  title: OAuth Authentication System\n  ```\n- **Multi-line text** (contains `\\n`): Literal style (`|`)\n  ```yaml\n  description: |\n    ## Overview\n    First paragraph.\n    ## Details\n    Second paragraph.\n  ```\n\n**Requirements:**\n\n- **Deterministic**: Same JSON → same YAML always\n- **Canonical formatting**: 2-space indentation, consistent style\n- **Preserves structure**: All fields, nested objects, arrays\n- **Line-break preservation**: `\\n` in JSON → actual line breaks in YAML\n\n**Input:** JSON object (Issue or Spec entity) **Output:** YAML string (multi-line, formatted)\n\n### 3\\. **YAML-to-JSONL Converter**\n\n**Purpose:** Transform YAML back to JSON, collapsing multi-line strings.\n\n**Requirements:**\n\n- **Lossless round-trip**: JSON → YAML → JSON preserves all data\n- **Line-break restoration**: YAML line breaks → `\\n` in JSON strings\n- **Type preservation**: Strings, numbers, booleans, nulls, arrays, objects\n\n**Input:** YAML string **Output:** JSON object\n\n### 4\\. **Git Three-Way Merge Wrapper**\n\n**Purpose:** Execute git's merge-file on YAML representations.\n\n**Interface:**\n\n- **Input:** base (YAML), ours (YAML), theirs (YAML)\n- **Output:** merged (YAML) + conflict status\n- **Uses:** `git merge-file` command or library\n\n**Behavior:**\n\n- Clean merge → returns merged YAML\n- Conflicts → returns YAML with conflict markers\n\n### 5\\. **Conflict Resolver**\n\n**Purpose:** Apply latest-wins strategy to remaining conflicts.\n\n**Strategy:**\n\n1. Parse YAML conflict markers\n1. Extract conflicting values\n1. Compare `updated_at` timestamps\n1. Choose value from entity with newer timestamp\n1. Replace conflict markers\n\n**Note:** Conflicts at this stage are genuine - same line changed differently by both agents.\n\n## Merge Strategy by Field Type\n\n### Multi-Line Text Fields (description, content)\n\n**Current behavior (JSON):**\n\n- Entire field is one string\n- Any change → full field conflict\n\n**New behavior (YAML literal style):**\n\n- Each line is separate in git's view\n- Line 1 changed by A, Line 3 changed by B → auto-merge\n- Same line changed differently → conflict → latest-wins\n\n### Array Fields (relationships, tags, feedback)\n\n**New behavior (MERGED FIRST):**\n\n- Arrays are merged using `mergeMetadata` **before** YAML conversion\n- All three versions get the same arrays (union of unique items)\n- No array conflicts in YAML merge\n- YAML just preserves the already-merged arrays\n\n**YAML block style (for already-merged arrays):**\n\n```yaml\nrelationships:\n  - from: i-123\n    to: s-456\n    type: implements\n  - from: i-123\n    to: i-789\n    type: blocks\n```\n\n### Simple Scalar Fields (id, uuid, title, status, priority)\n\n**YAML plain style:**\n\n```yaml\nid: s-abc123\ntitle: OAuth Authentication\nstatus: in_progress\npriority: 1\n```\n\n**Git behavior:**\n\n- Only ours changed → use ours\n- Only theirs changed → use theirs\n- Both changed differently → conflict → latest-wins\n\n### Nested Objects (location\\_anchor, feedback\\_anchor)\n\n**YAML nested structure:**\n\n```yaml\nlocation_anchor:\n  line: 42\n  text: example text\n  section: Overview\n```\n\n**Git behavior:**\n\n- Different nested fields changed → auto-merge\n- Same nested field changed → conflict → latest-wins\n\n## Implementation Details\n\n### Universal Three-Way Merge Function\n\n**Purpose:** Single merge function that handles ALL merge scenarios (true 3-way and simulated 3-way).\n\n**Function signature:**\n\n```typescript\nmergeThreeWay<T extends JSONLEntity>(\n  base: T[], // Can be empty array [] for simulated 3-way\n  ours: T[],\n  theirs: T[]\n): ResolvedResult<T>\n```\n\n**Alternative signature** (making base optional explicit):\n\n```typescript\nmergeThreeWay<T extends JSONLEntity>(\n  ours: T[],\n  theirs: T[],\n  base?: T[] // Optional - defaults to [] if not provided\n): ResolvedResult<T>\n```\n\n**Key insight:** By accepting `base` as optional or allowing empty array, this function handles both scenarios:\n\n- **True 3-way merge:** Pass actual base commit entities from merge-base\n- **Simulated 3-way merge:** Pass empty array `[]` or omit (for 2-way scenarios)\n\n### mergeThreeWay Implementation\n\n**Current implementation issues:**\n\n- Calls `mergeMetadata` AFTER YAML merge\n- Calls `resolveEntities` at the end which is mostly a no-op\n- Confusing flow with metadata \"rescue\" after the fact\n- Doesn't leverage YAML expansion for text field merging\n- Separate code path for 2-way scenarios\n\n**New unified approach:**\n\n```typescript\n// High-level approach for universal mergeThreeWay:\n// Handles both true 3-way (with base from merge-base) and simulated 3-way (base = [])\n\n// 0. Normalize base parameter\n//    - If base is undefined or not provided, default to [] (empty array)\n//    - This allows both signatures to work\n\n// 1. Group entities by UUID for all three versions (base, ours, theirs)\n//    - Create Map<uuid, entity> for each version\n//    - For simulated 3-way, base map will be empty\n\n// 2. Collect all unique UUIDs across all three versions\n//    - Union of UUIDs from base, ours, and theirs\n//    - For simulated 3-way, only ours and theirs UUIDs\n\n// 3. For each UUID:\n//    a. Collect versions for this UUID:\n//       - baseEntity = base map[uuid] or undefined\n//       - ourEntity = ours map[uuid] or undefined\n//       - theirEntity = theirs map[uuid] or undefined\n//\n//    b. If at least ours OR theirs exists:\n//       - **STEP 1: Merge metadata FIRST**\n//         - Collect all available versions: [baseEntity, ourEntity, theirEntity].filter(exists)\n//         - Call mergeMetadata(versions) to get canonical metadata\n//         - Apply merged metadata (tags, relationships, feedback) to all versions\n//         - For simulated 3-way with empty base, effectively unions metadata from ours + theirs\n//\n//       - **STEP 2: Convert to YAML**\n//         - Convert all three versions with merged metadata to YAML\n//         - For simulated 3-way, base YAML will be empty string\n//         - Now only text fields differ between versions\n//\n//       - **STEP 3: Run git merge-file**\n//         - Use mergeYaml(baseYaml, oursYaml, theirsYaml)\n//         - For simulated 3-way: empty base means git accepts all changes from both sides\n//         - For true 3-way: git performs standard 3-way merge\n//         - Git handles line-level text merging via YAML expansion\n//\n//       - **STEP 4: Resolve remaining conflicts**\n//         - If conflicts exist, apply resolveYamlConflicts with latest-wins\n//         - Use original entities' updated_at for timestamp comparison\n//         - Conflicts only occur when same line changed differently in ours vs theirs\n//\n//       - **STEP 5: Convert back to JSON**\n//         - yamlToJson to get final merged entity\n//         - Add to mergedEntities array\n//\n//       - **Error handling:** If YAML merge fails, fallback to pure metadata merge\n//\n//    c. Otherwise (only base exists, neither ours nor theirs):\n//       - Entity was deleted in both branches\n//       - Skip this entity (deletion wins)\n\n// 4. Sort merged entities by created_at (then by id for ties)\n//    - Standard JSONL sort order for git-friendly diffs\n//    - No need for separate resolveEntities - we already handled UUID deduplication\n\n// 5. Return { entities, stats } with input/output counts\n```\n\n**Key improvements:**\n\n1. **Single code path** - handles both true 3-way and simulated 3-way merge\n1. **Base parameter normalization** - empty array for 2-way scenarios\n1. **Metadata merge FIRST** - before YAML conversion, eliminates metadata conflicts\n1. **YAML expansion** - enables line-level text merging for both scenarios\n1. **No separate resolveEntities** - all logic unified in mergeThreeWay\n1. **Modification wins over deletion** - preserve work when conflict with deletion\n\n### resolveFile Integration\n\n**Current implementation issue:**\n\n- `resolveFile` in `cli/src/cli/merge-commands.ts` (lines 125-183)\n- Parses conflict markers manually\n- Calls `resolveEntities` directly\n- **Missing:** No access to base version, no YAML expansion benefits\n\n**Corrected approach:**\n\n```typescript\n// High-level approach for resolveFile refactoring:\n\n// 1. Try to get base/ours/theirs from git index stages\n//    - Call tryGetGitStages(filePath)\n//    - If null (not in merge state):\n//      - Return message: \"Not in a git merge state. Run 'git merge' first.\"\n//      - Don't attempt to parse conflict markers\n\n// 2. If git stages available:\n//    - Call mergeThreeWay(base, ours, theirs)\n//    - This applies the same YAML-based merge as the merge driver\n//    - Consistent behavior between automatic and manual resolution\n\n// 3. Write result if not dry-run\n//    - Use writeJSONL to persist merged entities\n\n// 4. Return stats and entityType\n\n// Helper: tryGetGitStages(filePath)\n//    - Get repo root using execFileNoThrow('git', ['rev-parse', '--show-toplevel'])\n//    - Calculate relative path from repo root\n//    - Try to read all three stages (1=base, 2=ours, 3=theirs)\n//    - Return { base, ours, theirs } or null if not in merge state\n\n// Helper: readGitStage(stage, relativePath)\n//    - Use execFileNoThrow('git', ['show', `:${stage}:${relativePath}`])\n//    - Parse JSONL from stdout (split by newline, filter empty, JSON.parse each)\n//    - Return empty array if stage doesn't exist (e.g., file added in one branch)\n//    - Use execFileNoThrow for security (no shell injection)\n```\n\n**Benefits:**\n\n- ✅ Reuses `mergeThreeWay` logic (no code duplication)\n- ✅ Simpler implementation (no manual conflict marker parsing)\n- ✅ Consistent behavior with merge driver\n- ✅ Secure git command execution with execFileNoThrow\n- ✅ Clear error messages when not in merge state\n\n### Updating 2-Way Merge Scenarios in Worktree Sync Service\n\n**Key insight:** All current 2-way merge operations in `server/src/services/worktree-sync-service.ts` should be converted to use `mergeThreeWay` with empty base.\n\n#### Scenario 1: `_mergeJSONLFiles` (line 1166)\n\n**Current approach:**\n\n- Combines local + worktree entities into single array\n- Calls `resolveEntities(allEntities)` for 2-way merge\n\n**Updated approach:**\n\n```typescript\nconst { entities: merged } = mergeThreeWay(\n  [],                  // base = empty array (simulated 3-way)\n  localEntities,       // ours = local working copy\n  worktreeEntities     // theirs = worktree version\n);\n```\n\n#### Scenario 2: `_resolveJSONLFile` (line 1357)\n\n**Current approach:**\n\n- Parses conflict markers into single combined array\n- Calls `resolveEntities(allEntities)` for 2-way merge\n\n**Updated approach:**\n\n- Separate ours and theirs when parsing conflict markers\n- Call `mergeThreeWay([], oursEntities, theirsEntities)`\n- Benefits from YAML expansion for text fields\n\n#### Scenario 3: `resolveFile` in merge-commands.ts (line 173)\n\n**Current approach:**\n\n- Parses conflict markers into single combined array\n- Calls `resolveEntities(allEntities)` for 2-way merge\n\n**Updated approach:**\n\n- Separate ours and theirs when parsing conflict markers\n- Call `mergeThreeWay([], oursEntities, theirsEntities)`\n- Consistent with worktree-sync-service implementation\n\n**Benefits across all scenarios:**\n\n- ✅ Single code path via universal `mergeThreeWay`\n- ✅ YAML expansion for better text field merging\n- ✅ Metadata merged first (relationships, tags, feedback)\n- ✅ No need for separate `resolveEntities` function\n\n## Edge Cases and Design Decisions\n\n### 1\\. **Deterministic YAML Formatting**\n\n**Decision:** Strict formatting rules to avoid spurious conflicts.\n\n- **Indentation:** 2 spaces (never tabs)\n- **Key order:** Preserve JSON insertion order (stable across conversions)\n- **Multi-line style:** Always literal (`|`) for multi-line strings\n- **Array style:** Always block style (one item per line with `-` )\n- **String quoting:** Only when necessary (special characters)\n- **Line endings:** LF (Unix-style)\n- **Trailing newlines:** Consistent (one trailing newline)\n\n### 2\\. **Multi-Line Detection**\n\n**Decision:** Use literal style (`|`) when:\n\n- String contains newline characters (`\\n`)\n- String length > 80 characters (optional, for readability)\n\nOtherwise use plain scalar style.\n\n### 3\\. **Timestamp Comparison**\n\n**Decision:** Normalize timestamps before comparison.\n\n- Handle ISO 8601: `2025-01-01T10:00:00Z` and `2025-01-01 10:00:00`\n- Missing timestamps: treat as oldest\n- Invalid timestamps: log warning, treat as oldest\n\n### 4\\. **Line-Level vs Character-Level Merging**\n\n**Decision:** Git merges at line granularity, not character.\n\n**Implication:** If two agents edit the same line of text differently, it's still a conflict (latest-wins applies).\n\n**Example:**\n\n```\nBase:    \"This is a sentence.\"\nAgent A: \"This is a great sentence.\"\nAgent B: \"This is a good sentence.\"\n```\n\n→ Conflict (same line changed differently)\n\n**Not a problem:** Most real editing happens at paragraph/section level, which are separate lines.\n\n### 5\\. **Metadata Merging Order**\n\n**Decision:** Merge metadata BEFORE YAML conversion (critical improvement).\n\n**Rationale:**\n\n- Metadata merging is deterministic (union)\n- Eliminates a whole class of conflicts\n- YAML merge focuses on text fields (its strength)\n- Clearer separation of concerns\n\n### 6\\. **Hash Collisions (Different UUIDs, Same ID)**\n\n**Decision:** Handle in the simplified flow without `resolveEntities`.\n\nIf final result has multiple entities with same ID but different UUIDs:\n\n- Detection during final sort\n- First occurrence keeps original ID\n- Subsequent get `.1`, `.2` suffixes\n\n**Note:** With metadata-first approach and single entity per UUID, this should be rare.\n\n### 7\\. **Entity Deletions**\n\n**Decision:** Accept git's standard deletion handling.\n\n- Entity deleted in ours, kept in theirs → theirs wins (entity preserved)\n- Deletion = absence from JSONL, not a field change\n\n### 8\\. **YAML Round-Trip Validation**\n\n**Decision:** Validate JSON → YAML → JSON preserves data.\n\n**Critical invariants:**\n\n- All fields preserved\n- Multi-line strings: `\\n` → line breaks → `\\n`\n- Arrays: order and content preserved\n- Numbers, booleans, nulls: type preserved\n\n**Tests:**\n\n- Unit tests for all entity types (Issue, Spec)\n- Edge cases: empty arrays, null values, special characters, unicode\n- Fail loudly if round-trip changes data\n\n### 9\\. **Markdown in Multi-Line Strings**\n\n**Decision:** Treat markdown as plain text.\n\nYAML doesn't interpret markdown syntax, so headers, lists, code blocks all work:\n\n```yaml\ndescription: |\n  ## Overview\n\n  Here's a list:\n  - Item 1\n  - Item 2\n\n  ```javascript\n  console.log(\"code block\");\n```\n\n```\n\nGit merges line-by-line as expected.\n\n### 10. **Performance Considerations**\n\n**Decision:** YAML conversion overhead acceptable for merge scenarios.\n\n- Merges are infrequent (human-triggered)\n- Typical entity size: 1-50 KB\n- YAML parsing: < 10ms per entity\n- Total overhead: < 100ms acceptable\n\nIf performance becomes issue: cache YAML conversions or parallelize.\n\n## Success Criteria\n\n### Functional Requirements\n\n1. ✅ **Metadata merged first:** Tags, relationships, feedback unioned before YAML conversion\n2. ✅ **Line-level merge in multi-line text:** Changes to different lines/paragraphs are auto-merged\n3. ✅ **Simple field merge:** Changes to different simple fields are preserved\n4. ✅ **Latest-wins for real conflicts:** Same line/field changed differently → newer wins\n5. ✅ **No data loss:** Round-trip preserves all data and structure\n6. ✅ **Deterministic:** Same inputs always produce same output\n7. ✅ **resolveFile integration:** Manual resolution uses same mergeThreeWay logic as merge driver\n\n### Non-Functional Requirements\n\n1. ✅ **Performance:** < 100ms per entity for YAML conversion + merge\n2. ✅ **Compatibility:** Works with existing JSONL format and merge-resolver\n3. ✅ **Debuggability:** Clear logs showing YAML conversions and merge results\n4. ✅ **Testability:** Comprehensive tests for all scenarios\n5. ✅ **Consistency:** Same behavior for automatic (merge driver) and manual (resolve-conflicts) resolution\n\n### Test Scenarios\n\n#### True 3-Way Merge Scenarios\n\n1. **Multi-line text - different paragraphs:** Agent A edits paragraph 1, Agent B edits paragraph 3 → both preserved\n2. **Multi-line text - same paragraph:** Both edit same line → conflict → latest-wins\n3. **Array additions:** Both agents add different relationships → both preserved (merged first)\n4. **Mixed changes:** A changes title, B changes description line 5 → both preserved\n5. **Nested object changes:** A changes anchor line, B changes anchor text → both preserved\n\n#### Simulated 3-Way Merge Scenarios (Empty Base)\n\n6. **2-way local + worktree merge:** Local has entity A, worktree has entity B → both preserved\n7. **2-way with metadata conflicts:** Both add different tags/relationships → all unioned\n8. **2-way with text conflicts:** Both edit same field → YAML expansion merges different lines\n9. **2-way conflict marker resolution:** Parse ours/theirs, merge via empty base → consistent with git driver\n\n#### Common Scenarios\n\n10. **Empty/null values:** Empty strings, empty arrays, null fields\n11. **Special characters:** Unicode, quotes, backslashes in text\n12. **Long text:** 10KB+ description with many paragraphs\n13. **Timestamp edge cases:** Missing, invalid, or identical timestamps\n14. **Round-trip validation:** All entity types and field combinations (JSON → YAML → JSON)\n15. **Consistency across merge types:** Same entities merged via true 3-way and simulated 3-way produce same results (when base is effectively empty)\n\n## Implementation Files\n\n### Core Implementation\n\n- `cli/src/merge-resolver.ts` - Refactor `mergeThreeWay` with universal 3-way approach (handles both true and simulated 3-way)\n- `cli/src/yaml-converter.ts` - JSON ↔ YAML conversion with multi-line support\n- `cli/src/yaml-conflict-resolver.ts` - Latest-wins conflict resolution\n- `cli/src/git-merge.ts` - Git merge-file wrapper\n\n### CLI Integration\n\n- `cli/src/cli/merge-commands.ts` - Update `resolveFile` to separate ours/theirs and use `mergeThreeWay` with empty base\n- `cli/src/utils/execFileNoThrow.ts` - Secure command execution helper (already exists)\n\n### Server Integration\n\n- `server/src/services/worktree-sync-service.ts` - Update `_mergeJSONLFiles` and `_resolveJSONLFile` to use `mergeThreeWay` with empty base\n  - Remove direct calls to `resolveEntities`\n  - Separate ours/theirs when parsing conflict markers\n  - Leverage YAML expansion for text field merging\n\n### Tests\n\n- `cli/tests/unit/yaml-converter.test.ts` - YAML conversion and round-trip\n- `cli/tests/unit/yaml-conflict-resolver.test.ts` - Conflict resolution\n- `cli/tests/unit/merge-resolver.test.ts` - mergeThreeWay logic (including simulated 3-way scenarios)\n- `cli/tests/integration/yaml-merge.test.ts` - End-to-end scenarios\n- `cli/tests/integration/manual-conflict-resolution.test.ts` - resolveFile with both true and simulated 3-way\n- `server/tests/integration/worktree-sync.test.ts` - Worktree sync with simulated 3-way merges\n\n### Deprecated/Removed\n\n- `resolveEntities` function can be deprecated once all usages are migrated to `mergeThreeWay`\n  - Currently used in 3 places (all converted to use `mergeThreeWay` with empty base)\n  - Can remain as internal helper for UUID deduplication, or be removed entirely\n\n## References\n\n- Related spec: <span data-entity-id=\"s-3mdp\" data-entity-type=\"spec\">s-3mdp</span> - Safe Merge for Uncommitted Local Changes\n- Current merge resolver: `cli/src/merge-resolver.ts`\n- Merge commands: `cli/src/cli/merge-commands.ts`\n- JSONL operations: `cli/src/jsonl.ts`\n- Git merge-file docs: https://git-scm.com/docs/git-merge-file\n- YAML spec: https://yaml.org/spec/1.2.2/\n- js-yaml library: https://github.com/nodeca/js-yaml\n```","priority":1,"archived":0,"archived_at":null,"created_at":"2025-12-15 00:17:13","updated_at":"2025-12-16 01:29:58","parent_id":null,"parent_uuid":null,"relationships":[{"from":"s-guo4","from_type":"spec","to":"s-3mdp","to_type":"spec","type":"related"}],"tags":[]}
{"id":"s-4bm4","uuid":"2faba4d3-3806-47ca-8d61-14801ce1ecd6","title":"On-Demand External Import","file_path":"specs/s-4bm4_on_demand_external_import.md","content":"## Overview\n\nAdd support for UI-driven, on-demand importing of entities from external systems (GitHub, Jira, Linear, etc.) into sudocode specs. Unlike the existing filesystem-based integrations that use real-time sync, this feature supports explicit user-initiated imports with optional refresh capability.\n\n## Motivation\n\n- GitHub issues, Jira tickets, and Linear issues are common sources of requirements\n- Users want to pull these into sudocode as specs for AI-assisted implementation\n- Real-time bidirectional sync is complex and often unnecessary for external APIs\n- On-demand import gives users explicit control over what gets imported\n\n## Design Decisions\n\n### Authentication\n- **Use `gh` CLI** for GitHub integration instead of managing tokens directly\n- User authenticates via `gh auth login` (already standard workflow)\n- Provider calls `gh api` subprocess for all GitHub API requests\n- Handles auth, rate limiting, and private repo access automatically\n- No token storage or OAuth flow needed in sudocode\n\n### Duplicate Handling\n- **Dedupe and redirect**: If URL already imported, redirect to existing entity\n- Offer refresh option on the existing entity\n- Preview endpoint returns `alreadyLinked` field when duplicate detected\n\n### Refresh Behavior\n- **Warn before overwriting**: If local changes exist since last sync, show diff and let user decide\n- User can choose: overwrite, skip, or view diff\n- Refresh only updates **title + content** fields (not priority, tags, etc.)\n\n### Comments Handling\n- **Import as feedback**: GitHub issue comments become `IssueFeedback` entries on the imported spec\n- Optional checkbox in import dialog: \"Include comments as feedback\"\n- Each comment becomes a separate feedback item with author attribution\n\n### Entity Type\n- **Always import as Spec** by default\n- GitHub issues represent requirements/intent → maps to sudocode Spec\n- No auto-detection based on labels (keep it simple)\n\n### External Deletion\n- **Handle gracefully**: On refresh, if external entity is gone, mark link as stale\n- Show warning: \"External issue no longer exists\"\n- User can unlink or keep as archived reference\n- No automatic deletion of sudocode entity\n\n### Content Transformation\n- **Keep as-is**: Minimal transformation of GitHub markdown\n- Preserve @mentions, #refs, task lists, images, mermaid diagrams\n- Add source attribution header only\n\n### Provider Architecture\n- **All providers are plugins**: No built-in providers\n- Install as needed: `@sudocode-ai/integration-github`, `@sudocode-ai/integration-jira`, etc.\n- Plugin loader discovers installed integration packages\n- Consistent interface across all providers\n\n## Requirements\n\n### Core Functionality\n\n1. **URL-based Import**: User pastes a URL, system detects provider and fetches entity\n2. **Preview Before Import**: Show entity details before creating in sudocode\n3. **Import as Spec**: All external issues become specs (default, no override needed)\n4. **Duplicate Detection**: Redirect to existing entity if already imported\n5. **External Link Tracking**: Store `external_link` for future refresh\n6. **On-Demand Refresh**: User can refresh linked entities to pull latest changes\n7. **Conflict Warning**: Warn if local changes will be overwritten on refresh\n8. **Comments as Feedback**: Optionally import comments as IssueFeedback\n9. **No Push**: Read-only integration (no writing back to external systems)\n\n### Provider Capabilities\n\nExtend `IntegrationProvider` interface with on-demand import capabilities:\n\n```typescript\ninterface IntegrationProvider {\n  // Existing capability flags\n  readonly supportsWatch: boolean;\n  readonly supportsPolling: boolean;\n  \n  // New capability flags\n  readonly supportsOnDemandImport: boolean;\n  readonly supportsSearch: boolean;\n  readonly supportsPush: boolean;\n}\n\ninterface OnDemandImportCapable {\n  /**\n   * Check if this provider can handle a given URL\n   * e.g., GitHub provider handles \"https://github.com/owner/repo/issues/123\"\n   */\n  canHandleUrl?(url: string): boolean;\n\n  /**\n   * Parse a URL to extract the external ID and metadata\n   * Returns null if URL is not valid for this provider\n   */\n  parseUrl?(url: string): {\n    externalId: string;\n    metadata?: Record<string, unknown>;\n  } | null;\n\n  /**\n   * Fetch entity directly by URL (convenience method)\n   * Combines parseUrl + fetchEntity\n   */\n  fetchByUrl?(url: string): Promise<ExternalEntity | null>;\n\n  /**\n   * Refresh multiple entities by their external IDs\n   * Batch refresh for efficiency\n   */\n  refreshEntities?(externalIds: string[]): Promise<(ExternalEntity | null)[]>;\n\n  /**\n   * Fetch comments/discussion for an entity (optional)\n   * Used when \"Include comments\" is checked\n   */\n  fetchComments?(externalId: string): Promise<ExternalComment[]>;\n}\n\ninterface ExternalComment {\n  id: string;\n  author: string;\n  body: string;\n  created_at: string;\n  url?: string;\n}\n```\n\n### API Endpoints\n\n#### List Import Providers\n```\nGET /api/import/providers\n\nResponse: {\n  providers: [{\n    name: string,\n    displayName: string,\n    supportsSearch: boolean,\n    supportsOnDemandImport: boolean,\n    urlPatterns: string[],\n    configured: boolean,\n    authMethod: \"gh-cli\" | \"token\" | \"oauth\",\n  }]\n}\n```\n\n#### Preview Import\n```\nPOST /api/import/preview\nBody: { url: string }\n\nResponse: {\n  provider: string,\n  entity: ExternalEntity,\n  commentsCount?: number,\n  alreadyLinked?: {\n    entityId: string,\n    entityType: \"spec\" | \"issue\",\n    lastSyncedAt: string\n  }\n}\n\nErrors:\n- 400: Invalid URL format\n- 404: Entity not found at URL\n- 422: No provider can handle this URL\n- 401: Provider not configured (e.g., gh CLI not authenticated)\n```\n\n#### Import Entity\n```\nPOST /api/import\nBody: {\n  url: string,\n  options?: {\n    includeComments?: boolean,  // Import comments as feedback\n    tags?: string[],\n    priority?: number,\n    parentId?: string,\n  }\n}\n\nResponse: {\n  entityId: string,\n  entityType: \"spec\",\n  externalLink: ExternalLink,\n  feedbackCount?: number  // If comments were imported\n}\n```\n\n#### Refresh Linked Entity\n```\nPOST /api/specs/:id/refresh\nPOST /api/issues/:id/refresh\n\nResponse: {\n  updated: boolean,\n  hasLocalChanges: boolean,\n  changes?: {\n    field: string,\n    localValue: string,\n    remoteValue: string\n  }[],\n  entity?: Spec | Issue  // Updated entity if no conflicts\n}\n\nIf hasLocalChanges=true, client should confirm before:\nPOST /api/specs/:id/refresh?force=true\n```\n\n#### Bulk Refresh\n```\nPOST /api/import/refresh\nBody: {\n  provider?: string,\n  entityIds?: string[],\n  force?: boolean  // Skip conflict check\n}\n\nResponse: {\n  refreshed: number,\n  skipped: number,  // Had local changes\n  failed: number,\n  stale: number,    // External entity deleted\n  results: [{\n    entityId: string,\n    status: \"updated\" | \"skipped\" | \"failed\" | \"stale\",\n    error?: string\n  }]\n}\n```\n\n### GitHub Provider Implementation\n\n```typescript\nclass GitHubProvider implements IntegrationProvider, OnDemandImportCapable {\n  readonly name = \"github\";\n  readonly supportsWatch = false;\n  readonly supportsPolling = false;\n  readonly supportsOnDemandImport = true;\n  readonly supportsSearch = true;\n  readonly supportsPush = false;\n\n  static URL_PATTERNS = [\n    /^https:\\/\\/github\\.com\\/[\\w.-]+\\/[\\w.-]+\\/issues\\/\\d+/,\n    /^https:\\/\\/github\\.com\\/[\\w.-]+\\/[\\w.-]+\\/discussions\\/\\d+/,\n  ];\n\n  /**\n   * Execute gh CLI command and return parsed JSON\n   */\n  private async ghApi<T>(endpoint: string): Promise<T> {\n    const { stdout } = await execAsync(`gh api ${endpoint}`);\n    return JSON.parse(stdout);\n  }\n\n  /**\n   * Check if gh CLI is authenticated\n   */\n  async validate(): Promise<{ valid: boolean; errors: string[] }> {\n    try {\n      await execAsync('gh auth status');\n      return { valid: true, errors: [] };\n    } catch {\n      return { \n        valid: false, \n        errors: ['GitHub CLI not authenticated. Run: gh auth login'] \n      };\n    }\n  }\n\n  canHandleUrl(url: string): boolean {\n    return GitHubProvider.URL_PATTERNS.some(p => p.test(url));\n  }\n\n  parseUrl(url: string): { externalId: string; metadata?: Record<string, unknown> } | null {\n    const issueMatch = url.match(\n      /^https:\\/\\/github\\.com\\/([\\w.-]+)\\/([\\w.-]+)\\/issues\\/(\\d+)/\n    );\n    if (issueMatch) {\n      const [, owner, repo, number] = issueMatch;\n      return {\n        externalId: `${owner}/${repo}#${number}`,\n        metadata: { owner, repo, number: parseInt(number), type: 'issue' }\n      };\n    }\n    return null;\n  }\n\n  async fetchEntity(externalId: string): Promise<ExternalEntity | null> {\n    const match = externalId.match(/^([\\w.-]+)\\/([\\w.-]+)#(\\d+)$/);\n    if (!match) return null;\n\n    const [, owner, repo, number] = match;\n    \n    try {\n      const issue = await this.ghApi<GitHubIssue>(\n        `/repos/${owner}/${repo}/issues/${number}`\n      );\n\n      return {\n        id: externalId,\n        type: 'spec',\n        title: issue.title,\n        description: issue.body || '',\n        status: issue.state,\n        url: issue.html_url,\n        created_at: issue.created_at,\n        updated_at: issue.updated_at,\n        raw: {\n          labels: issue.labels.map(l => l.name),\n          author: issue.user?.login,\n          comments_count: issue.comments,\n        }\n      };\n    } catch (error) {\n      if (error.message.includes('404')) return null;\n      throw error;\n    }\n  }\n\n  async fetchComments(externalId: string): Promise<ExternalComment[]> {\n    const match = externalId.match(/^([\\w.-]+)\\/([\\w.-]+)#(\\d+)$/);\n    if (!match) return [];\n\n    const [, owner, repo, number] = match;\n    \n    const comments = await this.ghApi<GitHubComment[]>(\n      `/repos/${owner}/${repo}/issues/${number}/comments`\n    );\n\n    return comments.map(c => ({\n      id: String(c.id),\n      author: c.user?.login || 'unknown',\n      body: c.body,\n      created_at: c.created_at,\n      url: c.html_url,\n    }));\n  }\n\n  mapToSudocode(external: ExternalEntity): { spec?: Partial<Spec> } {\n    return {\n      spec: {\n        title: external.title,\n        content: this.formatContent(external),\n        priority: 2,\n        tags: (external.raw?.labels as string[]) || [],\n      }\n    };\n  }\n\n  private formatContent(external: ExternalEntity): string {\n    const lines: string[] = [];\n    lines.push(`> Imported from [${external.id}](${external.url})`);\n    lines.push('');\n    if (external.description) {\n      lines.push(external.description);\n    }\n    return lines.join('\\n');\n  }\n}\n```\n\n### Configuration\n\n```json\n{\n  \"integrations\": {\n    \"github\": {\n      \"enabled\": true,\n      \"plugin\": \"@sudocode-ai/integration-github\"\n    }\n  }\n}\n```\n\nNo token configuration needed - uses `gh` CLI authentication.\n\n### UI Components\n\n#### Import Dialog\n```\n┌─────────────────────────────────────────────────┐\n│  Import from External Source                    │\n├─────────────────────────────────────────────────┤\n│                                                 │\n│  Paste URL:                                     │\n│  ┌─────────────────────────────────────────┐    │\n│  │ https://github.com/org/repo/issues/42   │    │\n│  └─────────────────────────────────────────┘    │\n│                                                 │\n│  ┌─────────────────────────────────────────┐    │\n│  │ ✓ GitHub Issue Detected                 │    │\n│  │                                         │    │\n│  │ Title: Add user authentication          │    │\n│  │ Repo: org/repo                          │    │\n│  │ Status: open                            │    │\n│  │ Comments: 5                             │    │\n│  │                                         │    │\n│  │ Preview:                                │    │\n│  │ ┌─────────────────────────────────────┐ │    │\n│  │ │ As a user, I want to...             │ │    │\n│  │ └─────────────────────────────────────┘ │    │\n│  └─────────────────────────────────────────┘    │\n│                                                 │\n│  ☑ Include comments as feedback (5 comments)   │\n│  Tags: [authentication] [feature] [+]           │\n│                                                 │\n│                    [Cancel]  [Import as Spec]   │\n└─────────────────────────────────────────────────┘\n```\n\n#### Already Imported State\n```\n┌─────────────────────────────────────────────────┐\n│  Import from External Source                    │\n├─────────────────────────────────────────────────┤\n│                                                 │\n│  ⚠️ Already Imported                            │\n│                                                 │\n│  This issue was imported as spec s-abc1        │\n│  Last synced: 2 hours ago                       │\n│                                                 │\n│         [View Spec]  [Refresh from GitHub]      │\n└─────────────────────────────────────────────────┘\n```\n\n#### Refresh Conflict Dialog\n```\n┌─────────────────────────────────────────────────┐\n│  Refresh Conflict                               │\n├─────────────────────────────────────────────────┤\n│                                                 │\n│  Local changes detected since last sync.        │\n│  Refreshing will overwrite these changes:       │\n│                                                 │\n│  ┌─────────────────────────────────────────┐    │\n│  │ Title:                                  │    │\n│  │   Local: \"Auth: Add OAuth support\"      │    │\n│  │   Remote: \"Add user authentication\"     │    │\n│  │                                         │    │\n│  │ Content: (3 lines changed)              │    │\n│  │   [View Diff]                           │    │\n│  └─────────────────────────────────────────┘    │\n│                                                 │\n│           [Cancel]  [Keep Local]  [Overwrite]   │\n└─────────────────────────────────────────────────┘\n```\n\n### External Link Schema\n\n```typescript\ninterface ExternalLink {\n  provider: string;\n  external_id: string;\n  external_url?: string;\n  sync_enabled: boolean;\n  sync_direction: \"inbound\";  // Always inbound for on-demand import\n  last_synced_at?: string;\n  imported_at: string;\n  content_hash?: string;      // Hash of content at last sync (for change detection)\n  import_metadata?: {\n    owner?: string;\n    repo?: string;\n    type?: string;\n    comments_imported?: boolean;\n  };\n}\n```\n\n## File Structure\n\n```\nplugins/integration-github/\n├── package.json\n├── tsconfig.json\n├── vitest.config.ts\n├── src/\n│   ├── index.ts              # GitHubPlugin + GitHubProvider\n│   ├── url-parser.ts         # URL parsing utilities\n│   ├── gh-client.ts          # gh CLI wrapper\n│   └── mappers.ts            # Entity mapping utilities\n└── tests/\n    ├── url-parser.test.ts\n    ├── gh-client.test.ts\n    └── provider.test.ts\n\nserver/src/routes/\n├── import.ts                 # /api/import/* endpoints\n\nfrontend/src/components/import/\n├── ImportDialog.tsx\n├── ImportPreview.tsx\n├── AlreadyImportedState.tsx\n├── RefreshConflictDialog.tsx\n└── ProviderIcon.tsx\n```\n\n## Acceptance Criteria\n\n- [ ] `IntegrationProvider` interface extended with capability flags\n- [ ] `OnDemandImportCapable` interface defined in types\n- [ ] `ExternalComment` type for comment import\n- [ ] GitHub provider uses `gh` CLI for all API calls\n- [ ] GitHub provider implements `fetchComments()`\n- [ ] API endpoints: `/api/import/providers`, `/api/import/preview`, `/api/import`\n- [ ] API endpoints: `/api/specs/:id/refresh`, `/api/issues/:id/refresh`\n- [ ] Duplicate detection returns existing entity\n- [ ] Refresh warns on local changes before overwriting\n- [ ] Comments imported as IssueFeedback when option enabled\n- [ ] Import dialog with preview and options\n- [ ] Already-imported state with refresh option\n- [ ] Refresh conflict dialog with diff view\n- [ ] External link stores `content_hash` for change detection\n- [ ] Unit tests for URL parsing and gh CLI wrapper\n- [ ] Integration tests for import and refresh flow","priority":1,"archived":0,"archived_at":null,"created_at":"2025-12-17 04:24:16","updated_at":"2025-12-17 04:45:25","parent_id":null,"parent_uuid":null,"relationships":[],"tags":["api","github","import","integration"]}
{"id":"s-7tk3","uuid":"357ce082-2245-4512-8a7c-57d0084bc04f","title":"MCP Auto-Configuration for Agent Executions","file_path":"specs/s-7tk3_mcp_auto_configuration_for_agent_executions.md","content":"# MCP Auto-Configuration for Agent Executions\n\n## Overview\n\nEnable automatic detection and configuration of the `sudocode-mcp` server for agent executions. When a user runs an execution with any supported agent (Claude Code, Copilot, Cursor, Codex), the system should automatically ensure that sudocode-mcp is available and configured, allowing agents to access sudocode tools without manual setup.\n\n## Problem Statement\n\nCurrently, users must manually configure the `sudocode-mcp` MCP server in their agent settings before it's available during executions. This creates friction:\n\n1. **New users** don't know they need to configure sudocode-mcp\n1. **Existing users** may have sudocode-mcp installed but not configured for all agents\n1. **Different agents** require different configuration approaches (inline vs global config)\n1. **Error messages** are unclear when sudocode tools are unavailable\n\n## Requirements\n\n### Detection Requirements\n\n**MUST**:\n\n- Detect if `sudocode-mcp` command is available in PATH before each execution\n- Support cross-platform detection (Unix `which`, Windows `where`)\n\n**MUST NOT**:\n\n- Proceed with auto-configuration if `sudocode-mcp` is not installed\n- Assume sudocode-mcp is available without verification\n\n### Error Handling Requirements\n\n**MUST**:\n\n- Return clear error if `sudocode-mcp` not installed, with link to [https://github.com/sudocode-ai/sudocode](https://github.com/sudocode-ai/sudocode)\n- Return error for agents without a configuration strategy\n- Log all auto-configuration attempts with success/failure status\n\n**MUST NOT**:\n\n- Silently fail if auto-configuration fails\n- Continue execution without sudocode-mcp if required\n\n### Configuration Detection Requirements\n\n**MUST**:\n\n- Check if sudocode-mcp is already configured before auto-configuring\n- Support detection of existing config\n- Skip auto-configuration if already present\n\n### Agent-Specific Configuration Strategies\n\n#### Claude Code (`claude-code`)\n\n**Strategy**: Runtime inline injection via `--mcp-config` flag\n\n**Implementation**:\n\n```typescript\n{\n  mcpServers: {\n    ...config.mcpServers,\n    'sudocode': {\n      command: 'sudocode-mcp',\n      env: { SUDOCODE_WORKING_DIR: workDir }\n    }\n  }\n}\n```\n\n**Requirements**:\n\n- MUST inject into `ExecutionConfig.mcpServers` before execution\n- MUST preserve any existing MCP server configurations\n- MUST set `SUDOCODE_WORKING_DIR` env var to execution workDir\n- MUST NOT modify any global configuration files\n\n**Rationale**: Claude Code accepts `--mcp-config` with inline JSON, enabling per-execution configuration without touching global settings.\n\n#### Copilot (`copilot`)\n\n**Strategy**: Project-local config via `XDG_CONFIG_HOME` environment variable\n\n**Implementation**:\n\n1. Read user's `~/.copilot/mcp-config.json` (if exists)\n1. Merge with sudocode-mcp server config\n1. Write merged config to `.sudocode/copilot-mcp-config.json` (make sure we update the .gitignore to include this file)\n1. Set `XDG_CONFIG_HOME` environment variable to `.sudocode/` directory\n\n**Requirements**:\n\n- MUST copy user's existing MCP config if present\n- MUST preserve all user-configured MCP servers\n- MUST write to `.sudocode/copilot-mcp-config.json` (project-local)\n- MUST set `XDG_CONFIG_HOME` to `.sudocode/` directory in execution env\n- MUST create `.sudocode/` directory if it doesn't exist\n- MUST NOT modify `~/.copilot/mcp-config.json` (user's global config)\n\n**Rationale**: Copilot reads MCP config from `$XDG_CONFIG_HOME/mcp-config.json`, allowing us to override the location per-execution without modifying the user's global settings.\n\n#### Cursor (`cursor`)\n\n**Strategy**: Project-local config file modification\n\n**Implementation**:\n\n1. Check if `.cursor/mcp.json` exists in project root\n1. Read existing config (if present)\n1. Add sudocode-mcp server with `trusted: true`\n1. Write updated config back to `.cursor/mcp.json`\n1. Set `approveMcps: true` in execution config\n\n**Requirements**:\n\n- MUST use project-local `.cursor/mcp.json` (not `~/.cursor/mcp.json`)\n- MUST create `.cursor/` directory and `mcp.json` if they don't exist\n- MUST preserve existing MCP server configurations\n- MUST NOT modify user's global `~/.cursor/mcp.json`\n\n**Rationale**: Cursor requires MCP servers to be defined in `mcp.json` with explicit trust. Using project-local config keeps modifications scoped to the project.\n\n#### Codex (`codex`)\n\n**Strategy**: Config file modification via TOML merge\n\n**Status**: ⚠️ NEEDS VALIDATION - Create separate issue to verify this approach works\n\n**Proposed Implementation**:\n\n1. Read user's `~/.codex/config.toml`\n1. Parse TOML structure\n1. Add `[mcp_servers.sudocode-mcp]` section with `command = \"sudocode-mcp\"`\n1. use -c flag to override at runtime (without modifying any files). WE SHOULD VERIFY THIS WORKS FIRST\n\n**Requirements** (pending validation):\n\n- MUST read and parse existing TOML config\n- MUST preserve all existing configuration\n- MUST add MCP server in correct TOML format\n- MUST handle TOML parsing/writing correctly\n- SHOULD investigate if `-c, --config` flag can override at runtime instead\n\n**Validation Needed**:\n\n- Can we dynamically add MCP server via `-c mcp_servers.sudocode-mcp.command=sudocode-mcp`?\n- Does Codex support per-execution MCP config overrides?\n- What is the exact TOML structure for MCP servers?\n\n**Example TOML**:\n\n```toml\n[mcp_servers.sudocode-mcp]\ncommand = \"sudocode-mcp\"\n```\n\n## Architecture\n\n### Service Structure\n\n```\nservices/mcp-auto-config/\n├── index.ts                    # McpAutoConfigService (main)\n├── detector.ts                 # McpDetector (availability check)\n├── types.ts                    # Interfaces\n└── strategies/\n    ├── claude-code.ts          # ClaudeCodeMcpStrategy\n    ├── copilot.ts              # CopilotMcpStrategy\n    ├── cursor.ts               # CursorMcpStrategy\n    └── codex.ts                # CodexMcpStrategy (TBD)\n```\n\n### Core Interfaces\n\n```typescript\ninterface McpAutoConfigStrategy {\n  agentType: AgentType;\n  shouldAutoConfigure(config: ExecutionConfig, workDir: string): Promise<boolean>;\n  apply(config: ExecutionConfig, workDir: string): Promise<ExecutionConfig>;\n  cleanup?(executionId: string): Promise<void>;\n}\n\ninterface McpDetector {\n  isAvailable(): Promise<boolean>;\n  getCommand(): Promise<string | null>;\n}\n```\n\n### Integration Point\n\n**ExecutionService.createExecution**:\n\n```typescript\nasync createExecution(issueId, config, prompt, agentType) {\n  // 1. Auto-configure MCP if needed\n  config = await this.mcpAutoConfigService.autoConfigure(\n    agentType,\n    config,\n    this.repoPath\n  );\n  \n  // 2. Continue with existing execution creation logic\n  // ...\n}\n```\n\n## Error Scenarios\n\n### Scenario 1: sudocode-mcp Not Installed\n\n**Condition**: `which sudocode-mcp` returns non-zero exit code\n\n**Error Message**:\n\n```\nError: sudocode-mcp is not installed or not found in PATH.\n\nTo use sudocode tools during agent executions, please install sudocode:\n  npm install -g sudocode\n\nFor more information, visit: https://github.com/sudocode-ai/sudocode\n\nAlternatively, you can disable auto-configuration by setting:\n  autoConfigureSudocodeMcp: false\n```\n\n**HTTP Status**: 400 Bad Request\n\n### Scenario 2: Agent Without Strategy\n\n**Condition**: Agent type has no `McpAutoConfigStrategy` implementation\n\n**Error Message**:\n\n```\nError: MCP auto-configuration is not supported for agent type '{agentType}'.\n\nSupported agents: claude-code, copilot, cursor\n\nPlease configure sudocode-mcp manually for this agent, or use a supported agent type.\n```\n\n**HTTP Status**: 400 Bad Request\n\n### Scenario 3: Configuration File Write Failure\n\n**Condition**: Cannot write to `.cursor/mcp.json` or `.sudocode/copilot-mcp-config.json`\n\n**Error Message**:\n\n```\nError: Failed to configure sudocode-mcp for {agentType}.\nReason: {error.message}\n\nPlease ensure:\n- The project directory is writable\n- You have permission to create files in the project directory\n\nError details: {error.stack}\n```\n\n**HTTP Status**: 500 Internal Server Error\n\n## Success Criteria\n\n### Functional Success\n\n- sudocode-mcp is detected correctly on Unix and Windows\n- Claude Code executions have sudocode tools available automatically\n- Copilot executions have sudocode tools available via XDG\\_CONFIG\\_HOME\n- Cursor executions have sudocode tools available via local .cursor/mcp.json\n- Existing MCP server configurations are preserved for all agents\n- Clear errors are shown when sudocode-mcp is not installed\n- Auto-configuration can be disabled via config flag\n\n### Non-Functional Success\n\n- Detection is cached for 5 minutes to avoid repeated checks\n- Configuration changes are logged at INFO level\n- No global config files are modified (except Codex, pending validation)\n- Auto-configuration adds <100ms latency to execution start\n- Concurrent executions don't conflict when writing config files\n\n## Future Considerations\n\n### Configuration Flag\n\nAdd optional flag to disable auto-configuration:\n\n```typescript\ninterface ExecutionConfig {\n  autoConfigureSudocodeMcp?: boolean; // default: true\n}\n```\n\n### Support for Other MCP Servers\n\nGeneralize the strategy pattern to support auto-configuration of other MCP servers beyond sudocode-mcp.\n\n### Runtime Override Detection\n\nFor Codex, investigate using `-c, --config` flag to override MCP config at runtime instead of modifying TOML file.\n\n## Related Issues\n\n- Create issue: Validate Codex MCP runtime configuration via `-c` flag\n- Create issue: Test MCP auto-configuration across all agent types\n- Create issue: Add integration tests for MCP auto-config service","priority":1,"archived":0,"archived_at":null,"created_at":"2025-12-17 04:51:53","updated_at":"2025-12-17 05:23:34","parent_id":null,"parent_uuid":null,"relationships":[],"tags":["agent-execution","auto-configuration","dx-improvement","mcp"]}
{"id":"s-64wi","uuid":"1f643019-8f56-486f-a5fb-e70ef3d49578","title":"Auto-inject sudocode-mcp MCP Server for Agent Executions","file_path":"specs/s-64wi_auto_inject_sudocode_mcp_mcp_server_for_agent_exec.md","content":"# Auto-inject sudocode-mcp MCP Server for Agent Executions\n\n## Overview\n\nAutomatically detect and configure the `sudocode-mcp` MCP server for all agent executions within the sudocode system. When an execution starts, the system should detect if the sudocode MCP plugin is installed for the agent and automatically add it to the execution's MCP server configuration.\n\nThis replaces the deprecated spec [[s-7tk3]] with a simpler, more maintainable approach using a centralized `buildExecutionConfig` helper method.\n\n## Problem Statement\n\nCurrently, users must manually configure the `sudocode-mcp` MCP server for their agents before sudocode tools are available during executions. This creates friction:\n\n1. **New users** may skip installing the sudocode MCP plugin\n1. **All execution types** (adhoc, issue, workflow) need the same auto-injection logic\n1. **No feedback** when sudocode tools are unavailable due to missing plugin\n\n## Requirements\n\n### Core Requirements\n\n**MUST**:\n\n- Detect if `sudocode-mcp` plugin is installed for the agent before each execution\n- If sudocode-mcp is not available on the machine, must raise an error\n- Automatically add `sudocode-mcp` to `mcpServers` config if missing\n- Work for all execution types (adhoc, issue-based, workflow sub-executions)\n- Preserve user-provided MCP server configurations\n- Support claude-code agent initially (extensible to others later)\n\n**MUST NOT**:\n\n- Modify global agent configuration files\n- duplicate sudocode-mcp installations\n\n### Detection Requirements (Claude Code)\n\n**Detection Method**: Check ~/.claude/settings.json for the sudocode plugin\n\n**Expected Output Format**:\n\n```\ncat ~/.claude/settings.json \n{\n  \"$schema\": \"https://json.schemastore.org/claude-code-settings.json\",\n  \"env\": {\n    \"MCP_TOOL_TIMEOUT\": \"60000\"\n  },\n  \"enabledPlugins\": {\n    \"sudocode@sudocode-marketplace\": true   <<<<<< this must be present and true\n  },\n  \"feedbackSurveyState\": {\n    \"lastShownTime\": 1754034959131\n  }\n}\n```\n\n**MUST**:\n\n- Return false if errors\n- Log detection failures\n\n**MUST NOT**:\n\n- Throw errors if detection fails (log and continue without auto-injection)\n\n## Architecture\n\n### New Components\n\n#### 1\\. `buildExecutionConfig` Helper Method\n\n**Location**: `server/src/services/execution-service.ts` (private method)\n\n**Signature**:\n\n```typescript\nprivate async buildExecutionConfig(\n  agentType: AgentType,\n  userConfig: TConfig,\n): Promise<TConfig>\n```\n\n**Responsibilities**:\n\n1. Detect if sudocode-mcp is installed for the agent\n1. Merge default MCP servers with user-provided config\n1. Return merged ExecutionConfig\n\n**Example Implementation**:\n\n```typescript\nprivate async buildExecutionConfig(\n  agentType: AgentType,\n  userConfig: ExecutionConfig,\n): Promise<ExecutionConfig> {\n  // Start with user config\n  const mergedConfig = { ...userConfig };\n  \n  // Detect if sudocode-mcp is present\n  const isInstalled = await this.detectSudocodeMcp();\n  if (!isInstalled) {\n   // raise error telling user to install sudocode, refer to github.com/sudocode-ai/sudocode\n   throw exception\n  }\n  const mcpPresent = await this.determineMcpConfigured(agentType);\n  \n  if (!mcpPresent) {\n    mergedConfig.mcpServers = {\n      ...(userConfig.mcpServers || {}),\n      'sudocode-mcp': {\n        command: 'sudocode-mcp',\n        args: [], // Plugin handles args\n      },\n    };\n  }\n  \n  return mergedConfig;\n}\n```\n\n#### 2\\. `detectSudocodeMcp` Helper Method\n\n**Location**: `server/src/services/execution-service.ts` (private method)\n\n**Signature**:\n\n```typescript\nprivate async detectSudocodeMcp(): Promise<boolean>\n```\n\n**Responsibilities**:\n\n1. checks to see if the `sudocode-mcp package is available`\n\n#### 3\\. `detectClaudeCodeMcp` Helper Method\n\n**Location**: `server/src/services/execution-service.ts` (private method)\n\n**Signature**:\n\n```typescript\nprivate async detectAgentMcp(agentType): Promise<boolean>\n```\n\n**Responsibilities**:\n\n1. checks ~/.claude/settings.json to see that sudocode plugin is installed (if agent type is claude code)\n\n### Integration Point\n\n**Modified: ExecutionService.createExecution**\n\n```typescript\nasync createExecution(\n  issueId: string | null,\n  config: ExecutionConfig,\n  prompt: string,\n  agentType: AgentType = \"claude-code\",\n  workflowContext?: WorkflowContext\n): Promise<Execution> {\n  // 1. Validate\n  if (!prompt.trim()) {\n    throw new Error(\"Prompt cannot be empty\");\n  }\n\n  // 2. Build execution config with auto-injected MCP servers\n  const mergedConfig = await this.buildExecutionConfig(\n    agentType,\n    config,\n    this.repoPath\n  );\n\n  // 3. Continue with existing execution creation logic using mergedConfig\n  const mode = mergedConfig.mode || \"worktree\";\n  // ... rest of method uses mergedConfig instead of config\n}\n```\n\n## Execution Flow\n\n```\nUser triggers execution (adhoc/issue/workflow)\n  ↓\nExecutionService.createExecution() called\n  ↓\nbuildExecutionConfig(agentType, userConfig, workDir)\n  ↓\ndetectSudocodeMcp(agentType)\n      ↓\n      detectAgentMcp() for claude-code agent\n      └─ Return boolean\n  ↓\nIf mcp is missing: Add to mergedConfig.mcpServers\n  ↓\nReturn mergedConfig to createExecution\n  ↓\nUse mergedConfig for execution (all existing logic)\n```\n\n## Logging\n\n**Detection Success**:\n\n```\n[ExecutionService] sudocode-mcp detected for claude-code (cached=false)\n[ExecutionService] Skipping\n```\n\n**Detection Failure**:\n\n```\n[ExecutionService] sudocode-mcp not detected for claude-code (plugin not installed)\n[ExecutionService] Adding sudocode-mcp to mcpServers\n```\n\n**Detection Error**:\n\n```\n[ExecutionService] MCP detection failed for claude-code: Error: Command timeout\n[ExecutionService] Skipping sudocode-mcp auto-injection for execution exec-123\n```\n\n## Error Handling\n\n### Scenario 1: Detection Fails\n\nproceed as normal (don't add any mcpservers)\n\n### Scenario 2: Plugin Not Installed\n\n**Condition**: Detection returns `false` (no plugin found)\n\n**raise an error to user, saying sudocode must be installed, check git repo**\n\n## Success Criteria\n\n### Functional Success\n\n- ✅ sudocode-mcp is detected correctly for claude-code agent\n- ✅ MCP server is auto-injected when plugin is NOT installed\n- ✅ User-provided MCP servers are preserved\n- ✅ All execution types (adhoc, issue, workflow) get auto-injection\n- ✅ Executions don't fail if detection fails\n- ✅ Clear logs indicate detection and injection status\n\n### Non-Functional Success\n\n- ✅ No global configuration files are modified\n\n## Future Extensions\n\n### Support for Other Agents\n\nThe architecture is designed to be extensible. To add support for other agents:\n\n1. Add detection method (e.g., `detectCopilotMcp()`)\n1. Update `detectSudocodeMcp()` switch statement\n1. Update agent-specific detection logic\n\n### BaseAgentConfig Extension\n\nIf we decide to make `mcpServers` a common field across all agents, we can add it to `BaseAgentConfig`:\n\n```typescript\n// types/src/agents.d.ts\nexport interface BaseAgentConfig {\n  /** MCP servers to connect to the agent */\n  mcpServers?: Record<string, McpServerConfig>;\n}\n```\n\nThis would make it clearer that MCP server configuration is a universal agent feature.\n\n## Testing Strategy\n\n### Unit Tests\n\n`buildExecutionConfig()` **tests**:\n\n- ✅ Throws error when `detectSudocodeMcp()` returns false\n- ✅ Adds sudocode-mcp to mcpServers when `detectAgentMcp()` returns false\n- ✅ Skips injection when `detectAgentMcp()` returns true (plugin already configured)\n- ✅ Preserves user-provided MCP servers when auto-injecting\n- ✅ Does not duplicate sudocode-mcp if user already provided it\n\n`detectSudocodeMcp()` **tests**:\n\n- ✅ Returns true when sudocode-mcp package is available in PATH\n- ✅ Returns false when sudocode-mcp package is not available\n- ✅ Returns false on detection errors (logs warning, doesn't throw)\n\n`detectAgentMcp()` **tests (claude-code)**:\n\n- ✅ Returns true when `~/.claude/settings.json` has `enabledPlugins.sudocode@sudocode-marketplace: true`\n- ✅ Returns false when settings.json exists but plugin is not enabled\n- ✅ Returns false when settings.json doesn't exist\n- ✅ Returns false when settings.json is malformed JSON (logs error)\n- ✅ Returns false when enabledPlugins.sudocode@sudocode-marketplace is false or missing\n- ✅ Handles file read errors gracefully (returns false, logs warning)\n\n`detectAgentMcp()` **tests (other agents)**:\n\n- ✅ Returns true for unsupported agents (copilot, cursor, codex)\n\n### Integration Tests\n\n**End-to-end execution tests**:\n\n- ✅ Execution succeeds with auto-injected sudocode-mcp when plugin not configured\n- ✅ Execution succeeds without injection when plugin already configured\n- ✅ Execution fails with clear error when sudocode-mcp package not installed\n- ✅ Verify sudocode tools are available in execution after auto-injection\n- ✅ Verify user-provided MCP servers are preserved alongside auto-injected one\n\n**Error scenario tests**:\n\n- ✅ Execution fails with informative error when sudocode-mcp not in PATH\n- ✅ Error message includes link to github.com/sudocode-ai/sudocode\n- ✅ Detection failures (settings.json read errors) don't block execution\n\n**Multi-execution type tests**:\n\n- ✅ Adhoc executions get auto-injection\n- ✅ Issue-based executions get auto-injection\n- ✅ Workflow sub-executions get auto-injection\n\n## Related Work\n\n**Supersedes**: [[s-7tk3]] - MCP Auto-Configuration for Agent Executions (deprecated)\n\n## Followups:\n\nhandle other agent executions, and ensure that the agent-execution library can handle mcp servers for all supported agents.","priority":1,"archived":0,"archived_at":null,"created_at":"2025-12-17 08:59:54","updated_at":"2025-12-17 09:38:01","parent_id":null,"parent_uuid":null,"relationships":[],"tags":["agent-execution","auto-configuration","dx-improvement","mcp"]}
{"id":"s-ir5r","uuid":"14589ede-a594-4b6c-ab98-5f226fa973be","title":"Voice Input and Narration for Chat Widget","file_path":"specs/s-ir5r_voice_input_and_narration_for_chat_widget.md","content":"# Voice Input and Narration for Chat Widget\n\n## Overview\n\nAdd voice capabilities to the sudocode chat widget, enabling users to:\n\n1. **Voice Input (STT)**: Speak to create follow-up prompts instead of typing\n1. **Voice Narration (TTS)**: Hear execution progress spoken aloud\n\nThis is a lightweight implementation that does NOT require LiveKit or real-time bidirectional audio streaming. It uses simple HTTP endpoints for audio processing and the existing WebSocket for event streaming.\n\n---\n\n## User Stories\n\n### Voice Input\n\n- As a user, I want to click a microphone button and speak my follow-up prompt\n- As a user, I want to see visual feedback while recording (pulsing indicator)\n- As a user, I want to see my transcribed text before it's submitted\n- As a user, I want the option to cancel or edit the transcription\n\n### Voice Narration\n\n- As a user, I want to toggle voice narration on/off for an execution\n- As a user, I want to hear summarized progress updates (not raw output)\n- As a user, I want to stop narration mid-speech if needed\n- As a user, I want narration to pause when I start recording voice input\n\n---\n\n## Architecture\n\n```\n┌─────────────────────────────────────────────────────────────────────┐\n│                         VOICE FLOW                                   │\n├─────────────────────────────────────────────────────────────────────┤\n│                                                                     │\n│  VOICE INPUT (User → System)                                        │\n│  ───────────────────────────                                        │\n│  Browser                          Server                            │\n│  ┌──────────────┐                ┌──────────────┐                  │\n│  │ MediaRecorder│ ──POST───────► │ /api/voice/  │                  │\n│  │ (audio/webm) │   audio blob   │ transcribe   │                  │\n│  └──────────────┘                └──────┬───────┘                  │\n│                                         │                           │\n│                                         ▼                           │\n│                                  ┌──────────────┐                  │\n│                                  │ STT Provider │                  │\n│                                  │ • Whisper    │                  │\n│                                  │ • OpenAI API │                  │\n│                                  └──────┬───────┘                  │\n│                                         │                           │\n│  ┌──────────────┐                       │                           │\n│  │ Show in UI   │ ◄──{ text }───────────┘                          │\n│  │ (editable)   │                                                   │\n│  └──────────────┘                                                   │\n│                                                                     │\n│  VOICE NARRATION (System → User)                                    │\n│  ───────────────────────────────                                    │\n│  Server                          Browser                            │\n│  ┌──────────────┐                ┌──────────────┐                  │\n│  │ Execution    │ ──WebSocket──► │ Narration    │                  │\n│  │ Events       │   voice_event  │ Handler      │                  │\n│  └──────────────┘                └──────┬───────┘                  │\n│                                         │                           │\n│         ┌───────────────────────────────┼───────────────────┐      │\n│         │                               │                   │      │\n│         ▼                               ▼                   ▼      │\n│  ┌──────────────┐                ┌──────────────┐   ┌────────────┐ │\n│  │ Browser TTS  │                │ Fetch audio  │   │ Kokoro     │ │\n│  │ (free)       │                │ from server  │   │ (local)    │ │\n│  └──────────────┘                └──────────────┘   └────────────┘ │\n│                                                                     │\n└─────────────────────────────────────────────────────────────────────┘\n```\n\n---\n\n## STT Provider Options\n\n| Provider | Hosting | Quality | Latency | Cost |\n| --- | --- | --- | --- | --- |\n| **Whisper.cpp** | Local | Excellent | ~1-3s | Free |\n| **OpenAI Whisper API** | Cloud | Excellent | ~1-2s | $0.006/min |\n| **Web Speech API** | Browser | Good | Real-time | Free |\n\n### Recommendation\n\n- **Default**: Local Whisper.cpp (privacy, no cost)\n- **Fallback**: OpenAI Whisper API (if local unavailable)\n- **Optional**: Web Speech API (for real-time preview while recording)\n\n---\n\n## TTS Provider Options\n\n| Provider | Hosting | Quality | Latency | Cost |\n| --- | --- | --- | --- | --- |\n| **Browser Speech API** | Browser | Basic | Instant | Free |\n| **Kokoro** | Local | Excellent | ~200ms | Free |\n| **OpenAI TTS** | Cloud | Excellent | ~500ms | $0.015/1K chars |\n\n### Recommendation\n\n- **Default**: Browser Speech API (zero setup, works everywhere)\n- **Enhanced**: Kokoro (if user has it running)\n- **Premium**: OpenAI TTS (opt-in, best quality)\n\n---\n\n## API Design\n\n### POST /api/voice/transcribe\n\nTranscribe audio to text.\n\n**Request:**\n\n```\nContent-Type: multipart/form-data\n- audio: Blob (audio/webm, audio/mp3, audio/wav)\n- language?: string (default: \"en\")\n```\n\n**Response:**\n\n```json\n{\n  \"text\": \"Fix the login validation bug\",\n  \"confidence\": 0.95,\n  \"duration_ms\": 2340\n}\n```\n\n### POST /api/voice/synthesize\n\nGenerate speech audio from text.\n\n**Request:**\n\n```json\n{\n  \"text\": \"I found the issue in the login component\",\n  \"voice\": \"nova\",\n  \"provider\": \"browser\" | \"kokoro\" | \"openai\"\n}\n```\n\n**Response:**\n\n- If `provider` is `browser`: `{ text: \"...\" }` (client uses Web Speech API)\n- If `provider` is `kokoro` or `openai`: Audio stream (audio/mpeg)\n\n### GET /api/voice/config\n\nGet available voice providers and settings.\n\n**Response:**\n\n```json\n{\n  \"stt\": {\n    \"providers\": [\"whisper-local\", \"openai\"],\n    \"default\": \"whisper-local\",\n    \"whisperAvailable\": true\n  },\n  \"tts\": {\n    \"providers\": [\"browser\", \"kokoro\", \"openai\"],\n    \"default\": \"browser\",\n    \"kokoroAvailable\": true,\n    \"voices\": {\n      \"browser\": [\"default\"],\n      \"kokoro\": [\"af_sky\", \"af_bella\", \"am_adam\"],\n      \"openai\": [\"nova\", \"alloy\", \"echo\", \"fable\", \"onyx\", \"shimmer\"]\n    }\n  }\n}\n```\n\n---\n\n## Voice Events (WebSocket)\n\nNew event types added to execution stream:\n\n```typescript\n// Emitted when agent has something to narrate\ninterface VoiceNarrationEvent {\n  type: 'voice_narration';\n  executionId: string;\n  text: string;\n  category: 'status' | 'progress' | 'result' | 'error';\n  priority: 'low' | 'normal' | 'high';\n}\n\n// Examples:\n{ type: 'voice_narration', text: 'Starting to work on the task', category: 'status' }\n{ type: 'voice_narration', text: 'Reading the login component', category: 'progress' }\n{ type: 'voice_narration', text: 'Found a bug in line 42', category: 'progress' }\n{ type: 'voice_narration', text: 'Fixed! All tests passing', category: 'result' }\n```\n\n### Narration Generation Rules\n\n| Execution Event | Narration |\n| --- | --- |\n| `tool_use: Read` | \"Reading \\[filename\\]\" |\n| `tool_use: Edit` | \"Editing \\[filename\\]\" |\n| `tool_use: Bash` | \"Running \\[command summary\\]\" |\n| `tool_use: speak` | Speak the provided text directly (agent-triggered) |\n| `assistant` (short) | Speak directly |\n| `assistant` (long) | Summarize to ~2 sentences |\n| `error` | \"Error: \\[summary\\]\" |\n| `result` | \"Done. \\[summary\\]\" |\n\n---\n\n## Agent-Triggered Speech (MCP Tool)\n\nAgents can explicitly trigger voice narration using the `speak` MCP tool. This allows agents to provide important spoken feedback to users without relying on passive narration of tool use.\n\n### MCP Tool Definition\n\n```typescript\n// In mcp/src/server.ts\n{\n  name: \"speak\",\n  description: \"Speak text aloud to the user via text-to-speech. Use for important announcements, summaries, or when you want to ensure the user hears specific information.\",\n  inputSchema: {\n    type: \"object\",\n    properties: {\n      text: {\n        type: \"string\",\n        description: \"The text to speak aloud to the user\"\n      },\n      priority: {\n        type: \"string\",\n        enum: [\"low\", \"normal\", \"high\"],\n        description: \"Priority level. 'high' interrupts current speech, 'low' may be skipped if queue is full. Default: 'normal'\"\n      }\n    },\n    required: [\"text\"]\n  }\n}\n```\n\n### How It Works\n\nThe `speak` tool leverages the existing tool\\_use flow:\n\n```\nAgent calls speak() MCP tool\n       ↓\nAppears as NormalizedEntry: { type: { kind: \"tool_use\", tool: { toolName: \"speak\" } } }\n       ↓\nNarrationService.summarizeForVoice() detects \"speak\" tool\n       ↓\nReturns the text directly (no transformation)\n       ↓\nbroadcastVoiceNarration() sends to frontend\n       ↓\nuseVoiceNarration plays via Web Speech API\n```\n\n### NarrationService Integration\n\n```typescript\n// In narration-service.ts - describeGenericTool()\ncase \"speak\":\n  // Agent explicitly wants to speak this text\n  const text = args.text as string;\n  const priority = (args.priority as NarrationPriority) || \"normal\";\n  return {\n    text,\n    category: \"status\",\n    priority,\n  };\n```\n\n### Usage Examples\n\nAgents can use the speak tool for:\n\n```typescript\n// Important completion announcement\nspeak({ text: \"Task complete! All tests are passing.\", priority: \"high\" })\n\n// Progress update the user should hear\nspeak({ text: \"Found 3 issues in the authentication module. Starting fixes.\" })\n\n// Summary before finishing\nspeak({ text: \"I've refactored the login flow and added input validation.\" })\n\n// Error requiring attention\nspeak({ text: \"Unable to connect to the database. Please check your configuration.\", priority: \"high\" })\n```\n\n### Design Rationale\n\n1. **No new entry type needed**: Reuses existing `tool_use` infrastructure\n1. **Explicit control**: Agents decide exactly what to speak and when\n1. **Priority support**: Important messages can interrupt current narration\n1. **Complements passive narration**: Works alongside automatic tool narration\n\n---\n\n## Frontend Components\n\n### New Files\n\n```\nfrontend/src/\n├── hooks/\n│   ├── useVoiceInput.ts           # Recording and transcription\n│   ├── useVoiceNarration.ts       # TTS playback and queue\n│   └── useVoiceConfig.ts          # Provider settings\n├── contexts/\n│   └── VoiceContext.tsx           # Global voice state\n├── components/voice/\n│   ├── index.ts\n│   ├── VoiceInputButton.tsx       # Mic button with states\n│   ├── VoiceInputPreview.tsx      # Transcription preview/edit\n│   ├── VoiceNarrationToggle.tsx   # Enable/disable narration\n│   └── VoiceSpeakingIndicator.tsx # Visual feedback when speaking\n└── lib/\n    └── voice.ts                   # Voice utilities\n```\n\n### Modified Files\n\n```\nfrontend/src/\n├── contexts/ChatWidgetContext.tsx  # Add voice state\n├── components/chat-widget/\n│   └── ChatWidgetContent.tsx       # Integrate voice components\n└── types/\n    └── voice.d.ts                  # Voice type definitions\n```\n\n---\n\n## UI/UX Design\n\n### Voice Input Button States\n\n```\n┌─────────────────────────────────────────────────────────────┐\n│  IDLE           RECORDING        TRANSCRIBING    ERROR      │\n│  ┌───┐          ┌───┐            ┌───┐          ┌───┐      │\n│  │🎤 │          │🔴 │ (pulsing)  │⏳ │          │⚠️ │      │\n│  └───┘          └───┘            └───┘          └───┘      │\n│  \"Click to      \"Recording...   \"Transcribing  \"Failed,   │\n│   speak\"         Click to stop\"  ...\"           retry\"    │\n└─────────────────────────────────────────────────────────────┘\n```\n\n### Voice Narration Toggle\n\n```\n┌─────────────────────────────────────────────────────────────┐\n│  Header bar:                                                │\n│  ┌────────────────────────────────────────────────────┐    │\n│  │ [Execution ▼]           [🔊] [⛶] [✕]               │    │\n│  └────────────────────────────────────────────────────┘    │\n│                             │                               │\n│                             └── Voice toggle button         │\n│                                 🔊 = enabled (speaking)     │\n│                                 🔇 = disabled               │\n│                                                             │\n│  When speaking, show indicator:                             │\n│  ┌────────────────────────────────────────────────────┐    │\n│  │ 🔊 ▁▃▅▇▅▃▁ \"Reading the login component...\"        │    │\n│  └────────────────────────────────────────────────────┘    │\n└─────────────────────────────────────────────────────────────┘\n```\n\n### Input Area with Voice\n\n```\n┌─────────────────────────────────────────────────────────────┐\n│  Current:                                                   │\n│  ┌────────────────────────────────────────────────────┐    │\n│  │ [Send a follow-up message...              ] [Send] │    │\n│  └────────────────────────────────────────────────────┘    │\n│                                                             │\n│  With voice:                                                │\n│  ┌────────────────────────────────────────────────────┐    │\n│  │ [Send a follow-up message...          ] [🎤] [Send]│    │\n│  └────────────────────────────────────────────────────┘    │\n│                                                             │\n│  While recording:                                           │\n│  ┌────────────────────────────────────────────────────┐    │\n│  │ [🔴 Recording... click to stop        ] [⏹️] [---]│    │\n│  └────────────────────────────────────────────────────┘    │\n│                                                             │\n│  After transcription (editable):                            │\n│  ┌────────────────────────────────────────────────────┐    │\n│  │ [Fix the login validation bug         ] [🎤] [Send]│    │\n│  └────────────────────────────────────────────────────┘    │\n└─────────────────────────────────────────────────────────────┘\n```\n\n---\n\n## Server Implementation\n\n### New Files\n\n```\nserver/src/\n├── routes/\n│   └── voice.ts                   # Voice API endpoints\n├── services/\n│   ├── stt-service.ts             # Speech-to-text abstraction\n│   ├── tts-service.ts             # Text-to-speech abstraction\n│   └── narration-service.ts       # Generate narration from events\n└── types/\n    └── voice.d.ts                 # Voice type definitions\n```\n\n### STT Service\n\n```typescript\n// services/stt-service.ts\ninterface STTProvider {\n  transcribe(audio: Buffer, options?: STTOptions): Promise<TranscriptionResult>;\n  isAvailable(): Promise<boolean>;\n}\n\nclass WhisperLocalProvider implements STTProvider {\n  // Uses whisper.cpp or local whisper server\n}\n\nclass OpenAIWhisperProvider implements STTProvider {\n  // Uses OpenAI Whisper API\n}\n\nclass STTService {\n  private providers: Map<string, STTProvider>;\n  \n  async transcribe(audio: Buffer, preferredProvider?: string): Promise<TranscriptionResult> {\n    // Try preferred provider, fall back to others\n  }\n}\n```\n\n### Narration Service\n\n```typescript\n// services/narration-service.ts\nclass NarrationService {\n  // Converts execution events to spoken text\n  \n  summarizeForVoice(event: ExecutionEvent): string | null {\n    switch (event.type) {\n      case 'tool_use':\n        return this.describeToolUse(event);\n      case 'assistant':\n        return this.summarizeAssistantMessage(event.content);\n      case 'error':\n        return `Error: ${this.summarizeError(event)}`;\n      default:\n        return null;\n    }\n  }\n  \n  private describeToolUse(event: ToolUseEvent): string {\n    // \"Reading src/login.tsx\"\n    // \"Running npm test\"\n    // \"Editing the validation function\"\n  }\n  \n  private summarizeAssistantMessage(content: string): string {\n    // If short (<100 chars), return as-is\n    // If long, summarize to 1-2 sentences\n  }\n}\n```\n\n---\n\n## Configuration\n\n### Environment Variables\n\n```bash\n# STT Configuration\nVOICE_STT_PROVIDER=whisper-local  # whisper-local | openai\nVOICE_WHISPER_MODEL=base          # tiny | base | small | medium | large\nVOICE_WHISPER_URL=http://localhost:2022/v1\n\n# TTS Configuration  \nVOICE_TTS_PROVIDER=browser        # browser | kokoro | openai\nVOICE_KOKORO_URL=http://localhost:8880/v1\nVOICE_TTS_VOICE=nova              # Default voice\n\n# Feature Flags\nVOICE_ENABLED=true\nVOICE_NARRATION_ENABLED=true\n```\n\n### User Preferences (localStorage)\n\n```typescript\ninterface VoicePreferences {\n  narrationEnabled: boolean;\n  ttsProvider: 'browser' | 'kokoro' | 'openai';\n  ttsVoice: string;\n  narrationSpeed: number;  // 0.5 - 2.0\n  narrationVolume: number; // 0 - 1\n}\n```\n\n---\n\n## Implementation Phases\n\n### Phase 1: Voice Input (STT)\n\n1. Create `useVoiceInput` hook with MediaRecorder\n1. Add `/api/voice/transcribe` endpoint\n1. Implement Whisper local provider\n1. Add `VoiceInputButton` to chat widget\n1. Add transcription preview/edit UI\n\n### Phase 2: Voice Narration (TTS) - Browser\n\n1. Create `useVoiceNarration` hook with Web Speech API\n1. Add `VoiceNarrationToggle` to chat widget header\n1. Add `VoiceSpeakingIndicator` component\n1. Emit `voice_narration` events from execution stream\n1. Create `NarrationService` for event summarization\n\n### Phase 3: Enhanced TTS Providers\n\n1. Add `/api/voice/synthesize` endpoint\n1. Implement Kokoro provider\n1. Implement OpenAI TTS provider\n1. Add provider selection in settings\n1. Add voice selection UI\n\n### Phase 4: Polish\n\n1. Add keyboard shortcuts (hold Space to record)\n1. Add audio level visualization while recording\n1. Persist voice preferences\n1. Add \"skip\" button during narration\n1. Handle edge cases (permissions, errors)\n\n---\n\n## Edge Cases\n\n| Scenario | Handling |\n| --- | --- |\n| Mic permission denied | Show error, offer to open settings |\n| No STT provider available | Disable voice input, show tooltip |\n| TTS interrupted by new narration | Queue or skip based on priority |\n| User starts recording while TTS playing | Pause TTS, resume after |\n| Long narration text | Chunk into sentences, allow skip |\n| Execution ends while narrating | Finish current sentence, stop |\n| Network error during transcription | Show error, allow retry |\n| Multiple executions with narration | Only narrate focused execution |\n\n---\n\n## Testing\n\n### Unit Tests\n\n- `useVoiceInput` hook states and transitions\n- `useVoiceNarration` queue management\n- `NarrationService` summarization logic\n- STT/TTS provider fallback logic\n\n### Integration Tests\n\n- Full recording → transcription → follow-up flow\n- Narration event → speech playback flow\n- Provider switching\n\n### E2E Tests\n\n- Voice input with mocked MediaRecorder\n- Voice narration with mocked SpeechSynthesis\n\n---\n\n## Success Metrics\n\n- Voice input used in >10% of follow-ups\n- Narration enabled by >20% of users\n- Transcription accuracy >95%\n- No audio playback issues reported\n\n---\n\n## Future Enhancements\n\n### Phase 5: Voice Input Modes (v1.1)\n\nAdd alternative input modes beyond manual click-to-record:\n\n#### Hold-to-Talk Mode\n\n- Hold Space bar (or mic button) to record\n- Release to stop and transcribe\n- Auto-submit after transcription (no preview)\n- Simple to implement - no VAD required\n\n```\n[Hold Space] → speak → [Release Space] → transcribe → submit\n```\n\n#### Auto-Detect Mode (VAD)\n\n- Click mic once to start listening\n- Voice Activity Detection (VAD) detects speech start/end\n- Automatically stops recording after silence threshold\n- Requires: `@ricky0123/vad-web` (Silero VAD for browser)\n\n```\n[Click mic] → VAD listening → speak → silence detected → transcribe → submit\n```\n\n**VAD Configuration:**\n\n```typescript\ninterface VADConfig {\n  silenceThresholdMs: number;    // 800-1500ms recommended\n  speechPadMs: number;           // Padding around speech (300ms)\n  minSpeechDurationMs: number;   // Minimum utterance length (250ms)\n}\n```\n\n**Implementation:**\n\n```typescript\nimport { MicVAD } from '@ricky0123/vad-web';\n\nconst vad = await MicVAD.new({\n  onSpeechEnd: async (audio: Float32Array) => {\n    const text = await transcribe(audio);\n    if (config.showPreview) {\n      setPreviewText(text);\n    } else {\n      submit(text);\n    }\n  },\n  positiveSpeechThreshold: 0.8,\n  negativeSpeechThreshold: 0.4,\n  redemptionFrames: 8,\n});\n```\n\n#### Mode Selection UI\n\n```\n┌─────────────────────────────────────────────────────────────┐\n│  Voice Input Mode (Settings):                               │\n│                                                             │\n│  ○ Manual - Click to start, click to stop                  │\n│  ○ Hold to talk - Hold Space or mic button                 │\n│  ○ Auto-detect - Stops when you stop speaking              │\n│                                                             │\n│  [Silence threshold: ●────────── 1.0s] (auto mode only)    │\n│                                                             │\n│  ☑ Show preview before sending                              │\n│  ☑ Play confirmation sound                                  │\n└─────────────────────────────────────────────────────────────┘\n```\n\n---\n\n### Phase 6: Real-time Transcription Preview (v1.2)\n\nShow live transcription while user is speaking using Web Speech API:\n\n```\n┌─────────────────────────────────────────────────────────────┐\n│  While recording with live preview:                         │\n│  ┌────────────────────────────────────────────────────┐    │\n│  │ [🔴 \"Fix the login validat...\" ] [⏹️]              │    │\n│  └────────────────────────────────────────────────────┘    │\n│         ↑ Live transcription (Web Speech API)              │\n│                                                             │\n│  After stop, refine with Whisper:                          │\n│  ┌────────────────────────────────────────────────────┐    │\n│  │ [Fix the login validation bug   ] [🎤] [Send]     │    │\n│  └────────────────────────────────────────────────────┘    │\n│         ↑ Final transcription (more accurate)              │\n└─────────────────────────────────────────────────────────────┘\n```\n\n**Implementation:**\n\n- Use Web Speech API for real-time preview (free, instant)\n- Use Whisper for final transcription (more accurate)\n- Show preview updating as user speaks\n- Replace with final result when Whisper completes\n\n---\n\n### Phase 7: Voice Commands (v1.3)\n\nDetect command phrases during narration or idle:\n\n| Command | Action |\n| --- | --- |\n| \"Stop\" / \"Cancel\" | Stop current execution |\n| \"Pause\" | Pause execution |\n| \"Resume\" / \"Continue\" | Resume paused execution |\n| \"Skip\" | Skip current narration |\n| \"Quieter\" / \"Louder\" | Adjust narration volume |\n| \"Faster\" / \"Slower\" | Adjust narration speed |\n| \"Repeat\" | Repeat last narration |\n\n**Implementation:**\n\n- Always-on listening with low-power VAD\n- Keyword spotting for command detection\n- Or: dedicated \"command mode\" button\n\n---\n\n### Phase 8: Continuous Conversation Mode (v2.0)\n\nFull back-and-forth voice conversation without clicking:\n\n```\n┌─────────────────────────────────────────────────────────────┐\n│  Continuous mode flow:                                      │\n│                                                             │\n│  Agent speaks → silence → User speaks → silence → Agent... │\n│       │                        │                            │\n│       └── VAD detects ────────┘                            │\n│           user ready                                        │\n│                                                             │\n│  UI shows current state:                                    │\n│  ┌────────────────────────────────────────────────────┐    │\n│  │  🤖 Speaking...  │  👂 Listening...  │  💭 Thinking │   │\n│  └────────────────────────────────────────────────────┘    │\n└─────────────────────────────────────────────────────────────┘\n```\n\n**Considerations:**\n\n- Requires LiveKit for low-latency bidirectional audio\n- Interruption handling (user speaks while agent speaking)\n- Turn-taking detection\n- Echo cancellation\n\n---\n\n### Phase 9: Advanced Features (v2.x)\n\n#### Wake Word Detection\n\n- \"Hey Claude\" or custom wake word\n- Always-on low-power listening\n- Libraries: Porcupine, Snowboy, or browser-based\n\n#### Multi-language Support\n\n- Language detection from speech\n- Auto-switch STT/TTS language\n- Translation mode (speak in one language, agent responds in another)\n\n#### Voice Personas\n\n- Different voices for different agent states\n- Thinking voice vs. responding voice\n- Error voice with different tone\n\n#### Audio Visualization\n\n- Waveform display while recording\n- Audio level meter\n- Voice activity indicator\n\n#### Accessibility\n\n- Screen reader announcements for voice events\n- Keyboard-only voice control\n- High contrast mode for indicators\n\n---\n\n### Dependency Summary for Future Phases\n\n| Phase | New Dependencies |\n| --- | --- |\n| 5 (VAD) | `@ricky0123/vad-web` (~2MB, Silero ONNX) |\n| 6 (Live preview) | None (Web Speech API is built-in) |\n| 7 (Commands) | Keyword spotting or full STT |\n| 8 (Continuous) | LiveKit client SDK |\n| 9 (Wake word) | Porcupine or similar |","priority":2,"archived":0,"archived_at":null,"created_at":"2025-12-21 21:52:25","updated_at":"2025-12-23 03:28:27","parent_id":null,"parent_uuid":null,"relationships":[],"tags":["accessibility","chat-widget","stt","tts","voice"]}
{"id":"s-9e6i","uuid":"7a9c8ea9-02cb-4156-b733-4c9418f3facf","title":"Project Assistant MCP Server","file_path":"specs/s-9e6i_project_assistant_mcp_server.md","content":"# Project Assistant MCP Server\n\n## Overview\n\nA new MCP server that provides the Project Assistant agent with full visibility and control over the sudocode project - including executions, workflows, issues, and specs. This follows the same architectural pattern as the Workflow MCP but is scoped to the entire project rather than a single workflow.\n\n## Background & Context\n\n### Existing Architecture\n\nThe codebase has two MCP server patterns:\n\n1. **Main MCP Server** (`/mcp/src/`)\n   - Uses CLI subprocess pattern (spawns `sudocode` CLI commands)\n   - Provides tools for issues, specs, relationships, feedback\n   - Tools: `ready`, `list_issues`, `show_issue`, `upsert_issue`, `list_specs`, `show_spec`, `upsert_spec`, `link`, `add_reference`, `add_feedback`\n\n2. **Workflow MCP Server** (`/server/src/workflow/mcp/`)\n   - Uses HTTP API client pattern (calls REST endpoints on main server)\n   - Scoped to a single workflow (requires `workflowId`)\n   - Spawned per-workflow when orchestrator execution starts\n   - Tools for workflow control, execution management, inspection, escalation\n\n### Why a New MCP Server?\n\nThe Project Assistant needs:\n- **Execution visibility**: List/view all executions, see changes and trajectories\n- **Workflow visibility**: List/view all workflows, see step progress\n- **Full control**: Start executions, create workflows, cancel operations\n- **Project-wide scope**: Not limited to a single workflow\n\nThe existing main MCP doesn't expose executions or workflows. The workflow MCP is scoped to a single workflow. A new MCP server bridges this gap.\n\n## Requirements\n\n### Functional Requirements\n\n1. **Spawned per-execution**: Server spawns the MCP subprocess when starting a project assistant execution\n2. **Full control scope**: Both read (visibility) and write (create/modify) operations\n3. **HTTP API pattern**: Follow workflow MCP pattern using HTTP client to call server REST API\n4. **Location**: `server/src/project-assistant/mcp/` alongside workflow MCP\n\n### CLI Arguments\n\n```bash\nnode index.js \\\n  --execution-id <id>   # The project assistant's own execution ID\n  --server-url <url>    # Base URL (e.g., http://localhost:3000)\n  --project-id <id>     # For X-Project-ID header\n  --repo-path <path>    # Repository root path\n```\n\nNote: Unlike workflow MCP, no `--workflow-id` - this operates at project level.\n\n## Design\n\n### File Structure\n\n```\nserver/src/project-assistant/mcp/\n├── index.ts              # Entry point, CLI argument parsing\n├── server.ts             # MCP server setup & tool dispatch\n├── api-client.ts         # HTTP client for main server communication\n├── types.ts              # Type definitions (params, results, context)\n└── tools/\n    ├── overview.ts       # project_status, ready_work\n    ├── executions.ts     # list, show, start, follow-up, cancel\n    ├── inspection.ts     # trajectory, changes, chain\n    ├── workflows.ts      # list, show, create, start, pause, cancel\n    ├── entities.ts       # list/show issues and specs\n    └── escalation.ts     # escalate_to_user, notify_user\n```\n\n### Context Interface\n\n```typescript\ninterface ProjectAssistantMCPContext {\n  executionId: string;  // The assistant's own execution ID\n  apiClient: ProjectAssistantAPIClient;\n  repoPath: string;\n}\n```\n\n### MCP Tools (22 total)\n\n#### Overview Tools (2)\n| Tool | Parameters | Description |\n|------|------------|-------------|\n| `project_status` | none | Get ready issues, active executions, running workflows |\n| `ready_work` | `limit?`, `includeInProgress?` | Get issues ready to work on |\n\n#### Execution Tools (6)\n| Tool | Parameters | Description |\n|------|------------|-------------|\n| `list_executions` | `status?[]`, `issueId?`, `limit?`, `since?`, `tags?[]` | List executions with filters |\n| `show_execution` | `execution_id` | Get execution details |\n| `start_execution` | `issue_id`, `agent_type?`, `model?`, `prompt?` | Start execution for issue |\n| `start_adhoc_execution` | `prompt`, `agent_type?`, `model?` | Start execution without issue |\n| `create_follow_up` | `execution_id`, `feedback` | Create follow-up execution |\n| `cancel_execution` | `execution_id`, `reason?` | Cancel running execution |\n\n#### Inspection Tools (3)\n| Tool | Parameters | Description |\n|------|------------|-------------|\n| `execution_trajectory` | `execution_id`, `max_entries?` | Get agent actions/tool calls |\n| `execution_changes` | `execution_id`, `include_diff?` | Get code changes |\n| `execution_chain` | `execution_id` | Get full execution chain |\n\n#### Workflow Tools (7)\n| Tool | Parameters | Description |\n|------|------------|-------------|\n| `list_workflows` | `status?[]`, `limit?` | List workflows |\n| `show_workflow` | `workflow_id` | Get workflow details |\n| `workflow_status` | `workflow_id` | Get extended status with steps |\n| `create_workflow` | `source`, `config?` | Create new workflow |\n| `start_workflow` | `workflow_id` | Start pending workflow |\n| `pause_workflow` | `workflow_id` | Pause running workflow |\n| `cancel_workflow` | `workflow_id` | Cancel workflow |\n\n#### Entity Tools (4)\n| Tool | Parameters | Description |\n|------|------------|-------------|\n| `list_issues` | `status?`, `priority?`, `search?`, `limit?` | List issues |\n| `show_issue` | `issue_id` | Get issue details |\n| `list_specs` | `search?`, `limit?` | List specs |\n| `show_spec` | `spec_id` | Get spec details |\n\n#### Escalation Tools (2)\n| Tool | Parameters | Description |\n|------|------------|-------------|\n| `escalate_to_user` | `message`, `options?[]`, `context?` | Request user input |\n| `notify_user` | `message`, `level?` | Send notification |\n\n### API Endpoints Used\n\n#### Existing Endpoints\n- `GET /api/executions` - list with filters\n- `GET /api/executions/:id` - get details\n- `GET /api/executions/:id/chain` - get chain\n- `GET /api/executions/:id/logs` - get trajectory\n- `GET /api/executions/:id/changes` - get changes\n- `POST /api/executions` - create adhoc\n- `POST /api/issues/:id/executions` - create for issue\n- `POST /api/executions/:id/follow-up` - create follow-up\n- `POST /api/executions/:id/cancel` - cancel\n- `GET /api/workflows` - list\n- `GET /api/workflows/:id` - get details\n- `GET /api/workflows/:id/status` - extended status\n- `POST /api/workflows` - create\n- `POST /api/workflows/:id/start|pause|cancel` - control\n- `GET /api/issues`, `GET /api/issues/:id`\n- `GET /api/specs`, `GET /api/specs/:id`\n\n#### New Endpoints Required\n- `POST /api/executions/:id/escalate` - create escalation for execution\n- `POST /api/executions/:id/notify` - send notification from execution\n\n### Key Differences from Workflow MCP\n\n| Aspect | Workflow MCP | Project Assistant MCP |\n|--------|--------------|----------------------|\n| Scope | Single workflow | Entire project |\n| Context | `workflowId` required | `executionId` (self) |\n| Purpose | Orchestrate workflow steps | General project management |\n| Tools | Workflow-centric (10) | Project-wide (22) |\n| Spawning | When workflow starts | When project assistant execution starts |\n\n## Implementation Plan\n\n### Phase 1: Core Infrastructure\n1. Create `server/src/project-assistant/mcp/` directory\n2. `types.ts` - Context interface, param/result types\n3. `api-client.ts` - HTTP client (copy pattern from workflow MCP)\n4. `server.ts` - MCP server setup with tool dispatch\n5. `index.ts` - CLI entry point\n\n### Phase 2: Read-Only Tools\n1. `tools/overview.ts` - project_status, ready_work\n2. `tools/entities.ts` - list/show issues and specs\n3. `tools/inspection.ts` - trajectory, changes, chain\n4. `tools/executions.ts` - list_executions, show_execution\n\n### Phase 3: Control Tools\n1. `tools/executions.ts` - start, follow-up, cancel\n2. `tools/workflows.ts` - all workflow tools\n3. Add escalation endpoints to server routes\n4. `tools/escalation.ts` - escalate_to_user, notify_user\n\n### Phase 4: Integration\n1. Modify execution service to spawn MCP for project assistant type\n2. Add build script for the MCP server\n3. Testing\n\n## Reference Files\n\n- `server/src/workflow/mcp/server.ts` - MCP server pattern to follow\n- `server/src/workflow/mcp/api-client.ts` - HTTP client pattern\n- `server/src/workflow/mcp/types.ts` - Type definitions pattern\n- `server/src/routes/executions.ts` - Add escalation endpoints\n- `server/src/services/execution-service.ts` - Integration point for spawning","priority":1,"archived":0,"archived_at":null,"created_at":"2025-12-23 02:48:23","updated_at":"2025-12-23 02:48:23","parent_id":null,"parent_uuid":null,"relationships":[],"tags":["architecture","feature","mcp","project-assistant"]}
{"id":"s-2hpj","uuid":"0ffd471b-4c22-40ea-98f1-7a02a8eca75f","title":"YAML-Based Three-Way Merge with Preserved Two-Way Resolution","file_path":"specs/s-2hpj_yaml_based_three_way_merge_with_preserved_two_way_.md","content":"# YAML-Based Three-Way Merge with Preserved Two-Way Resolution\n\n## Problem Statement\n\nThe current merge resolver has two critical issues:\n\n1. `mergeThreeWay` **ignores base version** - Treats all merges as two-way, losing valuable conflict resolution information\n1. **No line-level merging for text fields** - Entire multi-line fields (description, content, feedback) conflict atomicall\n\n### Current Behavior\n\n```typescript\n// Current naive implementation\nexport function mergeThreeWay<T extends JSONLEntity>(\n  base: T[], ours: T[], theirs: T[]\n): ResolvedResult<T> {\n  const allEntities = [...base, ...ours, ...theirs]; // Ignores base!\n  return resolveEntities(allEntities);\n}\n```\n\n**Result:** Agent A edits paragraph 1, Agent B edits paragraph 3 → full conflict, manual merge required\n\n### Previous Attempt (merge-fix-2 branch)\n\nThe merge-fix-2 branch implemented comprehensive YAML-based three-way merging but made a critical mistake: **removed** `resolveEntities` **entirely**. This broke two-way merge scenarios that depend on simple UUID-based deduplication.\n\n**Why this was wrong:**\n\n- `resolveEntities` is optimal for manual conflict resolution (already isolated by git markers)\n- YAML expansion is overkill for simple two-way scenarios\n- Two distinct use cases require two distinct algorithms\n\n## Solution: Dual-Algorithm Approach\n\nEnhance `mergeThreeWay` with proper three-way semantics and YAML expansion while **preserving** `resolveEntities` for two-way scenarios.\n\n### Use Case 1: Two-Way Merge → Keep `resolveEntities`\n\n**When:**\n\n- Manual conflict resolution (`sudocode resolve-conflicts`)\n- Conflicts already isolated by git conflict markers\n- Simple UUID deduplication sufficient\n\n**Why optimal:**\n\n- Fast (no YAML conversion overhead)\n- Simple (UUID grouping + metadata merge)\n- Proven (already works in production)\n\n### Use Case 2: Three-Way Merge → Enhance `mergeThreeWay`\n\n**When:**\n\n- Git merge driver operations\n- Worktree sync with true base/ours/theirs versions\n- Line-level merging needed for multi-line text fields\n\n**Why YAML expansion:**\n\n- Enables git merge-file to handle line-level changes\n- Auto-merges changes to different paragraphs/sections\n- Reduces conflicts to genuine same-line edits\n\n## Detailed Design: Enhanced `mergeThreeWay`\n\n### High-Level Flow\n\n```\nInput: base[], ours[], theirs[] (all three required)\n  ↓\n1. Group entities by UUID across all three versions\n  ↓\n2. For each UUID group:\n   a. Handle deletion cases (modification wins)\n   b. Merge metadata FIRST (tags, relationships, feedback)\n   c. Apply merged metadata to all three versions\n  ↓\n3. Convert to YAML with multi-line text expansion\n  ↓\n4. Run git merge-file (line-level merging)\n  ↓\n5. Resolve remaining YAML conflicts (latest-wins)\n  ↓\n6. Convert back to JSON\n  ↓\n7. Handle ID collisions (hash conflicts)\n  ↓\nOutput: Merged entities sorted by created_at\n```\n\n### Key Implementation Details\n\n#### Step 1: UUID Grouping\n\n```typescript\nconst byUuid = new Map<string, {\n  base?: T;\n  ours?: T;\n  theirs?: T;\n}>();\n\n// Populate from all three versions\nfor (const entity of base) byUuid.set(entity.uuid, { ...byUuid.get(entity.uuid), base: entity });\nfor (const entity of ours) byUuid.set(entity.uuid, { ...byUuid.get(entity.uuid), ours: entity });\nfor (const entity of theirs) byUuid.set(entity.uuid, { ...byUuid.get(entity.uuid), theirs: entity });\n```\n\n#### Step 2a: Deletion Handling\n\n```typescript\nconst { base: baseEntity, ours: oursEntity, theirs: theirsEntity } = versions;\n\n// Deleted in both → skip\nif (!oursEntity && !theirsEntity) continue;\n\n// Deleted in one, modified in other → modification wins\nif (baseEntity && !theirsEntity && oursEntity) {\n  mergedEntities.push(oursEntity);\n  continue;\n}\nif (baseEntity && !oursEntity && theirsEntity) {\n  mergedEntities.push(theirsEntity);\n  continue;\n}\n```\n\n#### Step 2b-c: Metadata Merge First\n\n```typescript\n// Collect non-null versions\nconst versionsForMetadata = [baseEntity, oursEntity, theirsEntity].filter(Boolean);\n\n// Merge metadata (existing function)\nconst metadataMerged = mergeMetadata(versionsForMetadata);\n\n// Apply to all versions\nconst baseWithMetadata = baseEntity ? { ...baseEntity, ...metadataMerged } : undefined;\nconst oursWithMetadata = { ...oursEntity, ...metadataMerged };\nconst theirsWithMetadata = { ...theirsEntity, ...metadataMerged };\n```\n\n**Critical insight:** By merging metadata BEFORE YAML conversion, we eliminate metadata conflicts entirely. Git merge-file only sees text field differences.\n\n#### Step 3: YAML Conversion with Multi-Line Expansion\n\n```typescript\nimport { toYaml, fromYaml } from './yaml-converter';\n\nconst baseYaml = baseWithMetadata ? toYaml(baseWithMetadata) : '';\nconst oursYaml = toYaml(oursWithMetadata);\nconst theirsYaml = toYaml(theirsWithMetadata);\n```\n\n**YAML Converter Requirements:**\n\n- Multi-line text fields → literal style (`|`)\n- Arrays (already merged) → block style with `-` items\n- Simple scalars → plain style\n- Deterministic formatting (2-space indent, stable key order)\n- Lossless round-trip (JSON → YAML → JSON)\n\n#### Step 4: Git Merge-File\n\n```typescript\nimport { mergeYamlContent } from './git-merge';\n\nconst gitMergeResult = mergeYamlContent({\n  base: baseYaml,\n  ours: oursYaml,\n  theirs: theirsYaml,\n});\n\nlet finalYaml = gitMergeResult.content;\n```\n\n**Git Merge Wrapper Requirements:**\n\n- Execute `git merge-file` on YAML strings\n- Return `{ content: string, hasConflicts: boolean }`\n- Handle empty base gracefully\n- Preserve conflict markers when conflicts exist\n\n#### Step 5: Conflict Resolution\n\n```typescript\nimport { resolveConflicts } from './yaml-conflict-resolver';\n\nif (gitMergeResult.hasConflicts) {\n  const resolveResult = resolveConflicts(\n    finalYaml,\n    oursWithMetadata,\n    theirsWithMetadata,\n    options\n  );\n  \n  finalYaml = resolveResult.content;\n}\n```\n\n**Conflict Resolver Requirements:**\n\n- Parse YAML conflict markers\n- Compare `updated_at` timestamps\n- Apply latest-wins strategy\n- Remove conflict markers\n- Fallback to keeping both if ambiguous\n\n#### Step 6: Convert Back to JSON\n\n```typescript\nconst mergedEntity = fromYaml(finalYaml) as T;\nmergedEntities.push(mergedEntity);\n```\n\n#### Step 7: ID Collision Handling\n\n```typescript\n// After all entities processed\nconst finalEntities = handleIdCollisions(mergedEntities);\n\n// Sort by created_at (git-friendly)\nfinalEntities.sort((a, b) => {\n  const dateCompare = new Date(a.created_at).getTime() - new Date(b.created_at).getTime();\n  return dateCompare !== 0 ? dateCompare : a.id.localeCompare(b.id);\n});\n```\n\n## YAML Converter Implementation\n\n### Multi-Line Detection\n\nUse literal style (`|`) when:\n\n- String contains `\\n` characters\n- String length > 80 characters (optional for readability)\n\n### Example YAML Output\n\n```yaml\nid: s-abc123\nuuid: 550e8400-e29b-41d4-a716-446655440000\ntitle: OAuth Authentication System\npriority: 1\nstatus: in_progress\ncreated_at: \"2025-01-01T10:00:00Z\"\nupdated_at: \"2025-01-02T15:30:00Z\"\ntags:\n  - backend\n  - security\nrelationships:\n  - from: i-123\n    to: s-abc123\n    type: implements\ndescription: |\n  ## Overview\n  \n  This spec defines the OAuth 2.0 authentication system.\n  \n  ## Requirements\n  \n  1. Support authorization code flow\n  2. Implement PKCE for security\n  3. Handle token refresh gracefully\ncontent: |\n  # Implementation Details\n  \n  The system will use the authorization code flow with PKCE.\n  \n  ## Architecture\n  \n  - Auth service handles OAuth flow\n  - Token service manages refresh tokens\n  - Middleware validates JWT tokens\n```\n\n**Key features:**\n\n- Multi-line strings use literal style with `|`\n- Each line of text is separate in git's view\n- Changes to different paragraphs auto-merge\n- Arrays use block style (one item per line)\n\n### Round-Trip Validation\n\nCritical invariants:\n\n```typescript\nconst original = { /* entity */ };\nconst yaml = toYaml(original);\nconst restored = fromYaml(yaml);\n\n// Must be deep equal\nexpect(restored).toEqual(original);\n```\n\n## Integration Points\n\n### 1\\. Git Merge Driver (Automatic Resolution)\n\nLocation: `cli/src/merge-driver.ts`\n\n```typescript\nconst baseEntities = await readJSONL(`:1:${relativePath}`); // git stage 1\nconst oursEntities = await readJSONL(`:2:${relativePath}`); // git stage 2\nconst theirsEntities = await readJSONL(`:3:${relativePath}`); // git stage 3\n\nconst { entities: merged } = mergeThreeWay(baseEntities, oursEntities, theirsEntities);\n\nawait writeJSONL(relativePath, merged);\n```\n\n### 2\\. Worktree Sync Service (Programmatic Merges)\n\nLocation: `server/src/services/worktree-sync-service.ts`\n\n**Current usage in** `_resolveJSONLFile`**:**\n\n```typescript\n// OLD: Naive merge ignoring base\nconst { entities: merged } = mergeThreeWay(\n  baseVersion,\n  ourVersion,\n  theirVersion\n);\n\n// NEW: Proper three-way merge with YAML expansion (same code, but mergeThreeWay is now enhanced)\n```\n\n**Keep two-way merge for uncommitted files:**\n\n```typescript\n// In _mergeJSONLFiles - when merging uncommitted local + worktree\n// This is truly two-way (no base), use resolveEntities\nconst allEntities = [...localEntities, ...worktreeEntities];\nconst { entities: merged } = resolveEntities(allEntities);\n```\n\n### 3\\. Manual Conflict Resolution\n\nLocation: `cli/src/cli/merge-commands.ts`\n\n**Keep existing** `resolveEntities` **usage:**\n\n```typescript\n// Parse conflict markers\nconst allEntities = extractEntitiesFromConflicts(content);\n\n// Resolve with UUID-based deduplication\nconst { entities: resolved, stats } = resolveEntities(allEntities, {\n  verbose: options.verbose,\n});\n```\n\n**Why not use** `mergeThreeWay` **here:**\n\n- Conflicts already isolated by git markers\n- No base version available (git index cleared after conflict)\n- Simple UUID deduplication is sufficient\n- `resolveEntities` is faster and simpler\n\n## Design Decisions\n\n### 1\\. Preserve `resolveEntities` Function\n\n**Decision:** Keep `resolveEntities` as-is for two-way merge scenarios.\n\n**Rationale:**\n\n- Optimal for manual conflict resolution\n- No YAML overhead needed\n- Already proven in production\n- Different use case than three-way merge\n\n### 2\\. Metadata Merge Before YAML\n\n**Decision:** Always merge metadata first, apply to all versions before YAML conversion.\n\n**Rationale:**\n\n- Eliminates metadata conflicts entirely\n- Git merge-file only sees text differences\n- Clearer separation of concerns\n- Metadata merging is deterministic (union)\n\n### 3\\. YAML Formatting Rules\n\n**Decision:** Strict, deterministic formatting.\n\n**Rules:**\n\n- 2-space indentation (never tabs)\n- Stable key order (preserve JSON insertion order)\n- Literal style (`|`) for multi-line strings\n- Block style for arrays (one item per line)\n- No unnecessary quoting\n- LF line endings\n- Single trailing newline\n\n**Rationale:** Prevents spurious conflicts from formatting differences.\n\n### 4\\. Latest-Wins for Conflicts\n\n**Decision:** Use `updated_at` timestamp to resolve YAML conflicts.\n\n**Rationale:**\n\n- Most recent change likely most correct\n- Simple, deterministic heuristic\n- Better than arbitrary choice\n- User can override manually if needed\n\n### 5\\. Modification Wins Over Deletion\n\n**Decision:** If entity deleted in one branch, modified in other → keep modification.\n\n**Rationale:**\n\n- Preserves work (deletion is easy to redo)\n- Aligns with git's default behavior\n- Conservative approach (avoid data loss)\n\n### 6\\. ID Collision Handling\n\n**Decision:** Keep collision detection in final step.\n\n**Strategy:**\n\n- First occurrence keeps original ID\n- Duplicates get `.1`, `.2` suffixes\n- Log warnings for visibility\n\n**Rationale:** Hash collisions rare but must be handled safely.\n\n## Implementation Files\n\n### New Files (from merge-fix-2 branch)\n\n`cli/src/yaml-converter.ts` (~160 lines)\n\n- `toYaml(entity: JSONLEntity): string`\n- `fromYaml(yaml: string): JSONLEntity`\n- Multi-line detection and conversion\n- Round-trip validation helpers\n\n`cli/src/git-merge.ts` (~170 lines)\n\n- `mergeYamlContent({ base, ours, theirs }): { content, hasConflicts }`\n- Wraps `git merge-file` command\n- Temp file management\n- Error handling\n\n`cli/src/yaml-conflict-resolver.ts` (~250 lines)\n\n- `resolveConflicts(yaml, oursEntity, theirsEntity, options): { content, stats }`\n- Parse YAML conflict markers\n- Latest-wins timestamp comparison\n- Fallback strategies\n\n### Modified Files\n\n`cli/src/merge-resolver.ts`\n\n- Enhance `mergeThreeWay` with YAML pipeline\n- **Keep** `resolveEntities` **unchanged** (critical!)\n- Add ID collision helper\n\n`cli/src/cli/merge-commands.ts`\n\n- **No changes needed** (continues using `resolveEntities`)\n\n`server/src/services/worktree-sync-service.ts`\n\n- Use enhanced `mergeThreeWay` in `_resolveJSONLFile`\n- **Keep** `resolveEntities` for `_mergeJSONLFiles` (uncommitted two-way merge)\n\n### Test Files\n\n`cli/tests/unit/yaml-converter.test.ts` (new)\n\n- Round-trip validation for all entity types\n- Multi-line string handling\n- Edge cases (empty, null, unicode)\n\n`cli/tests/unit/yaml-conflict-resolver.test.ts` (new)\n\n- Conflict marker parsing\n- Latest-wins logic\n- Timestamp edge cases\n\n`cli/tests/unit/merge-resolver.test.ts` (enhance)\n\n- True three-way merge scenarios\n- Deletion handling\n- Metadata-first validation\n- Keep existing `resolveEntities` tests\n\n`cli/tests/integration/yaml-merge.test.ts` (new)\n\n- End-to-end three-way merge\n- Multi-line text merging\n- ID collision scenarios\n\n## Success Criteria\n\n### Functional Requirements\n\n1. ✅ `resolveEntities` **preserved** - Two-way merge scenarios work unchanged\n1. ✅ `mergeThreeWay` **enhanced** - Proper three-way semantics with YAML\n1. ✅ **Metadata merged first** - No metadata conflicts in YAML stage\n1. ✅ **Line-level text merging** - Different paragraphs auto-merge\n1. ✅ **Latest-wins for conflicts** - Same line edited → newer wins\n1. ✅ **Lossless round-trip** - JSON → YAML → JSON preserves all data\n1. ✅ **Deterministic YAML** - Same input → same output always\n\n### Non-Functional Requirements\n\n1. ✅ **Performance** - < 100ms per entity for YAML pipeline\n1. ✅ **Backward compatibility** - Existing `resolveEntities` users unaffected\n1. ✅ **Clear separation** - Two algorithms for two use cases\n1. ✅ **Comprehensive tests** - 90%+ coverage for new code\n1. ✅ **Migration path** - Can integrate from merge-fix-2 branch\n\n## Test Scenarios\n\n### Three-Way Merge (Enhanced `mergeThreeWay`)\n\n1. **Multi-line text - different paragraphs** - Agent A edits paragraph 1, B edits paragraph 3 → both preserved\n1. **Multi-line text - same line** - Both edit same line → conflict → latest-wins\n1. **Metadata already merged** - No array conflicts in YAML stage\n1. **Deletion vs modification** - Deleted in ours, modified in theirs → modification wins\n1. **Nested object changes** - Different nested fields → auto-merge\n\n### Two-Way Merge (Preserved `resolveEntities`)\n\n1. **Manual conflict resolution** - Parse markers, UUID dedup, write back\n1. **Uncommitted local + worktree** - Simple entity merging without base\n1. **Hash collisions** - Different UUIDs, same ID → rename with suffix\n1. **Same UUID, different IDs** - Keep newest, merge metadata\n\n### Edge Cases\n\n1. **Empty base** - Base = \\[\\], ours and theirs both present\n1. **Empty arrays** - Empty tags, relationships, feedback\n1. **Null values** - Null fields preserved\n1. **Unicode text** - Multi-byte characters in descriptions\n1. **Long text** - 10KB+ descriptions\n1. **Timestamp edge cases** - Missing, invalid, identical timestamps\n\n## Migration from merge-fix-2\n\nThe merge-fix-2 branch has most of the code we need:\n\n**Files to copy:**\n\n- `cli/src/yaml-converter.ts` ✅\n- `cli/src/git-merge.ts` ✅\n- `cli/src/yaml-conflict-resolver.ts` ✅\n- Test files for above ✅\n\n**Files to modify:**\n\n- `cli/src/merge-resolver.ts` - Integrate enhanced `mergeThreeWay` BUT keep `resolveEntities`\n- `server/src/services/worktree-sync-service.ts` - Update to use appropriate function for each scenario\n\n**Critical difference from merge-fix-2:**\n\n- **DO NOT remove** `resolveEntities` - it must remain for two-way scenarios\n- **DO NOT change merge-commands.ts** - it should continue using `resolveEntities`\n- **Only enhance** `mergeThreeWay` - leave two-way merge path intact\n\n## Out of Scope\n\n- Auto-resolving non-JSONL file conflicts\n- Changes to `resolveEntities` function\n- UI changes for conflict visualization\n- Performance optimizations beyond basic requirements\n- Support for non-JSONL file merging\n\n## References\n\n- Current merge resolver: `cli/src/merge-resolver.ts`\n- Previous implementation: `merge-fix-2` branch\n- YAML spec: [https://yaml.org/spec/1.2.2/](https://yaml.org/spec/1.2.2/)\n- Git merge-file: [https://git-scm.com/docs/git-merge-file](https://git-scm.com/docs/git-merge-file)\n- js-yaml library: [https://github.com/nodeca/js-yaml](https://github.com/nodeca/js-yaml)\n","priority":1,"archived":0,"archived_at":null,"created_at":"2025-12-26 22:35:12","updated_at":"2026-01-02T22:51:58.285Z","parent_id":null,"parent_uuid":null,"relationships":[],"tags":["backend","jsonl","merge","three-way-merge","yaml"]}
{"id":"s-183k","uuid":"dbe11e5a-ea58-46ed-bcf3-9b280f2ca408","title":"Sudocode MCP Server Scope-Based Tool Extension","file_path":"specs/s-183k_sudocode_mcp_server_scope_based_tool_extension.md","content":"# Sudocode MCP Server Scope-Based Tool Extension\n\n## Overview\n\nUpgrade the existing `sudocode-mcp` server to support opt-in extended functionality via a `--scope` argument. This consolidates the planned \"project-assistant\" MCP server capabilities into the main sudocode-mcp server, avoiding the need for a separate MCP server process.\n\n## Goals\n\n1. **Single MCP server** - One `sudocode-mcp` binary serves all functionality\n2. **Opt-in extended tools** - New tools are only available when explicitly enabled via `--scope`\n3. **Backwards compatible** - Default behavior unchanged; `--scope default` is implicit\n4. **Graceful degradation** - Extended tools excluded from `list_tools` when prerequisites (server URL) not met\n\n## Scope System Design\n\n### Scope Argument\n\n```\nsudocode-mcp [options] --scope <scope-list>\n```\n\nWhere `<scope-list>` is a comma-separated list of scope identifiers.\n\n### Scope Hierarchy\n\n```\ndefault                    # Current 10 CLI-wrapped tools (baseline)\n├── ready\n├── list_issues\n├── show_issue\n├── upsert_issue\n├── list_specs\n├── show_spec\n├── upsert_spec\n├── link\n├── add_reference\n└── add_feedback\n\nexecutions                 # Execution management (requires --server-url)\n├── executions:read\n│   ├── list_executions\n│   └── show_execution\n└── executions:write\n    ├── start_execution\n    ├── start_adhoc_execution\n    ├── create_follow_up\n    └── cancel_execution\n\ninspection                 # Execution inspection (requires --server-url)\n├── execution_trajectory\n├── execution_changes\n└── execution_chain\n\nworkflows                  # Workflow orchestration (requires --server-url)\n├── workflows:read\n│   ├── list_workflows\n│   ├── show_workflow\n│   └── workflow_status\n└── workflows:write\n    ├── create_workflow\n    ├── start_workflow\n    ├── pause_workflow\n    ├── cancel_workflow\n    └── resume_workflow\n\noverview                   # Extended project overview (requires --server-url)\n└── project_status\n\nescalation                 # User communication (requires --server-url)\n├── escalate_to_user\n└── notify_user\n\n# Meta-scopes (aliases)\nproject-assistant          # = executions,inspection,workflows,overview,escalation\nall                        # = default,project-assistant\n```\n\n### Scope Resolution Rules\n\n1. **Implicit default**: If `--scope` is not provided, `default` is assumed\n2. **Additive**: Scopes are additive; `--scope default,executions` enables both\n3. **Granular override**: `executions:read` enables only read tools from executions\n4. **Meta-scope expansion**: `project-assistant` expands to all extended scopes\n5. **No duplicates**: If a tool is already in `default`, it's not re-added by extended scopes\n\n## CLI Interface\n\n### New Arguments\n\n```\n--scope <scopes>       Comma-separated list of scopes to enable (default: \"default\")\n--server-url <url>     Local server URL for extended tools (required if scope != default)\n--project-id <id>      Project ID for API calls (auto-discovered from .sudocode if not provided)\n```\n\n### Examples\n\n```bash\n# Current behavior (unchanged)\nsudocode-mcp --working-dir /path/to/repo\n\n# Explicit default scope\nsudocode-mcp --working-dir /path/to/repo --scope default\n\n# Enable execution tools\nsudocode-mcp --working-dir /path/to/repo --scope default,executions --server-url http://localhost:3000\n\n# Enable all extended tools\nsudocode-mcp --working-dir /path/to/repo --scope all --server-url http://localhost:3000\n\n# Read-only execution monitoring\nsudocode-mcp --working-dir /path/to/repo --scope default,executions:read,inspection --server-url http://localhost:3000\n\n# Project assistant mode (all extended tools)\nsudocode-mcp --working-dir /path/to/repo --scope project-assistant --server-url http://localhost:3000\n```\n\n## Tool Definitions\n\n### Extended Tools (New)\n\nAll extended tools require `--server-url` and use the HTTP API client.\n\n#### Overview Scope\n\n| Tool | Description |\n|------|-------------|\n| `project_status` | Get current project state including ready issues, active executions, and running workflows |\n\n#### Executions Scope\n\n| Tool | Scope | Description |\n|------|-------|-------------|\n| `list_executions` | executions:read | List executions with optional filters (status, issue_id, since, tags) |\n| `show_execution` | executions:read | Get detailed execution info (status, commits, files changed) |\n| `start_execution` | executions:write | Start new execution for an issue |\n| `start_adhoc_execution` | executions:write | Start execution without associated issue |\n| `create_follow_up` | executions:write | Create follow-up execution continuing from previous |\n| `cancel_execution` | executions:write | Cancel a running execution |\n\n#### Inspection Scope\n\n| Tool | Description |\n|------|-------------|\n| `execution_trajectory` | Get agent's actions and tool calls from an execution |\n| `execution_changes` | Get code changes (files modified, additions, deletions, commits) |\n| `execution_chain` | Get full execution chain (root + all follow-ups) |\n\n#### Workflows Scope\n\n| Tool | Scope | Description |\n|------|-------|-------------|\n| `list_workflows` | workflows:read | List workflows with optional status filter |\n| `show_workflow` | workflows:read | Get workflow details including configuration and steps |\n| `workflow_status` | workflows:read | Get extended status (step progress, active executions, ready steps) |\n| `create_workflow` | workflows:write | Create new workflow from spec or issue |\n| `start_workflow` | workflows:write | Start a pending workflow |\n| `pause_workflow` | workflows:write | Pause a running workflow |\n| `cancel_workflow` | workflows:write | Cancel a workflow |\n| `resume_workflow` | workflows:write | Resume a paused workflow |\n\n#### Escalation Scope\n\n| Tool | Description |\n|------|-------------|\n| `escalate_to_user` | Request user input for a decision (blocking) |\n| `notify_user` | Send non-blocking notification to user |\n\n## Implementation Architecture\n\n### Server Structure\n\n```\nmcp/src/\n├── index.ts                    # Entry point with arg parsing\n├── server.ts                   # Main server class (modified)\n├── client.ts                   # CLI wrapper client (existing)\n├── scopes.ts                   # NEW: Scope definitions and resolution\n├── api-client.ts               # NEW: HTTP API client for extended tools\n├── tools/\n│   ├── issues.ts               # Existing\n│   ├── specs.ts                # Existing\n│   ├── relationships.ts        # Existing\n│   ├── feedback.ts             # Existing\n│   ├── references.ts           # Existing\n│   ├── executions.ts           # NEW: Execution tools\n│   ├── workflows.ts            # NEW: Workflow tools\n│   ├── inspection.ts           # NEW: Inspection tools\n│   ├── overview.ts             # NEW: Overview tools\n│   └── escalation.ts           # NEW: Escalation tools\n└── types.ts                    # Extended types\n```\n\n### Scope Resolution\n\n```typescript\ntype Scope = \n  | 'default'\n  | 'executions' | 'executions:read' | 'executions:write'\n  | 'workflows' | 'workflows:read' | 'workflows:write'\n  | 'inspection'\n  | 'overview'\n  | 'escalation'\n  | 'project-assistant'\n  | 'all';\n\ninterface ScopeConfig {\n  enabledScopes: Set<Scope>;\n  serverUrl?: string;\n  projectId?: string;\n}\n\nfunction resolveScopes(scopeArg: string): Set<string>;\nfunction getEnabledTools(config: ScopeConfig): ToolDefinition[];\n```\n\n### ListTools Behavior\n\nThe `list_tools` handler should:\n\n1. Resolve enabled scopes from `--scope` argument\n2. Filter tool definitions by enabled scopes\n3. **Exclude extended tools if `--server-url` not provided** (even if scope enabled)\n4. Return only tools that can actually be invoked\n\n### CallTool Behavior\n\nWhen a tool is called:\n\n1. Check if tool is in enabled scope → error if not\n2. Check if tool requires server URL → error if not configured\n3. Route to appropriate handler (CLI client or API client)\n\n## Error Handling\n\n### Scope Validation Errors\n\n```\nError: Unknown scope 'foobar'. Valid scopes: default, executions, executions:read, ...\n```\n\n### Missing Server URL\n\n```\nError: Extended tools require --server-url. Tools in scope 'executions' will not be available.\n```\n\n(This is a warning at startup, not a fatal error. Tools are simply excluded from list_tools.)\n\n### Tool Invocation Without Prerequisites\n\n```json\n{\n  \"error\": \"Tool 'start_execution' requires --server-url to be configured\"\n}\n```\n\n## Migration Path\n\n1. **Phase 1**: Implement scope system and argument parsing\n2. **Phase 2**: Add API client (port from server/src/project-assistant/mcp/api-client.ts)\n3. **Phase 3**: Implement extended tool handlers\n4. **Phase 4**: Remove server/src/project-assistant/ directory (consolidate)\n\n## Testing\n\n- Unit tests for scope resolution\n- Integration tests for extended tools with mock server\n- E2E tests with real local server\n- Backwards compatibility tests (no --scope should work exactly as before)\n\n## Non-Goals\n\n- **No duplicate tools**: Extended scopes don't re-implement list_issues, show_issue, etc.\n- **No separate binary**: All functionality in single sudocode-mcp\n- **No breaking changes**: Default behavior is unchanged\n","priority":1,"archived":0,"archived_at":null,"created_at":"2025-12-29 00:06:20","updated_at":"2025-12-29 00:06:20","parent_id":null,"parent_uuid":null,"relationships":[],"tags":["architecture","mcp","scope-system"]}
{"id":"s-9af4","uuid":"a1780887-6287-4aad-9b63-17e10294fb5c","title":"Kokoro TTS Integration for Voice Narration","file_path":"specs/s-9af4_kokoro_tts_integration_for_voice_narration.md","content":"# Kokoro TTS Integration for Voice Narration\n\n## Overview\n\nIntegrate the `kokoro-js` npm package to provide high-quality text-to-speech for voice narration, running entirely in the browser using WebAssembly. This replaces/supplements the existing browser Web Speech API with a more natural-sounding 82M parameter TTS model.\n\n## Background\n\nCurrently, voice narration uses the browser's Web Speech API which:\n- Works instantly (no model loading)\n- Has limited voice quality (robotic sounding)\n- Varies significantly between browsers\n\nKokoro TTS provides:\n- High-quality, natural-sounding voices\n- Consistent output across browsers\n- 50+ voice options\n- Runs locally in browser via WASM\n\n## Requirements\n\n### Functional Requirements\n\n1. **Model Loading**\n   - Support explicit pre-loading via \"Load Model\" button in settings\n   - Support lazy loading on first narration if not pre-loaded\n   - Show download progress during model loading (~86 MB for q8 quantized)\n   - Cache model in browser (handled by Transformers.js/Cache API)\n   - Model persists in memory for session duration once loaded\n\n2. **TTS Provider Selection**\n   - Add TTS provider selector in Voice settings: \"Browser\" | \"Kokoro\"\n   - Save preference to config.json via existing voice settings API\n   - Default to \"Browser\" for backwards compatibility\n\n3. **Audio Generation & Playback**\n   - Generate audio from text using Kokoro model\n   - Support voice selection from available Kokoro voices\n   - Support speed/rate adjustment\n   - Queue audio playback (integrate with existing narration queue)\n\n4. **Fallback Behavior**\n   - If Kokoro fails to load, fall back to browser TTS with notification\n   - If audio generation fails, skip narration item and continue\n\n### Non-Functional Requirements\n\n1. **Performance**\n   - Use q8 quantized model (~86 MB) for balance of quality/size\n   - First load: 10-30s depending on connection\n   - Subsequent loads: 1-2s (cached)\n   - Audio generation: <1s for typical narration text\n\n2. **UX**\n   - Clear loading progress indicator\n   - Non-blocking UI during model load\n   - Toast notifications for errors/status\n\n## Architecture\n\n### New Files\n\n```\nfrontend/src/hooks/useKokoroTTS.ts     # Kokoro model management hook\nfrontend/src/lib/kokoroTTS.ts          # Singleton model instance & utilities\n```\n\n### Modified Files\n\n```\nfrontend/src/hooks/useVoiceNarration.ts  # Route to Kokoro when configured\nfrontend/src/hooks/useVoiceConfig.ts     # Add kokoroModelStatus\nfrontend/src/components/layout/SettingsDialog.tsx  # Add load button, provider selector\nfrontend/package.json                     # Add kokoro-js dependency\n```\n\n### Component Design\n\n#### 1. kokoroTTS.ts (Singleton Module)\n\n```typescript\n// Module-level singleton\nlet kokoroInstance: KokoroTTS | null = null\nlet loadingPromise: Promise<KokoroTTS> | null = null\n\ntype ModelStatus = 'idle' | 'loading' | 'ready' | 'error'\n\ninterface KokoroState {\n  status: ModelStatus\n  progress: number  // 0-100\n  error: string | null\n}\n\n// State listeners for React integration\nconst listeners = new Set<(state: KokoroState) => void>()\n\nexport async function loadKokoroModel(\n  onProgress?: (progress: number) => void\n): Promise<KokoroTTS>\n\nexport async function generateSpeech(\n  text: string,\n  options?: { voice?: string; speed?: number }\n): Promise<AudioBuffer>\n\nexport function getKokoroState(): KokoroState\nexport function subscribeToState(listener: (state: KokoroState) => void): () => void\n```\n\n#### 2. useKokoroTTS Hook\n\n```typescript\ninterface UseKokoroTTSReturn {\n  status: ModelStatus\n  progress: number\n  error: string | null\n  isReady: boolean\n  load: () => Promise<void>\n  generate: (text: string, options?: TTSOptions) => Promise<void>\n  stop: () => void\n  availableVoices: string[]\n}\n```\n\n#### 3. useVoiceNarration Updates\n\n```typescript\n// Add provider routing\nconst ttsProvider = voiceConfig?.settings?.tts?.provider || 'browser'\n\nif (ttsProvider === 'kokoro') {\n  // Lazy load model if needed\n  if (!kokoroState.isReady) {\n    await loadKokoroModel()\n  }\n  // Generate and play audio\n  await generateAndPlayKokoroAudio(text, options)\n} else {\n  // Existing Web Speech API code\n  speakWithWebSpeech(text, options)\n}\n```\n\n#### 4. Settings Dialog Updates\n\n- Add TTS Provider dropdown (Browser / Kokoro)\n- When Kokoro selected, show:\n  - Model status (idle/loading/ready)\n  - Load button (when idle)\n  - Progress bar (when loading)\n  - \"Ready\" indicator with model size (when loaded)\n  - Voice selector (Kokoro voices)\n\n## Voice Options\n\nKokoro provides 50+ voices. Key English voices:\n- `af_heart` - Female, warm\n- `af_bella` - Female, clear\n- `af_nova` - Female, energetic\n- `am_adam` - Male, neutral\n- `am_michael` - Male, authoritative\n\n## Configuration\n\nStored in `.sudocode/config.json`:\n\n```json\n{\n  \"voice\": {\n    \"enabled\": true,\n    \"tts\": {\n      \"provider\": \"kokoro\",\n      \"defaultVoice\": \"af_heart\"\n    },\n    \"narration\": {\n      \"enabled\": true,\n      \"speed\": 1.0,\n      \"volume\": 1.0\n    }\n  }\n}\n```\n\n## Error Handling\n\n| Scenario | Behavior |\n|----------|----------|\n| Model download fails | Toast error, fall back to browser TTS |\n| Model load fails (WASM) | Toast error, fall back to browser TTS |\n| Audio generation fails | Skip narration item, log error |\n| Browser doesn't support WASM | Show warning in settings, disable Kokoro option |\n\n## Testing\n\n1. Unit tests for useKokoroTTS hook (mock kokoro-js)\n2. Integration test for provider switching\n3. Manual testing for audio quality and latency\n\n## Open Questions\n\n1. Should we support WebGPU for faster inference? (Can add later)\n2. Voice preview in settings? (Nice to have)\n3. Streaming for long text? (kokoro-js supports it, evaluate need)\n","priority":1,"archived":0,"archived_at":null,"created_at":"2026-01-01 06:00:22","updated_at":"2026-01-01 06:00:22","parent_id":null,"parent_uuid":null,"relationships":[],"tags":["feature","frontend","kokoro","tts","voice"]}
{"id":"s-1ryc","uuid":"503dfc84-3364-460a-bacb-ef86477fbbbd","title":"Streamed Server Kokoro TTS","file_path":"specs/s-1ryc_streamed_server_kokoro_tts.md","content":"# Streamed Server Kokoro TTS\n\n## Overview\n\nServer-based Kokoro TTS with streaming audio delivery for sub-second time-to-first-audio. Replaces the in-browser WASM implementation (~7-8s generation time) with a Python sidecar service that leverages native GPU acceleration.\n\n## Goals\n\n- **Speed**: Sub-second time-to-first-audio via streaming\n- **Quality**: Native GPU acceleration (Metal/CUDA/DirectML) for better performance than WASM\n- **Simplicity**: Auto-managed sidecar, no manual Python setup required\n- **Reliability**: Graceful fallback to browser TTS if sidecar unavailable\n\n---\n\n## Architecture\n\n```\nBrowser (useKokoroTTS) \n    ↓ WebSocket\nsudocode server (TTS Router → Sidecar Manager)\n    ↓ stdin/stdout JSON-lines\nPython Sidecar (Text Chunker → Kokoro Model → Audio Streamer)\n```\n\n### Key Components\n\n1. **Python Sidecar**: Runs Kokoro TTS with native GPU (kokoro-onnx)\n2. **Sidecar Manager**: Spawns, monitors, restarts the Python process\n3. **WebSocket Handler**: Routes TTS requests, streams audio chunks\n4. **StreamingAudioPlayer**: Browser-side seamless chunk playback\n\n---\n\n## Sidecar Protocol (JSON-lines via stdin/stdout)\n\n**Request:**\n```json\n{\"id\": \"req-123\", \"type\": \"generate\", \"text\": \"Hello\", \"voice\": \"af_heart\", \"speed\": 1.0}\n```\n\n**Response (streamed):**\n```json\n{\"id\": \"req-123\", \"type\": \"audio\", \"chunk\": \"<base64 PCM>\", \"index\": 0}\n{\"id\": \"req-123\", \"type\": \"done\", \"total_chunks\": 1}\n```\n\n---\n\n## Text Chunking (Hybrid Strategy)\n\n1. Split on sentence boundaries (`.!?`)\n2. For sentences > 150 chars, split on clause boundaries (`, ; : —`)\n3. Preserve punctuation for natural prosody\n4. Minimum chunk size: 20 chars\n\n---\n\n## Directory Structure\n\n```\n~/.config/sudocode/tts/\n├── venv/           # Python virtual environment\n├── config.json     # TTS settings\n└── models/         # Cached ONNX models\n```\n\nCross-platform paths:\n- macOS/Linux: `~/.config/sudocode/tts/`\n- Windows: `%APPDATA%\\sudocode\\tts\\`\n\n---\n\n## Auto-Installation\n\nOn first TTS request:\n1. Check if venv exists, create if not\n2. Detect platform and install appropriate ONNX runtime:\n   - Apple Silicon: `onnxruntime-silicon`\n   - NVIDIA GPU: `onnxruntime-gpu`\n   - Windows: `onnxruntime-directml`\n   - CPU fallback: `onnxruntime`\n3. Install `kokoro-onnx`\n4. Start sidecar\n\n---\n\n## Sidecar Lifecycle\n\n- **Startup**: Lazy init on first TTS request\n- **Health Check**: Ping every 30s, restart if unresponsive\n- **Shutdown**: SIGTERM on server stop, SIGKILL after 5s\n- **Crash Recovery**: Auto-restart with exponential backoff (1s → 30s max)\n\n---\n\n## WebSocket Messages\n\n**Client → Server:**\n```typescript\ninterface TTSRequest {\n  type: 'tts_request'\n  request_id: string\n  text: string\n  voice?: string\n  speed?: number\n}\n```\n\n**Server → Client:**\n```typescript\ninterface TTSAudio {\n  type: 'tts_audio'\n  request_id: string\n  chunk: string      // base64 PCM (mono, 24kHz, float32)\n  index: number\n  is_final: boolean\n}\n\ninterface TTSEnd {\n  type: 'tts_end'\n  request_id: string\n  total_chunks: number\n  duration_ms: number\n}\n\ninterface TTSError {\n  type: 'tts_error'\n  request_id: string\n  error: string\n  recoverable: boolean\n  fallback: boolean\n}\n```\n\n---\n\n## Browser Playback\n\nStreamingAudioPlayer class:\n- Decodes base64 PCM to Float32Array\n- Creates AudioBuffer per chunk\n- Schedules playback seamlessly (100ms buffer ahead)\n- Tracks `scheduledTime` for gapless audio\n\n---\n\n## Error Handling\n\n- **Sidecar crash**: Auto-restart, send `tts_error` with `recoverable: true`\n- **Sidecar unavailable**: Return `tts_error` with `fallback: true`, frontend uses browser TTS\n- **Resource limits**: Max 3 concurrent requests, 10K char limit, 2GB memory watchdog\n\n---\n\n## Implementation Order\n\n1. Python sidecar script (`server/src/tts/sidecar.py`)\n2. Sidecar manager (`server/src/services/tts-sidecar-manager.ts`)\n3. WebSocket handler (`server/src/routes/tts-websocket.ts`)\n4. Frontend streaming player (`frontend/src/lib/streamingAudioPlayer.ts`)\n5. Updated useKokoroTTS hook (`frontend/src/hooks/useKokoroTTS.ts`)\n6. Settings UI toggle (browser vs server TTS)","priority":1,"archived":0,"archived_at":null,"created_at":"2026-01-02 09:28:54","updated_at":"2026-01-02 09:28:54","parent_id":null,"parent_uuid":null,"relationships":[],"tags":["architecture","kokoro","streaming","tts","voice"]}
{"id":"s-9gnd","uuid":"3e6afff5-00a9-46b3-a14e-77fbbf02c3a9","title":"ACP Migration: Unified Agent Execution Interface","file_path":"specs/s-9gnd_acp_migration_unified_agent_execution_interface.md","content":"# ACP Migration: Unified Agent Execution Interface\n\n## Overview\n\nMigrate from the current `agent-execution-engine` based execution system to Agent Client Protocol (ACP) via `acp-factory` as the unified interface for all agent interactions. This enables character-level streaming for faster response times and provides a cleaner, protocol-native abstraction.\n\n## Goals\n\n1. **Unified Interface** - All agents expose the same ACP-based interface (SessionUpdate streaming)\n1. **Character-level Streaming** - Enable real-time character streaming to frontend for faster perceived response\n1. **Simplified Architecture** - Remove intermediate translation layers (NormalizedEntry, AG-UI)\n1. **Backwards Compatibility** - Support legacy agents (Copilot, Cursor) via shim layer\n\n## Non-Goals\n\n- Changing the execution/worktree management system\n- Modifying the issue/spec/feedback data model\n- Migrating existing execution logs to new format\n\n---\n\n## Architecture\n\n### Primary Interface\n\nACP (`acp-factory`) becomes the unified abstraction for all agent interactions:\n\n```\n┌─────────────────────────────────────────────────────────────┐\n│                      AgentFactory                           │\n│  ┌─────────────────┐        ┌─────────────────────────────┐ │\n│  │ ACP Agents      │        │ Legacy Agents (Shim)        │ │\n│  │ - claude-code   │        │ - copilot → SessionUpdate   │ │\n│  │ - codex         │        │ - cursor  → SessionUpdate   │ │\n│  │ - gemini        │        │                             │ │\n│  │ - opencode      │        │                             │ │\n│  └────────┬────────┘        └──────────────┬──────────────┘ │\n└───────────┼─────────────────────────────────┼───────────────┘\n            │                                 │\n            └────────────┬────────────────────┘\n                         │ SessionUpdate (unified)\n                         ▼\n┌─────────────────────────────────────────────────────────────┐\n│                   AcpExecutorWrapper                        │\n│  - Manages AgentHandle lifecycle                            │\n│  - Streams SessionUpdate to transport                       │\n│  - Coalesces events before persistence                      │\n└─────────────────────────────────────────────────────────────┘\n                         │\n            ┌────────────┴────────────┐\n            ▼                         ▼\n   ┌─────────────────┐      ┌─────────────────┐\n   │ SSE Transport   │      │ ExecutionLogs   │\n   │ (SessionUpdate) │      │ (Coalesced)     │\n   └────────┬────────┘      └─────────────────┘\n            │\n            ▼\n   ┌─────────────────┐\n   │    Frontend     │\n   │ (SessionUpdate) │\n   └─────────────────┘\n```\n\n### Key Design Decisions\n\n| Area | Decision | Rationale |\n| --- | --- | --- |\n| **Primary interface** | ACP via acp-factory | Standardized protocol, character streaming support |\n| **Legacy support** | Shim at AgentFactory level | Contained complexity, unified consumer interface |\n| **Branching point** | ExecutorFactory | Clean separation, easy to delete legacy later |\n| **Frontend streaming** | SessionUpdate directly | Remove AG-UI translation layer |\n| **Storage format** | Coalesced SessionUpdate | Streaming for UX, complete messages for storage |\n| **Storage location** | Repurpose `raw_logs` column | No schema migration required |\n| **Format detection** | Infer from content shape | `sessionUpdate` key = ACP, `type.kind` = legacy |\n\n---\n\n## Components\n\n### 1\\. AcpExecutorWrapper\n\nNew executor wrapper that uses acp-factory for agent lifecycle management.\n\n**Responsibilities:**\n\n- Spawn agents via `AgentFactory.spawn()`\n- Create/manage sessions via `AgentHandle.createSession()`\n- Stream `SessionUpdate` events to transport layer\n- Coalesce events before persistence\n- Handle cancellation via `session.cancel()`\n- Manage session resume via `agent.loadSession()` or `session.fork()`\n\n**Interface:**\n\n```typescript\nclass AcpExecutorWrapper {\n  async executeWithLifecycle(\n    executionId: string,\n    task: ExecutionTask,\n    workDir: string\n  ): Promise<void>\n  \n  async resumeWithLifecycle(\n    executionId: string,\n    sessionId: string,\n    task: ExecutionTask,\n    workDir: string\n  ): Promise<void>\n  \n  async cancel(executionId: string): Promise<void>\n}\n```\n\n### 2\\. Legacy Agent Shim\n\nAdapter that makes legacy agents (Copilot, Cursor) emit SessionUpdate events.\n\n**Approach:**\n\n- Spawn legacy agent process via `agent-execution-engine` adapters\n- Parse output using existing normalizers\n- Convert NormalizedEntry → SessionUpdate events\n- Emit through same interface as native ACP agents\n\n**Mapping:**\n\n| NormalizedEntry | SessionUpdate |\n| --- | --- |\n| `assistant_message` | `agent_message_complete` |\n| `thinking` | `agent_thought_complete` |\n| `tool_use` | `tool_call_complete` |\n| `error` | `tool_call_complete` with failed status |\n\n### 3\\. SessionUpdate Coalescer\n\nUtility that merges streaming events into complete messages for storage.\n\n**Behavior:**\n\n- Accumulate consecutive `agent_message_chunk` events into `agent_message_complete`\n- Track tool lifecycle and store final state\n- Preserve timestamps from first event in sequence\n- Output NDJSON for storage in `raw_logs` column\n\n**Coalesced Event Types:**\n\n```typescript\ntype CoalescedSessionUpdate =\n  | { sessionUpdate: \"agent_message_complete\"; content: ContentBlock }\n  | { sessionUpdate: \"agent_thought_complete\"; content: ContentBlock }\n  | { sessionUpdate: \"tool_call_complete\"; toolCallId: string; title: string; status: ToolCallStatus; result?: unknown }\n```\n\n### 4\\. ExecutorFactory Updates\n\nModify factory to return appropriate executor based on agent ACP support.\n\n**Detection Logic:**\n\n```typescript\nfunction createExecutorForAgent(agentType: AgentType, ...): ExecutorWrapper {\n  // Check if agent is registered in AgentFactory (ACP-native)\n  if (AcpExecutorWrapper.isAcpSupported(agentType)) {\n    return new AcpExecutorWrapper(...)\n  }\n  \n  // Fall back to legacy shim (uses agent-execution-engine)\n  return new LegacyShimExecutorWrapper(...)\n}\n```\n\n### 5\\. Frontend Updates\n\nUpdate frontend to consume SessionUpdate directly instead of AG-UI events.\n\n**Changes:**\n\n- Replace `useAgUiStream` hook with `useSessionUpdateStream`\n- Update `AgentTrajectory` component to render SessionUpdate events\n- Update `ExecutionMonitor` for new event types\n- Remove AG-UI adapter code\n\n### 6\\. Storage Format Detection\n\nLogic to determine format when reading from logs.\n\n```typescript\nfunction detectLogFormat(firstLine: string): 'acp' | 'normalized_entry' {\n  const parsed = JSON.parse(firstLine)\n  if ('sessionUpdate' in parsed) return 'acp'\n  if ('type' in parsed && 'kind' in parsed.type) return 'normalized_entry'\n  throw new Error('Unknown log format')\n}\n```\n\n---\n\n## Migration Path\n\n### Phase 1: Build ACP Infrastructure ✅\n\n- Add `acp-factory` dependency to server package\n- Create `AcpExecutorWrapper` class\n- Create `SessionUpdateCoalescer` utility\n- Update `ExecutorFactory` with ACP detection logic\n\n### Phase 2: Legacy Agent Shim ✅\n\n- Create `LegacyShimExecutorWrapper`\n- Implement NormalizedEntry → SessionUpdate mapping\n- Register legacy agents in ExecutorFactory with shim routing\n\n### Phase 3: Frontend Migration ✅\n\n- Create `useSessionUpdateStream` hook\n- Update execution components for SessionUpdate\n- Add bridge layer in ExecutionMonitor for backwards compatibility\n\n### Phase 4: Storage Migration ✅\n\n- Implement format detection in `ExecutionLogsStore`\n- Create NormalizedEntry → CoalescedSessionUpdate converter\n- Update `/logs` endpoint to return CoalescedSessionUpdate\n- Update frontend `useExecutionLogs` hook\n\n### Phase 5: Cleanup ✅\n\n**Completed:**\n\n- Removed `AgentExecutorWrapper` (old executor using AG-UI)\n- Removed AG-UI adapter files and tests\n- Removed unused `ProgressIndicator` component\n- Removed `@ag-ui/core` dependency from both packages\n- Cleaned up stale dist files\n\n**Note:** `agent-execution-engine` dependency is **retained** for legacy agent support (Copilot, Cursor). The `LegacyShimExecutorWrapper` uses `CopilotExecutor` and `CursorExecutor` from this package to support non-ACP agents.\n\n---\n\n## Final Architecture\n\n```\n┌─────────────────────────────────────────────────────────────┐\n│                     ExecutorFactory                         │\n├──────────────────────────┬──────────────────────────────────┤\n│  AcpExecutorWrapper      │  LegacyShimExecutorWrapper       │\n│  (claude-code)           │  (copilot, cursor)               │\n│  via acp-factory         │  via agent-execution-engine      │\n├──────────────────────────┴──────────────────────────────────┤\n│              CoalescedSessionUpdate (unified)               │\n└─────────────────────────────────────────────────────────────┘\n```\n\n---\n\n## Design Decisions (Resolved)\n\n### 1\\. MCP Server Configuration\n\n**Decision:** Pass through agent config with execution-level overrides.\n\n- Default MCP servers configured in `AgentConfig`\n- Execution can add/override via task metadata\n- Passed to `createSession(cwd, { mcpServers })`\n\n### 2\\. Permission Handling\n\n**Decision:** Auto-approve by default, configurable per-execution.\n\n- Default: `permissionMode: \"auto-approve\"` (matches current behavior)\n- Users can configure per-execution when starting\n- Future: Could add interactive mode with UI for permission dialogs\n\n### 3\\. Error Handling\n\n**Decision:** Differentiated handling with retry by category.\n\n| Error Type | Behavior |\n| --- | --- |\n| **Connection errors** | Auto-retry with backoff (transient) |\n| **Agent errors** | Surface immediately, fail execution |\n| **Tool errors** | Part of normal flow, streamed as SessionUpdate |\n\n### 4\\. Session Resume\n\n**Decision:** Use ACP's native session management with both options available.\n\n- `agent.loadSession(sessionId, cwd)` - Continue same session linearly\n- `session.fork()` - Branch conversation, original preserved\n- UI offers both \"Continue\" and \"Branch\" for follow-ups\n\n### 5\\. Worktree Integration\n\n**Decision:** Create worktree first, pass path to ACP session.\n\n- `ExecutionLifecycleService` creates worktree (unchanged)\n- Worktree path passed as `cwd` to `agent.createSession(worktreePath)`\n- ACP operates entirely within the worktree\n\n---\n\n## Dependencies\n\n- `acp-factory` - Core ACP client library (for ACP-native agents)\n- `@agentclientprotocol/sdk` - ACP protocol types (peer dep of acp-factory)\n- `agent-execution-engine` - Legacy agent support (for copilot, cursor)\n\n## References\n\n- [Agent Client Protocol](https://agentclientprotocol.com/)\n- [acp-factory](../references/acp-factory/)\n- [Current agent-execution-engine](../references/agent-execution-engine/)","priority":1,"archived":0,"archived_at":null,"created_at":"2026-01-06 18:57:54","updated_at":"2026-01-07 06:56:47","parent_id":null,"parent_uuid":null,"relationships":[],"tags":["acp","architecture","execution","migration"]}
{"id":"s-1y3i","uuid":"fa97f775-0030-426b-a3aa-aa4dc720f4b2","title":"Voice Scope and Speak Tool for Narration","file_path":"specs/s-1y3i_voice_scope_and_speak_tool_for_narration.md","content":"# Voice Scope and Speak Tool for Narration\n\n## Overview\n\nAdd a `voice` scope to the MCP server with a `speak` tool, enabling agents to explicitly request text-to-speech narration. Support a new `narrateSpeakOnly` mode that only narrates explicit speak calls (disabling automatic tool/message narration).\n\n## Requirements\n\n### 1. New Narration Mode\n\nAdd `narrateSpeakOnly?: boolean` to the narration configuration in `types/src/voice.d.ts`:\n\n```typescript\nnarration?: {\n  enabled?: boolean;\n  voice?: string;\n  speed?: number;\n  volume?: number;\n  narrateToolUse?: boolean;\n  narrateToolResults?: boolean;\n  narrateAssistantMessages?: boolean;\n  narrateSpeakOnly?: boolean;  // NEW\n};\n```\n\n**Behavior:**\n- When `narrateSpeakOnly: true`, the existing flags (`narrateToolUse`, `narrateToolResults`, `narrateAssistantMessages`) are ignored\n- Only `NormalizedEntry` objects with tool name `speak` trigger narration\n- `enabled` must still be `true` for any narration to happen\n\n### 2. Voice Scope in MCP Server\n\nAdd a new `voice` scope to the MCP server:\n\n**In `mcp/src/scopes.ts`:**\n- Add `\"voice\"` to the `Scope` type\n- Add to `ALL_SCOPES` array\n- Add to `SERVER_REQUIRED_SCOPES` array\n- Add mapping: `voice: [\"speak\"]` to `SCOPE_TOOLS`\n\n### 3. Speak Tool Definition\n\nAdd the `speak` tool to `mcp/src/tool-registry.ts`:\n\n```typescript\n{\n  name: \"speak\",\n  scope: \"voice\",\n  description: \"Narrate text aloud via text-to-speech. Only available when narration is enabled.\",\n  inputSchema: {\n    type: \"object\",\n    properties: {\n      text: { type: \"string\", description: \"Text to speak aloud\" },\n    },\n    required: [\"text\"],\n  },\n}\n```\n\n### 4. Tool Handler (No-Op)\n\nThe `speak` tool returns a simple success response. The actual narration is triggered server-side when parsing the agent's output stream:\n\n- Tool returns `{ success: true }` to the agent\n- Server parses `NormalizedEntry` with `toolName: \"speak\"` from stream\n- `NarrationService.summarizeForVoice()` extracts the text directly\n- `broadcastVoiceNarration()` sends to frontend\n\n### 5. Narration Service Changes\n\nUpdate `server/src/services/narration-service.ts` to check `narrateSpeakOnly`:\n\n```typescript\nif (narrationConfig.narrateSpeakOnly) {\n  // Only narrate if this is an explicit Speak tool call\n  if (entry.type !== 'tool_use' || entry.toolName?.toLowerCase() !== 'speak') {\n    return null; // Skip narration\n  }\n}\n```\n\n### 6. Conditional Scope Injection\n\nWhen building MCP config for an execution, conditionally include `voice` scope:\n\n```typescript\nconst scopes = [\"default\", ...otherScopes];\n\nif (narrationConfig?.enabled) {\n  scopes.push(\"voice\");\n}\n```\n\n**Behavior:**\n- When narration is enabled → agent sees the `speak` tool\n- When narration is disabled → agent doesn't see the tool at all\n\n## Design Decisions\n\n1. **`narrateSpeakOnly` as additive flag** - Doesn't break existing config, clear intent\n2. **Speak tool respects `enabled` flag** - If narration disabled, speak calls are not narrated and tool is not visible\n3. **No backend endpoint needed** - Server parses tool calls from agent stream, triggers narration directly\n4. **Minimal parameters** - Just `text` for now, can expand later (priority, voice, speed)\n5. **Conditional scope injection** - Execution service controls tool visibility based on narration config\n\n## Files to Modify\n\n| File | Change |\n|------|--------|\n| `types/src/voice.d.ts` | Add `narrateSpeakOnly?: boolean` |\n| `mcp/src/scopes.ts` | Add `voice` scope |\n| `mcp/src/tool-registry.ts` | Add `speak` tool definition |\n| `mcp/src/api-client.ts` or handler | Simple success response |\n| `server/src/services/narration-service.ts` | Check `narrateSpeakOnly` flag |\n| Execution service (MCP config builder) | Conditionally add `voice` scope |","priority":2,"archived":0,"archived_at":null,"created_at":"2026-01-06 19:18:53","updated_at":"2026-01-06 19:18:53","parent_id":null,"parent_uuid":null,"relationships":[],"tags":["mcp","narration","speak-tool","voice"]}
{"id":"s-329o","uuid":"c7c92f0d-ea24-4e24-b8ab-bda5d1f47a40","title":"Dataplane Integration - Git Coordination Layer","file_path":"specs/s-329o_dataplane_integration_git_coordination_layer.md","content":"# Dataplane Integration - Git Coordination Layer\n\n## Overview\n\nReplace sudocode's git management layer with dataplane library to enable:\n- Parallel agent coordination without filesystem conflicts\n- Stacked execution chains with fork/rebase/merge/cascade\n- Stable change tracking across rebases (via Change-Id)\n- Deferred conflict resolution with multiple strategies\n- Full audit trail with checkpointing and rollback\n- Ordered merge queue for stacked diffs and interleaved workflows\n\n## Core Design Decisions\n\n### 1. Migration Approach\n**Clean break** - New dataplane layer only works with new executions. Existing worktrees/executions are not migrated.\n\n### 2. Stream Hierarchy (Approach C)\n**Issue = Stream Family, Execution = Child Stream**\n\n```\nIssue: i-auth\n├── Stream: issue/i-auth        ← Issue-level stream (merge target)\n│   ├── Stream: exec/abc123     ← Execution by agent-1\n│   └── Stream: exec/def456     ← Execution by agent-2 (parallel)\n\nIssue: i-api (depends on i-auth)\n├── Stream: issue/i-api         ← Depends on issue/i-auth\n│   └── Stream: exec/ghi789     ← Execution by agent-1\n```\n\n### 3. Merge Workflow\n**Flexible merge targets** - User chooses per execution:\n- Execution → Issue stream (checkpoint)\n- Execution → Main (direct)\n- Issue stream → Main (promote)\n\n### 4. Local Mode\n**Stream on existing branch** - Local mode creates stream tracking current branch without creating worktree. Unified model where everything is a stream.\n\n### 5. Sync Mode Mapping\n| Sudocode | Dataplane |\n|----------|-----------|\n| Squash | `mergeStream({ strategy: 'squash' })` |\n| Preserve | `mergeStream({ strategy: 'merge-commit' })` |\n| Stage | Sudocode-only (apply diff without merge) |\n\n### 6. JSONL Resolution\nStays in sudocode - dataplane reports conflicts, sudocode auto-resolves JSONL via three-way merge callback.\n\n### 7. Reconciliation (Hybrid)\n- **Read operations**: Auto-reconcile silently (detect external git changes)\n- **Write operations**: Detect and warn, require confirmation\n\n### 8. Merge Queue\nExplicit ordering for streams merging to a target branch:\n- Queue position determines merge order\n- Respects stream dependencies (can't skip ahead of dependencies)\n- Reordering triggers cascade rebase\n- Enables stacked diffs workflow (implicit via spec + issues + queue)\n\n### 9. Conflict Configuration\n```json\n{\n  \"dataplane\": {\n    \"conflictStrategy\": {\n      \"default\": \"defer\",\n      \"code\": \"defer | ours | theirs\",\n      \"cascade\": \"stop_on_conflict | skip_conflicting | defer_conflicts\"\n    },\n    \"mergeQueue\": {\n      \"enabled\": true,\n      \"autoEnqueue\": true\n    }\n  }\n}\n```\n\n## Architecture\n\n```\n┌─────────────────────────────────────────────────────────────┐\n│                      Sudocode Server                        │\n├─────────────────────────────────────────────────────────────┤\n│  ExecutionService          │  WorktreeSyncService           │\n│  ExecutionLifecycleService │  ExecutionChangesService       │\n├─────────────────────────────────────────────────────────────┤\n│                 DataplaneAdapter (NEW)                      │\n│  - Maps executions ↔ streams                                │\n│  - Maps issues ↔ stream families                            │\n│  - Handles JSONL conflict resolution                        │\n│  - Translates sync modes to dataplane operations            │\n│  - Exposes merge queue operations                           │\n├─────────────────────────────────────────────────────────────┤\n│                 MultiAgentRepoTracker                       │\n│                 (dataplane library)                         │\n└─────────────────────────────────────────────────────────────┘\n```\n\n## Data Model Mapping\n\n| Sudocode | Dataplane | Relationship |\n|----------|-----------|--------------|\n| Issue | Stream family (`issue/{id}`) | 1:1, created on first execution |\n| Execution | Stream (`exec/{id}`) | 1:1, forks from issue stream |\n| Execution chain | Stream fork chain | parent_execution → parentStream |\n| Issue dependency | Stream dependency | blocks/depends-on → addDependency() |\n| Stacked diffs | Merge queue + dependencies | Implicit via spec + issues + queue position |\n\n## Key Workflows\n\n### Stacked Diffs\n1. Create issues with dependencies (i-schema → i-api → i-ui)\n2. Execute each, creating streams\n3. Enqueue in order\n4. mergeNext() merges bottom, cascades to rest\n5. Repeat until stack complete\n\n### Interleaved Workflows\n- Cross-workflow dependencies supported (issue in W1 depends on issue in W2)\n- Merge queue handles ordering when both workflows ready\n- Cascade rebases affected streams after each merge\n\n### Orchestrator Pattern\n```python\nwhile workflow_incomplete:\n    ready_issues = sudocode.ready()\n    for issue in ready_issues:\n        spawn_agent(issue)\n    await any_execution_completes()\n    for completed in get_completed():\n        enqueue_for_merge(completed)\n    merge_next_ready()\n```\n\n## Implementation Phases\n\n1. **Dataplane Enhancements** - Existing branch support, stream-worktree association, reconcile API, merge queue\n2. **DataplaneAdapter Layer** - Core adapter class with stream/worktree/change/queue methods\n3. **Service Integration** - Replace WorktreeManager and GitSyncCli calls\n4. **Sync Operations** - Squash/preserve via adapter, JSONL conflict handler\n5. **Cascade & Dependencies** - Issue dependency sync, cascade triggers, UI\n6. **Conflict Resolution UI** - Deferred conflicts, resolution strategies\n\n---\n\n## Future Enhancements (Deferred)\n\n### External Agent Integration via MCP\n\n**Problem:** Currently, this design only tracks executions managed through the sudocode server. External agents (Claude Code, Cursor, etc.) using only the MCP server for issue management have no git tracking - their commits, branches, and changes are invisible to dataplane.\n\n**Proposed Solution (deferred):** Add MCP tools for external agents to participate in dataplane tracking:\n\n```typescript\n// Potential MCP tools\ntrack_branch({ issue_id, branch_name? })    // Register work with dataplane\ncommit_change({ execution_id, message })     // Commit with Change-Id\nenqueue_for_merge({ issue_id })              // Add to merge queue\nget_queue_position({ issue_id })             // Check queue status\n```\n\n**Considerations:**\n- Minimal friction for external agents\n- Change-Id tracking optional but encouraged\n- Reconciliation handles commits made outside system\n- Merge queue accessible to all agents\n\nThis will be addressed in a future spec after the core integration is complete.","priority":1,"archived":0,"archived_at":null,"created_at":"2026-01-08 06:01:07","updated_at":"2026-01-08 22:57:31","parent_id":null,"parent_uuid":null,"relationships":[],"tags":["architecture","dataplane","git","integration"]}
{"id":"s-5zxn","uuid":"2216955f-f9c6-4033-a52e-e38827346d17","title":"Dataplane Enhancements","file_path":"specs/s-5zxn_dataplane_enhancements.md","content":"# Dataplane Enhancements\n\nAdd features to dataplane library required for sudocode integration.\n\n## 1. Stream on Existing Branch (Local Mode)\n\nSupport creating a stream that tracks an existing branch without creating a new one.\n\n```typescript\ntracker.createStream({\n  name: 'exec/abc123',\n  existingBranch: 'main',      // Track existing branch\n  createBranch: false,          // Don't create new branch\n  agentId: 'claude-code',\n});\n```\n\n**Schema changes:**\n```sql\nALTER TABLE streams ADD COLUMN existing_branch TEXT;\nALTER TABLE streams ADD COLUMN is_local_mode BOOLEAN DEFAULT FALSE;\n```\n\n## 2. Stream-Worktree Association\n\nAllow worktrees to be associated with streams (not just agents).\n\n```typescript\ntracker.createWorktree({\n  streamId: 'exec/abc123',      // Associate with stream\n  agentId: 'claude-code',       // Keep for multi-agent tracking\n  path: '.sudocode/worktrees/abc123',\n});\n```\n\n**Schema changes:**\n```sql\nALTER TABLE agent_worktrees ADD COLUMN stream_id TEXT REFERENCES streams(id);\n```\n\n## 3. Reconcile API\n\nDetect and handle external git changes (commits made outside dataplane).\n\n```typescript\ntracker.reconcileStream(streamId): Promise<{\n  status: 'in_sync' | 'reconciled' | 'diverged';\n  newCommits: number;\n  externalCommits: number;      // Commits without Change-Id\n  updatedChanges: string[];     // Change-Ids that moved\n}>;\n```\n\n**Behavior:**\n1. Compare stream's recorded HEAD with actual branch HEAD\n2. Scan new commits for Change-Ids\n3. Update tracking for known changes (rebased commits)\n4. Create new Change records for external commits\n5. Update stream HEAD\n\n## 4. Enhanced Conflict Callback\n\nAllow conflict callbacks to return custom resolution content.\n\n```typescript\ntracker.mergeStream({\n  sourceStream,\n  targetStream,\n  onConflict: async (conflict: ConflictInfo) => {\n    return {\n      strategy: 'custom',\n      resolvedContent?: string,  // For JSONL auto-merge\n    };\n  }\n});\n```\n\n## 5. Merge Queue\n\nExplicit ordering for streams merging to a target branch.\n\n**Schema:**\n```sql\nCREATE TABLE merge_queue (\n  id TEXT PRIMARY KEY,\n  target_branch TEXT NOT NULL,\n  stream_id TEXT NOT NULL REFERENCES streams(id),\n  position INTEGER NOT NULL,\n  status TEXT NOT NULL DEFAULT 'pending',\n  enqueued_at TEXT NOT NULL,\n  enqueued_by TEXT,\n  merged_at TEXT,\n  metadata TEXT,\n  \n  UNIQUE(target_branch, stream_id),\n  UNIQUE(target_branch, position)\n);\n\nCREATE INDEX idx_queue_target ON merge_queue(target_branch, position);\nCREATE INDEX idx_queue_stream ON merge_queue(stream_id);\n```\n\n**API:**\n```typescript\ninterface MergeQueueAPI {\n  getQueue(targetBranch: string): QueueEntry[];\n  getPosition(streamId: string): number | null;\n  \n  enqueue(params: {\n    streamId: string;\n    targetBranch: string;\n    position?: number;\n    enqueuedBy?: string;\n  }): QueueEntry;\n  \n  dequeue(streamId: string): void;\n  \n  reorder(params: {\n    streamId: string;\n    newPosition: number;\n    cascadeStrategy?: CascadeStrategy;\n  }): ReorderResult;\n  \n  mergeNext(params: {\n    targetBranch: string;\n    onConflict?: ConflictCallback;\n  }): MergeResult;\n  \n  mergeUpTo(params: {\n    streamId: string;\n    onConflict?: ConflictCallback;\n  }): MergeResult[];\n}\n```\n\n## Files to Modify/Create\n\n- `src/streams.ts` - Add existingBranch, createBranch options\n- `src/worktrees.ts` - Add streamId association\n- `src/reconcile.ts` - NEW: reconciliation logic\n- `src/queue.ts` - NEW: merge queue operations\n- `src/conflicts.ts` - Enhanced callback return type\n- `src/schema.ts` - Schema migrations for all new tables/columns\n- `src/tracker.ts` - Expose new APIs on MultiAgentRepoTracker\n- `tests/` - Tests for all new features","priority":1,"archived":0,"archived_at":null,"created_at":"2026-01-08 06:02:21","updated_at":"2026-01-08 22:44:24","parent_id":"s-329o","parent_uuid":"c7c92f0d-ea24-4e24-b8ab-bda5d1f47a40","relationships":[],"tags":["dataplane","enhancement"]}
{"id":"s-7a0k","uuid":"785ddd95-e30e-4a6f-8887-a6e73cb62e13","title":"DataplaneAdapter Layer","file_path":"specs/s-7a0k_dataplaneadapter_layer.md","content":"# DataplaneAdapter Layer\n\nCreate the integration layer between sudocode services and dataplane.\n\n## DataplaneAdapter Class\n\n```typescript\n// server/src/services/dataplane-adapter.ts\n\nclass DataplaneAdapter {\n  private tracker: MultiAgentRepoTracker;\n  private config: DataplaneConfig;\n  \n  constructor(repoPath: string, config: DataplaneConfig) {\n    this.tracker = new MultiAgentRepoTracker({\n      repoPath,\n      dbPath: '.sudocode/dataplane.db',\n    });\n    this.config = config;\n  }\n\n  // === Stream Management ===\n  async ensureIssueStream(issueId: string): Promise<string>;\n  async createExecutionStream(params: {\n    executionId: string;\n    issueId?: string;\n    agentType: AgentType;\n    targetBranch: string;\n    mode: 'worktree' | 'local';\n  }): Promise<ExecutionStreamResult>;\n  async createFollowUpStream(params: {\n    parentExecutionId: string;\n    executionId: string;\n    reuseWorktree: boolean;\n  }): Promise<ExecutionStreamResult>;\n\n  // === Worktree Management ===\n  async getOrCreateWorktree(streamId: string): Promise<WorktreeInfo>;\n  async cleanupWorktree(streamId: string): Promise<void>;\n  \n  // === Change Tracking ===\n  async getChanges(executionId: string): Promise<ChangeSet>;\n  async getFileDiff(executionId: string, filePath: string): Promise<FileDiff>;\n  async commitChanges(params: CommitParams): Promise<CommitResult>;\n\n  // === Sync Operations ===\n  async previewSync(executionId: string): Promise<SyncPreview>;\n  async squashSync(executionId: string, options: SyncOptions): Promise<SyncResult>;\n  async preserveSync(executionId: string, options: SyncOptions): Promise<SyncResult>;\n  async stageSync(executionId: string): Promise<void>;\n\n  // === Conflict Handling ===\n  async resolveConflict(conflictId: string, strategy: ConflictStrategy): Promise<void>;\n  async getConflicts(executionId: string): Promise<Conflict[]>;\n  \n  // === Reconciliation ===\n  async reconcileStream(streamId: string): Promise<ReconcileResult>;\n  async healthCheck(): Promise<HealthReport>;\n\n  // === Dependencies & Cascade ===\n  async syncIssueDependencies(issueId: string): Promise<void>;\n  async triggerCascade(streamId: string): Promise<CascadeReport>;\n\n  // === Merge Queue ===\n  async enqueue(params: {\n    executionId: string;\n    targetBranch: string;\n    position?: number;\n  }): Promise<QueueEntry>;\n  async dequeue(executionId: string): Promise<void>;\n  async getQueuePosition(executionId: string): Promise<number | null>;\n  async getQueue(targetBranch: string): Promise<QueueEntry[]>;\n  async reorderQueue(executionId: string, newPosition: number): Promise<ReorderResult>;\n  async mergeNext(targetBranch: string): Promise<MergeResult>;\n  async mergeUpTo(executionId: string): Promise<MergeResult[]>;\n}\n```\n\n## Stream Metadata Schema\n\n```typescript\ninterface SudocodeStreamMetadata {\n  sudocode: {\n    type: 'issue' | 'execution';\n    issue_id: string;\n    execution_id?: string;\n    agent_type?: AgentType;\n    target_branch?: string;\n  }\n}\n```\n\n## Configuration\n\n```typescript\n// server/src/services/dataplane-config.ts\n\ninterface DataplaneConfig {\n  conflictStrategy: {\n    default: 'defer' | 'ours' | 'theirs';\n    code: 'defer' | 'ours' | 'theirs';\n    cascade: 'stop_on_conflict' | 'skip_conflicting' | 'defer_conflicts';\n  };\n  autoReconcile: boolean;\n  cascadeOnMerge: boolean;\n  mergeQueue: {\n    enabled: boolean;\n    autoEnqueue: boolean;\n    requireQueue: boolean;\n  };\n}\n\nfunction loadDataplaneConfig(): DataplaneConfig {\n  // Load from .sudocode/config.json, merge with defaults\n}\n```\n\n## JSONL Conflict Handler\n\n```typescript\n// Built into adapter, used for all merge operations\nprivate jsonlConflictHandler = async (conflict: ConflictInfo) => {\n  if (isJsonlFile(conflict.path)) {\n    const resolved = await mergeThreeWay(\n      conflict.base,\n      conflict.ours,\n      conflict.theirs\n    );\n    return { strategy: 'custom', resolvedContent: resolved };\n  }\n  return { strategy: this.config.conflictStrategy.code };\n};\n```\n\n## Files to Create\n\n- `server/src/services/dataplane-adapter.ts` - Main adapter class\n- `server/src/services/dataplane-config.ts` - Config loading\n- `server/src/services/dataplane-types.ts` - TypeScript interfaces\n- `server/tests/services/dataplane-adapter.test.ts` - Unit tests","priority":1,"archived":0,"archived_at":null,"created_at":"2026-01-08 06:02:21","updated_at":"2026-01-08 22:44:24","parent_id":"s-329o","parent_uuid":"c7c92f0d-ea24-4e24-b8ab-bda5d1f47a40","relationships":[{"from":"s-7a0k","from_type":"spec","to":"s-5zxn","to_type":"spec","type":"depends-on"}],"tags":["adapter","integration","sudocode"]}
{"id":"s-3wb1","uuid":"db5f06cd-67e6-49a7-9262-94738abe737c","title":"Cascade and Dependencies","file_path":"specs/s-3wb1_cascade_and_dependencies.md","content":"# Cascade and Dependencies\n\nImplement issue dependency sync and cascade rebase functionality.\n\n## Issue Dependency Sync\n\nSync sudocode issue relationships to dataplane stream dependencies.\n\n```typescript\n// DataplaneAdapter method\nasync syncIssueDependencies(issueId: string): Promise<void> {\n  const issue = await getIssue(issueId);\n  const issueStream = await this.ensureIssueStream(issueId);\n  \n  // Get issue's blockers from sudocode relationships\n  const blockers = await getRelationships({\n    to_id: issueId,\n    type: 'blocks'\n  });\n  \n  // Sync to dataplane stream dependencies\n  for (const blocker of blockers) {\n    const blockerStream = await this.ensureIssueStream(blocker.from_id);\n    await this.tracker.addDependency(issueStream, blockerStream);\n  }\n}\n```\n\n## Cascade Trigger on Merge\n\n```typescript\nasync squashSync(executionId: string, options: SyncOptions): Promise<SyncResult> {\n  const result = await this.tracker.mergeStream({\n    sourceStream: executionStreamId,\n    targetStream: options.targetStream,\n    strategy: 'squash',\n    onConflict: options.conflictHandler,\n  });\n\n  // Trigger cascade if enabled and merging to issue stream\n  let cascade: CascadeReport | undefined;\n  if (this.config.cascadeOnMerge && isIssueStream(options.targetStream)) {\n    cascade = await this.triggerCascade(options.targetStream);\n  }\n\n  return { ...result, cascade };\n}\n\nasync triggerCascade(streamId: string): Promise<CascadeReport> {\n  const result = await this.tracker.cascadeRebase({\n    streamId,\n    strategy: this.config.conflictStrategy.cascade,\n    onConflict: this.jsonlConflictHandler,\n  });\n\n  return {\n    triggered_by: streamId,\n    affected_streams: result.results.map(r => ({\n      stream_id: r.streamId,\n      issue_id: this.getIssueIdFromStream(r.streamId),\n      result: r.status,\n      conflict_files: r.conflicts?.map(c => c.path),\n      new_head: r.newHead,\n    })),\n  };\n}\n```\n\n## Cascade Configuration\n\n```json\n{\n  \"dataplane\": {\n    \"cascadeOnMerge\": true,\n    \"conflictStrategy\": {\n      \"cascade\": \"skip_conflicting\"\n    }\n  }\n}\n```\n\n**Cascade strategies:**\n- `stop_on_conflict` - Stop cascade on first conflict\n- `skip_conflicting` - Skip conflicted streams, continue others\n- `defer_conflicts` - Record all conflicts, continue cascade\n\n## UI Updates for Cascade\n\n```typescript\n// After sync completes, show cascade report\ninterface SyncResultUI {\n  success: boolean;\n  message: string;\n  cascade?: {\n    count: number;\n    rebased: string[];      // Issue IDs successfully rebased\n    conflicted: string[];   // Issue IDs with conflicts\n    skipped: string[];      // Issue IDs skipped\n  };\n}\n```\n\n## Files to Modify\n\n- `server/src/services/dataplane-adapter.ts` - Add syncIssueDependencies, triggerCascade\n- `server/src/services/worktree-sync-service.ts` - Cascade after merge\n- `frontend/src/components/executions/SyncResultDialog.tsx` - Show cascade results\n- `server/src/routes/executions.ts` - Return cascade report in sync response","priority":2,"archived":0,"archived_at":null,"created_at":"2026-01-08 06:02:22","updated_at":"2026-01-08 06:02:22","parent_id":"s-329o","parent_uuid":"c7c92f0d-ea24-4e24-b8ab-bda5d1f47a40","relationships":[{"from":"s-3wb1","from_type":"spec","to":"s-71d1","to_type":"spec","type":"depends-on"},{"from":"s-3wb1","from_type":"spec","to":"s-gljp","to_type":"spec","type":"depends-on"}],"tags":["cascade","dependencies","sudocode"]}
{"id":"s-71d1","uuid":"1be5316f-057c-4d83-98cc-4e919209c689","title":"Sync Operations Integration","file_path":"specs/s-71d1_sync_operations_integration.md","content":"# Sync Operations Integration\n\nImplement sync operations through DataplaneAdapter with JSONL conflict handling.\n\n## WorktreeSyncService Changes\n\n```typescript\n// server/src/services/worktree-sync-service.ts\n\nclass WorktreeSyncService {\n  constructor(private adapter: DataplaneAdapter) {}\n\n  async previewSync(executionId: string): Promise<SyncPreview> {\n    // Auto-reconcile on read\n    await this.adapter.reconcileStream(executionId);\n    return this.adapter.previewSync(executionId);\n  }\n\n  async squashSync(executionId: string, options: SyncOptions): Promise<SyncResult> {\n    return this.adapter.squashSync(executionId, {\n      ...options,\n      conflictHandler: this.jsonlConflictHandler,\n    });\n  }\n\n  async preserveSync(executionId: string, options: SyncOptions): Promise<SyncResult> {\n    return this.adapter.preserveSync(executionId, {\n      ...options,\n      conflictHandler: this.jsonlConflictHandler,\n    });\n  }\n\n  // Stage stays in sudocode - applies diff without dataplane merge\n  async stageSync(executionId: string, options: StageOptions): Promise<void> {\n    const changes = await this.adapter.getChanges(executionId);\n    await this.applyDiffToWorkingTree(changes, options.targetPath);\n    // Stream remains open (not merged)\n  }\n\n  private jsonlConflictHandler = async (conflict: ConflictInfo) => {\n    if (isJsonlFile(conflict.path)) {\n      const resolved = await mergeThreeWay(\n        conflict.base,\n        conflict.ours,\n        conflict.theirs\n      );\n      return { strategy: 'custom', resolvedContent: resolved };\n    }\n    // Use configured default for non-JSONL\n    return { strategy: this.config.conflictStrategy.code };\n  };\n}\n```\n\n## Sync Preview Response\n\n```typescript\ninterface SyncPreview {\n  commits: Array<{\n    sha: string;\n    message: string;\n    changeId?: string;  // Stable identity\n  }>;\n  conflicts: Array<{\n    path: string;\n    type: 'code' | 'jsonl';\n    canAutoResolve: boolean;\n  }>;\n  warnings: string[];\n  cascadeTargets: string[];  // Streams that will be rebased\n}\n```\n\n## Sync Result with Cascade Report\n\n```typescript\ninterface SyncResult {\n  success: boolean;\n  mergedCommit?: string;\n  conflicts?: Conflict[];\n  cascade?: CascadeReport;\n}\n\ninterface CascadeReport {\n  triggered_by: string;\n  affected_streams: Array<{\n    stream_id: string;\n    issue_id?: string;\n    result: 'rebased' | 'conflict' | 'skipped';\n    conflict_files?: string[];\n    new_head?: string;\n  }>;\n}\n```\n\n## Files to Modify\n\n- `server/src/services/worktree-sync-service.ts` - Use adapter, add JSONL handler\n- `server/src/routes/executions.ts` - Update sync endpoints for new response shape\n- `types/src/index.d.ts` - Add SyncResult, CascadeReport types","priority":2,"archived":0,"archived_at":null,"created_at":"2026-01-08 06:02:22","updated_at":"2026-01-08 06:02:22","parent_id":"s-329o","parent_uuid":"c7c92f0d-ea24-4e24-b8ab-bda5d1f47a40","relationships":[{"from":"s-71d1","from_type":"spec","to":"s-926y","to_type":"spec","type":"depends-on"}],"tags":["conflicts","sudocode","sync"]}
{"id":"s-8b1o","uuid":"fc07fdcb-2d94-405f-b6f2-ae22a2f7ae58","title":"Conflict Resolution UI","file_path":"specs/s-8b1o_conflict_resolution_ui.md","content":"# Conflict Resolution UI\n\nUpdate UI to handle deferred conflicts and resolution strategies.\n\n## Execution Status Extension\n\n```typescript\n// Execution can now be in 'conflicted' status\ntype ExecutionStatus = \n  | 'preparing' | 'pending' | 'running' \n  | 'paused' | 'completed' | 'failed' | 'cancelled' | 'stopped'\n  | 'conflicted';  // NEW\n```\n\n## Conflict Display Component\n\n```typescript\n// frontend/src/components/executions/ConflictPanel.tsx\n\ninterface ConflictPanelProps {\n  executionId: string;\n  conflicts: Conflict[];\n  onResolve: (conflictId: string, strategy: ConflictStrategy) => void;\n}\n\n// Shows:\n// - List of conflicted files\n// - Conflict type (code vs jsonl - though jsonl auto-resolved)\n// - Conflicting stream info\n// - Resolution options per file or bulk\n```\n\n## Resolution Options UI\n\n```\n┌─────────────────────────────────────────────────────┐\n│ Conflicts in exec-abc123                            │\n├─────────────────────────────────────────────────────┤\n│ ⚠️ src/api/auth.ts                                  │\n│   Conflicting with: issue/i-auth                    │\n│   [Keep Mine] [Accept Theirs] [Open in Editor]      │\n├─────────────────────────────────────────────────────┤\n│ ⚠️ src/utils/helpers.ts                             │\n│   Conflicting with: issue/i-auth                    │\n│   [Keep Mine] [Accept Theirs] [Open in Editor]      │\n├─────────────────────────────────────────────────────┤\n│ Bulk Actions: [Keep All Mine] [Accept All Theirs]   │\n│                                                     │\n│ Default strategy for future: [Dropdown: defer ▾]   │\n└─────────────────────────────────────────────────────┘\n```\n\n## Conflict Resolution Flow\n\n```typescript\n// frontend/src/hooks/useConflictResolution.ts\n\nconst useConflictResolution = (executionId: string) => {\n  const resolveConflict = async (\n    conflictId: string, \n    strategy: 'ours' | 'theirs' | 'manual'\n  ) => {\n    await api.post(`/executions/${executionId}/conflicts/${conflictId}/resolve`, {\n      strategy,\n    });\n    // Refetch execution status\n  };\n\n  const resolveAll = async (strategy: 'ours' | 'theirs') => {\n    await api.post(`/executions/${executionId}/conflicts/resolve-all`, {\n      strategy,\n    });\n  };\n\n  const retryOperation = async () => {\n    // After conflicts resolved, retry the original merge/rebase\n    await api.post(`/executions/${executionId}/retry`);\n  };\n};\n```\n\n## API Endpoints\n\n```\nPOST /api/executions/:id/conflicts/:conflictId/resolve\n  Body: { strategy: 'ours' | 'theirs' | 'manual' }\n\nPOST /api/executions/:id/conflicts/resolve-all\n  Body: { strategy: 'ours' | 'theirs' }\n\nPOST /api/executions/:id/retry\n  Retry original operation after conflict resolution\n```\n\n## Files to Create/Modify\n\n- `frontend/src/components/executions/ConflictPanel.tsx` - NEW\n- `frontend/src/hooks/useConflictResolution.ts` - NEW\n- `frontend/src/components/executions/ExecutionView.tsx` - Show conflicts\n- `server/src/routes/executions.ts` - Conflict resolution endpoints","priority":3,"archived":0,"archived_at":null,"created_at":"2026-01-08 06:02:22","updated_at":"2026-01-08 06:02:22","parent_id":"s-329o","parent_uuid":"c7c92f0d-ea24-4e24-b8ab-bda5d1f47a40","relationships":[{"from":"s-8b1o","from_type":"spec","to":"s-71d1","to_type":"spec","type":"depends-on"}],"tags":["conflicts","frontend","ui"]}
{"id":"s-926y","uuid":"036050a1-f94b-4bbd-9a25-b4ea522f451b","title":"Service Integration","file_path":"specs/s-926y_service_integration.md","content":"# Service Integration\n\nReplace existing git/worktree operations with DataplaneAdapter calls.\n\n## ExecutionLifecycleService Changes\n\n```typescript\n// server/src/services/execution-lifecycle.ts\n\nclass ExecutionLifecycleService {\n  constructor(\n    private adapter: DataplaneAdapter,  // NEW: inject adapter\n    // ... existing deps\n  ) {}\n\n  async createExecutionWithWorktree(params) {\n    // BEFORE: WorktreeManager.createWorktree() + manual git\n    // AFTER:\n    const result = await this.adapter.createExecutionStream({\n      executionId: params.id,\n      issueId: params.issueId,\n      agentType: params.agentType,\n      targetBranch: params.targetBranch,\n      mode: 'worktree',\n    });\n    \n    // Create execution record with stream reference\n    return createExecution({\n      ...params,\n      worktree_path: result.worktree.path,\n      branch_name: result.stream.branchName,\n      before_commit: result.stream.baseCommit,\n      stream_id: result.stream.id,  // NEW field\n    });\n  }\n\n  async createFollowUp(parentExecutionId: string, params) {\n    const result = await this.adapter.createFollowUpStream({\n      parentExecutionId,\n      executionId: params.id,\n      reuseWorktree: params.reuseWorktree,\n    });\n    // ...\n  }\n}\n```\n\n## ExecutionChangesService Changes\n\n```typescript\n// server/src/services/execution-changes-service.ts\n\nclass ExecutionChangesService {\n  constructor(private adapter: DataplaneAdapter) {}\n\n  async getChanges(executionId: string): Promise<ExecutionChanges> {\n    // BEFORE: Manual git diff with before_commit/after_commit\n    // AFTER:\n    return this.adapter.getChanges(executionId);\n  }\n\n  async getFileDiff(executionId: string, filePath: string): Promise<FileDiff> {\n    return this.adapter.getFileDiff(executionId, filePath);\n  }\n}\n```\n\n## Execution Schema Addition\n\n```sql\n-- Add stream_id to executions table\nALTER TABLE executions ADD COLUMN stream_id TEXT;\n```\n\n## Dependency Injection Setup\n\n```typescript\n// server/src/index.ts or container setup\n\nconst dataplaneAdapter = new DataplaneAdapter(\n  repoPath,\n  loadDataplaneConfig()\n);\n\nconst executionLifecycle = new ExecutionLifecycleService(\n  dataplaneAdapter,\n  // ... other deps\n);\n```\n\n## Files to Modify\n\n- `server/src/services/execution-lifecycle.ts` - Use adapter for stream/worktree\n- `server/src/services/execution-changes-service.ts` - Use adapter for changes\n- `server/src/services/execution-service.ts` - Inject adapter\n- `types/src/index.d.ts` - Add stream_id to Execution type\n- `types/src/schema.ts` - Add stream_id column","priority":2,"archived":0,"archived_at":null,"created_at":"2026-01-08 06:02:22","updated_at":"2026-01-08 06:02:22","parent_id":"s-329o","parent_uuid":"c7c92f0d-ea24-4e24-b8ab-bda5d1f47a40","relationships":[{"from":"s-926y","from_type":"spec","to":"s-7a0k","to_type":"spec","type":"depends-on"}],"tags":["integration","services","sudocode"]}
{"id":"s-gljp","uuid":"c0c4562e-4fa8-483a-b33b-eb85247b0057","title":"Merge Queue","file_path":"specs/s-gljp_merge_queue.md","content":"# Merge Queue\n\nExplicit ordering for streams merging to a target branch. Complements dependency-based ordering with explicit position control.\n\n## Overview\n\n**Without queue (default):** Merge order derived from stream dependencies via topological sort. Parallel streams have undefined order.\n\n**With queue:** Explicit position determines merge order. Parallel streams can be explicitly ordered. Still respects dependencies.\n\n## Data Model\n\n```sql\n-- dataplane schema addition\nCREATE TABLE merge_queue (\n  id TEXT PRIMARY KEY,\n  target_branch TEXT NOT NULL,\n  stream_id TEXT NOT NULL REFERENCES streams(id),\n  position INTEGER NOT NULL,\n  status TEXT NOT NULL DEFAULT 'pending',  -- pending, ready, merging, conflicted, merged\n  enqueued_at TEXT NOT NULL,\n  enqueued_by TEXT,  -- agent, user, orchestrator\n  merged_at TEXT,\n  metadata TEXT,  -- JSON for extensibility\n  \n  UNIQUE(target_branch, stream_id),\n  UNIQUE(target_branch, position)\n);\n\nCREATE INDEX idx_queue_target ON merge_queue(target_branch, position);\nCREATE INDEX idx_queue_stream ON merge_queue(stream_id);\n```\n\n## Queue Entry States\n\n| Status | Description |\n|--------|-------------|\n| `pending` | In queue, not ready to merge (execution in progress or dependencies not merged) |\n| `ready` | Ready to merge (execution complete, dependencies merged) |\n| `merging` | Currently being merged |\n| `conflicted` | Merge attempted, conflicts detected |\n| `merged` | Successfully merged, kept for history |\n\n## API\n\n```typescript\n// dataplane/src/queue.ts\n\ninterface MergeQueueAPI {\n  // Query\n  getQueue(targetBranch: string): QueueEntry[];\n  getPosition(streamId: string): number | null;\n  getQueueStatus(targetBranch: string): QueueSummary;\n  \n  // Enqueue/Dequeue\n  enqueue(params: {\n    streamId: string;\n    targetBranch: string;\n    position?: number;      // Optional, defaults to end\n    enqueuedBy?: string;\n  }): QueueEntry;\n  \n  dequeue(streamId: string): void;\n  \n  // Reorder\n  reorder(params: {\n    streamId: string;\n    newPosition: number;\n    cascadeStrategy?: CascadeStrategy;\n  }): ReorderResult;\n  \n  // Merge operations\n  mergeNext(params: {\n    targetBranch: string;\n    onConflict?: ConflictCallback;\n  }): MergeResult;\n  \n  mergeUpTo(params: {\n    streamId: string;        // Merge everything up to and including this\n    onConflict?: ConflictCallback;\n  }): MergeResult[];\n  \n  // Conflict handling\n  skipConflicted(streamId: string): void;  // Move past conflicted entry\n  retryConflicted(streamId: string): MergeResult;\n}\n```\n\n## Queue Entry Type\n\n```typescript\ninterface QueueEntry {\n  id: string;\n  targetBranch: string;\n  streamId: string;\n  position: number;\n  status: 'pending' | 'ready' | 'merging' | 'conflicted' | 'merged';\n  enqueuedAt: Date;\n  enqueuedBy?: string;\n  mergedAt?: Date;\n  \n  // Computed fields\n  stream?: Stream;                  // Populated on query\n  blockedByDependency?: string;     // Stream ID that must merge first\n  conflictsWith?: string[];         // Earlier entries with detected conflicts\n}\n\ninterface QueueSummary {\n  targetBranch: string;\n  total: number;\n  pending: number;\n  ready: number;\n  conflicted: number;\n  merged: number;\n  nextToMerge?: QueueEntry;\n}\n```\n\n## Reorder Behavior\n\n```\nBefore: [A, B, C, D] (positions 1-4)\nReorder: Move C to position 2\n\nAfter: [A, C, B, D] (positions 1-4)\n\nCascade triggered:\n1. C rebases onto A (its new base)\n2. B rebases onto C (was on A, now on A+C)\n3. D rebases onto B (was on A+B+C, now on A+C+B)\n```\n\n```typescript\ninterface ReorderResult {\n  newOrder: QueueEntry[];\n  cascade: CascadeReport;  // Results of rebasing affected streams\n}\n```\n\n## Dependency Integration\n\nQueue respects stream dependencies:\n\n```typescript\n// Cannot enqueue at position earlier than dependencies\nenqueue({ streamId: 'exec-C', position: 1 })\n// Error: exec-C depends on exec-A which is at position 2\n\n// Cannot merge if dependencies not merged\nmergeNext({ targetBranch: 'main' })\n// Skips exec-C if exec-A (dependency) hasn't merged yet\n```\n\n## Auto-Queue on Sync\n\nWhen execution syncs via DataplaneAdapter:\n\n```typescript\n// DataplaneAdapter.squashSync()\nasync squashSync(executionId: string, options: SyncOptions) {\n  const stream = this.getStreamForExecution(executionId);\n  \n  // Auto-enqueue if not already in queue\n  if (!this.tracker.queue.getPosition(stream.id)) {\n    this.tracker.queue.enqueue({\n      streamId: stream.id,\n      targetBranch: options.targetBranch,\n      enqueuedBy: 'sync',\n    });\n  }\n  \n  // If at front of queue (or no queue enforcement), merge immediately\n  // Otherwise, mark ready and wait for turn\n}\n```\n\n## Configuration\n\n```json\n{\n  \"dataplane\": {\n    \"mergeQueue\": {\n      \"enabled\": true,\n      \"autoEnqueue\": true,         // Auto-add to queue on sync\n      \"requireQueue\": false,       // If true, reject merges not in queue\n      \"conflictBehavior\": \"block\"  // block | skip | defer\n    }\n  }\n}\n```\n\n## Files to Create\n\n- `dataplane/src/queue.ts` - Queue operations\n- `dataplane/src/schema.ts` - Add merge_queue table\n- `dataplane/tests/queue.test.ts` - Queue tests\n- Update `MultiAgentRepoTracker` to expose queue API","priority":2,"archived":0,"archived_at":null,"created_at":"2026-01-08 08:42:12","updated_at":"2026-01-08 08:42:12","parent_id":"s-329o","parent_uuid":"c7c92f0d-ea24-4e24-b8ab-bda5d1f47a40","relationships":[{"from":"s-gljp","from_type":"spec","to":"s-5zxn","to_type":"spec","type":"depends-on"}],"tags":["dataplane","merge-queue","orchestration"]}
