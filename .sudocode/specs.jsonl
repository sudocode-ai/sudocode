{"id":"SPEC-001","uuid":"37d447c6-5f01-435d-b7e8-99d689e597f8","title":"Agent Execution System","file_path":"specs/agent_execution_system.md","content":"# Agent Execution System\n\n## Overview\n\nA flexible system for running different coding agents on issues and tracking their execution trajectories. Designed for sudocode's TypeScript/Node.js stack.\n\n## Architecture\n\n### Three-Layer Execution Model\n\n```\nIssue → Execution → Trajectory Entries\n  ↓         ↓            ↓\nTask      Process    Log Events\n```\n\n**1\\. Issue** (existing)\n\n- Already implemented in sudocode\n- Represents a task to be completed\n\n**2\\. Execution** (new)\n\n- Represents a single agent run on an issue\n- Tracks: agent type, status, git context, session info\n- Multiple executions can exist per issue (retries, different agents)\n\n**3\\. Trajectory Entry** (new)\n\n- Individual events/actions during execution\n- Tool uses, thinking, messages, file changes\n- Enables playback and analysis of agent behavior\n\n### Supported Agents\n\nPhase 1: **Claude Code** (via `@anthropic-ai/claude-code`) Phase 2: **Codex** (via `@phasehq/codex`) Future: Aider, Cursor, custom agents\n\n## Data Models\n\n### Execution\n\n```typescript\ninterface Execution {\n  id: string;                    // UUID\n  issueId: string;               // Foreign key to issues\n  agentType: AgentType;          // Which agent ran\n  status: ExecutionStatus;       // Current state\n  \n  // Timestamps\n  startedAt: Date;\n  completedAt?: Date;\n  \n  // Process info\n  exitCode?: number;\n  \n  // Git context (captured before/after)\n  beforeCommit?: string;         // Git SHA before execution\n  afterCommit?: string;          // Git SHA after execution\n  \n  // Session tracking (for resume/fork)\n  sessionId?: string;            // External session ID from agent\n  prompt?: string;               // Initial prompt sent\n  summary?: string;              // Final agent summary\n  \n  // Metadata\n  createdAt: Date;\n  updatedAt: Date;\n}\n\ntype AgentType = 'claude-code' | 'codex';\n\ntype ExecutionStatus = \n  | 'running'\n  | 'completed' \n  | 'failed'\n  | 'stopped';\n```\n\n### Trajectory Entry\n\n```typescript\ninterface TrajectoryEntry {\n  id: number;                    // Auto-increment\n  executionId: string;           // Foreign key to executions\n  index: number;                 // Sequential order within execution\n  timestamp: Date;\n  \n  // Entry type and data (polymorphic)\n  type: EntryType;\n  content: string;               // Display text\n  metadata?: Record<string, any>; // Type-specific data\n}\n\ntype EntryType = \n  | 'tool_use'        // Agent used a tool\n  | 'thinking'        // Agent reasoning/planning\n  | 'assistant_msg'   // Agent message to user\n  | 'user_msg'        // User message to agent\n  | 'user_feedback'   // User approval/denial\n  | 'system_msg'      // System notifications\n  | 'error_msg';      // Errors\n\n// Tool use metadata\ninterface ToolUseMetadata {\n  toolName: string;\n  action: ActionType;\n  status: 'created' | 'running' | 'success' | 'failed';\n}\n\ntype ActionType =\n  | { type: 'file_read', path: string }\n  | { type: 'file_edit', path: string, changes: FileChange[] }\n  | { type: 'file_write', path: string, content: string }\n  | { type: 'command_run', command: string, result?: CommandResult }\n  | { type: 'search', query: string }\n  | { type: 'web_fetch', url: string }\n  | { type: 'task_create', description: string }\n  | { type: 'tool', toolName: string, args: any, result?: any };\n\ninterface FileChange {\n  type: 'edit' | 'write';\n  unifiedDiff?: string;          // For edits\n  content?: string;              // For writes\n  hasLineNumbers: boolean;\n}\n\ninterface CommandResult {\n  exitStatus: { code: number } | { success: boolean };\n  output: string;\n}\n```\n\n## Agent Abstraction\n\n### CodingAgent Interface\n\n```typescript\ninterface CodingAgent {\n  // Spawn initial execution\n  spawn(\n    workDir: string, \n    prompt: string\n  ): Promise<SpawnedProcess>;\n  \n  // Spawn follow-up (resume/fork)\n  spawnFollowUp(\n    workDir: string,\n    prompt: string, \n    sessionId: string\n  ): Promise<SpawnedProcess>;\n  \n  // Normalize agent-specific logs to TrajectoryEntry\n  normalizeLogs(\n    rawLogs: AsyncIterable<string>\n  ): AsyncIterable<TrajectoryEntry>;\n  \n  // Capabilities\n  supportsSessionFork(): boolean;\n  supportsMCP(): boolean;\n  getDefaultMCPConfigPath(): string | null;\n}\n\ninterface SpawnedProcess {\n  process: ChildProcess;\n  exitSignal?: Promise<void>;  // Optional early exit signal\n}\n```\n\n### Claude Code Executor\n\n```typescript\nclass ClaudeCodeExecutor implements CodingAgent {\n  async spawn(workDir: string, prompt: string) {\n    const proc = spawn('npx', [\n      '-y', '@anthropic-ai/claude-code@latest',\n      '-p',\n      '--output-format=stream-json',\n      '--include-partial-messages',\n      '--verbose'\n    ], { \n      cwd: workDir,\n      stdio: ['pipe', 'pipe', 'pipe']\n    });\n    \n    proc.stdin.write(prompt);\n    proc.stdin.end();\n    \n    return { process: proc };\n  }\n  \n  async spawnFollowUp(workDir: string, prompt: string, sessionId: string) {\n    const proc = spawn('npx', [\n      '-y', '@anthropic-ai/claude-code@latest',\n      '-p',\n      '--output-format=stream-json',\n      '--include-partial-messages',\n      '--verbose',\n      '--fork-session',\n      '--resume', sessionId\n    ], { cwd: workDir });\n    \n    proc.stdin.write(prompt);\n    proc.stdin.end();\n    \n    return { process: proc };\n  }\n  \n  async *normalizeLogs(rawLogs: AsyncIterable<string>) {\n    let buffer = '';\n    let sessionIdExtracted = false;\n    let entryIndex = 0;\n    \n    for await (const chunk of rawLogs) {\n      buffer += chunk;\n      \n      // Process complete JSON lines\n      const lines = buffer.split('\\n');\n      buffer = lines.pop() || '';\n      \n      for (const line of lines) {\n        const trimmed = line.trim();\n        if (!trimmed) continue;\n        \n        try {\n          const json = JSON.parse(trimmed);\n          \n          // Extract session ID\n          if (!sessionIdExtracted && json.session_id) {\n            sessionIdExtracted = true;\n            // Emit session ID separately for storage\n          }\n          \n          // Normalize to TrajectoryEntry\n          const entries = this.normalizeClaudeJson(json, entryIndex);\n          for (const entry of entries) {\n            yield entry;\n            entryIndex++;\n          }\n        } catch (e) {\n          // Non-JSON output - treat as system message\n          yield {\n            index: entryIndex++,\n            type: 'system_msg',\n            content: trimmed,\n            timestamp: new Date()\n          };\n        }\n      }\n    }\n  }\n  \n  private normalizeClaudeJson(json: any, startIndex: number): TrajectoryEntry[] {\n    // Parse Claude's JSON format into TrajectoryEntry[]\n    const entries: TrajectoryEntry[] = [];\n    \n    switch (json.type) {\n      case 'system':\n        if (json.subtype !== 'init') {\n          entries.push({\n            index: startIndex,\n            type: 'system_msg',\n            content: `System: ${json.subtype || 'message'}`,\n            timestamp: new Date(),\n            metadata: json\n          });\n        }\n        break;\n        \n      case 'assistant':\n        for (const item of json.message.content) {\n          if (item.type === 'text') {\n            entries.push({\n              index: startIndex + entries.length,\n              type: 'assistant_msg',\n              content: item.text,\n              timestamp: new Date(),\n              metadata: item\n            });\n          } else if (item.type === 'thinking') {\n            entries.push({\n              index: startIndex + entries.length,\n              type: 'thinking',\n              content: item.thinking,\n              timestamp: new Date(),\n              metadata: item\n            });\n          } else if (item.type === 'tool_use') {\n            entries.push({\n              index: startIndex + entries.length,\n              type: 'tool_use',\n              content: this.generateToolContent(item),\n              timestamp: new Date(),\n              metadata: {\n                toolName: item.name,\n                action: this.extractAction(item),\n                status: 'created'\n              }\n            });\n          }\n        }\n        break;\n        \n      case 'user':\n        // Handle tool results and user messages\n        break;\n    }\n    \n    return entries;\n  }\n  \n  supportsSessionFork() { return true; }\n  supportsMCP() { return true; }\n  getDefaultMCPConfigPath() { \n    return `${os.homedir()}/.claude.json`; \n  }\n}\n```\n\n### Codex Executor\n\n```typescript\nclass CodexExecutor implements CodingAgent {\n  async spawn(workDir: string, prompt: string) {\n    // Similar structure, but using Codex CLI\n    const proc = spawn('npx', [\n      '-y', '@phasehq/codex@latest',\n      // Codex-specific flags\n    ], { cwd: workDir });\n    \n    // Codex has different input format\n    proc.stdin.write(JSON.stringify({ prompt }));\n    proc.stdin.end();\n    \n    return { process: proc };\n  }\n  \n  async *normalizeLogs(rawLogs: AsyncIterable<string>) {\n    // Codex-specific log parsing\n    // Different format than Claude\n  }\n  \n  supportsSessionFork() { return true; }\n  supportsMCP() { return true; }\n}\n```\n\n## Database Schema\n\n### Executions Table\n\n[[ISSUE-028]]{ references }\n\n```sql\nCREATE TABLE executions (\n  id TEXT PRIMARY KEY,\n  issue_id TEXT NOT NULL REFERENCES issues(id) ON DELETE CASCADE,\n  agent_type TEXT NOT NULL,  -- 'claude-code' | 'codex' | etc\n  status TEXT NOT NULL,      -- 'running' | 'completed' | 'failed' | 'stopped'\n  \n  started_at INTEGER NOT NULL,\n  completed_at INTEGER,\n  exit_code INTEGER,\n  \n  before_commit TEXT,\n  after_commit TEXT,\n  \n  session_id TEXT,\n  prompt TEXT,\n  summary TEXT,\n  \n  created_at INTEGER NOT NULL DEFAULT (unixepoch()),\n  updated_at INTEGER NOT NULL DEFAULT (unixepoch())\n);\n\nCREATE INDEX idx_executions_issue_id ON executions(issue_id);\nCREATE INDEX idx_executions_status ON executions(status);\nCREATE INDEX idx_executions_session_id ON executions(session_id);\n```\n\n### Trajectory Entries Table\n\n```sql\nCREATE TABLE trajectory_entries (\n  id INTEGER PRIMARY KEY AUTOINCREMENT,\n  execution_id TEXT NOT NULL REFERENCES executions(id) ON DELETE CASCADE,\n  entry_index INTEGER NOT NULL,\n  timestamp INTEGER NOT NULL,\n  \n  type TEXT NOT NULL,  -- 'tool_use' | 'thinking' | 'assistant_msg' | etc\n  content TEXT NOT NULL,\n  metadata TEXT,       -- JSON blob\n  \n  created_at INTEGER NOT NULL DEFAULT (unixepoch())\n);\n\nCREATE INDEX idx_trajectory_entries_execution_id ON trajectory_entries(execution_id);\nCREATE INDEX idx_trajectory_entries_execution_index ON trajectory_entries(execution_id, entry_index);\n```\n\n## API Endpoints\n\n[[ISSUE-031]]{ references }\n\n### Start Execution\n\n```\nPOST /api/issues/:issueId/executions\n{\n  \"agentType\": \"claude-code\",\n  \"prompt\": \"Fix the authentication bug\"\n}\n\nResponse: { \"executionId\": \"exec-123\" }\n```\n\n### Get Execution Status\n\n```\nGET /api/executions/:executionId\n\nResponse: {\n  \"id\": \"exec-123\",\n  \"issueId\": \"issue-456\",\n  \"agentType\": \"claude-code\",\n  \"status\": \"running\",\n  \"startedAt\": \"2025-01-26T10:00:00Z\",\n  ...\n}\n```\n\n### Stream Trajectory (WebSocket)\n\n```\nWS /api/executions/:executionId/trajectory\n\nMessages:\n{\n  \"type\": \"entry\",\n  \"data\": {\n    \"index\": 5,\n    \"type\": \"tool_use\",\n    \"content\": \"`src/auth.ts`\",\n    \"timestamp\": \"2025-01-26T10:01:23Z\",\n    \"metadata\": { ... }\n  }\n}\n\n{\n  \"type\": \"session_id\",\n  \"data\": { \"sessionId\": \"claude-session-abc\" }\n}\n\n{\n  \"type\": \"finished\",\n  \"data\": { \"exitCode\": 0 }\n}\n```\n\n### Stop Execution\n\n```\nPOST /api/executions/:executionId/stop\n\nResponse: { \"status\": \"stopped\" }\n```\n\n### List Executions for Issue\n\n```\nGET /api/issues/:issueId/executions\n\nResponse: {\n  \"executions\": [\n    { \"id\": \"exec-123\", ... },\n    { \"id\": \"exec-124\", ... }\n  ]\n}\n```\n\n## Implementation Phases\n\n### Phase 1: Core Execution (MVP)\n\n[[ISSUE-029]]{ references }**Goal**: Basic process spawning and log storage\n\n**Issues**:\n\n- [[ISSUE-028]] - Database schema and TypeScript types for executions\n- [[ISSUE-029]] - Implement ExecutionManager class for process lifecycle management\n- [[ISSUE-030]] - Implement basic Claude Code process spawning\n- [[ISSUE-031]] - API endpoints for execution management\n- [[ISSUE-032]] - Raw log storage in temp files\n- [[ISSUE-033]] - Integration test for Phase 1 MVP\n\n**Deliverable**: Can start Claude Code on an issue, track if it's running, and know when it finishes.\n\n### Phase 2: Trajectory Normalization\n\n**Goal**: Parse and store structured logs\n\n- Add trajectory\\_entries table\n- ClaudeCodeExecutor with normalization\n- Parse Claude JSON format → TrajectoryEntry\n- Store entries in database\n- API endpoint: get trajectory entries\n\n**Deliverable**: Can view what Claude did step-by-step (tools used, files edited, etc.)\n\n### Phase 3: Real-Time Streaming\n\n**Goal**: Live updates in UI\n\n- WebSocket endpoint for live trajectory\n- Frontend TrajectoryViewer component\n- Display tool uses, thinking, messages\n- Auto-scroll and updates\n\n**Deliverable**: Watch agent execution in real-time\n\n### Phase 4: Session Management\n\n**Goal**: Resume and fork executions\n\n- Extract session IDs during execution\n- Store session\\_id in executions table\n- Implement spawnFollowUp\n- API endpoint: resume execution\n- UI: \"Continue\" button on executions\n\n**Deliverable**: Can send follow-up prompts to same session\n\n### Phase 5: Multiple Agents\n\n**Goal**: Support Codex and others\n\n- CodingAgent abstraction\n- CodexExecutor implementation\n- Agent selection in UI\n- Agent-specific config (MCP, etc.)\n\n**Deliverable**: Can choose between Claude Code and Codex\n\n### Phase 6: Advanced Features\n\n**Goal**: Production-ready\n\n- Git integration (capture commits)\n- Execution history and comparison\n- Trajectory search and filtering\n- Cost tracking (token usage)\n- Approval system for tool execution\n- Export trajectories\n\n## Key Design Decisions\n\n### Why Three Layers (Issue → Execution → Trajectory)?\n\n- **Issue** = What to do (user-defined task)\n- **Execution** = Agent run (can retry, use different agents)\n- **Trajectory** = How it was done (reproducibility, debugging)\n\nThis allows:\n\n1. Multiple attempts on same issue\n1. Comparing different agents\n1. Detailed playback and analysis\n\n### Why Normalize Logs?\n\nDifferent agents have wildly different output formats:\n\n- Claude Code: Structured JSON\n- Codex: Different JSON format\n- Aider: Plain text with markers\n\nNormalization gives us:\n\n1. Unified UI across all agents\n1. Consistent database schema\n1. Easier analysis and search\n\n### Why AsyncIterable for Log Processing?\n\n```typescript\nasync *normalizeLogs(rawLogs: AsyncIterable<string>)\n```\n\nBenefits:\n\n1. Streaming - process logs as they arrive\n1. Memory efficient - don't load all logs at once\n1. Cancellable - can stop mid-stream\n1. Natural async/await syntax\n\n### Why Store Raw + Normalized?\n\nStore both raw logs (temp files) AND normalized entries: [[ISSUE-032]]{ references }\n\n- Raw logs: debugging, replay, re-parsing\n- Normalized: fast queries, UI display\n\nTrade storage for flexibility.\n\n## Testing Strategy\n\n### Unit Tests\n\n- Log normalization logic\n- Action type extraction\n- Session ID parsing\n\n### Integration Tests\n\n[[ISSUE-033]]{ references }\n\n- Full execution lifecycle\n- WebSocket streaming\n- Database persistence\n\n### E2E Tests\n\n- Start execution via API\n- Verify trajectory entries created\n- Check final status\n\n## Open Questions\n\n1. **Where to run executions?**\n  - Option A: Same machine as server (simpler)\n  - Option B: Separate worker processes (scalable)\n  - **Recommendation**: Start with A, migrate to B later\n1. **How to handle long-running executions?**\n  - Timeout after N minutes?\n  - User-configurable timeout?\n  - **Recommendation**: 30min default, configurable per-issue\n1. **Store raw logs where?**\n  - Temp files (deleted after normalization)?\n  - Database blob?\n  - S3/object storage?\n  - **Recommendation**: Temp files initially, add retention later\n1. **How to handle git context?**\n  - Create isolated git worktrees for executions?\n  - Run in-place and capture commits?\n  - **Recommendation**: Start in-place, add worktrees in Phase 6\n\n## Success Metrics\n\n- **MVP (Phase 1)**: Can run Claude Code on an issue\n- **Useful (Phase 3)**: Can watch execution in real-time\n- **Powerful (Phase 4)**: Can have multi-turn conversations\n- **Production (Phase 6)**: Multiple agents, git integration, approval workflows\n\n## References\n\n- Claude Code: [https://docs.anthropic.com/en/docs/claude-code](https://docs.anthropic.com/en/docs/claude-code)\n- Codex: [https://github.com/phasehq/codex](https://github.com/phasehq/codex)\n","priority":0,"archived":1,"archived_at":"2025-10-28T19:03:55.817Z","created_at":"2025-10-27 00:06:59","updated_at":"2025-11-03T03:10:12.596Z","parent_id":null,"parent_uuid":null,"relationships":[{"from":"SPEC-001","from_type":"spec","to":"ISSUE-028","to_type":"issue","type":"references"},{"from":"SPEC-001","from_type":"spec","to":"ISSUE-031","to_type":"issue","type":"references"},{"from":"SPEC-001","from_type":"spec","to":"ISSUE-029","to_type":"issue","type":"references"},{"from":"SPEC-001","from_type":"spec","to":"ISSUE-030","to_type":"issue","type":"references"},{"from":"SPEC-001","from_type":"spec","to":"ISSUE-032","to_type":"issue","type":"references"},{"from":"SPEC-001","from_type":"spec","to":"ISSUE-033","to_type":"issue","type":"references"}],"tags":[]}
{"id":"SPEC-002","uuid":"603f99a9-53d6-448a-b66c-cf6c902894cf","title":"Execution System","file_path":"specs/execution_system.md","content":"Execution System Specification for Sudocode\n\n  Overview\n\n  Design a flexible, simple-first execution system that can spawn Claude Code instances to work on issues and\n  specs, with real-time progress tracking and the ability to upgrade to a pool-based strategy later.\n\n  Architecture Goals\n\n  1. Simple First: Start with straightforward process spawning\n  2. Flexible Design: Easy to upgrade to pool strategy without breaking changes\n  3. Real-time Feedback: Stream progress to frontend via WebSocket\n  4. Context-Aware: Build rich prompts from issue, spec, and codebase data\n  5. Reliable: Handle errors, timeouts, and process crashes gracefully\n\n  System Components\n\n  ┌─────────────────────────────────────────────────────────────┐\n  │                     Execution System                         │\n  ├─────────────────────────────────────────────────────────────┤\n  │                                                              │\n  │  ┌──────────────┐      ┌──────────────┐      ┌──────────┐  │\n  │  │   Context    │      │  Execution   │      │ Progress │  │\n  │  │   Builder    │─────▶│ Orchestrator │─────▶│ Tracker  │  │\n  │  └──────────────┘      └──────┬───────┘      └────┬─────┘  │\n  │                               │                    │         │\n  │                               ▼                    ▼         │\n  │                    ┌──────────────────┐    ┌──────────────┐ │\n  │                    │ Simple Execution │    │  WebSocket   │ │\n  │                    │    Strategy      │    │   Service    │ │\n  │                    └────────┬─────────┘    └──────────────┘ │\n  │                             │                                │\n  │                             ▼                                │\n  │                   ┌──────────────────┐                       │\n  │                   │ Simple Process   │                       │\n  │                   │    Manager       │                       │\n  │                   └────────┬─────────┘                       │\n  │                            │                                 │\n  │                            ▼                                 │\n  │                   ┌──────────────────┐                       │\n  │                   │  Claude Code     │                       │\n  │                   │  CLI Process     │                       │\n  │                   └──────────────────┘                       │\n  │                                                              │\n  └─────────────────────────────────────────────────────────────┘\n\n  Data Flow\n\n  1. User triggers execution (via API/UI)\n     ↓\n  2. ExecutionOrchestrator.executeIssue(issueId)\n     ↓\n  3. ContextBuilder.buildIssueContext(issueId)\n     - Read issue from database\n     - Find related specs via relationships\n     - Find related issues (dependencies, parent)\n     - Read spec content from markdown files\n     - Build comprehensive prompt\n     ↓\n  4. Create ExecutionTask\n     - Task ID, entity type, context, priority\n     ↓\n  5. SimpleExecutionStrategy.executeTask(task)\n     ↓\n  6. SimpleProcessManager.acquireProcess(task)\n     - Spawn new Claude Code CLI process\n     - Return ManagedProcess handle\n     ↓\n  7. Send prompt to Claude via stdin\n     - Use stream-json output format\n     - Parse output line by line\n     ↓\n  8. ProgressTracker emits updates\n     - Phase changes (initializing → executing → finalizing)\n     - Tool use events (reading files, editing, etc.)\n     - Completion status\n     ↓\n  9. WebSocketService broadcasts to frontend\n     - Real-time progress updates\n     - Execution logs\n     - Final results\n     ↓\n  10. Update execution record in database\n      - Status, exit code, duration, etc.\n      ↓\n  11. SimpleProcessManager.releaseProcess(processId)\n      - Terminate Claude process\n      - Clean up resources\n\n  Component Specifications\n\n  1. Context Builder\n\n  Purpose: Build rich, context-aware prompts for Claude Code\n\n  Inspired by: CodeMachine-CLI's context-manager-agent\n  (references/CodeMachine-CLI/prompts/templates/codemachine/agents/04-context-manager-agent.md)\n\n  Interface:\n  interface IContextBuilder {\n    buildIssueContext(issueId: string): Promise<ExecutionContext>;\n    buildSpecContext(specId: string): Promise<ExecutionContext>;\n    buildBatchContext(entityIds: string[]): Promise<Map<string, ExecutionContext>>;\n  }\n\n  interface ExecutionContext {\n    workDir: string;\n    entityType: 'issue' | 'spec';\n    entityId: string;\n\n    // Core data\n    title: string;\n    description: string;\n\n    // Related entities\n    relatedSpecs: Array<{\n      id: string;\n      title: string;\n      content: string;\n      relationship: string;\n    }>;\n\n    relatedIssues: Array<{\n      id: string;\n      title: string;\n      description: string;\n      status: string;\n      relationship: string;\n    }>;\n\n    // Codebase context (optional, for later enhancement)\n    relevantFiles?: string[];\n\n    // Final prompt\n    prompt: string;\n  }\n\n  Prompt Template Structure (inspired by CodeMachine-CLI):\n  # Task: Work on Issue {issueId}\n\n  ## Issue Details\n  **Title**: {issue.title}\n  **Status**: {issue.status}\n  **Priority**: {issue.priority}\n\n  **Description**:\n  {issue.description}\n\n  ## Related Specifications\n\n  {for each related spec}\n  ### {spec.id}: {spec.title}\n  **Relationship**: {relationship.type}\n\n  {spec.content}\n  {end for}\n\n  ## Related Issues\n\n  {for each related issue}\n  ### {issue.id}: {issue.title}\n  **Status**: {issue.status}\n  **Relationship**: {relationship.type}\n\n  {issue.description}\n  {end for}\n\n  ## Instructions\n\n  1. Analyze the issue description and related specifications\n  2. Understand the requirements and acceptance criteria\n  3. Implement the necessary changes to address the issue\n  4. Test your implementation\n  5. Ensure code quality and adherence to project standards\n\n  ## Project Context\n\n  - Working directory: {workDir}\n  - Project: sudocode issue tracking system\n  - Use TypeScript for all implementations\n  - Follow existing code patterns in the codebase\n\n  ## Output Requirements\n\n  - Make necessary code changes\n  - Update tests if needed\n  - Provide a summary of changes made\n\n  Implementation Notes:\n  - Use template strings or a templating library (handlebars, mustache)\n  - Cache spec content to avoid repeated file reads\n  - Handle missing relationships gracefully\n  - Support both issue and spec execution contexts\n\n  ---\n  2. Execution Orchestrator\n\n  Purpose: Main coordinator that ties all components together\n\n  Inspired by:\n  - CodeMachine-CLI's workflow orchestrator (references/CodeMachine-CLI/src/workflows/execution/workflow.ts)\n  - claude-flow's SwarmCoordinator (references/claude-flow/src/swarm/coordinator.ts)\n\n  Interface:\n  class ExecutionOrchestrator {\n    constructor(\n      private strategy: IExecutionStrategy,\n      private contextBuilder: IContextBuilder,\n      private progressTracker: IProgressTracker,\n      private db: Database.Database\n    );\n\n    // Primary methods\n    executeIssue(issueId: string, options?: ExecutionOptions): Promise<ExecutionResult>;\n    executeSpec(specId: string, options?: ExecutionOptions): Promise<ExecutionResult>;\n    executeMultiple(entityIds: string[], options?: ExecutionOptions): Promise<ExecutionResult[]>;\n\n    // Control methods\n    stopExecution(executionId: string): Promise<void>;\n    getExecutionStatus(executionId: string): ExecutionProgress | null;\n\n    // Strategy management\n    switchStrategy(newStrategy: IExecutionStrategy): void;\n  }\n\n  interface ExecutionOptions {\n    workDir?: string;\n    maxDuration?: number;  // milliseconds\n    priority?: number;\n    customPrompt?: string; // Override generated prompt\n  }\n\n  Key Responsibilities:\n  1. Coordinate between context builder, strategy, and progress tracker\n  2. Create and persist execution records in database\n  3. Handle errors and timeouts gracefully\n  4. Provide clean API for frontend/API layer\n\n  Implementation Pattern (from CodeMachine-CLI):\n  async executeIssue(issueId: string, options: ExecutionOptions = {}): Promise<ExecutionResult> {\n    // 1. Build context\n    const context = await this.contextBuilder.buildIssueContext(issueId);\n\n    // 2. Create task\n    const task: ExecutionTask = {\n      id: generateId('task'),\n      type: 'issue',\n      entityId: issueId,\n      context: {\n        ...context,\n        workDir: options.workDir || process.cwd(),\n      },\n      priority: options.priority || 1,\n      dependencies: [], // TODO: Resolve from relationships\n    };\n\n    // 3. Create execution record in DB\n    const execution = createExecution(this.db, {\n      issue_id: issueId,\n      agent_type: 'claude-code',\n      status: 'running',\n    });\n\n    // 4. Start progress tracking\n    this.progressTracker.startTracking(execution.id, task);\n\n    try {\n      // 5. Execute via strategy\n      const result = await this.strategy.executeTask(task);\n\n      // 6. Update database\n      updateExecution(this.db, execution.id, {\n        status: result.success ? 'completed' : 'failed',\n        exit_code: result.success ? 0 : 1,\n        completed_at: Math.floor(Date.now() / 1000),\n        error_message: result.error,\n      });\n\n      // 7. Complete tracking\n      this.progressTracker.completeTracking(execution.id, result);\n\n      return result;\n    } catch (error) {\n      // Handle errors\n      const errorMessage = error instanceof Error ? error.message : 'Unknown error';\n\n      updateExecution(this.db, execution.id, {\n        status: 'failed',\n        completed_at: Math.floor(Date.now() / 1000),\n        error_message: errorMessage,\n      });\n\n      this.progressTracker.completeTracking(execution.id, {\n        ...result,\n        success: false,\n        error: errorMessage,\n      });\n\n      throw error;\n    }\n  }\n\n  ---\n  3. Simple Execution Strategy\n\n  Purpose: Execute tasks by spawning Claude Code processes on-demand\n\n  Inspired by:\n  - CodeMachine-CLI's step execution (references/CodeMachine-CLI/src/workflows/execution/step.ts)\n  - claude-flow's SimpleExecutionStrategy pattern\n\n  Interface:\n  class SimpleExecutionStrategy implements IExecutionStrategy {\n    constructor(\n      private processManager: IProcessManager,\n      private maxConcurrent: number = 3,\n      private defaultTimeout: number = 300_000 // 5 minutes\n    );\n\n    executeTask(task: ExecutionTask): Promise<ExecutionResult>;\n    executeTasks(tasks: ExecutionTask[]): Promise<ExecutionResult[]>;\n    getMetrics(): StrategyMetrics;\n    shutdown(): Promise<void>;\n  }\n\n  Key Implementation Details:\n\n  1. Process Spawning (from CodeMachine-CLI pattern):\n  private async runTask(\n    process: ManagedProcess,\n    task: ExecutionTask\n  ): Promise<ExecutionResult> {\n    const startTime = Date.now();\n\n    return new Promise((resolve, reject) => {\n      let outputBuffer = '';\n      let errorBuffer = '';\n\n      // Set up timeout\n      const timeout = setTimeout(() => {\n        process.process.kill('SIGTERM');\n        reject(new Error('Execution timed out'));\n      }, this.defaultTimeout);\n\n      // Parse stream-json output (from CodeMachine-CLI)\n      process.process.stdout?.on('data', (chunk: Buffer) => {\n        const text = chunk.toString();\n        outputBuffer += text;\n\n        // Parse JSON lines\n        const lines = text.split('\\n');\n        for (const line of lines) {\n          if (!line.trim()) continue;\n\n          try {\n            const json = JSON.parse(line);\n            this.handleStreamJsonLine(json, task);\n          } catch {\n            // Not JSON, treat as regular output\n          }\n        }\n      });\n\n      process.process.stderr?.on('data', (chunk: Buffer) => {\n        errorBuffer += chunk.toString();\n      });\n\n      process.process.on('exit', (code) => {\n        clearTimeout(timeout);\n\n        const duration = Date.now() - startTime;\n        const result: ExecutionResult = {\n          taskId: task.id,\n          executionId: process.id,\n          success: code === 0,\n          output: outputBuffer,\n          error: code !== 0 ? errorBuffer : undefined,\n          duration,\n          metadata: this.extractMetadata(outputBuffer),\n        };\n\n        resolve(result);\n      });\n\n      process.process.on('error', (error) => {\n        clearTimeout(timeout);\n        reject(error);\n      });\n    });\n  }\n\n  2. Stream JSON Parsing (from CodeMachine-CLI claude runner):\n  private handleStreamJsonLine(json: any, task: ExecutionTask): void {\n    // Parse different event types from Claude's stream-json format\n    if (json.type === 'assistant' && json.message?.content) {\n      for (const content of json.message.content) {\n        if (content.type === 'text') {\n          this.emitProgress(task.id, {\n            phase: 'executing',\n            message: content.text.substring(0, 200),\n          });\n        } else if (content.type === 'tool_use') {\n          this.emitProgress(task.id, {\n            phase: 'executing',\n            message: `Using tool: ${content.name}`,\n            metadata: { tool: content.name, args: content.input },\n          });\n        }\n      }\n    } else if (json.type === 'result') {\n      // Final result with usage stats\n      this.emitProgress(task.id, {\n        phase: 'finalizing',\n        message: 'Task completed',\n        metadata: {\n          duration: json.duration_ms,\n          tokensUsed: json.usage?.total_tokens,\n        },\n      });\n    }\n  }\n\n  3. Concurrency Control (simple batching):\n  async executeTasks(tasks: ExecutionTask[]): Promise<ExecutionResult[]> {\n    const results: ExecutionResult[] = [];\n\n    // Execute in batches\n    for (let i = 0; i < tasks.length; i += this.maxConcurrent) {\n      const batch = tasks.slice(i, i + this.maxConcurrent);\n      const batchResults = await Promise.all(\n        batch.map(task => this.executeTask(task))\n      );\n      results.push(...batchResults);\n    }\n\n    return results;\n  }\n\n  ---\n  4. Simple Process Manager\n\n  Purpose: Manage Claude Code CLI process lifecycle\n\n  Inspired by:\n  - claude-flow's process management (references/claude-flow/src/swarm/claude-code-interface.ts)\n  - Your existing ExecutionManager\n\n  Interface:\n  class SimpleProcessManager implements IProcessManager {\n    constructor(\n      private logsDir: string,\n      private claudePath: string = 'claude'\n    );\n\n    acquireProcess(task: ExecutionTask): Promise<ManagedProcess>;\n    releaseProcess(processId: string): Promise<void>;\n    terminateProcess(processId: string): Promise<void>;\n    getProcessMetrics(): ProcessMetrics;\n    shutdown(): Promise<void>;\n  }\n\n  Key Implementation:\n\n  1. Spawn Claude Code (from CodeMachine-CLI pattern):\n  private spawnClaudeProcess(task: ExecutionTask): ChildProcess {\n    const args = [\n      '--print',                          // Non-interactive mode\n      '--output-format', 'stream-json',   // Structured output\n      '--dangerously-skip-permissions',   // Skip permission prompts\n      '--permission-mode', 'bypassPermissions',\n    ];\n\n    const process = spawn(this.claudePath, args, {\n      cwd: task.context.workDir,\n      stdio: ['pipe', 'pipe', 'pipe'],\n      env: {\n        ...process.env,\n        // Add any custom environment variables\n      },\n    });\n\n    // Write prompt to stdin\n    process.stdin?.write(task.context.prompt);\n    process.stdin?.end();\n\n    return process;\n  }\n\n  2. Process Tracking:\n  async acquireProcess(task: ExecutionTask): Promise<ManagedProcess> {\n    const process = this.spawnClaudeProcess(task);\n\n    if (!process.pid) {\n      throw new Error('Failed to spawn Claude process');\n    }\n\n    const managed: ManagedProcess = {\n      id: generateId('process'),\n      process,\n      status: 'busy',\n      spawnedAt: new Date(),\n      lastActivity: new Date(),\n      tasksCompleted: 0,\n      metrics: {\n        totalDuration: 0,\n        successRate: 1.0,\n      },\n    };\n\n    this.activeProcesses.set(managed.id, managed);\n    return managed;\n  }\n\n  3. Graceful Termination:\n  async terminateProcess(processId: string): Promise<void> {\n    const managed = this.activeProcesses.get(processId);\n    if (!managed) return;\n\n    managed.status = 'terminating';\n\n    // Try SIGTERM first\n    managed.process.kill('SIGTERM');\n\n    // Wait for graceful shutdown\n    await new Promise(resolve => setTimeout(resolve, 2000));\n\n    // Force kill if needed\n    if (!managed.process.killed && managed.process.exitCode === null) {\n      managed.process.kill('SIGKILL');\n    }\n\n    this.activeProcesses.delete(processId);\n  }\n\n  ---\n  5. Progress Tracker\n\n  Purpose: Track and emit real-time progress updates\n\n  Inspired by: claude-flow's event emission patterns\n\n  Interface:\n  interface IProgressTracker {\n    startTracking(executionId: string, task: ExecutionTask): void;\n    updateProgress(executionId: string, update: ProgressUpdate): void;\n    completeTracking(executionId: string, result: ExecutionResult): void;\n    getProgress(executionId: string): ExecutionProgress | null;\n    onProgress(callback: (update: ProgressUpdate) => void): void;\n  }\n\n  interface ProgressUpdate {\n    executionId: string;\n    phase: 'initializing' | 'context_building' | 'executing' | 'finalizing';\n    message: string;\n    percentage?: number;\n    metadata?: {\n      tool?: string;\n      args?: any;\n      tokensUsed?: number;\n      filesChanged?: string[];\n    };\n  }\n\n  Implementation:\n  class WebSocketProgressTracker implements IProgressTracker {\n    private progressMap = new Map<string, ExecutionProgress>();\n    private callbacks: Array<(update: ProgressUpdate) => void> = [];\n\n    constructor(private wss: WebSocketService) {}\n\n    startTracking(executionId: string, task: ExecutionTask): void {\n      const progress: ExecutionProgress = {\n        executionId,\n        taskId: task.id,\n        status: 'running',\n        currentPhase: 'initializing',\n        startTime: new Date(),\n        lastUpdate: new Date(),\n      };\n\n      this.progressMap.set(executionId, progress);\n\n      // Emit initial update\n      this.emitUpdate({\n        executionId,\n        phase: 'initializing',\n        message: 'Starting execution...',\n        percentage: 0,\n      });\n    }\n\n    updateProgress(executionId: string, update: ProgressUpdate): void {\n      const progress = this.progressMap.get(executionId);\n      if (!progress) return;\n\n      progress.currentPhase = update.phase;\n      progress.lastUpdate = new Date();\n\n      this.emitUpdate(update);\n    }\n\n    completeTracking(executionId: string, result: ExecutionResult): void {\n      const progress = this.progressMap.get(executionId);\n      if (!progress) return;\n\n      progress.status = result.success ? 'completed' : 'failed';\n\n      this.emitUpdate({\n        executionId,\n        phase: 'finalizing',\n        message: result.success ? 'Execution completed successfully' : `Execution failed: ${result.error}`,\n        percentage: 100,\n        metadata: result.metadata,\n      });\n\n      // Clean up after a delay\n      setTimeout(() => {\n        this.progressMap.delete(executionId);\n      }, 60_000); // Keep for 1 minute\n    }\n\n    private emitUpdate(update: ProgressUpdate): void {\n      // Emit to WebSocket clients\n      this.wss.broadcast('execution:progress', update);\n\n      // Emit to registered callbacks\n      for (const callback of this.callbacks) {\n        callback(update);\n      }\n    }\n\n    onProgress(callback: (update: ProgressUpdate) => void): void {\n      this.callbacks.push(callback);\n    }\n  }\n\n  ---\n  Integration with Existing Code\n\n  1. Update ExecutionManager\n\n  // server/src/execution/manager.ts\n  export class ExecutionManager {\n    private orchestrator: ExecutionOrchestrator;\n\n    constructor(\n      db: Database.Database,\n      wss: WebSocketService,\n      logsDir?: string\n    ) {\n      // Initialize components\n      const contextBuilder = new DefaultContextBuilder(db);\n      const progressTracker = new WebSocketProgressTracker(wss);\n      const processManager = new SimpleProcessManager(logsDir || path.join(os.tmpdir(),\n  'sudocode-executions'));\n      const strategy = new SimpleExecutionStrategy(processManager, 3);\n\n      // Create orchestrator\n      this.orchestrator = new ExecutionOrchestrator(\n        strategy,\n        contextBuilder,\n        progressTracker,\n        db\n      );\n    }\n\n    // Delegate to orchestrator\n    async startExecution(input: StartExecutionInput): Promise<Execution> {\n      return this.orchestrator.executeIssue(input.issue_id, {\n        workDir: input.work_dir,\n        customPrompt: input.prompt,\n      });\n    }\n\n    async stopExecution(executionId: string): Promise<void> {\n      return this.orchestrator.stopExecution(executionId);\n    }\n\n    getExecutionStatus(executionId: string): ExecutionProgress | null {\n      return this.orchestrator.getExecutionStatus(executionId);\n    }\n  }\n\n  2. Add API Endpoints\n\n  // server/src/routes/executions.ts\n  router.post('/executions', async (req, res) => {\n    const { issue_id, work_dir, prompt } = req.body;\n\n    try {\n      const result = await executionManager.startExecution({\n        issue_id,\n        agent_type: 'claude-code',\n        work_dir,\n        prompt,\n      });\n\n      res.json(result);\n    } catch (error) {\n      res.status(500).json({ error: error.message });\n    }\n  });\n\n  router.get('/executions/:id/status', async (req, res) => {\n    const status = executionManager.getExecutionStatus(req.params.id);\n\n    if (!status) {\n      return res.status(404).json({ error: 'Execution not found' });\n    }\n\n    res.json(status);\n  });\n\n  router.post('/executions/:id/stop', async (req, res) => {\n    await executionManager.stopExecution(req.params.id);\n    res.json({ success: true });\n  });\n\n  3. WebSocket Integration\n\n  // server/src/services/websocket.ts\n  export class WebSocketService {\n    broadcast(event: string, data: any): void {\n      this.wss.clients.forEach(client => {\n        if (client.readyState === WebSocket.OPEN) {\n          client.send(JSON.stringify({ event, data }));\n        }\n      });\n    }\n  }\n\n  // Frontend can subscribe to execution progress\n  socket.on('execution:progress', (update: ProgressUpdate) => {\n    console.log(`[${update.executionId}] ${update.phase}: ${update.message}`);\n    // Update UI with progress\n  });\n\n  ---\n  File Structure\n\n  server/src/execution/\n  ├── manager.ts                    # Existing ExecutionManager (updated)\n  ├── spawn-claude-code.ts         # Existing spawn utility\n  ├── orchestrator.ts              # NEW: ExecutionOrchestrator\n  ├── strategies/\n  │   ├── base.ts                  # IExecutionStrategy interface\n  │   ├── simple-strategy.ts       # SimpleExecutionStrategy\n  │   └── pool-strategy.ts         # (Future) PoolExecutionStrategy\n  ├── process-managers/\n  │   ├── base.ts                  # IProcessManager interface\n  │   ├── simple-manager.ts        # SimpleProcessManager\n  │   └── pool-manager.ts          # (Future) PoolProcessManager\n  ├── context/\n  │   ├── builder.ts               # IContextBuilder interface\n  │   ├── default-builder.ts       # DefaultContextBuilder\n  │   └── templates.ts             # Prompt templates\n  ├── progress/\n  │   ├── tracker.ts               # IProgressTracker interface\n  │   └── websocket-tracker.ts    # WebSocketProgressTracker\n  └── types.ts                     # Shared types and interfaces\n\n  ---\n  Implementation Phases\n\n  Phase 1: Core Infrastructure (Week 1)\n  - Define all interfaces in types.ts\n  - Implement DefaultContextBuilder\n  - Implement SimpleProcessManager\n  - Implement SimpleExecutionStrategy\n  - Write unit tests for each component\n\n  Phase 2: Orchestration (Week 2)\n  - Implement ExecutionOrchestrator\n  - Integrate with existing ExecutionManager\n  - Add API endpoints for execution control\n  - Write integration tests\n\n  Phase 3: Progress Tracking (Week 3)\n  - Implement WebSocketProgressTracker\n  - Add WebSocket event handling\n  - Update frontend to display progress\n  - Test end-to-end flow\n\n  Phase 4: Polish & Documentation (Week 4)\n  - Add error handling and recovery\n  - Write comprehensive documentation\n  - Create example usage guides\n  - Performance testing and optimization\n","priority":0,"archived":1,"archived_at":"2025-10-28T08:31:01.555Z","created_at":"2025-10-27 18:30:25","updated_at":"2025-11-03T03:10:12.596Z","parent_id":null,"parent_uuid":null,"relationships":[],"tags":[]}
{"id":"SPEC-003","uuid":"48dd725d-675a-4038-83d2-b5f5e41dd75a","title":"Process Layer - Claude Code Process Management","file_path":"specs/process_layer_claude_code_process_management.md","content":"# Process Layer Specification\n\n## Overview\n\nThe Process Layer (Layer 1) manages the lifecycle of individual Claude Code CLI processes. This is the foundation of the execution system, inspired by claude-flow's simple yet flexible approach.\n\n## Design Goals\n\n1. **Simple First**: Start with basic process spawning using Node.js child_process\n2. **Event-Driven**: Use native event emitters for real-time I/O streaming\n3. **Flexible**: Easy to upgrade from simple spawning to process pooling\n4. **Reliable**: Handle timeouts, crashes, and cleanup gracefully\n5. **Observable**: Expose all process events for upper layers\n\n## Architecture\n\nBased on Execution System spec, this implements the process spawning and management foundation.\n\n```\n┌─────────────────────────────────────────┐\n│        Process Layer (Layer 1)          │\n├─────────────────────────────────────────┤\n│                                         │\n│  ┌──────────────────────────────────┐  │\n│  │   IProcessManager (Interface)    │  │\n│  └────────────┬─────────────────────┘  │\n│               │                         │\n│               ├──────────────────────┐  │\n│               │                      │  │\n│     ┌─────────▼────────┐   ┌────────▼──────────┐\n│     │ SimpleProcess    │   │  PoolProcess      │\n│     │    Manager       │   │   Manager         │\n│     │  (Start Here)    │   │  (Future)         │\n│     └──────────────────┘   └───────────────────┘\n│                                         │\n└─────────────────────────────────────────┘\n```\n\n## Core Types\n\n### ManagedProcess\nRepresents a single Claude Code process instance with its lifecycle state.\n\n```typescript\ninterface ManagedProcess {\n  // Identity\n  id: string;                    // Unique process ID\n  pid: number;                   // OS process ID\n  \n  // Lifecycle\n  status: ProcessStatus;\n  spawnedAt: Date;\n  lastActivity: Date;\n  exitCode: number | null;\n  signal: string | null;\n  \n  // Resources\n  process: ChildProcess;         // Node.js child process handle\n  streams: {\n    stdout: Readable;\n    stderr: Readable;\n    stdin: Writable;\n  };\n  \n  // Metrics\n  metrics: {\n    totalDuration: number;       // milliseconds\n    tasksCompleted: number;\n    successRate: number;\n  };\n}\n\ntype ProcessStatus = \n  | 'spawning'     // Being created\n  | 'idle'         // Ready for work (pool only)\n  | 'busy'         // Executing task\n  | 'terminating'  // Shutting down\n  | 'crashed'      // Exited unexpectedly\n  | 'completed';   // Exited normally\n```\n\n### ProcessConfig\nConfiguration for spawning Claude Code processes.\n\n```typescript\ninterface ProcessConfig {\n  // Claude Code CLI path\n  claudePath: string;            // Default: 'claude'\n  \n  // Working directory\n  workDir: string;\n  \n  // Claude Code CLI arguments\n  args: {\n    print: boolean;              // --print (non-interactive)\n    outputFormat: 'stream-json' | 'json' | 'text';\n    dangerouslySkipPermissions: boolean;\n    permissionMode?: string;\n  };\n  \n  // Environment variables\n  env?: Record<string, string>;\n  \n  // Timeouts\n  timeout?: number;              // Max execution time (ms)\n  idleTimeout?: number;          // Max idle time before cleanup (pool only)\n  \n  // Retry configuration\n  retry?: {\n    maxAttempts: number;\n    backoffMs: number;\n  };\n}\n```\n\n## IProcessManager Interface\n\nThe core abstraction that all process managers implement.\n\n```typescript\ninterface IProcessManager {\n  // Process lifecycle\n  acquireProcess(config: ProcessConfig): Promise<ManagedProcess>;\n  releaseProcess(processId: string): Promise<void>;\n  terminateProcess(processId: string, signal?: NodeJS.Signals): Promise<void>;\n  \n  // Process communication\n  sendInput(processId: string, input: string): Promise<void>;\n  onOutput(processId: string, handler: OutputHandler): void;\n  onError(processId: string, handler: ErrorHandler): void;\n  \n  // Monitoring\n  getProcess(processId: string): ManagedProcess | null;\n  getActiveProcesses(): ManagedProcess[];\n  getMetrics(): ProcessMetrics;\n  \n  // Cleanup\n  shutdown(): Promise<void>;\n}\n\ntype OutputHandler = (data: Buffer, type: 'stdout' | 'stderr') => void;\ntype ErrorHandler = (error: Error) => void;\n\ninterface ProcessMetrics {\n  totalSpawned: number;\n  currentlyActive: number;\n  totalCompleted: number;\n  totalFailed: number;\n  averageDuration: number;\n}\n```\n\n## SimpleProcessManager Implementation\n\nStart with this simple, production-ready implementation based on claude-flow's pattern.\n\n### Key Features\n\n1. **One Process Per Task**: Spawn fresh process for each task\n2. **Event-Based I/O**: Stream stdout/stderr in real-time\n3. **Graceful Termination**: SIGTERM → wait → SIGKILL if needed\n4. **Automatic Cleanup**: Remove completed processes from tracking\n5. **Error Handling**: Capture spawn errors, exit codes, crashes\n\n### Implementation Pattern\n\n```typescript\nclass SimpleProcessManager implements IProcessManager {\n  private activeProcesses = new Map<string, ManagedProcess>();\n  private metrics: ProcessMetrics = {\n    totalSpawned: 0,\n    currentlyActive: 0,\n    totalCompleted: 0,\n    totalFailed: 0,\n    averageDuration: 0,\n  };\n\n  constructor(\n    private defaultConfig: Partial<ProcessConfig> = {}\n  ) {}\n\n  async acquireProcess(config: ProcessConfig): Promise<ManagedProcess> {\n    const mergedConfig = { ...this.defaultConfig, ...config };\n    const process = await this.spawnClaudeProcess(mergedConfig);\n    \n    if (!process.pid) {\n      throw new Error('Failed to spawn Claude Code process');\n    }\n\n    const managed: ManagedProcess = {\n      id: generateId('process'),\n      pid: process.pid,\n      status: 'busy',\n      spawnedAt: new Date(),\n      lastActivity: new Date(),\n      exitCode: null,\n      signal: null,\n      process,\n      streams: {\n        stdout: process.stdout!,\n        stderr: process.stderr!,\n        stdin: process.stdin!,\n      },\n      metrics: {\n        totalDuration: 0,\n        tasksCompleted: 0,\n        successRate: 1.0,\n      },\n    };\n\n    this.setupProcessHandlers(managed, config);\n    this.activeProcesses.set(managed.id, managed);\n    this.metrics.totalSpawned++;\n    this.metrics.currentlyActive++;\n\n    return managed;\n  }\n\n  private async spawnClaudeProcess(config: ProcessConfig): Promise<ChildProcess> {\n    const args = this.buildClaudeArgs(config);\n\n    const process = spawn(config.claudePath, args, {\n      cwd: config.workDir,\n      stdio: ['pipe', 'pipe', 'pipe'],\n      env: {\n        ...process.env,\n        ...config.env,\n      },\n    });\n\n    return process;\n  }\n\n  private buildClaudeArgs(config: ProcessConfig): string[] {\n    const args: string[] = [];\n\n    if (config.args.print) {\n      args.push('--print');\n    }\n\n    if (config.args.outputFormat) {\n      args.push('--output-format', config.args.outputFormat);\n    }\n\n    if (config.args.dangerouslySkipPermissions) {\n      args.push('--dangerously-skip-permissions');\n    }\n\n    if (config.args.permissionMode) {\n      args.push('--permission-mode', config.args.permissionMode);\n    }\n\n    return args;\n  }\n\n  private setupProcessHandlers(managed: ManagedProcess, config: ProcessConfig): void {\n    const { process } = managed;\n    let timeoutHandle: NodeJS.Timeout | null = null;\n\n    // Set timeout if configured\n    if (config.timeout) {\n      timeoutHandle = setTimeout(() => {\n        this.terminateProcess(managed.id, 'SIGTERM');\n      }, config.timeout);\n    }\n\n    // Handle exit\n    process.on('exit', (code, signal) => {\n      if (timeoutHandle) clearTimeout(timeoutHandle);\n\n      managed.exitCode = code;\n      managed.signal = signal;\n      managed.status = code === 0 ? 'completed' : 'crashed';\n\n      const duration = Date.now() - managed.spawnedAt.getTime();\n      managed.metrics.totalDuration = duration;\n\n      // Update global metrics\n      this.metrics.currentlyActive--;\n      if (code === 0) {\n        this.metrics.totalCompleted++;\n      } else {\n        this.metrics.totalFailed++;\n      }\n\n      // Clean up after delay\n      setTimeout(() => {\n        this.activeProcesses.delete(managed.id);\n      }, 5000);\n    });\n\n    // Handle spawn errors\n    process.on('error', (error) => {\n      if (timeoutHandle) clearTimeout(timeoutHandle);\n      \n      managed.status = 'crashed';\n      this.metrics.currentlyActive--;\n      this.metrics.totalFailed++;\n    });\n\n    // Update activity on I/O\n    process.stdout?.on('data', () => {\n      managed.lastActivity = new Date();\n    });\n  }\n\n  async sendInput(processId: string, input: string): Promise<void> {\n    const managed = this.activeProcesses.get(processId);\n    if (!managed) {\n      throw new Error(`Process ${processId} not found`);\n    }\n\n    return new Promise((resolve, reject) => {\n      managed.streams.stdin.write(input, (error) => {\n        if (error) reject(error);\n        else resolve();\n      });\n    });\n  }\n\n  onOutput(processId: string, handler: OutputHandler): void {\n    const managed = this.activeProcesses.get(processId);\n    if (!managed) return;\n\n    managed.streams.stdout.on('data', (data: Buffer) => {\n      handler(data, 'stdout');\n    });\n\n    managed.streams.stderr.on('data', (data: Buffer) => {\n      handler(data, 'stderr');\n    });\n  }\n\n  async terminateProcess(\n    processId: string, \n    signal: NodeJS.Signals = 'SIGTERM'\n  ): Promise<void> {\n    const managed = this.activeProcesses.get(processId);\n    if (!managed) return;\n\n    managed.status = 'terminating';\n\n    // Try graceful shutdown first\n    managed.process.kill(signal);\n\n    // Wait for graceful shutdown\n    await new Promise(resolve => setTimeout(resolve, 2000));\n\n    // Force kill if still running\n    if (!managed.process.killed && managed.exitCode === null) {\n      managed.process.kill('SIGKILL');\n    }\n  }\n\n  async releaseProcess(processId: string): Promise<void> {\n    await this.terminateProcess(processId);\n  }\n\n  getProcess(processId: string): ManagedProcess | null {\n    return this.activeProcesses.get(processId) || null;\n  }\n\n  getActiveProcesses(): ManagedProcess[] {\n    return Array.from(this.activeProcesses.values());\n  }\n\n  getMetrics(): ProcessMetrics {\n    return { ...this.metrics };\n  }\n\n  async shutdown(): Promise<void> {\n    const processes = Array.from(this.activeProcesses.keys());\n    await Promise.all(\n      processes.map(id => this.terminateProcess(id, 'SIGTERM'))\n    );\n  }\n}\n```\n\n## Usage Example\n\n```typescript\n// Initialize manager\nconst processManager = new SimpleProcessManager({\n  claudePath: 'claude',\n  args: {\n    print: true,\n    outputFormat: 'stream-json',\n    dangerouslySkipPermissions: true,\n  },\n});\n\n// Spawn process\nconst process = await processManager.acquireProcess({\n  claudePath: 'claude',\n  workDir: '/path/to/project',\n  args: {\n    print: true,\n    outputFormat: 'stream-json',\n    dangerouslySkipPermissions: true,\n  },\n  timeout: 300000, // 5 minutes\n});\n\n// Send input\nawait processManager.sendInput(process.id, 'Fix the bug in auth.ts\\n');\n\n// Listen to output\nprocessManager.onOutput(process.id, (data, type) => {\n  console.log(`[${type}]`, data.toString());\n});\n\n// Clean up\nawait processManager.releaseProcess(process.id);\n```\n\n## Testing Strategy\n\n### Unit Tests\n\n1. **Process spawning**\n   - Spawns with correct arguments\n   - Sets working directory\n   - Passes environment variables\n\n2. **Lifecycle management**\n   - Tracks process status correctly\n   - Updates metrics on exit\n   - Cleans up resources\n\n3. **I/O handling**\n   - Sends input to stdin\n   - Receives stdout/stderr\n   - Handles stream errors\n\n4. **Termination**\n   - Graceful shutdown (SIGTERM)\n   - Force kill after timeout\n   - Cleans up after termination\n\n### Integration Tests\n\n1. **End-to-end execution**\n   - Spawn → send prompt → receive output → terminate\n   - Multiple concurrent processes\n   - Process crash recovery\n\n2. **Error scenarios**\n   - Invalid claude path\n   - Process spawn failure\n   - Timeout handling\n\n## Future Enhancements\n\n### Path to Pool-Based Strategy\n\nThe interface design makes it easy to add pooling later:\n\n```typescript\nclass PoolProcessManager implements IProcessManager {\n  private pool: ManagedProcess[] = [];\n  private maxPoolSize: number;\n  private minIdleProcesses: number;\n\n  async acquireProcess(config: ProcessConfig): Promise<ManagedProcess> {\n    // Try to get idle process from pool\n    const idle = this.pool.find(p => p.status === 'idle');\n    \n    if (idle) {\n      idle.status = 'busy';\n      return idle;\n    }\n\n    // Create new if under limit\n    if (this.pool.length < this.maxPoolSize) {\n      return this.createAndAddToPool(config);\n    }\n\n    // Wait for available process\n    return this.waitForAvailableProcess(config);\n  }\n\n  async releaseProcess(processId: string): Promise<void> {\n    const process = this.pool.find(p => p.id === processId);\n    if (process) {\n      process.status = 'idle';\n      process.metrics.tasksCompleted++;\n    }\n  }\n\n  // ... pool management logic\n}\n```\n\n### Other Future Features\n\n1. **Process health checks** - Ping processes periodically\n2. **Automatic restarts** - Restart crashed processes in pool\n3. **Resource limits** - Memory/CPU monitoring\n4. **Process affinity** - Pin processes to specific tasks/users\n\n## File Structure\n\n```\nserver/src/execution/process/\n├── types.ts                    # Core types and interfaces\n├── manager.ts                  # IProcessManager interface\n├── simple-manager.ts           # SimpleProcessManager (start here)\n├── pool-manager.ts             # PoolProcessManager (future)\n└── utils.ts                    # Helper functions\n```\n\n## Implementation Checklist\n\n- [ ] Define core types in types.ts\n- [ ] Define IProcessManager interface\n- [ ] Implement SimpleProcessManager\n- [ ] Add process spawning with child_process\n- [ ] Add event handlers for exit, error, I/O\n- [ ] Add graceful termination (SIGTERM → SIGKILL)\n- [ ] Add metrics tracking\n- [ ] Write unit tests for process lifecycle\n- [ ] Write integration tests for end-to-end flow\n- [ ] Document usage examples\n\n## Related Specs\n\n- Execution System (parent spec)\n- Next: Engine Layer (Layer 2) - Multi-agent task execution\n","priority":0,"archived":1,"archived_at":"2025-11-05T05:38:42.773Z","created_at":"2025-10-28 07:34:44","updated_at":"2025-11-05 05:38:42","parent_id":null,"parent_uuid":null,"relationships":[],"tags":["execution","infrastructure","layer-1","process-management"]}
{"id":"SPEC-004","uuid":"7c8ba15b-95d6-40e1-bf1f-e4305e5ddd80","title":"Engine Layer - Multi-Agent Task Execution","file_path":"specs/engine_layer_multi_agent_task_execution.md","content":"# Engine Layer Specification\n\n## Overview\n\nThe Engine Layer (Layer 2) manages multiple Claude Code agents to execute tasks concurrently. It sits above the Process Layer and provides task queueing, capacity management, and result collection.\n\n## Design Goals\n\n1. **Simple First**: Start with queue-based task distribution\n2. **Capacity Control**: Prevent resource exhaustion with configurable limits\n3. **Fair Scheduling**: FIFO queue with optional priority support\n4. **Observable**: Expose task progress and engine metrics\n5. **Upgradeable**: Easy path to intelligent agent pooling\n\n## Architecture\n\nBased on Execution System spec and [[SPEC-003]] (Process Layer).\n\n```\n┌─────────────────────────────────────────────────┐\n│         Engine Layer (Layer 2)                  │\n├─────────────────────────────────────────────────┤\n│                                                 │\n│  ┌──────────────────────────────────────────┐  │\n│  │      IExecutionEngine (Interface)        │  │\n│  └────────────┬─────────────────────────────┘  │\n│               │                                 │\n│               ├──────────────────────────────┐  │\n│               │                              │  │\n│     ┌─────────▼────────┐         ┌──────────▼─────────┐\n│     │  SimpleEngine    │         │   PoolEngine       │\n│     │  (Start Here)    │         │   (Future)         │\n│     └────────┬─────────┘         └────────────────────┘\n│              │                                  │\n│              ▼                                  │\n│     ┌─────────────────┐                        │\n│     │   Task Queue    │                        │\n│     │   (FIFO/Prio)   │                        │\n│     └────────┬────────┘                        │\n│              │                                  │\n│              ▼                                  │\n│     ┌─────────────────┐                        │\n│     │ Process Manager │◄───────────────────────┘\n│     │  (Layer 1)      │                        │\n│     └─────────────────┘                        │\n│                                                 │\n└─────────────────────────────────────────────────┘\n```\n\n## Core Types\n\n### ExecutionTask\nRepresents a unit of work to be executed by a Claude Code agent.\n\n```typescript\ninterface ExecutionTask {\n  // Identity\n  id: string;\n  type: 'issue' | 'spec' | 'custom';\n  entityId?: string;              // Issue/spec ID if applicable\n  \n  // Execution context\n  prompt: string;                 // What to send to Claude\n  workDir: string;                // Where to execute\n  \n  // Scheduling\n  priority: number;               // 0 = highest\n  dependencies: string[];         // Task IDs that must complete first\n  createdAt: Date;\n  \n  // Configuration\n  config: {\n    timeout?: number;             // Max duration (ms)\n    maxRetries?: number;          // Retry attempts\n    env?: Record<string, string>; // Environment variables\n  };\n  \n  // Metadata\n  metadata?: Record<string, any>; // Custom data\n}\n```\n\n### ExecutionResult\nThe outcome of executing a task.\n\n```typescript\ninterface ExecutionResult {\n  // Identity\n  taskId: string;\n  executionId: string;            // Process ID that ran it\n  \n  // Outcome\n  success: boolean;\n  exitCode: number;\n  \n  // Output\n  output: string;                 // stdout\n  error?: string;                 // stderr or error message\n  \n  // Timing\n  startedAt: Date;\n  completedAt: Date;\n  duration: number;               // milliseconds\n  \n  // Parsed data (from stream-json)\n  metadata?: {\n    toolsUsed?: string[];\n    filesChanged?: string[];\n    tokensUsed?: number;\n    cost?: number;\n  };\n}\n```\n\n### EngineMetrics\nReal-time engine performance statistics.\n\n```typescript\ninterface EngineMetrics {\n  // Capacity\n  maxConcurrent: number;\n  currentlyRunning: number;\n  availableSlots: number;\n  \n  // Queue\n  queuedTasks: number;\n  completedTasks: number;\n  failedTasks: number;\n  \n  // Performance\n  averageDuration: number;        // ms\n  successRate: number;            // 0-1\n  throughput: number;             // tasks/minute\n  \n  // Resources\n  totalProcessesSpawned: number;\n  activeProcesses: number;\n}\n```\n\n## IExecutionEngine Interface\n\nThe core abstraction for task execution engines.\n\n```typescript\ninterface IExecutionEngine {\n  // Task submission\n  submitTask(task: ExecutionTask): Promise<string>; // Returns task ID\n  submitTasks(tasks: ExecutionTask[]): Promise<string[]>;\n  \n  // Task control\n  cancelTask(taskId: string): Promise<void>;\n  getTaskStatus(taskId: string): TaskStatus | null;\n  \n  // Execution\n  waitForTask(taskId: string): Promise<ExecutionResult>;\n  waitForTasks(taskIds: string[]): Promise<ExecutionResult[]>;\n  \n  // Monitoring\n  getMetrics(): EngineMetrics;\n  onTaskComplete(handler: TaskCompleteHandler): void;\n  onTaskFailed(handler: TaskFailedHandler): void;\n  \n  // Lifecycle\n  shutdown(): Promise<void>;\n}\n\ntype TaskStatus = \n  | { state: 'queued'; position: number }\n  | { state: 'running'; processId: string; startedAt: Date }\n  | { state: 'completed'; result: ExecutionResult }\n  | { state: 'failed'; error: string }\n  | { state: 'cancelled'; cancelledAt: Date };\n\ntype TaskCompleteHandler = (result: ExecutionResult) => void;\ntype TaskFailedHandler = (taskId: string, error: Error) => void;\n```\n\n## SimpleExecutionEngine Implementation\n\nQueue-based engine that spawns a process per task, with concurrency limits.\n\n### Key Features\n\n1. **FIFO Queue**: Tasks execute in submission order\n2. **Concurrency Limit**: Max N simultaneous processes\n3. **Automatic Retry**: Optional retry on failure\n4. **Event Emission**: Notify on task completion/failure\n5. **Graceful Shutdown**: Wait for running tasks or force terminate\n\n### Implementation Pattern\n\n```typescript\nclass SimpleExecutionEngine implements IExecutionEngine {\n  private taskQueue: ExecutionTask[] = [];\n  private runningTasks = new Map<string, RunningTask>();\n  private completedResults = new Map<string, ExecutionResult>();\n  private taskResolvers = new Map<string, TaskResolver>();\n  \n  private metrics: EngineMetrics;\n  private completeHandlers: TaskCompleteHandler[] = [];\n  private failedHandlers: TaskFailedHandler[] = [];\n  \n  constructor(\n    private processManager: IProcessManager,\n    private config: EngineConfig = {}\n  ) {\n    this.metrics = {\n      maxConcurrent: config.maxConcurrent || 3,\n      currentlyRunning: 0,\n      availableSlots: config.maxConcurrent || 3,\n      queuedTasks: 0,\n      completedTasks: 0,\n      failedTasks: 0,\n      averageDuration: 0,\n      successRate: 1.0,\n      throughput: 0,\n      totalProcessesSpawned: 0,\n      activeProcesses: 0,\n    };\n  }\n\n  async submitTask(task: ExecutionTask): Promise<string> {\n    // Add to queue\n    this.taskQueue.push(task);\n    this.metrics.queuedTasks++;\n    \n    // Try to start immediately if capacity available\n    this.processQueue();\n    \n    return task.id;\n  }\n\n  async submitTasks(tasks: ExecutionTask[]): Promise<string[]> {\n    const ids: string[] = [];\n    for (const task of tasks) {\n      const id = await this.submitTask(task);\n      ids.push(id);\n    }\n    return ids;\n  }\n\n  private async processQueue(): Promise<void> {\n    // Check if we have capacity\n    while (\n      this.taskQueue.length > 0 &&\n      this.runningTasks.size < this.metrics.maxConcurrent\n    ) {\n      const task = this.taskQueue.shift()!;\n      this.metrics.queuedTasks--;\n      \n      // Check dependencies\n      if (!this.areDependenciesMet(task)) {\n        // Re-queue at end\n        this.taskQueue.push(task);\n        this.metrics.queuedTasks++;\n        break; // Stop processing to avoid infinite loop\n      }\n      \n      // Start execution\n      this.executeTask(task).catch(error => {\n        this.handleTaskFailure(task.id, error);\n      });\n    }\n  }\n\n  private areDependenciesMet(task: ExecutionTask): boolean {\n    for (const depId of task.dependencies) {\n      const result = this.completedResults.get(depId);\n      if (!result || !result.success) {\n        return false;\n      }\n    }\n    return true;\n  }\n\n  private async executeTask(task: ExecutionTask): Promise<void> {\n    const startTime = Date.now();\n    \n    try {\n      // Acquire process\n      const process = await this.processManager.acquireProcess({\n        claudePath: this.config.claudePath || 'claude',\n        workDir: task.workDir,\n        args: {\n          print: true,\n          outputFormat: 'stream-json',\n          dangerouslySkipPermissions: true,\n          permissionMode: 'bypassPermissions',\n        },\n        env: task.config.env,\n        timeout: task.config.timeout,\n      });\n\n      this.metrics.totalProcessesSpawned++;\n      this.metrics.currentlyRunning++;\n      this.metrics.activeProcesses++;\n      this.metrics.availableSlots--;\n\n      // Track running task\n      const running: RunningTask = {\n        task,\n        process,\n        startedAt: new Date(),\n        attempt: 1,\n      };\n      this.runningTasks.set(task.id, running);\n\n      // Send prompt\n      await this.processManager.sendInput(process.id, task.prompt);\n      \n      // Collect output\n      let outputBuffer = '';\n      let errorBuffer = '';\n      \n      this.processManager.onOutput(process.id, (data, type) => {\n        if (type === 'stdout') {\n          outputBuffer += data.toString();\n        } else {\n          errorBuffer += data.toString();\n        }\n      });\n\n      // Wait for completion\n      await this.waitForProcessExit(process);\n\n      const duration = Date.now() - startTime;\n      \n      // Build result\n      const result: ExecutionResult = {\n        taskId: task.id,\n        executionId: process.id,\n        success: process.exitCode === 0,\n        exitCode: process.exitCode || 0,\n        output: outputBuffer,\n        error: process.exitCode !== 0 ? errorBuffer : undefined,\n        startedAt: running.startedAt,\n        completedAt: new Date(),\n        duration,\n        metadata: this.parseMetadata(outputBuffer),\n      };\n\n      // Handle result\n      if (result.success) {\n        this.handleTaskSuccess(task.id, result);\n      } else {\n        // Retry if configured\n        if (\n          task.config.maxRetries &&\n          running.attempt < task.config.maxRetries\n        ) {\n          running.attempt++;\n          this.taskQueue.unshift(task); // Priority re-queue\n          this.metrics.queuedTasks++;\n        } else {\n          this.handleTaskFailure(\n            task.id,\n            new Error(result.error || 'Task failed')\n          );\n        }\n      }\n\n      // Clean up\n      this.runningTasks.delete(task.id);\n      await this.processManager.releaseProcess(process.id);\n      \n      this.metrics.currentlyRunning--;\n      this.metrics.activeProcesses--;\n      this.metrics.availableSlots++;\n\n      // Process next queued task\n      this.processQueue();\n      \n    } catch (error) {\n      this.metrics.currentlyRunning--;\n      this.metrics.activeProcesses--;\n      this.metrics.availableSlots++;\n      this.runningTasks.delete(task.id);\n      \n      throw error;\n    }\n  }\n\n  private async waitForProcessExit(process: ManagedProcess): Promise<void> {\n    return new Promise((resolve) => {\n      const checkInterval = setInterval(() => {\n        if (\n          process.status === 'completed' ||\n          process.status === 'crashed' ||\n          process.status === 'terminated'\n        ) {\n          clearInterval(checkInterval);\n          resolve();\n        }\n      }, 100);\n    });\n  }\n\n  private parseMetadata(output: string): ExecutionResult['metadata'] {\n    // Parse stream-json output for metadata\n    const metadata: ExecutionResult['metadata'] = {\n      toolsUsed: [],\n      filesChanged: [],\n      tokensUsed: 0,\n      cost: 0,\n    };\n\n    const lines = output.split('\\n');\n    for (const line of lines) {\n      if (!line.trim()) continue;\n      \n      try {\n        const json = JSON.parse(line);\n        \n        // Extract tool usage\n        if (json.type === 'assistant' && json.message?.content) {\n          for (const content of json.message.content) {\n            if (content.type === 'tool_use') {\n              metadata.toolsUsed?.push(content.name);\n              \n              // Track file changes\n              if (\n                content.name === 'Write' ||\n                content.name === 'Edit'\n              ) {\n                metadata.filesChanged?.push(content.input.file_path);\n              }\n            }\n          }\n        }\n        \n        // Extract usage stats\n        if (json.type === 'result' && json.usage) {\n          metadata.tokensUsed = json.usage.total_tokens || 0;\n        }\n      } catch {\n        // Not JSON, skip\n      }\n    }\n\n    return metadata;\n  }\n\n  private handleTaskSuccess(taskId: string, result: ExecutionResult): void {\n    this.completedResults.set(taskId, result);\n    this.metrics.completedTasks++;\n    \n    // Update averages\n    this.updateMetrics(result.duration, true);\n    \n    // Resolve promise\n    const resolver = this.taskResolvers.get(taskId);\n    if (resolver) {\n      resolver.resolve(result);\n      this.taskResolvers.delete(taskId);\n    }\n    \n    // Emit event\n    for (const handler of this.completeHandlers) {\n      handler(result);\n    }\n  }\n\n  private handleTaskFailure(taskId: string, error: Error): void {\n    this.metrics.failedTasks++;\n    this.updateMetrics(0, false);\n    \n    // Resolve promise with error\n    const resolver = this.taskResolvers.get(taskId);\n    if (resolver) {\n      resolver.reject(error);\n      this.taskResolvers.delete(taskId);\n    }\n    \n    // Emit event\n    for (const handler of this.failedHandlers) {\n      handler(taskId, error);\n    }\n  }\n\n  private updateMetrics(duration: number, success: boolean): void {\n    const total = this.metrics.completedTasks + this.metrics.failedTasks;\n    \n    // Update average duration\n    this.metrics.averageDuration = \n      (this.metrics.averageDuration * (total - 1) + duration) / total;\n    \n    // Update success rate\n    this.metrics.successRate = this.metrics.completedTasks / total;\n  }\n\n  async waitForTask(taskId: string): Promise<ExecutionResult> {\n    // Check if already completed\n    const existing = this.completedResults.get(taskId);\n    if (existing) return existing;\n    \n    // Wait for completion\n    return new Promise((resolve, reject) => {\n      this.taskResolvers.set(taskId, { resolve, reject });\n    });\n  }\n\n  async waitForTasks(taskIds: string[]): Promise<ExecutionResult[]> {\n    return Promise.all(taskIds.map(id => this.waitForTask(id)));\n  }\n\n  async cancelTask(taskId: string): Promise<void> {\n    // Remove from queue\n    const queueIndex = this.taskQueue.findIndex(t => t.id === taskId);\n    if (queueIndex >= 0) {\n      this.taskQueue.splice(queueIndex, 1);\n      this.metrics.queuedTasks--;\n      return;\n    }\n    \n    // Stop running task\n    const running = this.runningTasks.get(taskId);\n    if (running) {\n      await this.processManager.terminateProcess(running.process.id);\n      this.runningTasks.delete(taskId);\n      this.metrics.currentlyRunning--;\n    }\n  }\n\n  getTaskStatus(taskId: string): TaskStatus | null {\n    // Check completed\n    const result = this.completedResults.get(taskId);\n    if (result) {\n      return { state: 'completed', result };\n    }\n    \n    // Check running\n    const running = this.runningTasks.get(taskId);\n    if (running) {\n      return {\n        state: 'running',\n        processId: running.process.id,\n        startedAt: running.startedAt,\n      };\n    }\n    \n    // Check queued\n    const queuePos = this.taskQueue.findIndex(t => t.id === taskId);\n    if (queuePos >= 0) {\n      return { state: 'queued', position: queuePos };\n    }\n    \n    return null;\n  }\n\n  getMetrics(): EngineMetrics {\n    return { ...this.metrics };\n  }\n\n  onTaskComplete(handler: TaskCompleteHandler): void {\n    this.completeHandlers.push(handler);\n  }\n\n  onTaskFailed(handler: TaskFailedHandler): void {\n    this.failedHandlers.push(handler);\n  }\n\n  async shutdown(): Promise<void> {\n    // Stop accepting new tasks\n    this.taskQueue = [];\n    \n    // Wait for running tasks or force terminate\n    const runningIds = Array.from(this.runningTasks.keys());\n    for (const taskId of runningIds) {\n      await this.cancelTask(taskId);\n    }\n    \n    // Shutdown process manager\n    await this.processManager.shutdown();\n  }\n}\n\ninterface EngineConfig {\n  maxConcurrent?: number;\n  claudePath?: string;\n}\n\ninterface RunningTask {\n  task: ExecutionTask;\n  process: ManagedProcess;\n  startedAt: Date;\n  attempt: number;\n}\n\ninterface TaskResolver {\n  resolve: (result: ExecutionResult) => void;\n  reject: (error: Error) => void;\n}\n```\n\n## Usage Example\n\n```typescript\n// Initialize engine with process manager\nconst processManager = new SimpleProcessManager();\nconst engine = new SimpleExecutionEngine(processManager, {\n  maxConcurrent: 5,\n  claudePath: 'claude',\n});\n\n// Listen to completion events\nengine.onTaskComplete((result) => {\n  console.log(`Task ${result.taskId} completed in ${result.duration}ms`);\n  console.log(`Files changed:`, result.metadata?.filesChanged);\n});\n\n// Submit tasks\nconst task1 = {\n  id: 'task-1',\n  type: 'issue',\n  entityId: 'ISSUE-001',\n  prompt: 'Fix the authentication bug described in ISSUE-001',\n  workDir: '/path/to/project',\n  priority: 0,\n  dependencies: [],\n  createdAt: new Date(),\n  config: {\n    timeout: 300000,\n    maxRetries: 2,\n  },\n};\n\nconst taskId = await engine.submitTask(task1);\n\n// Wait for completion\nconst result = await engine.waitForTask(taskId);\nconsole.log('Success:', result.success);\n\n// Check metrics\nconst metrics = engine.getMetrics();\nconsole.log(`Queue: ${metrics.queuedTasks}, Running: ${metrics.currentlyRunning}`);\n```\n\n## Testing Strategy\n\n### Unit Tests\n\n1. **Task queueing**\n   - Tasks added to queue in order\n   - Queue processes FIFO\n   - Priority ordering (future)\n\n2. **Concurrency control**\n   - Respects maxConcurrent limit\n   - Starts next task when slot available\n   - Tracks running tasks correctly\n\n3. **Dependency resolution**\n   - Waits for dependencies before execution\n   - Handles failed dependencies\n   - Prevents circular dependencies\n\n4. **Retry logic**\n   - Retries failed tasks up to maxRetries\n   - Uses exponential backoff (future)\n   - Stops retrying after limit\n\n### Integration Tests\n\n1. **End-to-end execution**\n   - Submit → queue → execute → complete\n   - Multiple concurrent tasks\n   - Task cancellation during execution\n\n2. **Metrics tracking**\n   - Counts update correctly\n   - Averages calculate properly\n   - Throughput measured accurately\n\n## Future Enhancements\n\n### Path to Pool-Based Strategy\n\n```typescript\nclass PoolExecutionEngine implements IExecutionEngine {\n  private agentPool: AgentPool;\n  \n  async submitTask(task: ExecutionTask): Promise<string> {\n    // Get idle agent from pool or wait\n    const agent = await this.agentPool.acquire();\n    \n    // Reuse existing process\n    await agent.reset(); // Clear previous state\n    await agent.execute(task);\n    \n    // Return to pool\n    this.agentPool.release(agent);\n    \n    return task.id;\n  }\n  \n  // ... intelligent pool management\n}\n```\n\n### Other Future Features\n\n1. **Priority queue** - Higher priority tasks jump queue\n2. **Task batching** - Group similar tasks for efficiency\n3. **Smart scheduling** - Assign tasks based on agent capabilities\n4. **Resource-aware** - Consider memory/CPU before scheduling\n5. **Adaptive concurrency** - Auto-adjust limits based on load\n\n## File Structure\n\n```\nserver/src/execution/engine/\n├── types.ts                    # Core types (ExecutionTask, etc.)\n├── engine.ts                   # IExecutionEngine interface\n├── simple-engine.ts            # SimpleExecutionEngine (start here)\n├── pool-engine.ts              # PoolExecutionEngine (future)\n└── utils.ts                    # Helper functions\n```\n\n## Implementation Checklist\n\n- [ ] Define core types in types.ts\n- [ ] Define IExecutionEngine interface\n- [ ] Implement SimpleExecutionEngine\n- [ ] Add task queue (FIFO)\n- [ ] Add concurrency control\n- [ ] Add dependency resolution\n- [ ] Add retry logic\n- [ ] Add event emission\n- [ ] Integrate with Process Layer\n- [ ] Write unit tests\n- [ ] Write integration tests\n\n## Related Specs\n\n- Execution System (root spec)\n- [[SPEC-003]] - Process Layer (dependency)\n- Next: Task Execution Layer (Layer 3) - Resilience & retry\n","priority":0,"archived":1,"archived_at":"2025-11-05T05:38:47.341Z","created_at":"2025-10-28 07:36:09","updated_at":"2025-11-05 05:38:47","parent_id":null,"parent_uuid":null,"relationships":[{"from":"SPEC-004","from_type":"spec","to":"SPEC-003","to_type":"spec","type":"references"}],"tags":["concurrency","engine","execution","layer-2","task-queue"]}
{"id":"SPEC-005","uuid":"91c92cf2-110f-4341-88f1-2b90820c769f","title":"Task Execution Layer - Resilience & Retry","file_path":"specs/task_execution_layer_resilience_retry.md","content":"# Task Execution Layer Specification\n\n## Overview\n\nThe Task Execution Layer (Layer 3) adds resilience patterns to task execution. It wraps the Engine Layer with retry logic, circuit breakers, and fault tolerance mechanisms.\n\n## Design Goals\n\n1. **Resilient**: Automatically recover from transient failures\n2. **Smart Retry**: Exponential backoff with jitter\n3. **Circuit Breaker**: Prevent cascading failures\n4. **Fault Isolation**: One agent failure doesn't affect others\n5. **Observable**: Track retry attempts and failure patterns\n\n## Architecture\n\nBased on Execution System spec, [[SPEC-003]] (Process Layer), and [[SPEC-004]] (Engine Layer).\n\n```\n┌──────────────────────────────────────────────────┐\n│      Task Execution Layer (Layer 3)              │\n├──────────────────────────────────────────────────┤\n│                                                  │\n│  ┌────────────────────────────────────────────┐ │\n│  │   IResilientExecutor (Interface)           │ │\n│  └────────────┬───────────────────────────────┘ │\n│               │                                  │\n│     ┌─────────▼────────────┐                    │\n│     │  ResilientExecutor   │                    │\n│     └──────────┬────────────┘                    │\n│                │                                  │\n│         ┌──────┴───────┬──────────┬──────────┐  │\n│         │              │          │          │  │\n│    ┌────▼─────┐  ┌────▼────┐ ┌──▼────┐ ┌───▼──┐│\n│    │  Retry   │  │ Circuit │ │Timeout│ │Error ││\n│    │ Handler  │  │ Breaker │ │Handler│ │Catch ││\n│    └──────────┘  └─────────┘ └───────┘ └──────┘│\n│                                                  │\n│    ┌──────────────────────────────────────────┐ │\n│    │      Execution Engine (Layer 2)          │ │\n│    └──────────────────────────────────────────┘ │\n│                                                  │\n└──────────────────────────────────────────────────┘\n```\n\n## Core Types\n\n### RetryPolicy\nConfiguration for retry behavior.\n\n```typescript\ninterface RetryPolicy {\n  // Retry limits\n  maxAttempts: number;           // Max retry attempts (0 = no retry)\n  \n  // Backoff strategy\n  backoff: {\n    type: 'exponential' | 'linear' | 'fixed';\n    baseDelayMs: number;         // Initial delay\n    maxDelayMs: number;          // Cap on delay\n    jitter: boolean;             // Add randomness to prevent thundering herd\n  };\n  \n  // Retry conditions\n  retryableErrors: string[];     // Error types to retry\n  retryableExitCodes: number[];  // Exit codes to retry\n  \n  // Circuit breaker integration\n  shouldOpenCircuit?: (error: Error, attempts: number) => boolean;\n}\n```\n\n### CircuitBreakerState\nCircuit breaker for preventing cascading failures.\n\n```typescript\ninterface CircuitBreaker {\n  // Identity\n  name: string;                  // Breaker name (e.g., 'issue-executor')\n  \n  // State\n  state: CircuitState;\n  \n  // Configuration\n  config: {\n    failureThreshold: number;    // Failures before opening (e.g., 5)\n    successThreshold: number;    // Successes to close (e.g., 2)\n    timeout: number;             // Half-open retry delay (ms)\n  };\n  \n  // Metrics\n  metrics: {\n    totalRequests: number;\n    failedRequests: number;\n    successfulRequests: number;\n    lastFailureTime?: Date;\n    lastSuccessTime?: Date;\n  };\n}\n\ntype CircuitState = 'closed' | 'open' | 'half-open';\n```\n\n### ExecutionAttempt\nRecord of a single execution attempt.\n\n```typescript\ninterface ExecutionAttempt {\n  attemptNumber: number;\n  startedAt: Date;\n  completedAt?: Date;\n  duration?: number;\n  success: boolean;\n  error?: Error;\n  exitCode?: number;\n  willRetry: boolean;\n  nextRetryAt?: Date;\n}\n```\n\n### ResilientExecutionResult\nEnhanced result with retry information.\n\n```typescript\ninterface ResilientExecutionResult extends ExecutionResult {\n  // Retry information\n  attempts: ExecutionAttempt[];\n  totalAttempts: number;\n  finalAttempt: ExecutionAttempt;\n  \n  // Failure analysis\n  failureReason?: string;\n  circuitBreakerTriggered?: boolean;\n}\n```\n\n## IResilientExecutor Interface\n\nThe core abstraction for resilient task execution.\n\n```typescript\ninterface IResilientExecutor {\n  // Execute with resilience\n  executeTask(\n    task: ExecutionTask,\n    policy?: RetryPolicy\n  ): Promise<ResilientExecutionResult>;\n  \n  executeTasks(\n    tasks: ExecutionTask[],\n    policy?: RetryPolicy\n  ): Promise<ResilientExecutionResult[]>;\n  \n  // Circuit breaker management\n  getCircuitBreaker(name: string): CircuitBreaker | null;\n  resetCircuitBreaker(name: string): void;\n  \n  // Monitoring\n  getRetryMetrics(): RetryMetrics;\n  onRetryAttempt(handler: RetryAttemptHandler): void;\n  onCircuitOpen(handler: CircuitOpenHandler): void;\n}\n\ntype RetryAttemptHandler = (\n  taskId: string,\n  attempt: ExecutionAttempt\n) => void;\n\ntype CircuitOpenHandler = (\n  circuitName: string,\n  breaker: CircuitBreaker\n) => void;\n\ninterface RetryMetrics {\n  totalRetries: number;\n  successfulRetries: number;\n  failedRetries: number;\n  averageAttemptsToSuccess: number;\n  circuitBreakers: Map<string, CircuitBreaker>;\n}\n```\n\n## ResilientExecutor Implementation\n\nWraps the execution engine with retry and circuit breaker logic.\n\n### Key Features\n\n1. **Exponential Backoff**: Delay increases exponentially (2^attempt)\n2. **Jitter**: Random delay component to prevent thundering herd\n3. **Circuit Breaker**: Per-task-type circuit breakers\n4. **Smart Retry**: Only retry transient errors\n5. **Detailed Tracking**: Record all attempts and failures\n\n### Implementation Pattern\n\n```typescript\nclass ResilientExecutor implements IResilientExecutor {\n  private circuitBreakers = new Map<string, CircuitBreaker>();\n  private retryHandlers: RetryAttemptHandler[] = [];\n  private circuitOpenHandlers: CircuitOpenHandler[] = [];\n  \n  private metrics: RetryMetrics = {\n    totalRetries: 0,\n    successfulRetries: 0,\n    failedRetries: 0,\n    averageAttemptsToSuccess: 1.0,\n    circuitBreakers: new Map(),\n  };\n  \n  constructor(\n    private engine: IExecutionEngine,\n    private defaultPolicy: RetryPolicy = DEFAULT_RETRY_POLICY\n  ) {}\n\n  async executeTask(\n    task: ExecutionTask,\n    policy?: RetryPolicy\n  ): Promise<ResilientExecutionResult> {\n    const retryPolicy = policy || this.defaultPolicy;\n    const attempts: ExecutionAttempt[] = [];\n    \n    // Get or create circuit breaker for this task type\n    const circuitBreaker = this.getOrCreateCircuitBreaker(task.type);\n    \n    // Check circuit breaker\n    if (circuitBreaker.state === 'open') {\n      if (!this.shouldAttemptHalfOpen(circuitBreaker)) {\n        throw new Error(\n          `Circuit breaker '${circuitBreaker.name}' is OPEN. ` +\n          `Too many failures. Try again later.`\n        );\n      }\n      circuitBreaker.state = 'half-open';\n    }\n    \n    // Execute with retry\n    for (let attempt = 1; attempt <= retryPolicy.maxAttempts; attempt++) {\n      const attemptRecord: ExecutionAttempt = {\n        attemptNumber: attempt,\n        startedAt: new Date(),\n        success: false,\n        willRetry: false,\n      };\n      \n      try {\n        // Submit to engine\n        const taskId = await this.engine.submitTask(task);\n        \n        // Wait for result\n        const result = await this.engine.waitForTask(taskId);\n        \n        attemptRecord.completedAt = new Date();\n        attemptRecord.duration = \n          attemptRecord.completedAt.getTime() - \n          attemptRecord.startedAt.getTime();\n        attemptRecord.success = result.success;\n        attemptRecord.exitCode = result.exitCode;\n        \n        attempts.push(attemptRecord);\n        \n        if (result.success) {\n          // Success! Record and close circuit\n          this.recordSuccess(circuitBreaker);\n          \n          return {\n            ...result,\n            attempts,\n            totalAttempts: attempt,\n            finalAttempt: attemptRecord,\n          };\n        } else {\n          // Task failed\n          attemptRecord.error = new Error(result.error || 'Task failed');\n          \n          // Check if we should retry\n          const shouldRetry = \n            attempt < retryPolicy.maxAttempts &&\n            this.isRetryable(result, retryPolicy);\n          \n          if (shouldRetry) {\n            // Calculate backoff delay\n            const delay = this.calculateBackoff(\n              attempt,\n              retryPolicy.backoff\n            );\n            \n            attemptRecord.willRetry = true;\n            attemptRecord.nextRetryAt = new Date(Date.now() + delay);\n            \n            // Emit retry event\n            for (const handler of this.retryHandlers) {\n              handler(task.id, attemptRecord);\n            }\n            \n            this.metrics.totalRetries++;\n            \n            // Wait before retry\n            await this.sleep(delay);\n          } else {\n            // No more retries\n            this.recordFailure(circuitBreaker, attemptRecord.error);\n            \n            this.metrics.failedRetries++;\n            \n            return {\n              ...result,\n              attempts,\n              totalAttempts: attempt,\n              finalAttempt: attemptRecord,\n              failureReason: attemptRecord.error.message,\n            };\n          }\n        }\n      } catch (error) {\n        // Engine-level error (spawn failure, etc.)\n        attemptRecord.completedAt = new Date();\n        attemptRecord.duration = \n          attemptRecord.completedAt.getTime() - \n          attemptRecord.startedAt.getTime();\n        attemptRecord.error = error as Error;\n        attemptRecord.success = false;\n        \n        attempts.push(attemptRecord);\n        \n        // Check if we should retry\n        const shouldRetry = \n          attempt < retryPolicy.maxAttempts &&\n          this.isErrorRetryable(error as Error, retryPolicy);\n        \n        if (shouldRetry) {\n          const delay = this.calculateBackoff(attempt, retryPolicy.backoff);\n          attemptRecord.willRetry = true;\n          attemptRecord.nextRetryAt = new Date(Date.now() + delay);\n          \n          for (const handler of this.retryHandlers) {\n            handler(task.id, attemptRecord);\n          }\n          \n          this.metrics.totalRetries++;\n          await this.sleep(delay);\n        } else {\n          this.recordFailure(circuitBreaker, error as Error);\n          this.metrics.failedRetries++;\n          \n          throw error;\n        }\n      }\n    }\n    \n    // Should never reach here, but TypeScript requires it\n    throw new Error('Max retry attempts exceeded');\n  }\n\n  async executeTasks(\n    tasks: ExecutionTask[],\n    policy?: RetryPolicy\n  ): Promise<ResilientExecutionResult[]> {\n    return Promise.all(\n      tasks.map(task => this.executeTask(task, policy))\n    );\n  }\n\n  private getOrCreateCircuitBreaker(taskType: string): CircuitBreaker {\n    let breaker = this.circuitBreakers.get(taskType);\n    \n    if (!breaker) {\n      breaker = {\n        name: taskType,\n        state: 'closed',\n        config: {\n          failureThreshold: 5,\n          successThreshold: 2,\n          timeout: 60000, // 1 minute\n        },\n        metrics: {\n          totalRequests: 0,\n          failedRequests: 0,\n          successfulRequests: 0,\n        },\n      };\n      \n      this.circuitBreakers.set(taskType, breaker);\n      this.metrics.circuitBreakers.set(taskType, breaker);\n    }\n    \n    return breaker;\n  }\n\n  private shouldAttemptHalfOpen(breaker: CircuitBreaker): boolean {\n    if (!breaker.metrics.lastFailureTime) return true;\n    \n    const timeSinceFailure = \n      Date.now() - breaker.metrics.lastFailureTime.getTime();\n    \n    return timeSinceFailure >= breaker.config.timeout;\n  }\n\n  private recordSuccess(breaker: CircuitBreaker): void {\n    breaker.metrics.totalRequests++;\n    breaker.metrics.successfulRequests++;\n    breaker.metrics.lastSuccessTime = new Date();\n    \n    if (breaker.state === 'half-open') {\n      // Count consecutive successes in half-open state\n      const recentSuccesses = this.getRecentSuccessCount(breaker);\n      if (recentSuccesses >= breaker.config.successThreshold) {\n        breaker.state = 'closed';\n        breaker.metrics.failedRequests = 0; // Reset failure count\n      }\n    }\n    \n    this.metrics.successfulRetries++;\n  }\n\n  private recordFailure(breaker: CircuitBreaker, error: Error): void {\n    breaker.metrics.totalRequests++;\n    breaker.metrics.failedRequests++;\n    breaker.metrics.lastFailureTime = new Date();\n    \n    // Check if we should open circuit\n    if (\n      breaker.state === 'closed' &&\n      breaker.metrics.failedRequests >= breaker.config.failureThreshold\n    ) {\n      breaker.state = 'open';\n      \n      // Emit circuit open event\n      for (const handler of this.circuitOpenHandlers) {\n        handler(breaker.name, breaker);\n      }\n    } else if (breaker.state === 'half-open') {\n      // Failed in half-open, back to open\n      breaker.state = 'open';\n    }\n  }\n\n  private getRecentSuccessCount(breaker: CircuitBreaker): number {\n    // In a real implementation, track recent attempts\n    // For now, simplified\n    return breaker.metrics.successfulRequests;\n  }\n\n  private calculateBackoff(\n    attempt: number,\n    config: RetryPolicy['backoff']\n  ): number {\n    let delay: number;\n    \n    switch (config.type) {\n      case 'exponential':\n        delay = config.baseDelayMs * Math.pow(2, attempt - 1);\n        break;\n      case 'linear':\n        delay = config.baseDelayMs * attempt;\n        break;\n      case 'fixed':\n        delay = config.baseDelayMs;\n        break;\n    }\n    \n    // Cap at max delay\n    delay = Math.min(delay, config.maxDelayMs);\n    \n    // Add jitter if configured\n    if (config.jitter) {\n      const jitterAmount = delay * 0.1; // 10% jitter\n      delay += Math.random() * jitterAmount - jitterAmount / 2;\n    }\n    \n    return Math.floor(delay);\n  }\n\n  private isRetryable(\n    result: ExecutionResult,\n    policy: RetryPolicy\n  ): boolean {\n    // Check exit code\n    if (\n      result.exitCode !== undefined &&\n      policy.retryableExitCodes.includes(result.exitCode)\n    ) {\n      return true;\n    }\n    \n    // Check error message\n    if (result.error) {\n      for (const retryableError of policy.retryableErrors) {\n        if (result.error.includes(retryableError)) {\n          return true;\n        }\n      }\n    }\n    \n    return false;\n  }\n\n  private isErrorRetryable(error: Error, policy: RetryPolicy): boolean {\n    for (const retryableError of policy.retryableErrors) {\n      if (error.message.includes(retryableError)) {\n        return true;\n      }\n    }\n    return false;\n  }\n\n  private sleep(ms: number): Promise<void> {\n    return new Promise(resolve => setTimeout(resolve, ms));\n  }\n\n  getCircuitBreaker(name: string): CircuitBreaker | null {\n    return this.circuitBreakers.get(name) || null;\n  }\n\n  resetCircuitBreaker(name: string): void {\n    const breaker = this.circuitBreakers.get(name);\n    if (breaker) {\n      breaker.state = 'closed';\n      breaker.metrics.failedRequests = 0;\n      breaker.metrics.successfulRequests = 0;\n    }\n  }\n\n  getRetryMetrics(): RetryMetrics {\n    return { ...this.metrics };\n  }\n\n  onRetryAttempt(handler: RetryAttemptHandler): void {\n    this.retryHandlers.push(handler);\n  }\n\n  onCircuitOpen(handler: CircuitOpenHandler): void {\n    this.circuitOpenHandlers.push(handler);\n  }\n}\n\n// Default retry policy\nconst DEFAULT_RETRY_POLICY: RetryPolicy = {\n  maxAttempts: 3,\n  backoff: {\n    type: 'exponential',\n    baseDelayMs: 1000,\n    maxDelayMs: 30000,\n    jitter: true,\n  },\n  retryableErrors: [\n    'ECONNREFUSED',\n    'ETIMEDOUT',\n    'ENOTFOUND',\n    'timeout',\n    'network',\n  ],\n  retryableExitCodes: [1, 137], // Generic error, SIGKILL\n};\n```\n\n## Usage Example\n\n```typescript\n// Initialize stack\nconst processManager = new SimpleProcessManager();\nconst engine = new SimpleExecutionEngine(processManager, {\n  maxConcurrent: 5,\n});\n\nconst resilientExecutor = new ResilientExecutor(engine, {\n  maxAttempts: 3,\n  backoff: {\n    type: 'exponential',\n    baseDelayMs: 1000,\n    maxDelayMs: 30000,\n    jitter: true,\n  },\n  retryableErrors: ['timeout', 'ECONNREFUSED'],\n  retryableExitCodes: [1],\n});\n\n// Listen to retry attempts\nresilientExecutor.onRetryAttempt((taskId, attempt) => {\n  console.log(\n    `Task ${taskId} attempt ${attempt.attemptNumber} failed. ` +\n    `Retrying in ${attempt.nextRetryAt}...`\n  );\n});\n\n// Listen to circuit breaker events\nresilientExecutor.onCircuitOpen((name, breaker) => {\n  console.log(\n    `Circuit breaker '${name}' opened after ` +\n    `${breaker.metrics.failedRequests} failures`\n  );\n});\n\n// Execute task with resilience\nconst task = {\n  id: 'task-1',\n  type: 'issue',\n  entityId: 'ISSUE-001',\n  prompt: 'Fix the bug',\n  workDir: '/path/to/project',\n  priority: 0,\n  dependencies: [],\n  createdAt: new Date(),\n  config: {},\n};\n\nconst result = await resilientExecutor.executeTask(task);\n\nconsole.log(`Success: ${result.success}`);\nconsole.log(`Attempts: ${result.totalAttempts}`);\nconsole.log(`Attempts:`, result.attempts);\n```\n\n## Testing Strategy\n\n### Unit Tests\n\n1. **Retry logic**\n   - Retries up to maxAttempts\n   - Calculates backoff correctly\n   - Adds jitter when configured\n   - Stops retrying on non-retryable errors\n\n2. **Circuit breaker**\n   - Opens after failure threshold\n   - Transitions to half-open after timeout\n   - Closes after success threshold\n   - Rejects requests when open\n\n3. **Backoff calculation**\n   - Exponential: 1s, 2s, 4s, 8s, 16s\n   - Linear: 1s, 2s, 3s, 4s, 5s\n   - Fixed: 1s, 1s, 1s, 1s, 1s\n   - Respects maxDelay cap\n\n### Integration Tests\n\n1. **End-to-end resilience**\n   - Task fails → retries → succeeds\n   - Circuit breaker opens → half-open → closes\n   - Multiple task types have separate breakers\n\n2. **Failure scenarios**\n   - Transient errors are retried\n   - Permanent errors fail fast\n   - Circuit breaker prevents cascading failures\n\n## Future Enhancements\n\n1. **Adaptive retry** - Adjust backoff based on load\n2. **Bulkhead pattern** - Isolate task types with separate pools\n3. **Rate limiting** - Prevent overwhelming downstream services\n4. **Retry budgets** - Limit total retry percentage\n5. **Dead letter queue** - Store permanently failed tasks\n\n## File Structure\n\n```\nserver/src/execution/resilience/\n├── types.ts                    # Core types (RetryPolicy, etc.)\n├── executor.ts                 # IResilientExecutor interface\n├── resilient-executor.ts       # ResilientExecutor implementation\n├── circuit-breaker.ts          # Circuit breaker logic\n├── retry.ts                    # Retry and backoff logic\n└── utils.ts                    # Helper functions\n```\n\n## Implementation Checklist\n\n- [ ] Define core types in types.ts\n- [ ] Define IResilientExecutor interface\n- [ ] Implement ResilientExecutor\n- [ ] Add retry logic with exponential backoff\n- [ ] Add jitter to backoff\n- [ ] Implement circuit breaker\n- [ ] Add retryable error detection\n- [ ] Add metrics tracking\n- [ ] Write unit tests for retry logic\n- [ ] Write unit tests for circuit breaker\n- [ ] Write integration tests\n\n## Related Specs\n\n- Execution System (root spec)\n- [[SPEC-003]] - Process Layer (foundation)\n- [[SPEC-004]] - Engine Layer (dependency)\n- Next: Workflow Layer (Layer 4) - Orchestration & state\n","priority":0,"archived":1,"archived_at":"2025-11-05T05:39:07.062Z","created_at":"2025-10-28 07:45:43","updated_at":"2025-11-05 05:39:07","parent_id":null,"parent_uuid":null,"relationships":[{"from":"SPEC-005","from_type":"spec","to":"SPEC-003","to_type":"spec","type":"references"},{"from":"SPEC-005","from_type":"spec","to":"SPEC-004","to_type":"spec","type":"references"}],"tags":["circuit-breaker","execution","layer-3","resilience","retry"]}
{"id":"SPEC-006","uuid":"3d34e745-31ce-409e-b43b-9459ea4704bc","title":"Workflow Layer - Orchestration & State Management","file_path":"specs/workflow_layer_orchestration_state_management.md","content":"# Workflow Layer Specification\n\n## Overview\n\nThe Workflow Layer (Layer 4) orchestrates complex multi-step executions with state persistence, dependency management, and workflow resumption. It enables building sophisticated agent workflows that can survive crashes and resume from checkpoints.\n\n## Design Goals\n\n1. **Stateful**: Persist workflow state for crash recovery\n2. **Resumable**: Continue from last checkpoint after failure\n3. **Composable**: Build complex workflows from simple steps\n4. **Observable**: Track workflow progress in real-time\n5. **Simple First**: Start with linear workflows, upgrade to DAGs\n\n## Architecture\n\nBased on Execution System spec, [[SPEC-003]] (Process), [[SPEC-004]] (Engine), and [[SPEC-005]] (Resilience).\n\n```\n┌────────────────────────────────────────────────────┐\n│       Workflow Layer (Layer 4)                     │\n├────────────────────────────────────────────────────┤\n│                                                    │\n│  ┌──────────────────────────────────────────────┐ │\n│  │    IWorkflowOrchestrator (Interface)         │ │\n│  └──────────────┬───────────────────────────────┘ │\n│                 │                                  │\n│       ┌─────────▼──────────┐                      │\n│       │ LinearOrchestrator │                      │\n│       │  (Start Here)      │                      │\n│       └─────────┬──────────┘                      │\n│                 │                                  │\n│          ┌──────┴───────┬────────────┐            │\n│          │              │            │            │\n│     ┌────▼────┐   ┌────▼────┐  ┌───▼──────┐     │\n│     │Workflow │   │  Step   │  │  State   │     │\n│     │Executor │   │Executor │  │Persister │     │\n│     └─────────┘   └─────────┘  └──────────┘     │\n│                                                    │\n│    ┌────────────────────────────────────────────┐ │\n│    │   Resilient Executor (Layer 3)             │ │\n│    └────────────────────────────────────────────┘ │\n│                                                    │\n└────────────────────────────────────────────────────┘\n```\n\n## Core Types\n\n### WorkflowDefinition\nDefines a multi-step workflow.\n\n```typescript\ninterface WorkflowDefinition {\n  // Identity\n  id: string;\n  name: string;\n  version: string;\n  \n  // Steps\n  steps: WorkflowStep[];\n  \n  // Configuration\n  config: {\n    checkpointInterval?: number;  // Save state every N steps\n    continueOnStepFailure?: boolean;\n    timeout?: number;             // Overall workflow timeout\n  };\n  \n  // Metadata\n  metadata?: Record<string, any>;\n}\n\ninterface WorkflowStep {\n  // Identity\n  id: string;\n  name: string;\n  \n  // Task configuration\n  taskType: 'issue' | 'spec' | 'custom';\n  promptTemplate: string;         // Template with variables\n  \n  // Dependencies\n  dependsOn: string[];            // Step IDs that must complete first\n  \n  // Execution config\n  retryPolicy?: RetryPolicy;\n  timeout?: number;\n  \n  // Condition\n  condition?: (context: WorkflowContext) => boolean;\n  \n  // Output mapping\n  outputMapping?: Record<string, string>; // Map outputs to context vars\n}\n```\n\n### WorkflowExecution\nRuntime state of a workflow execution.\n\n```typescript\ninterface WorkflowExecution {\n  // Identity\n  id: string;\n  workflowId: string;\n  \n  // State\n  status: WorkflowStatus;\n  currentStep?: string;          // Currently executing step ID\n  \n  // Progress\n  completedSteps: string[];\n  failedSteps: string[];\n  skippedSteps: string[];\n  \n  // Context (variables shared across steps)\n  context: WorkflowContext;\n  \n  // Results\n  stepResults: Map<string, ExecutionResult>;\n  \n  // Timing\n  startedAt: Date;\n  completedAt?: Date;\n  lastCheckpointAt?: Date;\n  \n  // Metadata\n  metadata?: Record<string, any>;\n}\n\ntype WorkflowStatus = \n  | 'pending'\n  | 'running'\n  | 'paused'\n  | 'completed'\n  | 'failed'\n  | 'cancelled';\n\ninterface WorkflowContext {\n  // Global variables\n  variables: Record<string, any>;\n  \n  // Step outputs (accessible by step ID)\n  outputs: Record<string, any>;\n  \n  // Shared state\n  shared: Record<string, any>;\n}\n```\n\n### WorkflowCheckpoint\nSerializable checkpoint for resumption.\n\n```typescript\ninterface WorkflowCheckpoint {\n  executionId: string;\n  workflowId: string;\n  timestamp: Date;\n  \n  // State snapshot\n  execution: WorkflowExecution;\n  \n  // Next step to execute\n  nextStep?: string;\n}\n```\n\n## IWorkflowOrchestrator Interface\n\nThe core abstraction for workflow orchestration.\n\n```typescript\ninterface IWorkflowOrchestrator {\n  // Workflow execution\n  startWorkflow(\n    workflow: WorkflowDefinition,\n    initialContext?: Partial<WorkflowContext>\n  ): Promise<string>; // Returns execution ID\n  \n  resumeWorkflow(\n    checkpointId: string\n  ): Promise<string>; // Returns execution ID\n  \n  // Control\n  pauseWorkflow(executionId: string): Promise<void>;\n  cancelWorkflow(executionId: string): Promise<void>;\n  \n  // Monitoring\n  getExecution(executionId: string): WorkflowExecution | null;\n  getStepStatus(executionId: string, stepId: string): StepStatus | null;\n  \n  // Waiting\n  waitForWorkflow(executionId: string): Promise<WorkflowResult>;\n  \n  // Checkpointing\n  saveCheckpoint(executionId: string): Promise<string>; // Returns checkpoint ID\n  listCheckpoints(workflowId: string): Promise<WorkflowCheckpoint[]>;\n  \n  // Events\n  onStepComplete(handler: StepCompleteHandler): void;\n  onWorkflowComplete(handler: WorkflowCompleteHandler): void;\n  onCheckpoint(handler: CheckpointHandler): void;\n}\n\ninterface StepStatus {\n  stepId: string;\n  status: 'pending' | 'running' | 'completed' | 'failed' | 'skipped';\n  result?: ExecutionResult;\n  attempts: number;\n}\n\ninterface WorkflowResult {\n  executionId: string;\n  success: boolean;\n  completedSteps: number;\n  failedSteps: number;\n  outputs: Record<string, any>;\n  duration: number;\n}\n\ntype StepCompleteHandler = (\n  executionId: string,\n  stepId: string,\n  result: ExecutionResult\n) => void;\n\ntype WorkflowCompleteHandler = (result: WorkflowResult) => void;\n\ntype CheckpointHandler = (checkpoint: WorkflowCheckpoint) => void;\n```\n\n## LinearOrchestrator Implementation\n\nSimple linear workflow execution with checkpointing.\n\n### Key Features\n\n1. **Sequential Execution**: Steps execute in defined order\n2. **Dependency Resolution**: Wait for dependencies before executing\n3. **Context Passing**: Share data between steps via context\n4. **Checkpointing**: Save state after each step for resumption\n5. **Conditional Steps**: Skip steps based on conditions\n\n### Implementation Pattern\n\n```typescript\nclass LinearOrchestrator implements IWorkflowOrchestrator {\n  private executions = new Map<string, WorkflowExecution>();\n  private checkpoints = new Map<string, WorkflowCheckpoint>();\n  \n  private stepCompleteHandlers: StepCompleteHandler[] = [];\n  private workflowCompleteHandlers: WorkflowCompleteHandler[] = [];\n  private checkpointHandlers: CheckpointHandler[] = [];\n  \n  constructor(\n    private executor: IResilientExecutor,\n    private storage?: IWorkflowStorage\n  ) {}\n\n  async startWorkflow(\n    workflow: WorkflowDefinition,\n    initialContext?: Partial<WorkflowContext>\n  ): Promise<string> {\n    const execution: WorkflowExecution = {\n      id: generateId('execution'),\n      workflowId: workflow.id,\n      status: 'pending',\n      completedSteps: [],\n      failedSteps: [],\n      skippedSteps: [],\n      context: {\n        variables: initialContext?.variables || {},\n        outputs: {},\n        shared: {},\n      },\n      stepResults: new Map(),\n      startedAt: new Date(),\n    };\n    \n    this.executions.set(execution.id, execution);\n    \n    // Start execution in background\n    this.executeWorkflow(workflow, execution).catch(error => {\n      execution.status = 'failed';\n      execution.completedAt = new Date();\n    });\n    \n    return execution.id;\n  }\n\n  async resumeWorkflow(checkpointId: string): Promise<string> {\n    const checkpoint = this.checkpoints.get(checkpointId);\n    if (!checkpoint) {\n      throw new Error(`Checkpoint ${checkpointId} not found`);\n    }\n    \n    // Restore execution state\n    const execution = checkpoint.execution;\n    execution.status = 'pending';\n    this.executions.set(execution.id, execution);\n    \n    // Find workflow definition\n    const workflow = await this.loadWorkflowDefinition(execution.workflowId);\n    \n    // Resume from next step\n    this.executeWorkflow(workflow, execution, checkpoint.nextStep).catch(\n      error => {\n        execution.status = 'failed';\n        execution.completedAt = new Date();\n      }\n    );\n    \n    return execution.id;\n  }\n\n  private async executeWorkflow(\n    workflow: WorkflowDefinition,\n    execution: WorkflowExecution,\n    startFromStep?: string\n  ): Promise<void> {\n    execution.status = 'running';\n    \n    // Find starting point\n    let startIndex = 0;\n    if (startFromStep) {\n      startIndex = workflow.steps.findIndex(s => s.id === startFromStep);\n      if (startIndex === -1) {\n        throw new Error(`Step ${startFromStep} not found in workflow`);\n      }\n    }\n    \n    // Execute steps sequentially\n    for (let i = startIndex; i < workflow.steps.length; i++) {\n      const step = workflow.steps[i];\n      \n      // Check if paused or cancelled\n      if (execution.status === 'paused' || execution.status === 'cancelled') {\n        return;\n      }\n      \n      // Check dependencies\n      if (!this.areDependenciesMet(step, execution)) {\n        execution.failedSteps.push(step.id);\n        if (!workflow.config.continueOnStepFailure) {\n          execution.status = 'failed';\n          execution.completedAt = new Date();\n          return;\n        }\n        continue;\n      }\n      \n      // Check condition\n      if (step.condition && !step.condition(execution.context)) {\n        execution.skippedSteps.push(step.id);\n        continue;\n      }\n      \n      // Execute step\n      execution.currentStep = step.id;\n      \n      try {\n        const result = await this.executeStep(step, execution, workflow);\n        \n        execution.stepResults.set(step.id, result);\n        execution.completedSteps.push(step.id);\n        \n        // Update context with step outputs\n        if (step.outputMapping) {\n          for (const [key, path] of Object.entries(step.outputMapping)) {\n            execution.context.outputs[key] = this.extractValue(result, path);\n          }\n        }\n        \n        // Emit step complete event\n        for (const handler of this.stepCompleteHandlers) {\n          handler(execution.id, step.id, result);\n        }\n        \n        // Checkpoint if configured\n        if (\n          workflow.config.checkpointInterval &&\n          execution.completedSteps.length % workflow.config.checkpointInterval === 0\n        ) {\n          await this.saveCheckpoint(execution.id);\n        }\n      } catch (error) {\n        execution.failedSteps.push(step.id);\n        \n        if (!workflow.config.continueOnStepFailure) {\n          execution.status = 'failed';\n          execution.completedAt = new Date();\n          throw error;\n        }\n      }\n    }\n    \n    // Workflow completed\n    execution.status = 'completed';\n    execution.completedAt = new Date();\n    \n    // Emit workflow complete event\n    const result: WorkflowResult = {\n      executionId: execution.id,\n      success: execution.failedSteps.length === 0,\n      completedSteps: execution.completedSteps.length,\n      failedSteps: execution.failedSteps.length,\n      outputs: execution.context.outputs,\n      duration: execution.completedAt.getTime() - execution.startedAt.getTime(),\n    };\n    \n    for (const handler of this.workflowCompleteHandlers) {\n      handler(result);\n    }\n  }\n\n  private areDependenciesMet(\n    step: WorkflowStep,\n    execution: WorkflowExecution\n  ): boolean {\n    for (const depId of step.dependsOn) {\n      if (!execution.completedSteps.includes(depId)) {\n        return false;\n      }\n    }\n    return true;\n  }\n\n  private async executeStep(\n    step: WorkflowStep,\n    execution: WorkflowExecution,\n    workflow: WorkflowDefinition\n  ): Promise<ExecutionResult> {\n    // Render prompt template with context\n    const prompt = this.renderTemplate(step.promptTemplate, execution.context);\n    \n    // Build execution task\n    const task: ExecutionTask = {\n      id: generateId('task'),\n      type: step.taskType,\n      entityId: undefined,\n      prompt,\n      workDir: process.cwd(), // TODO: Make configurable\n      priority: 0,\n      dependencies: [],\n      createdAt: new Date(),\n      config: {\n        timeout: step.timeout,\n      },\n    };\n    \n    // Execute with resilience\n    return await this.executor.executeTask(task, step.retryPolicy);\n  }\n\n  private renderTemplate(\n    template: string,\n    context: WorkflowContext\n  ): string {\n    let rendered = template;\n    \n    // Replace variables: {{variable}}\n    for (const [key, value] of Object.entries(context.variables)) {\n      rendered = rendered.replace(\n        new RegExp(`{{${key}}}`, 'g'),\n        String(value)\n      );\n    }\n    \n    // Replace outputs: {{step.output}}\n    for (const [key, value] of Object.entries(context.outputs)) {\n      rendered = rendered.replace(\n        new RegExp(`{{${key}}}`, 'g'),\n        String(value)\n      );\n    }\n    \n    return rendered;\n  }\n\n  private extractValue(result: ExecutionResult, path: string): any {\n    // Simple path extraction (e.g., \"output\" or \"metadata.filesChanged\")\n    const parts = path.split('.');\n    let value: any = result;\n    \n    for (const part of parts) {\n      value = value[part];\n      if (value === undefined) break;\n    }\n    \n    return value;\n  }\n\n  async saveCheckpoint(executionId: string): Promise<string> {\n    const execution = this.executions.get(executionId);\n    if (!execution) {\n      throw new Error(`Execution ${executionId} not found`);\n    }\n    \n    const checkpoint: WorkflowCheckpoint = {\n      executionId,\n      workflowId: execution.workflowId,\n      timestamp: new Date(),\n      execution: { ...execution },\n      nextStep: execution.currentStep,\n    };\n    \n    const checkpointId = generateId('checkpoint');\n    this.checkpoints.set(checkpointId, checkpoint);\n    \n    execution.lastCheckpointAt = new Date();\n    \n    // Persist to storage if available\n    if (this.storage) {\n      await this.storage.saveCheckpoint(checkpointId, checkpoint);\n    }\n    \n    // Emit checkpoint event\n    for (const handler of this.checkpointHandlers) {\n      handler(checkpoint);\n    }\n    \n    return checkpointId;\n  }\n\n  async pauseWorkflow(executionId: string): Promise<void> {\n    const execution = this.executions.get(executionId);\n    if (execution) {\n      execution.status = 'paused';\n    }\n  }\n\n  async cancelWorkflow(executionId: string): Promise<void> {\n    const execution = this.executions.get(executionId);\n    if (execution) {\n      execution.status = 'cancelled';\n      execution.completedAt = new Date();\n    }\n  }\n\n  getExecution(executionId: string): WorkflowExecution | null {\n    return this.executions.get(executionId) || null;\n  }\n\n  getStepStatus(executionId: string, stepId: string): StepStatus | null {\n    const execution = this.executions.get(executionId);\n    if (!execution) return null;\n    \n    const result = execution.stepResults.get(stepId);\n    \n    let status: StepStatus['status'];\n    if (execution.completedSteps.includes(stepId)) {\n      status = 'completed';\n    } else if (execution.failedSteps.includes(stepId)) {\n      status = 'failed';\n    } else if (execution.skippedSteps.includes(stepId)) {\n      status = 'skipped';\n    } else if (execution.currentStep === stepId) {\n      status = 'running';\n    } else {\n      status = 'pending';\n    }\n    \n    return {\n      stepId,\n      status,\n      result,\n      attempts: 1, // TODO: Track attempts\n    };\n  }\n\n  async waitForWorkflow(executionId: string): Promise<WorkflowResult> {\n    return new Promise((resolve, reject) => {\n      const checkInterval = setInterval(() => {\n        const execution = this.executions.get(executionId);\n        if (!execution) {\n          clearInterval(checkInterval);\n          reject(new Error(`Execution ${executionId} not found`));\n          return;\n        }\n        \n        if (\n          execution.status === 'completed' ||\n          execution.status === 'failed' ||\n          execution.status === 'cancelled'\n        ) {\n          clearInterval(checkInterval);\n          \n          const result: WorkflowResult = {\n            executionId,\n            success: execution.status === 'completed',\n            completedSteps: execution.completedSteps.length,\n            failedSteps: execution.failedSteps.length,\n            outputs: execution.context.outputs,\n            duration: execution.completedAt\n              ? execution.completedAt.getTime() - execution.startedAt.getTime()\n              : 0,\n          };\n          \n          resolve(result);\n        }\n      }, 100);\n    });\n  }\n\n  async listCheckpoints(workflowId: string): Promise<WorkflowCheckpoint[]> {\n    const checkpoints: WorkflowCheckpoint[] = [];\n    \n    for (const checkpoint of this.checkpoints.values()) {\n      if (checkpoint.workflowId === workflowId) {\n        checkpoints.push(checkpoint);\n      }\n    }\n    \n    return checkpoints;\n  }\n\n  onStepComplete(handler: StepCompleteHandler): void {\n    this.stepCompleteHandlers.push(handler);\n  }\n\n  onWorkflowComplete(handler: WorkflowCompleteHandler): void {\n    this.workflowCompleteHandlers.push(handler);\n  }\n\n  onCheckpoint(handler: CheckpointHandler): void {\n    this.checkpointHandlers.push(handler);\n  }\n\n  private async loadWorkflowDefinition(\n    workflowId: string\n  ): Promise<WorkflowDefinition> {\n    // TODO: Load from storage\n    throw new Error('Not implemented');\n  }\n}\n\ninterface IWorkflowStorage {\n  saveCheckpoint(id: string, checkpoint: WorkflowCheckpoint): Promise<void>;\n  loadCheckpoint(id: string): Promise<WorkflowCheckpoint | null>;\n}\n```\n\n## Usage Example\n\n```typescript\n// Define workflow\nconst bugFixWorkflow: WorkflowDefinition = {\n  id: 'bug-fix-workflow',\n  name: 'Bug Fix and Test',\n  version: '1.0',\n  steps: [\n    {\n      id: 'analyze',\n      name: 'Analyze Issue',\n      taskType: 'issue',\n      promptTemplate: 'Analyze the bug in {{issueId}} and suggest a fix',\n      dependsOn: [],\n      outputMapping: {\n        analysis: 'output',\n      },\n    },\n    {\n      id: 'implement',\n      name: 'Implement Fix',\n      taskType: 'issue',\n      promptTemplate: 'Implement the fix for {{issueId}}. Analysis: {{analysis}}',\n      dependsOn: ['analyze'],\n      outputMapping: {\n        filesChanged: 'metadata.filesChanged',\n      },\n    },\n    {\n      id: 'test',\n      name: 'Run Tests',\n      taskType: 'custom',\n      promptTemplate: 'Run tests for files: {{filesChanged}}',\n      dependsOn: ['implement'],\n    },\n  ],\n  config: {\n    checkpointInterval: 1,\n    continueOnStepFailure: false,\n  },\n};\n\n// Execute workflow\nconst orchestrator = new LinearOrchestrator(resilientExecutor);\n\norchestrator.onStepComplete((execId, stepId, result) => {\n  console.log(`Step ${stepId} completed:`, result.success);\n});\n\nconst executionId = await orchestrator.startWorkflow(bugFixWorkflow, {\n  variables: {\n    issueId: 'ISSUE-001',\n  },\n});\n\nconst result = await orchestrator.waitForWorkflow(executionId);\nconsole.log(`Workflow completed: ${result.success}`);\nconsole.log(`Outputs:`, result.outputs);\n```\n\n## Testing Strategy\n\n### Unit Tests\n\n1. **Step execution**\n   - Executes steps in order\n   - Passes context between steps\n   - Handles step failures\n   - Skips conditional steps\n\n2. **Checkpointing**\n   - Saves checkpoint after interval\n   - Resumes from checkpoint correctly\n   - Preserves execution state\n\n3. **Template rendering**\n   - Replaces variables correctly\n   - Handles nested paths\n   - Handles missing variables\n\n### Integration Tests\n\n1. **End-to-end workflows**\n   - Multi-step workflow completes\n   - Checkpoint and resume works\n   - Context data flows correctly\n\n2. **Failure scenarios**\n   - Step failure stops workflow\n   - Resume after crash\n   - Handle partial completion\n\n## Future Enhancements\n\n1. **DAG workflows** - Parallel step execution\n2. **Conditional branches** - If/else logic\n3. **Loops** - Repeat steps until condition\n4. **Sub-workflows** - Compose workflows\n5. **Workflow versioning** - A/B testing\n\n## File Structure\n\n```\nserver/src/execution/workflow/\n├── types.ts                    # Core types (WorkflowDefinition, etc.)\n├── orchestrator.ts             # IWorkflowOrchestrator interface\n├── linear-orchestrator.ts      # LinearOrchestrator (start here)\n├── dag-orchestrator.ts         # DAGOrchestrator (future)\n├── storage.ts                  # Checkpoint persistence\n└── utils.ts                    # Template rendering, etc.\n```\n\n## Implementation Checklist\n\n- [ ] Define core types\n- [ ] Define IWorkflowOrchestrator interface\n- [ ] Implement LinearOrchestrator\n- [ ] Add sequential step execution\n- [ ] Add dependency resolution\n- [ ] Add template rendering\n- [ ] Add checkpointing\n- [ ] Add workflow resumption\n- [ ] Add conditional step execution\n- [ ] Write unit tests\n- [ ] Write integration tests\n\n## Related Specs\n\n- Execution System (root spec)\n- [[SPEC-003]] - Process Layer\n- [[SPEC-004]] - Engine Layer\n- [[SPEC-005]] - Task Execution Layer (dependency)\n- Next: Output Processing Layer (Layer 5)\n","priority":0,"archived":1,"archived_at":"2025-11-05T05:39:12.948Z","created_at":"2025-10-28 07:45:45","updated_at":"2025-11-05 05:39:12","parent_id":null,"parent_uuid":null,"relationships":[{"from":"SPEC-006","from_type":"spec","to":"SPEC-003","to_type":"spec","type":"references"},{"from":"SPEC-006","from_type":"spec","to":"SPEC-004","to_type":"spec","type":"references"}],"tags":["execution","layer-4","orchestration","state","workflow"]}
{"id":"SPEC-007","uuid":"cb9b2531-e8ce-4696-a74e-6973649ccdc7","title":"Output Processing Layer - Real-time Parsing","file_path":"specs/output_processing_layer_real_time_parsing.md","content":"# Output Processing Layer Specification\n\n## Overview\n\nThe Output Processing Layer (Layer 5) handles real-time parsing and processing of Claude Code's output. It parses stream-json format, extracts structured data, tracks progress, and provides event-driven updates.\n\n## Design Goals\n\n1. **Real-time**: Parse output as it streams, not after completion\n1. **Structured**: Extract tool calls, file changes, errors from JSON\n1. **Event-driven**: Emit events for progress tracking\n1. **Robust**: Handle malformed JSON gracefully\n1. **Flexible**: Support multiple output formats\n\n## Architecture\n\nBased on Execution System spec and all previous layers.\n\n```\n┌──────────────────────────────────────────────────┐\n│     Output Processing Layer (Layer 5)            │\n├──────────────────────────────────────────────────┤\n│                                                  │\n│  ┌────────────────────────────────────────────┐ │\n│  │   IOutputProcessor (Interface)             │ │\n│  └────────────┬───────────────────────────────┘ │\n│               │                                  │\n│     ┌─────────▼──────────┐                      │\n│     │ StreamJsonProcessor│                      │\n│     │  (Start Here)      │                      │\n│     └─────────┬──────────┘                      │\n│               │                                  │\n│        ┌──────┴──────┬──────────┬──────────┐   │\n│        │             │          │          │   │\n│   ┌────▼────┐  ┌────▼────┐ ┌──▼────┐ ┌───▼──┐│\n│   │  JSON   │  │  Event  │ │ Meta  │ │Error ││\n│   │ Parser  │  │ Emitter │ │Extract│ │Handle││\n│   └─────────┘  └─────────┘ └───────┘ └──────┘│\n│                                                  │\n│    ┌──────────────────────────────────────────┐ │\n│    │      Process Manager (Layer 1)           │ │\n│    └──────────────────────────────────────────┘ │\n│                                                  │\n└──────────────────────────────────────────────────┘\n```\n\n## Core Types\n\n### StreamMessage\n\nParsed message from Claude Code stream-json output.\n\n```typescript\ninterface StreamMessage {\n  type: MessageType;\n  timestamp: Date;\n  raw: string;                   // Original JSON line\n  data: any;                     // Parsed JSON\n}\n\ntype MessageType = \n  | 'user'                       // User message\n  | 'assistant'                  // Assistant message\n  | 'tool_use'                   // Tool invocation\n  | 'tool_result'                // Tool result\n  | 'result'                     // Final result with usage\n  | 'error'                      // Error message\n  | 'unknown';                   // Unparseable\n```\n\n### ToolCall\n\nExtracted tool call information.\n\n```typescript\ninterface ToolCall {\n  id: string;\n  name: string;\n  input: Record<string, any>;\n  timestamp: Date;\n}\n\ninterface ToolResult {\n  toolCallId: string;\n  success: boolean;\n  output?: any;\n  error?: string;\n  timestamp: Date;\n}\n```\n\n### ExecutionProgress\n\nReal-time execution progress.\n\n```typescript\ninterface ExecutionProgress {\n  // Basic info\n  processId: string;\n  startedAt: Date;\n  lastUpdate: Date;\n  \n  // Progress\n  toolCalls: ToolCall[];\n  toolResults: ToolResult[];\n  filesChanged: string[];\n  errors: string[];\n  \n  // Current state\n  currentActivity?: string;      // e.g., \"Reading file auth.ts\"\n  \n  // Usage\n  usage?: {\n    inputTokens: number;\n    outputTokens: number;\n    totalTokens: number;\n    cost?: number;\n  };\n}\n```\n\n### OutputProcessingOptions\n\nConfiguration for output processing.\n\n```typescript\ninterface OutputProcessingOptions {\n  // Format\n  format: 'stream-json' | 'json' | 'text';\n  \n  // Filtering\n  captureToolCalls?: boolean;\n  captureFileChanges?: boolean;\n  captureErrors?: boolean;\n  \n  // Events\n  emitProgressEvents?: boolean;\n  progressInterval?: number;     // ms between progress events\n  \n  // Buffering\n  maxBufferSize?: number;        // Max lines to buffer\n  lineSeparator?: string;        // Default: '\\n'\n}\n```\n\n## IOutputProcessor Interface\n\nThe core abstraction for output processing.\n\n```typescript\ninterface IOutputProcessor {\n  // Processing\n  processLine(line: string): StreamMessage | null;\n  processBuffer(buffer: string): StreamMessage[];\n  \n  // Progress tracking\n  getProgress(processId: string): ExecutionProgress | null;\n  \n  // Events\n  onToolCall(handler: ToolCallHandler): void;\n  onFileChange(handler: FileChangeHandler): void;\n  onProgress(handler: ProgressHandler): void;\n  onError(handler: ErrorHandler): void;\n  onComplete(handler: CompleteHandler): void;\n  \n  // Extraction\n  extractMetadata(messages: StreamMessage[]): ExecutionMetadata;\n  extractToolCalls(messages: StreamMessage[]): ToolCall[];\n  extractFileChanges(messages: StreamMessage[]): string[];\n}\n\ntype ToolCallHandler = (processId: string, toolCall: ToolCall) => void;\ntype FileChangeHandler = (processId: string, filePath: string) => void;\ntype ProgressHandler = (processId: string, progress: ExecutionProgress) => void;\ntype ErrorHandler = (processId: string, error: string) => void;\ntype CompleteHandler = (processId: string, metadata: ExecutionMetadata) => void;\n\ninterface ExecutionMetadata {\n  toolsUsed: string[];\n  filesChanged: string[];\n  tokensUsed: number;\n  cost: number;\n  duration: number;\n}\n```\n\n## StreamJsonProcessor Implementation\n\nParses Claude Code's stream-json format in real-time.\n\n### Key Features\n\n1. **Line-by-line parsing**: Handle incomplete JSON gracefully\n1. **Event emission**: Notify listeners on key events\n1. **Progress tracking**: Build execution progress in real-time\n1. **Metadata extraction**: Extract structured data from messages\n1. **Error handling**: Gracefully handle malformed JSON\n\n### Implementation Pattern\n\n```typescript\nclass StreamJsonProcessor implements IOutputProcessor {\n  private progressTracking = new Map<string, ExecutionProgress>();\n  \n  private toolCallHandlers: ToolCallHandler[] = [];\n  private fileChangeHandlers: FileChangeHandler[] = [];\n  private progressHandlers: ProgressHandler[] = [];\n  private errorHandlers: ErrorHandler[] = [];\n  private completeHandlers: CompleteHandler[] = [];\n  \n  private currentProcessId?: string;\n  \n  constructor(private options: OutputProcessingOptions = {}) {\n    this.options = {\n      format: 'stream-json',\n      captureToolCalls: true,\n      captureFileChanges: true,\n      captureErrors: true,\n      emitProgressEvents: true,\n      progressInterval: 1000,\n      maxBufferSize: 10000,\n      lineSeparator: '\\n',\n      ...options,\n    };\n  }\n\n  processLine(line: string): StreamMessage | null {\n    if (!line.trim()) return null;\n    \n    try {\n      const data = JSON.parse(line);\n      const message: StreamMessage = {\n        type: this.detectMessageType(data),\n        timestamp: new Date(),\n        raw: line,\n        data,\n      };\n      \n      // Process message\n      this.handleMessage(message);\n      \n      return message;\n    } catch (error) {\n      // Not valid JSON, might be plain text\n      return {\n        type: 'unknown',\n        timestamp: new Date(),\n        raw: line,\n        data: { text: line },\n      };\n    }\n  }\n\n  processBuffer(buffer: string): StreamMessage[] {\n    const lines = buffer.split(this.options.lineSeparator!);\n    const messages: StreamMessage[] = [];\n    \n    for (const line of lines) {\n      const message = this.processLine(line);\n      if (message) {\n        messages.push(message);\n      }\n    }\n    \n    return messages;\n  }\n\n  private detectMessageType(data: any): MessageType {\n    if (data.type === 'user') return 'user';\n    if (data.type === 'assistant') return 'assistant';\n    if (data.type === 'result') return 'result';\n    if (data.type === 'error') return 'error';\n    \n    // Check for tool use/result in message content\n    if (data.message?.content) {\n      const content = Array.isArray(data.message.content)\n        ? data.message.content[0]\n        : data.message.content;\n      \n      if (content.type === 'tool_use') return 'tool_use';\n      if (content.type === 'tool_result') return 'tool_result';\n    }\n    \n    return 'unknown';\n  }\n\n  private handleMessage(message: StreamMessage): void {\n    if (!this.currentProcessId) return;\n    \n    const progress = this.getOrCreateProgress(this.currentProcessId);\n    progress.lastUpdate = new Date();\n    \n    switch (message.type) {\n      case 'assistant':\n        this.handleAssistantMessage(message, progress);\n        break;\n      case 'tool_use':\n        this.handleToolUse(message, progress);\n        break;\n      case 'tool_result':\n        this.handleToolResult(message, progress);\n        break;\n      case 'result':\n        this.handleResult(message, progress);\n        break;\n      case 'error':\n        this.handleError(message, progress);\n        break;\n    }\n    \n    // Emit progress event\n    if (this.options.emitProgressEvents) {\n      this.emitProgress(this.currentProcessId, progress);\n    }\n  }\n\n  private handleAssistantMessage(\n    message: StreamMessage,\n    progress: ExecutionProgress\n  ): void {\n    const { data } = message;\n    \n    if (!data.message?.content) return;\n    \n    const contents = Array.isArray(data.message.content)\n      ? data.message.content\n      : [data.message.content];\n    \n    for (const content of contents) {\n      if (content.type === 'tool_use') {\n        const toolCall: ToolCall = {\n          id: content.id,\n          name: content.name,\n          input: content.input,\n          timestamp: message.timestamp,\n        };\n        \n        progress.toolCalls.push(toolCall);\n        \n        // Update current activity\n        progress.currentActivity = `Using tool: ${toolCall.name}`;\n        \n        // Track file changes\n        if (\n          this.options.captureFileChanges &&\n          (content.name === 'Write' || content.name === 'Edit')\n        ) {\n          const filePath = content.input.file_path;\n          if (filePath && !progress.filesChanged.includes(filePath)) {\n            progress.filesChanged.push(filePath);\n            \n            // Emit file change event\n            for (const handler of this.fileChangeHandlers) {\n              handler(progress.processId, filePath);\n            }\n          }\n        }\n        \n        // Emit tool call event\n        if (this.options.captureToolCalls) {\n          for (const handler of this.toolCallHandlers) {\n            handler(progress.processId, toolCall);\n          }\n        }\n      }\n    }\n  }\n\n  private handleToolUse(\n    message: StreamMessage,\n    progress: ExecutionProgress\n  ): void {\n    // Similar to handleAssistantMessage tool_use handling\n    const { data } = message;\n    \n    const toolCall: ToolCall = {\n      id: data.id || generateId('tool'),\n      name: data.name,\n      input: data.input,\n      timestamp: message.timestamp,\n    };\n    \n    progress.toolCalls.push(toolCall);\n    progress.currentActivity = `Using tool: ${toolCall.name}`;\n  }\n\n  private handleToolResult(\n    message: StreamMessage,\n    progress: ExecutionProgress\n  ): void {\n    const { data } = message;\n    \n    const result: ToolResult = {\n      toolCallId: data.tool_use_id || data.id,\n      success: !data.is_error,\n      output: data.content,\n      error: data.is_error ? data.content : undefined,\n      timestamp: message.timestamp,\n    };\n    \n    progress.toolResults.push(result);\n  }\n\n  private handleResult(\n    message: StreamMessage,\n    progress: ExecutionProgress\n  ): void {\n    const { data } = message;\n    \n    // Extract usage information\n    if (data.usage) {\n      progress.usage = {\n        inputTokens: data.usage.input_tokens || 0,\n        outputTokens: data.usage.output_tokens || 0,\n        totalTokens: data.usage.total_tokens || 0,\n        cost: this.calculateCost(data.usage),\n      };\n    }\n    \n    // Emit complete event\n    const metadata = this.buildMetadata(progress);\n    for (const handler of this.completeHandlers) {\n      handler(progress.processId, metadata);\n    }\n  }\n\n  private handleError(\n    message: StreamMessage,\n    progress: ExecutionProgress\n  ): void {\n    const { data } = message;\n    const error = data.error?.message || data.message || 'Unknown error';\n    \n    if (this.options.captureErrors) {\n      progress.errors.push(error);\n      \n      // Emit error event\n      for (const handler of this.errorHandlers) {\n        handler(progress.processId, error);\n      }\n    }\n  }\n\n  private getOrCreateProgress(processId: string): ExecutionProgress {\n    let progress = this.progressTracking.get(processId);\n    \n    if (!progress) {\n      progress = {\n        processId,\n        startedAt: new Date(),\n        lastUpdate: new Date(),\n        toolCalls: [],\n        toolResults: [],\n        filesChanged: [],\n        errors: [],\n      };\n      this.progressTracking.set(processId, progress);\n    }\n    \n    return progress;\n  }\n\n  private emitProgress(processId: string, progress: ExecutionProgress): void {\n    for (const handler of this.progressHandlers) {\n      handler(processId, progress);\n    }\n  }\n\n  private buildMetadata(progress: ExecutionProgress): ExecutionMetadata {\n    const toolsUsed = Array.from(\n      new Set(progress.toolCalls.map(tc => tc.name))\n    );\n    \n    const duration = progress.lastUpdate.getTime() - progress.startedAt.getTime();\n    \n    return {\n      toolsUsed,\n      filesChanged: progress.filesChanged,\n      tokensUsed: progress.usage?.totalTokens || 0,\n      cost: progress.usage?.cost || 0,\n      duration,\n    };\n  }\n\n  private calculateCost(usage: any): number {\n    // Simplified cost calculation\n    // Claude Sonnet pricing (example)\n    const inputCostPer1M = 3.00;\n    const outputCostPer1M = 15.00;\n    \n    const inputCost = (usage.input_tokens / 1000000) * inputCostPer1M;\n    const outputCost = (usage.output_tokens / 1000000) * outputCostPer1M;\n    \n    return inputCost + outputCost;\n  }\n\n  getProgress(processId: string): ExecutionProgress | null {\n    return this.progressTracking.get(processId) || null;\n  }\n\n  extractMetadata(messages: StreamMessage[]): ExecutionMetadata {\n    const toolCalls = this.extractToolCalls(messages);\n    const filesChanged = this.extractFileChanges(messages);\n    \n    let usage = { inputTokens: 0, outputTokens: 0, totalTokens: 0, cost: 0 };\n    \n    for (const message of messages) {\n      if (message.type === 'result' && message.data.usage) {\n        usage = {\n          inputTokens: message.data.usage.input_tokens || 0,\n          outputTokens: message.data.usage.output_tokens || 0,\n          totalTokens: message.data.usage.total_tokens || 0,\n          cost: this.calculateCost(message.data.usage),\n        };\n      }\n    }\n    \n    const toolsUsed = Array.from(new Set(toolCalls.map(tc => tc.name)));\n    \n    return {\n      toolsUsed,\n      filesChanged,\n      tokensUsed: usage.totalTokens,\n      cost: usage.cost,\n      duration: 0, // Would need start/end times\n    };\n  }\n\n  extractToolCalls(messages: StreamMessage[]): ToolCall[] {\n    const toolCalls: ToolCall[] = [];\n    \n    for (const message of messages) {\n      if (message.type === 'assistant' && message.data.message?.content) {\n        const contents = Array.isArray(message.data.message.content)\n          ? message.data.message.content\n          : [message.data.message.content];\n        \n        for (const content of contents) {\n          if (content.type === 'tool_use') {\n            toolCalls.push({\n              id: content.id,\n              name: content.name,\n              input: content.input,\n              timestamp: message.timestamp,\n            });\n          }\n        }\n      }\n    }\n    \n    return toolCalls;\n  }\n\n  extractFileChanges(messages: StreamMessage[]): string[] {\n    const files = new Set<string>();\n    const toolCalls = this.extractToolCalls(messages);\n    \n    for (const toolCall of toolCalls) {\n      if (toolCall.name === 'Write' || toolCall.name === 'Edit') {\n        const filePath = toolCall.input.file_path;\n        if (filePath) {\n          files.add(filePath);\n        }\n      }\n    }\n    \n    return Array.from(files);\n  }\n\n  // Event registration\n  onToolCall(handler: ToolCallHandler): void {\n    this.toolCallHandlers.push(handler);\n  }\n\n  onFileChange(handler: FileChangeHandler): void {\n    this.fileChangeHandlers.push(handler);\n  }\n\n  onProgress(handler: ProgressHandler): void {\n    this.progressHandlers.push(handler);\n  }\n\n  onError(handler: ErrorHandler): void {\n    this.errorHandlers.push(handler);\n  }\n\n  onComplete(handler: CompleteHandler): void {\n    this.completeHandlers.push(handler);\n  }\n\n  // Set current process for tracking\n  setCurrentProcess(processId: string): void {\n    this.currentProcessId = processId;\n  }\n}\n```\n\n## Usage Example\n\n```typescript\n// Create processor\nconst processor = new StreamJsonProcessor({\n  format: 'stream-json',\n  captureToolCalls: true,\n  captureFileChanges: true,\n  emitProgressEvents: true,\n});\n\n// Set up event listeners\nprocessor.onToolCall((processId, toolCall) => {\n  console.log(`[${processId}] Tool: ${toolCall.name}`, toolCall.input);\n});\n\nprocessor.onFileChange((processId, filePath) => {\n  console.log(`[${processId}] File changed: ${filePath}`);\n});\n\nprocessor.onProgress((processId, progress) => {\n  console.log(`[${processId}] Progress:`, {\n    toolCalls: progress.toolCalls.length,\n    filesChanged: progress.filesChanged.length,\n    activity: progress.currentActivity,\n  });\n});\n\nprocessor.onComplete((processId, metadata) => {\n  console.log(`[${processId}] Complete:`, metadata);\n});\n\n// Integrate with process manager\nconst processManager = new SimpleProcessManager();\nconst process = await processManager.acquireProcess({\n  claudePath: 'claude',\n  workDir: '/path/to/project',\n  args: {\n    print: true,\n    outputFormat: 'stream-json',\n    dangerouslySkipPermissions: true,\n  },\n});\n\nprocessor.setCurrentProcess(process.id);\n\n// Process output as it streams\nprocessManager.onOutput(process.id, (data, type) => {\n  if (type === 'stdout') {\n    const lines = data.toString().split('\\n');\n    for (const line of lines) {\n      processor.processLine(line);\n    }\n  }\n});\n\n// Send input\nawait processManager.sendInput(process.id, 'Fix the bug in auth.ts\\n');\n```\n\n## Testing Strategy\n\n### Unit Tests\n\n1. **JSON parsing**\n\n- Parses valid stream-json lines\n- Handles malformed JSON gracefully\n- Detects message types correctly\n\n1. **Metadata extraction**\n\n- Extracts tool calls from messages\n- Extracts file changes from Write/Edit tools\n- Calculates usage and cost correctly\n\n1. **Event emission**\n\n- Emits tool call events\n- Emits file change events\n- Emits progress events at interval\n\n### Integration Tests\n\n1. **End-to-end processing**\n\n- Process real Claude Code output\n- Track progress accurately\n- Extract complete metadata\n\n1. **Real-time streaming**\n\n- Handle partial lines\n- Process incomplete JSON\n- Buffer management\n\n## Future Enhancements\n\n1. **Format adapters** - Support text, JSON formats\n1. **Filtering** - Filter events by type/pattern\n1. **Aggregation** - Aggregate metrics across processes\n1. **Persistence** - Store output for replay\n1. **Compression** - Compress large outputs\n\n## File Structure\n\n```\nserver/src/execution/output/\n├── types.ts                    # Core types (StreamMessage, etc.)\n├── processor.ts                # IOutputProcessor interface\n├── stream-json-processor.ts    # StreamJsonProcessor (start here)\n├── text-processor.ts           # TextProcessor (future)\n└── utils.ts                    # JSON parsing, cost calculation\n```\n\n## Implementation Checklist\n\n- Define core types\n- Define IOutputProcessor interface\n- Implement StreamJsonProcessor\n- Add line-by-line JSON parsing\n- Add message type detection\n- Add tool call extraction\n- Add file change tracking\n- Add progress tracking\n- Add event emission\n- Add metadata extraction\n- Write unit tests\n- Write integration tests\n\n## Related Specs\n\n- Execution System (root spec)\n- [[SPEC-003]] - Process Layer (integrates with)\n- [[SPEC-004]] - Engine Layer\n- [[SPEC-005]] - Task Execution Layer\n- [[SPEC-006]] - Workflow Layer","priority":0,"archived":1,"archived_at":"2025-11-05T05:38:59.391Z","created_at":"2025-10-28 07:45:45","updated_at":"2025-11-05 08:55:52","parent_id":null,"parent_uuid":null,"relationships":[{"from":"SPEC-007","from_type":"spec","to":"SPEC-003","to_type":"spec","type":"references"},{"from":"SPEC-007","from_type":"spec","to":"SPEC-004","to_type":"spec","type":"references"},{"from":"SPEC-007","from_type":"spec","to":"SPEC-006","to_type":"spec","type":"references"}],"tags":["execution","layer-5","output-processing","parsing","streaming"]}
{"id":"SPEC-008","uuid":"1ece2c76-6874-4849-9dd4-1555b885ec88","title":"Inline Feedback Visualization for Spec Documents","file_path":"specs/inline_feedback_visualization_for_spec_documents.md","content":"\n# Inline Feedback Visualization for Spec Documents\n\n## Overview\n\nImplement a Google Docs-style feedback visualization system for spec documents that displays feedback inline with the document content or aligned in a side panel. This replaces the current separate column approach with a more integrated, contextual feedback experience.\n\n## Goals\n\n- **Contextual Feedback**: Show feedback aligned with the specific lines/sections it references\n- **Visual Clarity**: Use highlights and indicators to show where feedback exists\n- **Flexible Layout**: Support both general document comments and line-specific feedback\n- **Minimal Dependencies**: Leverage existing Tiptap editor without paid extensions\n- **Responsive Design**: Work across different screen sizes\n\n## Current State\n\nCurrently, `SpecDetailPage` displays feedback in a completely separate `SpecFeedbackPanel` column with no visual connection to the referenced content. Users must manually correlate feedback with document locations using line numbers.\n\n**Key files:**\n- `frontend/src/pages/SpecDetailPage.tsx` - Main spec view page\n- `frontend/src/components/specs/SpecFeedbackPanel.tsx` - Current feedback panel\n- `frontend/src/components/specs/TiptapEditor.tsx` - Rich text editor\n- `frontend/src/components/specs/SpecViewer.tsx` - Markdown source view\n\n## Proposed Design\n\n### Hybrid Approach: Margin Indicators + Aligned Side Panel\n\n```\n┌───────────────────────────────────────┬─────────────────────┐\n│                Spec Content           │ Feedback Panel      │\n│                                       │                     │\n│ # Introduction                        │ 💭 General Comments │\n│ This spec... [💬] ← highlighted       │   \"Overall good\"    │\n│                                       │                     │\n│ ## Architecture                       │ 💬 Line 6          │\n│ System design...                      │   \"Missing details\" │\n│ Implementation [💬] ← highlighted     │   ↑ aligned        │\n│                                       │                     │\n└───────────────────────────────────────┴─────────────────────┘\n```\n\n### Key Features\n\n1. **Inline Indicators**: Show 💬 emoji or icon at feedback locations\n2. **Text Highlighting**: Subtle background color on referenced text\n3. **Aligned Comments**: Side panel comments vertically aligned with their anchors\n4. **General Comments**: Unanchored feedback shown at top of panel\n5. **Interactive**: Click indicator or highlight to focus the comment\n\n## Technical Approach\n\n### Architecture Decision: Free Tiptap Features Only\n\nSince Tiptap's Collaboration and Comments extensions are paid features, we'll use:\n\n- ✅ **Custom Marks** - For text highlighting (free)\n- ✅ **ProseMirror Decorations** - For overlay indicators (free)\n- ✅ **Native DOM APIs** - For position tracking (`getBoundingClientRect`)\n- ✅ **React State** - For coordinating editor and panel\n\n### Component Structure\n\n```typescript\nSpecDetailPage\n├── SpecEditor (with feedback extensions)\n│   ├── TiptapEditor\n│   │   ├── FeedbackMark (highlight text)\n│   │   └── FeedbackDecorations (add indicators)\n│   └── Feedback indicators overlaid\n└── AlignedFeedbackPanel\n    ├── GeneralComments (no anchor)\n    └── AnchoredComments (positioned absolutely)\n```\n\n### Key Components\n\n1. **FeedbackMark** - Custom Tiptap mark extension for highlighting text with feedback\n2. **FeedbackDecorations** - ProseMirror plugin for adding clickable indicators\n3. **useFeedbackPositions** - React hook for tracking vertical positions\n4. **AlignedFeedbackPanel** - Component displaying comments aligned with document\n\n## Implementation Phases\n\n### Phase 1: Basic Infrastructure\n\n**Tasks:**\n- Create `FeedbackMark` Tiptap extension\n- Create `useFeedbackPositions` hook\n- Create `AlignedFeedbackPanel` component\n- Update `SpecDetailPage` layout for side-by-side view\n- Implement basic position tracking with scroll sync\n\n**Files to create:**\n- `frontend/src/components/specs/extensions/FeedbackMark.ts`\n- `frontend/src/hooks/useFeedbackPositions.ts`\n- `frontend/src/components/specs/AlignedFeedbackPanel.tsx`\n\n**Files to modify:**\n- `frontend/src/components/specs/TiptapEditor.tsx`\n- `frontend/src/pages/SpecDetailPage.tsx`\n\n**Deliverable**: Feedback panel shows comments aligned with rough positions\n\n### Phase 2: Decorations & Indicators\n\n**Tasks:**\n- Implement `FeedbackDecorations` extension\n- Add clickable indicators (💬) in document margins\n- Wire up click handlers to focus comments\n- Add hover states for highlights\n- Implement scroll-to-comment functionality\n\n**Files to create:**\n- `frontend/src/components/specs/extensions/FeedbackDecorations.ts`\n\n**Deliverable**: Visual indicators in document, clickable to show comments\n\n### Phase 3: Polish & Edge Cases\n\n**Tasks:**\n- Handle feedback without anchors (general comments)\n- Handle stale anchors (content changed, line moved)\n- Optimize position updates (debouncing, throttling)\n- Add transitions/animations for smooth UX\n- Test with long documents and many comments\n- Mobile responsive behavior (stack instead of side-by-side)\n\n**Deliverable**: Production-ready feature with edge cases handled\n\n### Phase 4: Advanced Features (Optional)\n\n**Tasks:**\n- Filter comments by type in side panel\n- Show/hide resolved comments\n- Keyboard navigation between comments\n- Minimap showing comment distribution\n- Export with comment indicators\n\n## Technical Considerations\n\n### Anchor Resolution\n\nWhen feedback has an anchor, resolve the position using this priority:\n\n1. **Exact text match**: Search for `anchor.text_snippet` in document\n2. **Line number**: Fall back to `anchor.line_number` if text moved\n3. **Section heading**: Use `anchor.section_heading` as last resort\n4. **Mark as stale**: If none match, show in \"Stale Comments\" section\n\n### Performance\n\n- **Debounce position updates**: 100ms delay on scroll/resize\n- **Memoize calculations**: Use `useMemo` for filtered feedback lists\n- **Virtual scrolling**: If >50 comments, consider virtualization\n- **Lazy decorations**: Only create decorations for visible viewport\n\n### View Modes\n\nSupport both Formatted (Tiptap) and Markdown views:\n\n- **Formatted**: Use Tiptap marks and decorations\n- **Markdown**: Show indicators in line number gutter\n\n## Dependencies\n\n**No new dependencies required** - uses existing:\n- `@tiptap/react` (already installed)\n- `@tiptap/core` (already installed)\n- Native browser APIs (`getBoundingClientRect`, `IntersectionObserver`)\n- React hooks (`useState`, `useEffect`, `useRef`)\n\n**Optional lightweight additions** (if needed):\n- `floating-ui` (7kb) - For smarter popover positioning\n- `react-intersection-observer` (3.5kb) - For performance optimization\n\n## Success Metrics\n\n- Feedback is visually connected to document locations\n- Users can quickly identify which content has feedback\n- Position sync is smooth and performant (no jank on scroll)\n- Works in both Formatted and Markdown view modes\n- Mobile experience is usable (stacked or simplified layout)\n","priority":1,"archived":1,"archived_at":"2025-11-05T05:39:21.988Z","created_at":"2025-10-29 10:10:27","updated_at":"2025-11-05 05:39:21","parent_id":null,"parent_uuid":null,"relationships":[],"tags":["feedback","frontend","tiptap","ui/ux"]}
{"id":"SPEC-009","uuid":"8ef5d62f-6681-4207-a088-230caae2e884","title":"AG-UI Protocol Integration","file_path":"specs/ag_ui_protocol_integration.md","content":"# AG-UI Protocol Integration Specification\n\n## Overview\n\nThis specification details the integration of the AG-UI (Agent-User Interaction) Protocol into the sudocode execution system. AG-UI is a lightweight, event-based protocol that standardizes how AI agents connect to user-facing applications, enabling real-time streaming of agent execution state to frontend applications.\n\nThis spec builds on **SPEC-007 (Output Processing Layer)** which provides the foundation for parsing agent output into structured `StreamMessage` format. The AG-UI integration adds a second transformation layer that converts these generic messages into standardized AG-UI events.\n\n**Transformation Flow:**\n\n```\nRaw Agent Output → [SPEC-007] → StreamMessage → [SPEC-009] → AgUiEvent → SSE → Frontend\n                    OutputProcessor              AgUiAdapter\n```\n\nThe integration consists of three main layers:\n\n1. **AG-UI Adapter Layer**: Transforms `StreamMessage` (from SPEC-007) into standardized AG-UI events\n1. **SSE Transport Layer**: Streams AG-UI events to frontend via Server-Sent Events\n1. **Frontend Integration**: Consumes and displays AG-UI events in real-time\n\n## Design Goals\n\n1. **Standardized**: Use AG-UI's 17 event types for consistent agent communication\n1. **Real-time**: Stream events as they occur, not after completion\n1. **Multi-Agent Ready**: Support any AG-UI compatible agent (Claude Code, Cursor, etc.)\n1. **SSE-based**: Stream events via Server-Sent Events for simplicity and native browser support\n1. **Type-Safe**: Full TypeScript typing with Zod validation\n1. **Observable**: Complete visibility into agent execution lifecycle\n1. **Layered**: Clean separation between parsing (SPEC-007) and protocol transformation (SPEC-009)\n\n## Architecture\n\n```\n┌──────────────────────────────────────────────────────────────┐\n│                 Frontend (React)                             │\n├──────────────────────────────────────────────────────────────┤\n│                                                              │\n│  ┌────────────────────┐     ┌──────────────────────────┐   │\n│  │  useAgUiStream()   │────▶│  ExecutionMonitor        │   │\n│  │  Hook              │     │  Component               │   │\n│  └────────┬───────────┘     └──────────────────────────┘   │\n│           │                                                  │\n│           │ EventSource (SSE)                               │\n│           │                                                  │\n└───────────┼──────────────────────────────────────────────────┘\n            │\n            │ Server-Sent Events\n            ▼\n┌──────────────────────────────────────────────────────────────┐\n│            SSE Transport Layer (Server)                      │\n├──────────────────────────────────────────────────────────────┤\n│                                                              │\n│              ┌─────────────────────┐                        │\n│              │   SseTransport      │                        │\n│              │   (EventStream)     │                        │\n│              └─────────┬───────────┘                        │\n│                        │                                     │\n└────────────────────────┼────────────────────────────────────┘\n                         │\n                         │ AG-UI Events\n                         ▼\n┌──────────────────────────────────────────────────────────────┐\n│            AG-UI Adapter Layer (Server)                      │\n├──────────────────────────────────────────────────────────────┤\n│                                                              │\n│  ┌────────────────────────────────────────────────────────┐ │\n│  │         AgUiEventAdapter                               │ │\n│  │                                                        │ │\n│  │  Transforms StreamMessage → AgUiEvent                 │ │\n│  │                                                        │ │\n│  │  ┌──────────────┐  ┌──────────────┐  ┌─────────────┐ │ │\n│  │  │ Tool Call    │  │ Message      │  │ State       │ │ │\n│  │  │ Mapper       │  │ Mapper       │  │ Mapper      │ │ │\n│  │  └──────────────┘  └──────────────┘  └─────────────┘ │ │\n│  └────────────┬───────────────────────────────────────────┘ │\n│               │                                             │\n└───────────────┼─────────────────────────────────────────────┘\n                │\n                │ StreamMessage (SPEC-007)\n                ▼\n┌──────────────────────────────────────────────────────────────┐\n│     Output Processing Layer (SPEC-007)                       │\n├──────────────────────────────────────────────────────────────┤\n│                                                              │\n│  ┌────────────────────────────────────────────────────────┐ │\n│  │         StreamJsonProcessor                            │ │\n│  │                                                        │ │\n│  │  Parses Raw Output → StreamMessage                    │ │\n│  │                                                        │ │\n│  │  Types: assistant | tool_use | tool_result | error   │ │\n│  └────────────┬───────────────────────────────────────────┘ │\n│               │                                             │\n└───────────────┼─────────────────────────────────────────────┘\n                │\n                │ Raw stdout/stderr\n                ▼\n┌──────────────────────────────────────────────────────────────┐\n│     Process Layer (SPEC-003)                                 │\n├──────────────────────────────────────────────────────────────┤\n│  SimpleProcessManager │ LinearOrchestrator (SPEC-006)       │\n└──────────────────────────────────────────────────────────────┘\n```\n\n**Layer Responsibilities:**\n\n- **SPEC-003 (Process Layer)**: Spawns agent process, captures raw output\n- **SPEC-007 (Output Processing)**: Parses raw output into `StreamMessage` format\n- **SPEC-009 (AG-UI Adapter)**: Transforms `StreamMessage` into AG-UI events\n- **SSE Transport**: Broadcasts AG-UI events to connected clients\n- **Frontend**: Consumes and displays events in real-time\n\n## Part 1: AG-UI Adapter Layer\n\n### Core Types\n\n#### AG-UI Event Types Enum\n\n```typescript\nexport enum AgUiEventType {\n  // Lifecycle Events\n  RUN_STARTED = 'RUN_STARTED',\n  RUN_FINISHED = 'RUN_FINISHED',\n  RUN_ERROR = 'RUN_ERROR',\n  STEP_STARTED = 'STEP_STARTED',\n  STEP_FINISHED = 'STEP_FINISHED',\n\n  // Text Message Events\n  TEXT_MESSAGE_START = 'TEXT_MESSAGE_START',\n  TEXT_MESSAGE_CONTENT = 'TEXT_MESSAGE_CONTENT',\n  TEXT_MESSAGE_END = 'TEXT_MESSAGE_END',\n\n  // Tool Call Events\n  TOOL_CALL_START = 'TOOL_CALL_START',\n  TOOL_CALL_ARGS = 'TOOL_CALL_ARGS',\n  TOOL_CALL_END = 'TOOL_CALL_END',\n  TOOL_CALL_RESULT = 'TOOL_CALL_RESULT',\n\n  // State Management Events\n  STATE_SNAPSHOT = 'STATE_SNAPSHOT',\n  STATE_DELTA = 'STATE_DELTA',\n  MESSAGES_SNAPSHOT = 'MESSAGES_SNAPSHOT',\n\n  // Special Events\n  RAW = 'RAW',\n  CUSTOM = 'CUSTOM',\n}\n```\n\n#### Base Event Schema\n\n```typescript\nimport { z } from 'zod';\n\nexport const BaseEventSchema = z.object({\n  type: z.nativeEnum(AgUiEventType),\n  timestamp: z.number().optional(),\n  rawEvent: z.any().optional(),\n});\n\nexport type BaseEvent = z.infer<typeof BaseEventSchema>;\n```\n\n#### Lifecycle Event Schemas\n\n```typescript\n// RUN_STARTED\nexport const RunStartedEventSchema = BaseEventSchema.extend({\n  type: z.literal(AgUiEventType.RUN_STARTED),\n  runId: z.string(),\n  threadId: z.string().optional(),\n  workflowId: z.string().optional(),\n});\n\nexport type RunStartedEvent = z.infer<typeof RunStartedEventSchema>;\n\n// RUN_FINISHED\nexport const RunFinishedEventSchema = BaseEventSchema.extend({\n  type: z.literal(AgUiEventType.RUN_FINISHED),\n  runId: z.string(),\n  result: z.any().optional(),\n});\n\nexport type RunFinishedEvent = z.infer<typeof RunFinishedEventSchema>;\n\n// RUN_ERROR\nexport const RunErrorEventSchema = BaseEventSchema.extend({\n  type: z.literal(AgUiEventType.RUN_ERROR),\n  runId: z.string(),\n  error: z.object({\n    message: z.string(),\n    code: z.string().optional(),\n    stack: z.string().optional(),\n  }),\n});\n\nexport type RunErrorEvent = z.infer<typeof RunErrorEventSchema>;\n\n// STEP_STARTED\nexport const StepStartedEventSchema = BaseEventSchema.extend({\n  type: z.literal(AgUiEventType.STEP_STARTED),\n  runId: z.string(),\n  stepId: z.string(),\n  stepName: z.string(),\n});\n\nexport type StepStartedEvent = z.infer<typeof StepStartedEventSchema>;\n\n// STEP_FINISHED\nexport const StepFinishedEventSchema = BaseEventSchema.extend({\n  type: z.literal(AgUiEventType.STEP_FINISHED),\n  runId: z.string(),\n  stepId: z.string(),\n  status: z.enum(['success', 'error']),\n  output: z.any().optional(),\n});\n\nexport type StepFinishedEvent = z.infer<typeof StepFinishedEventSchema>;\n```\n\n#### Text Message Event Schemas\n\n```typescript\n// TEXT_MESSAGE_START\nexport const TextMessageStartEventSchema = BaseEventSchema.extend({\n  type: z.literal(AgUiEventType.TEXT_MESSAGE_START),\n  messageId: z.string(),\n  role: z.enum(['assistant', 'user', 'system']),\n});\n\nexport type TextMessageStartEvent = z.infer<typeof TextMessageStartEventSchema>;\n\n// TEXT_MESSAGE_CONTENT\nexport const TextMessageContentEventSchema = BaseEventSchema.extend({\n  type: z.literal(AgUiEventType.TEXT_MESSAGE_CONTENT),\n  messageId: z.string(),\n  delta: z.string(),\n});\n\nexport type TextMessageContentEvent = z.infer<typeof TextMessageContentEventSchema>;\n\n// TEXT_MESSAGE_END\nexport const TextMessageEndEventSchema = BaseEventSchema.extend({\n  type: z.literal(AgUiEventType.TEXT_MESSAGE_END),\n  messageId: z.string(),\n});\n\nexport type TextMessageEndEvent = z.infer<typeof TextMessageEndEventSchema>;\n```\n\n#### Tool Call Event Schemas\n\n```typescript\n// TOOL_CALL_START\nexport const ToolCallStartEventSchema = BaseEventSchema.extend({\n  type: z.literal(AgUiEventType.TOOL_CALL_START),\n  toolCallId: z.string(),\n  toolCallName: z.string(),\n  parentMessageId: z.string().optional(),\n});\n\nexport type ToolCallStartEvent = z.infer<typeof ToolCallStartEventSchema>;\n\n// TOOL_CALL_ARGS\nexport const ToolCallArgsEventSchema = BaseEventSchema.extend({\n  type: z.literal(AgUiEventType.TOOL_CALL_ARGS),\n  toolCallId: z.string(),\n  delta: z.string(), // JSON fragment\n});\n\nexport type ToolCallArgsEvent = z.infer<typeof ToolCallArgsEventSchema>;\n\n// TOOL_CALL_END\nexport const ToolCallEndEventSchema = BaseEventSchema.extend({\n  type: z.literal(AgUiEventType.TOOL_CALL_END),\n  toolCallId: z.string(),\n});\n\nexport type ToolCallEndEvent = z.infer<typeof ToolCallEndEventSchema>;\n\n// TOOL_CALL_RESULT\nexport const ToolCallResultEventSchema = BaseEventSchema.extend({\n  type: z.literal(AgUiEventType.TOOL_CALL_RESULT),\n  messageId: z.string(),\n  toolCallId: z.string(),\n  content: z.string(),\n  role: z.literal('tool').optional(),\n});\n\nexport type ToolCallResultEvent = z.infer<typeof ToolCallResultEventSchema>;\n```\n\n#### State Management Event Schemas\n\n```typescript\n// STATE_SNAPSHOT\nexport const StateSnapshotEventSchema = BaseEventSchema.extend({\n  type: z.literal(AgUiEventType.STATE_SNAPSHOT),\n  runId: z.string(),\n  state: z.record(z.any()),\n});\n\nexport type StateSnapshotEvent = z.infer<typeof StateSnapshotEventSchema>;\n\n// STATE_DELTA (JSON Patch RFC 6902)\nexport const JsonPatchOperationSchema = z.object({\n  op: z.enum(['add', 'remove', 'replace', 'move', 'copy', 'test']),\n  path: z.string(),\n  value: z.any().optional(),\n  from: z.string().optional(),\n});\n\nexport const StateDeltaEventSchema = BaseEventSchema.extend({\n  type: z.literal(AgUiEventType.STATE_DELTA),\n  runId: z.string(),\n  delta: z.array(JsonPatchOperationSchema),\n});\n\nexport type StateDeltaEvent = z.infer<typeof StateDeltaEventSchema>;\n\n// MESSAGES_SNAPSHOT\nexport const MessageSchema = z.object({\n  id: z.string(),\n  role: z.enum(['user', 'assistant', 'system', 'tool']),\n  content: z.string(),\n  timestamp: z.string().optional(),\n});\n\nexport const MessagesSnapshotEventSchema = BaseEventSchema.extend({\n  type: z.literal(AgUiEventType.MESSAGES_SNAPSHOT),\n  runId: z.string(),\n  messages: z.array(MessageSchema),\n});\n\nexport type MessagesSnapshotEvent = z.infer<typeof MessagesSnapshotEventSchema>;\n```\n\n#### Custom and Raw Event Schemas\n\n```typescript\n// RAW\nexport const RawEventSchema = BaseEventSchema.extend({\n  type: z.literal(AgUiEventType.RAW),\n  event: z.any(),\n  source: z.string().optional(),\n});\n\nexport type RawEvent = z.infer<typeof RawEventSchema>;\n\n// CUSTOM\nexport const CustomEventSchema = BaseEventSchema.extend({\n  type: z.literal(AgUiEventType.CUSTOM),\n  name: z.string(),\n  value: z.any(),\n});\n\nexport type CustomEvent = z.infer<typeof CustomEventSchema>;\n```\n\n#### Discriminated Union\n\n```typescript\nexport const AgUiEventSchema = z.discriminatedUnion('type', [\n  RunStartedEventSchema,\n  RunFinishedEventSchema,\n  RunErrorEventSchema,\n  StepStartedEventSchema,\n  StepFinishedEventSchema,\n  TextMessageStartEventSchema,\n  TextMessageContentEventSchema,\n  TextMessageEndEventSchema,\n  ToolCallStartEventSchema,\n  ToolCallArgsEventSchema,\n  ToolCallEndEventSchema,\n  ToolCallResultEventSchema,\n  StateSnapshotEventSchema,\n  StateDeltaEventSchema,\n  MessagesSnapshotEventSchema,\n  RawEventSchema,\n  CustomEventSchema,\n]);\n\nexport type AgUiEvent = z.infer<typeof AgUiEventSchema>;\n```\n\n### AG-UI Event Adapter Implementation\n\nThe `AgUiEventAdapter` is the core component that transforms `StreamMessage` objects (from SPEC-007's `OutputProcessor`) into AG-UI events. It subscribes to the output processor's event stream and maps each message type to the appropriate AG-UI event(s).\n\n**Key Principle**: This adapter is protocol-agnostic at its input (works with any `StreamMessage` source) and protocol-specific at its output (emits AG-UI events).\n\n```typescript\n// server/src/execution/output/ag-ui-adapter.ts\nimport { StreamMessage, ExecutionProgress } from './types.js';\nimport { AgUiEvent, AgUiEventType } from './ag-ui-types.js';\nimport { generateId } from '../utils.js';\n\nexport class AgUiEventAdapter {\n  private listeners: Array<(event: AgUiEvent) => void> = [];\n  private messageBuffers = new Map<string, string[]>();\n  private toolCallBuffers = new Map<string, string>();\n\n  constructor() {}\n\n  /**\n   * Transform a StreamMessage from Claude Code into AG-UI events\n   */\n  transformStreamMessage(\n    message: StreamMessage,\n    processId: string\n  ): AgUiEvent[] {\n    const events: AgUiEvent[] = [];\n\n    switch (message.type) {\n      case 'assistant':\n        events.push(...this.handleAssistantMessage(message, processId));\n        break;\n      case 'tool_use':\n        events.push(...this.handleToolUse(message, processId));\n        break;\n      case 'tool_result':\n        events.push(...this.handleToolResult(message, processId));\n        break;\n      case 'result':\n        events.push(...this.handleResult(message, processId));\n        break;\n      case 'error':\n        events.push(...this.handleError(message, processId));\n        break;\n    }\n\n    // Emit all events\n    events.forEach(event => this.emit(event));\n\n    return events;\n  }\n\n  /**\n   * Handle Claude assistant messages\n   */\n  private handleAssistantMessage(\n    message: StreamMessage,\n    processId: string\n  ): AgUiEvent[] {\n    const events: AgUiEvent[] = [];\n    const contents = Array.isArray(message.data.message?.content)\n      ? message.data.message.content\n      : [message.data.message?.content];\n\n    for (const content of contents) {\n      if (!content) continue;\n\n      if (content.type === 'text') {\n        // Text message: START → CONTENT → END\n        const messageId = generateId('msg');\n\n        events.push({\n          type: AgUiEventType.TEXT_MESSAGE_START,\n          messageId,\n          role: 'assistant',\n          timestamp: Date.now(),\n        });\n\n        events.push({\n          type: AgUiEventType.TEXT_MESSAGE_CONTENT,\n          messageId,\n          delta: content.text,\n          timestamp: Date.now(),\n        });\n\n        events.push({\n          type: AgUiEventType.TEXT_MESSAGE_END,\n          messageId,\n          timestamp: Date.now(),\n        });\n      } else if (content.type === 'tool_use') {\n        // Tool call: START → ARGS → END\n        const toolCallId = content.id || generateId('tool');\n\n        events.push({\n          type: AgUiEventType.TOOL_CALL_START,\n          toolCallId,\n          toolCallName: content.name,\n          timestamp: Date.now(),\n        });\n\n        // Serialize arguments as JSON\n        const argsJson = JSON.stringify(content.input);\n        events.push({\n          type: AgUiEventType.TOOL_CALL_ARGS,\n          toolCallId,\n          delta: argsJson,\n          timestamp: Date.now(),\n        });\n\n        events.push({\n          type: AgUiEventType.TOOL_CALL_END,\n          toolCallId,\n          timestamp: Date.now(),\n        });\n      }\n    }\n\n    return events;\n  }\n\n  /**\n   * Handle tool usage events\n   */\n  private handleToolUse(\n    message: StreamMessage,\n    processId: string\n  ): AgUiEvent[] {\n    const toolCallId = message.data.id || generateId('tool');\n\n    return [\n      {\n        type: AgUiEventType.TOOL_CALL_START,\n        toolCallId,\n        toolCallName: message.data.name,\n        timestamp: Date.now(),\n      },\n      {\n        type: AgUiEventType.TOOL_CALL_ARGS,\n        toolCallId,\n        delta: JSON.stringify(message.data.input),\n        timestamp: Date.now(),\n      },\n      {\n        type: AgUiEventType.TOOL_CALL_END,\n        toolCallId,\n        timestamp: Date.now(),\n      },\n    ];\n  }\n\n  /**\n   * Handle tool result events\n   */\n  private handleToolResult(\n    message: StreamMessage,\n    processId: string\n  ): AgUiEvent[] {\n    const messageId = generateId('msg');\n    const toolCallId = message.data.tool_use_id || message.data.id;\n\n    return [\n      {\n        type: AgUiEventType.TOOL_CALL_RESULT,\n        messageId,\n        toolCallId,\n        content: JSON.stringify(message.data.content),\n        role: 'tool',\n        timestamp: Date.now(),\n      },\n    ];\n  }\n\n  /**\n   * Handle execution result (final usage stats)\n   */\n  private handleResult(\n    message: StreamMessage,\n    processId: string\n  ): AgUiEvent[] {\n    // Could emit a CUSTOM event with usage stats\n    return [\n      {\n        type: AgUiEventType.CUSTOM,\n        name: 'usage_stats',\n        value: {\n          usage: message.data.usage,\n          cost: this.calculateCost(message.data.usage),\n        },\n        timestamp: Date.now(),\n      },\n    ];\n  }\n\n  /**\n   * Handle error events\n   */\n  private handleError(\n    message: StreamMessage,\n    processId: string\n  ): AgUiEvent[] {\n    const error = message.data.error || message.data;\n\n    return [\n      {\n        type: AgUiEventType.RUN_ERROR,\n        runId: processId,\n        error: {\n          message: error.message || error.toString(),\n          code: error.code,\n          stack: error.stack,\n        },\n        timestamp: Date.now(),\n      },\n    ];\n  }\n\n  /**\n   * Emit progress update as STATE_DELTA\n   */\n  emitProgressDelta(progress: ExecutionProgress): void {\n    const event: AgUiEvent = {\n      type: AgUiEventType.STATE_DELTA,\n      runId: progress.processId,\n      delta: [\n        {\n          op: 'replace',\n          path: '/progress',\n          value: {\n            toolCalls: progress.toolCalls.length,\n            filesChanged: progress.filesChanged,\n            currentActivity: progress.currentActivity,\n          },\n        },\n      ],\n      timestamp: Date.now(),\n    };\n\n    this.emit(event);\n  }\n\n  /**\n   * Emit state snapshot\n   */\n  emitStateSnapshot(runId: string, state: Record<string, any>): void {\n    const event: AgUiEvent = {\n      type: AgUiEventType.STATE_SNAPSHOT,\n      runId,\n      state,\n      timestamp: Date.now(),\n    };\n\n    this.emit(event);\n  }\n\n  /**\n   * Register event listener\n   */\n  onEvent(listener: (event: AgUiEvent) => void): void {\n    this.listeners.push(listener);\n  }\n\n  /**\n   * Remove event listener\n   */\n  offEvent(listener: (event: AgUiEvent) => void): void {\n    const index = this.listeners.indexOf(listener);\n    if (index >= 0) {\n      this.listeners.splice(index, 1);\n    }\n  }\n\n  /**\n   * Emit event to all listeners\n   */\n  private emit(event: AgUiEvent): void {\n    this.listeners.forEach(listener => {\n      try {\n        listener(event);\n      } catch (error) {\n        console.error('Error in AG-UI event listener:', error);\n      }\n    });\n  }\n\n  private calculateCost(usage: any): number {\n    // Simplified cost calculation\n    const inputCostPer1M = 3.0;\n    const outputCostPer1M = 15.0;\n\n    const inputCost = (usage.input_tokens / 1000000) * inputCostPer1M;\n    const outputCost = (usage.output_tokens / 1000000) * outputCostPer1M;\n\n    return inputCost + outputCost;\n  }\n}\n```\n\n### Integration with SPEC-007 Output Processor\n\nThe AgUiAdapter integrates with SPEC-007's `StreamJsonProcessor` by subscribing to its output messages. This creates a clean pipeline where SPEC-007 handles parsing and SPEC-009 handles protocol transformation.\n\n**Pattern**: Wire the output processor's message events to the AG-UI adapter's transformation method.\n\n```typescript\n// server/src/execution/output/ag-ui-integration.ts\nimport { StreamJsonProcessor } from './stream-json-processor.js';\nimport { AgUiEventAdapter } from './ag-ui-adapter.js';\n\n/**\n * Wire SPEC-007's output processor to SPEC-009's AG-UI adapter\n */\nexport function createAgUiPipeline(\n  processor: StreamJsonProcessor,\n  adapter: AgUiEventAdapter,\n  processId: string\n): void {\n  // Subscribe to processor's message stream\n  // Note: This requires adding a message event to StreamJsonProcessor\n  processor.onMessage?.((message: StreamMessage) => {\n    adapter.transformStreamMessage(message, processId);\n  });\n\n  // Alternative: If StreamJsonProcessor doesn't have onMessage,\n  // wrap its processLine method\n  const originalProcessLine = processor.processLine.bind(processor);\n  processor.processLine = (line: string) => {\n    const message = originalProcessLine(line);\n    if (message) {\n      adapter.transformStreamMessage(message, processId);\n    }\n    return message;\n  };\n}\n\n/**\n * Factory function to create a complete AG-UI pipeline\n */\nexport function createAgUiSystem(processId: string) {\n  const processor = new StreamJsonProcessor({\n    format: 'stream-json',\n    captureToolCalls: true,\n    captureFileChanges: true,\n    emitProgressEvents: true,\n  });\n\n  const adapter = new AgUiEventAdapter();\n\n  // Wire them together\n  createAgUiPipeline(processor, adapter, processId);\n\n  return { processor, adapter };\n}\n```\n\n**Usage Example:**\n\n```typescript\n// Create the pipeline\nconst { processor, adapter } = createAgUiSystem('process-123');\n\n// Connect adapter to SSE transport\nconst sseTransport = new SseTransport();\nadapter.onEvent(event => {\n  sseTransport.broadcastToRun('process-123', event);\n});\n\n// Feed raw output from process manager\nprocessManager.onOutput('process-123', (data, type) => {\n  if (type === 'stdout') {\n    const lines = data.toString().split('\\n');\n    for (const line of lines) {\n      processor.processLine(line); // → StreamMessage → AgUiEvent → SSE\n    }\n  }\n});\n```\n\n### Integration with LinearOrchestrator\n\n```typescript\n// server/src/execution/workflow/linear-orchestrator.ts (MODIFIED)\nimport { AgUiEventAdapter } from '../output/ag-ui-adapter.js';\nimport { AgUiEventType } from '../output/ag-ui-types.js';\n\nexport class LinearOrchestrator implements IWorkflowOrchestrator {\n  private agUiAdapter: AgUiEventAdapter;\n\n  constructor(\n    private executor: IResilientExecutor,\n    private storage?: IWorkflowStorage,\n    agUiAdapter?: AgUiEventAdapter\n  ) {\n    this.agUiAdapter = agUiAdapter || new AgUiEventAdapter();\n  }\n\n  async startWorkflow(\n    workflow: WorkflowDefinition,\n    initialContext?: Partial<WorkflowContext>\n  ): Promise<string> {\n    const execution = /* ... create execution ... */;\n\n    // Emit RUN_STARTED\n    this.agUiAdapter.onEvent({\n      type: AgUiEventType.RUN_STARTED,\n      runId: execution.id,\n      threadId: workflow.id,\n      workflowId: workflow.id,\n      timestamp: Date.now(),\n    });\n\n    this.executeWorkflow(workflow, execution).catch(error => {\n      // Emit RUN_ERROR\n      this.agUiAdapter.onEvent({\n        type: AgUiEventType.RUN_ERROR,\n        runId: execution.id,\n        error: {\n          message: error.message,\n          stack: error.stack,\n        },\n        timestamp: Date.now(),\n      });\n    });\n\n    return execution.id;\n  }\n\n  private async executeWorkflow(\n    workflow: WorkflowDefinition,\n    execution: WorkflowExecution,\n    startFromStep?: string\n  ): Promise<void> {\n    execution.status = 'running';\n\n    for (let i = startIndex; i < workflow.steps.length; i++) {\n      const step = workflow.steps[i];\n\n      // Emit STEP_STARTED\n      this.agUiAdapter.onEvent({\n        type: AgUiEventType.STEP_STARTED,\n        runId: execution.id,\n        stepId: step.id,\n        stepName: step.name,\n        timestamp: Date.now(),\n      });\n\n      try {\n        const result = await this.executeStep(step, execution, workflow);\n\n        // Emit STEP_FINISHED\n        this.agUiAdapter.onEvent({\n          type: AgUiEventType.STEP_FINISHED,\n          runId: execution.id,\n          stepId: step.id,\n          status: 'success',\n          output: result,\n          timestamp: Date.now(),\n        });\n\n        // ... existing checkpoint logic\n      } catch (error) {\n        // Emit STEP_FINISHED with error\n        this.agUiAdapter.onEvent({\n          type: AgUiEventType.STEP_FINISHED,\n          runId: execution.id,\n          stepId: step.id,\n          status: 'error',\n          timestamp: Date.now(),\n        });\n\n        throw error;\n      }\n    }\n\n    // Emit RUN_FINISHED\n    this.agUiAdapter.onEvent({\n      type: AgUiEventType.RUN_FINISHED,\n      runId: execution.id,\n      result: {\n        completedSteps: execution.completedSteps.length,\n        outputs: execution.context.outputs,\n      },\n      timestamp: Date.now(),\n    });\n  }\n\n  /**\n   * Get AG-UI adapter for transport layer\n   */\n  getAgUiAdapter(): AgUiEventAdapter {\n    return this.agUiAdapter;\n  }\n}\n```\n\n## Part 2: AG-UI Transport Layer\n\n### Server-Sent Events (SSE) Transport\n\n```typescript\n// server/src/execution/transport/sse-transport.ts\nimport { Response } from 'express';\nimport { AgUiEvent } from '../output/ag-ui-types.js';\n\nexport interface SseClient {\n  id: string;\n  response: Response;\n  runId?: string;\n  connectedAt: Date;\n}\n\nexport class SseTransport {\n  private clients = new Map<string, SseClient>();\n  private heartbeatInterval: NodeJS.Timeout | null = null;\n\n  constructor(\n    private heartbeatIntervalMs: number = 30000 // 30 seconds\n  ) {\n    this.startHeartbeat();\n  }\n\n  /**\n   * Handle new SSE connection\n   */\n  handleConnection(\n    clientId: string,\n    res: Response,\n    runId?: string\n  ): void {\n    // Set SSE headers\n    res.writeHead(200, {\n      'Content-Type': 'text/event-stream',\n      'Cache-Control': 'no-cache, no-transform',\n      'Connection': 'keep-alive',\n      'X-Accel-Buffering': 'no', // Disable nginx buffering\n    });\n\n    // Create client\n    const client: SseClient = {\n      id: clientId,\n      response: res,\n      runId,\n      connectedAt: new Date(),\n    };\n\n    this.clients.set(clientId, client);\n\n    // Handle client disconnect\n    res.on('close', () => {\n      this.removeClient(clientId);\n    });\n\n    // Send initial connection event\n    this.sendToClient(clientId, {\n      type: AgUiEventType.CUSTOM,\n      name: 'connection_established',\n      value: { clientId, runId },\n      timestamp: Date.now(),\n    });\n  }\n\n  /**\n   * Send event to specific client\n   */\n  sendToClient(clientId: string, event: AgUiEvent): boolean {\n    const client = this.clients.get(clientId);\n    if (!client) return false;\n\n    try {\n      const data = JSON.stringify(event);\n      client.response.write(`event: ${event.type}\\n`);\n      client.response.write(`data: ${data}\\n\\n`);\n      return true;\n    } catch (error) {\n      console.error(`Error sending event to client ${clientId}:`, error);\n      this.removeClient(clientId);\n      return false;\n    }\n  }\n\n  /**\n   * Broadcast event to all clients\n   */\n  broadcast(event: AgUiEvent): void {\n    this.clients.forEach((client, clientId) => {\n      this.sendToClient(clientId, event);\n    });\n  }\n\n  /**\n   * Broadcast event to clients subscribed to specific run\n   */\n  broadcastToRun(runId: string, event: AgUiEvent): void {\n    this.clients.forEach((client, clientId) => {\n      if (client.runId === runId) {\n        this.sendToClient(clientId, event);\n      }\n    });\n  }\n\n  /**\n   * Remove client\n   */\n  removeClient(clientId: string): void {\n    const client = this.clients.get(clientId);\n    if (client) {\n      try {\n        client.response.end();\n      } catch (error) {\n        // Ignore errors when ending response\n      }\n      this.clients.delete(clientId);\n    }\n  }\n\n  /**\n   * Start heartbeat to keep connections alive\n   */\n  private startHeartbeat(): void {\n    this.heartbeatInterval = setInterval(() => {\n      this.clients.forEach((client, clientId) => {\n        try {\n          client.response.write(': heartbeat\\n\\n');\n        } catch (error) {\n          this.removeClient(clientId);\n        }\n      });\n    }, this.heartbeatIntervalMs);\n  }\n\n  /**\n   * Stop heartbeat\n   */\n  stopHeartbeat(): void {\n    if (this.heartbeatInterval) {\n      clearInterval(this.heartbeatInterval);\n      this.heartbeatInterval = null;\n    }\n  }\n\n  /**\n   * Get active client count\n   */\n  getClientCount(): number {\n    return this.clients.size;\n  }\n\n  /**\n   * Cleanup all clients\n   */\n  shutdown(): void {\n    this.stopHeartbeat();\n    this.clients.forEach((client, clientId) => {\n      this.removeClient(clientId);\n    });\n  }\n}\n```\n\n### Transport Manager\n\nSimplified transport manager that coordinates SSE transport with AG-UI adapter.\n\n```typescript\n// server/src/execution/transport/transport-manager.ts\nimport { AgUiEvent } from '../output/ag-ui-types.js';\nimport { AgUiEventAdapter } from '../output/ag-ui-adapter.js';\nimport { SseTransport } from './sse-transport.js';\n\nexport class TransportManager {\n  private sseTransport: SseTransport;\n\n  constructor() {\n    this.sseTransport = new SseTransport();\n  }\n\n  /**\n   * Connect AG-UI adapter to SSE transport\n   */\n  connectAdapter(adapter: AgUiEventAdapter, runId?: string): void {\n    adapter.onEvent((event: AgUiEvent) => {\n      if (runId) {\n        this.broadcastToRun(runId, event);\n      } else {\n        this.broadcast(event);\n      }\n    });\n  }\n\n  /**\n   * Broadcast event to all clients\n   */\n  broadcast(event: AgUiEvent): void {\n    this.sseTransport.broadcast(event);\n  }\n\n  /**\n   * Broadcast to specific run\n   */\n  broadcastToRun(runId: string, event: AgUiEvent): void {\n    this.sseTransport.broadcastToRun(runId, event);\n  }\n\n  /**\n   * Get SSE transport\n   */\n  getSseTransport(): SseTransport {\n    return this.sseTransport;\n  }\n\n  /**\n   * Cleanup\n   */\n  shutdown(): void {\n    this.sseTransport.shutdown();\n  }\n}\n```\n\n### API Routes\n\n```typescript\n// server/src/routes/executions-stream.ts\nimport { Router, Request, Response } from 'express';\nimport { TransportManager } from '../execution/transport/transport-manager.js';\nimport { generateId } from '../execution/utils.js';\n\nexport function createExecutionStreamRoutes(\n  transportManager: TransportManager\n): Router {\n  const router = Router();\n\n  /**\n   * SSE endpoint for execution streaming\n   * GET /api/executions/:executionId/stream\n   */\n  router.get('/:executionId/stream', (req: Request, res: Response) => {\n    const { executionId } = req.params;\n    const clientId = generateId('client');\n\n    // TODO: Add authentication/authorization\n\n    const sseTransport = transportManager.getSseTransport();\n    sseTransport.handleConnection(clientId, res, executionId);\n  });\n\n  return router;\n}\n```\n\n## Part 3: Frontend Integration\n\n### React Hook for AG-UI Streaming\n\n```typescript\n// frontend/src/hooks/useAgUiStream.ts\nimport { useEffect, useState, useRef, useCallback } from 'react';\nimport { AgUiEvent, AgUiEventType } from '../types/ag-ui';\n\nexport interface AgUiStreamState {\n  status: 'connecting' | 'connected' | 'disconnected' | 'error';\n  events: AgUiEvent[];\n  messages: Array<{\n    id: string;\n    role: string;\n    content: string;\n  }>;\n  toolCalls: Array<{\n    id: string;\n    name: string;\n    args: any;\n    result?: any;\n    status: 'running' | 'completed' | 'error';\n  }>;\n  currentStep?: {\n    id: string;\n    name: string;\n  };\n  progress?: {\n    toolCalls: number;\n    filesChanged: string[];\n    currentActivity?: string;\n  };\n  error?: string;\n}\n\nexport interface UseAgUiStreamOptions {\n  executionId: string;\n  onEvent?: (event: AgUiEvent) => void;\n  onError?: (error: Error) => void;\n}\n\nexport function useAgUiStream(options: UseAgUiStreamOptions) {\n  const { executionId, onEvent, onError } = options;\n\n  const [state, setState] = useState<AgUiStreamState>({\n    status: 'connecting',\n    events: [],\n    messages: [],\n    toolCalls: [],\n  });\n\n  const eventSourceRef = useRef<EventSource | null>(null);\n  const messageBuffers = useRef<Map<string, string[]>>(new Map());\n  const toolCallBuffers = useRef<Map<string, string>>(new Map());\n\n  const handleEvent = useCallback((event: AgUiEvent) => {\n    // Call custom handler\n    onEvent?.(event);\n\n    // Update state based on event type\n    setState(prev => {\n      const newState = { ...prev };\n      newState.events = [...prev.events, event];\n\n      switch (event.type) {\n        case AgUiEventType.TEXT_MESSAGE_START:\n          messageBuffers.current.set(event.messageId, []);\n          break;\n\n        case AgUiEventType.TEXT_MESSAGE_CONTENT:\n          const buffer = messageBuffers.current.get(event.messageId) || [];\n          buffer.push(event.delta);\n          messageBuffers.current.set(event.messageId, buffer);\n          break;\n\n        case AgUiEventType.TEXT_MESSAGE_END:\n          const content = messageBuffers.current.get(event.messageId)?.join('') || '';\n          newState.messages = [\n            ...prev.messages,\n            {\n              id: event.messageId,\n              role: 'assistant',\n              content,\n            },\n          ];\n          messageBuffers.current.delete(event.messageId);\n          break;\n\n        case AgUiEventType.TOOL_CALL_START:\n          newState.toolCalls = [\n            ...prev.toolCalls,\n            {\n              id: event.toolCallId,\n              name: event.toolCallName,\n              args: null,\n              status: 'running',\n            },\n          ];\n          toolCallBuffers.current.set(event.toolCallId, '');\n          break;\n\n        case AgUiEventType.TOOL_CALL_ARGS:\n          const argBuffer = toolCallBuffers.current.get(event.toolCallId) || '';\n          toolCallBuffers.current.set(event.toolCallId, argBuffer + event.delta);\n          break;\n\n        case AgUiEventType.TOOL_CALL_END:\n          const argsJson = toolCallBuffers.current.get(event.toolCallId) || '{}';\n          newState.toolCalls = prev.toolCalls.map(tc =>\n            tc.id === event.toolCallId\n              ? { ...tc, args: JSON.parse(argsJson) }\n              : tc\n          );\n          toolCallBuffers.current.delete(event.toolCallId);\n          break;\n\n        case AgUiEventType.TOOL_CALL_RESULT:\n          newState.toolCalls = prev.toolCalls.map(tc =>\n            tc.id === event.toolCallId\n              ? { ...tc, result: event.content, status: 'completed' }\n              : tc\n          );\n          break;\n\n        case AgUiEventType.STEP_STARTED:\n          newState.currentStep = {\n            id: event.stepId,\n            name: event.stepName,\n          };\n          break;\n\n        case AgUiEventType.STEP_FINISHED:\n          if (prev.currentStep?.id === event.stepId) {\n            newState.currentStep = undefined;\n          }\n          break;\n\n        case AgUiEventType.STATE_DELTA:\n          // Apply JSON Patch to progress\n          event.delta.forEach(patch => {\n            if (patch.path === '/progress') {\n              newState.progress = patch.value;\n            }\n          });\n          break;\n\n        case AgUiEventType.RUN_ERROR:\n          newState.error = event.error.message;\n          break;\n      }\n\n      return newState;\n    });\n  }, [onEvent]);\n\n  useEffect(() => {\n    // Use Server-Sent Events for real-time streaming\n    const eventSource = new EventSource(\n      `/api/executions/${executionId}/stream`\n    );\n\n    eventSourceRef.current = eventSource;\n\n    eventSource.onopen = () => {\n      setState(prev => ({ ...prev, status: 'connected' }));\n    };\n\n    // Listen to all AG-UI event types\n    Object.values(AgUiEventType).forEach(eventType => {\n      eventSource.addEventListener(eventType, (e: MessageEvent) => {\n        try {\n          const event: AgUiEvent = JSON.parse(e.data);\n          handleEvent(event);\n        } catch (error) {\n          console.error('Error parsing AG-UI event:', error);\n        }\n      });\n    });\n\n    eventSource.onerror = (error) => {\n      setState(prev => ({\n        ...prev,\n        status: 'error',\n        error: 'Connection lost',\n      }));\n      onError?.(new Error('EventSource error'));\n      eventSource.close();\n    };\n\n    return () => {\n      eventSource.close();\n    };\n  }, [executionId, handleEvent, onError]);\n\n  return state;\n}\n```\n\n### Execution Monitor Component\n\n```typescript\n// frontend/src/components/executions/ExecutionMonitor.tsx\nimport React from 'react';\nimport { useAgUiStream } from '../../hooks/useAgUiStream';\nimport { MessageStream } from './MessageStream';\nimport { ToolCallViewer } from './ToolCallViewer';\nimport { ProgressIndicator } from './ProgressIndicator';\n\nexport interface ExecutionMonitorProps {\n  executionId: string;\n  onComplete?: () => void;\n}\n\nexport const ExecutionMonitor: React.FC<ExecutionMonitorProps> = ({\n  executionId,\n  onComplete,\n}) => {\n  const stream = useAgUiStream({\n    executionId,\n    onEvent: (event) => {\n      if (event.type === 'RUN_FINISHED' && onComplete) {\n        onComplete();\n      }\n    },\n  });\n\n  return (\n    <div className=\"execution-monitor\">\n      <div className=\"execution-header\">\n        <h2>Execution: {executionId}</h2>\n        <div className=\"status-badge\" data-status={stream.status}>\n          {stream.status}\n        </div>\n      </div>\n\n      {stream.error && (\n        <div className=\"error-banner\">\n          <strong>Error:</strong> {stream.error}\n        </div>\n      )}\n\n      {stream.currentStep && (\n        <div className=\"current-step\">\n          <strong>Current Step:</strong> {stream.currentStep.name}\n        </div>\n      )}\n\n      {stream.progress && (\n        <ProgressIndicator progress={stream.progress} />\n      )}\n\n      <div className=\"execution-content\">\n        <div className=\"messages-section\">\n          <h3>Messages</h3>\n          <MessageStream messages={stream.messages} />\n        </div>\n\n        <div className=\"tool-calls-section\">\n          <h3>Tool Calls ({stream.toolCalls.length})</h3>\n          <ToolCallViewer toolCalls={stream.toolCalls} />\n        </div>\n      </div>\n    </div>\n  );\n};\n```\n\n### Tool Call Viewer Component\n\n```typescript\n// frontend/src/components/executions/ToolCallViewer.tsx\nimport React, { useState } from 'react';\n\nexport interface ToolCall {\n  id: string;\n  name: string;\n  args: any;\n  result?: any;\n  status: 'running' | 'completed' | 'error';\n}\n\nexport interface ToolCallViewerProps {\n  toolCalls: ToolCall[];\n}\n\nexport const ToolCallViewer: React.FC<ToolCallViewerProps> = ({ toolCalls }) => {\n  const [expandedIds, setExpandedIds] = useState<Set<string>>(new Set());\n\n  const toggleExpand = (id: string) => {\n    setExpandedIds(prev => {\n      const next = new Set(prev);\n      if (next.has(id)) {\n        next.delete(id);\n      } else {\n        next.add(id);\n      }\n      return next;\n    });\n  };\n\n  return (\n    <div className=\"tool-call-viewer\">\n      {toolCalls.length === 0 && (\n        <div className=\"empty-state\">No tool calls yet</div>\n      )}\n\n      {toolCalls.map(toolCall => (\n        <div\n          key={toolCall.id}\n          className=\"tool-call-item\"\n          data-status={toolCall.status}\n        >\n          <div\n            className=\"tool-call-header\"\n            onClick={() => toggleExpand(toolCall.id)}\n          >\n            <span className=\"tool-name\">{toolCall.name}</span>\n            <span className=\"tool-status\">{toolCall.status}</span>\n          </div>\n\n          {expandedIds.has(toolCall.id) && (\n            <div className=\"tool-call-details\">\n              {toolCall.args && (\n                <div className=\"tool-args\">\n                  <strong>Arguments:</strong>\n                  <pre>{JSON.stringify(toolCall.args, null, 2)}</pre>\n                </div>\n              )}\n\n              {toolCall.result && (\n                <div className=\"tool-result\">\n                  <strong>Result:</strong>\n                  <pre>{JSON.stringify(toolCall.result, null, 2)}</pre>\n                </div>\n              )}\n            </div>\n          )}\n        </div>\n      ))}\n    </div>\n  );\n};\n```\n\n### Message Stream Component\n\n```typescript\n// frontend/src/components/executions/MessageStream.tsx\nimport React, { useEffect, useRef } from 'react';\n\nexport interface Message {\n  id: string;\n  role: string;\n  content: string;\n}\n\nexport interface MessageStreamProps {\n  messages: Message[];\n  autoScroll?: boolean;\n}\n\nexport const MessageStream: React.FC<MessageStreamProps> = ({\n  messages,\n  autoScroll = true,\n}) => {\n  const containerRef = useRef<HTMLDivElement>(null);\n\n  useEffect(() => {\n    if (autoScroll && containerRef.current) {\n      containerRef.current.scrollTop = containerRef.current.scrollHeight;\n    }\n  }, [messages, autoScroll]);\n\n  return (\n    <div ref={containerRef} className=\"message-stream\">\n      {messages.length === 0 && (\n        <div className=\"empty-state\">No messages yet</div>\n      )}\n\n      {messages.map(message => (\n        <div key={message.id} className=\"message\" data-role={message.role}>\n          <div className=\"message-role\">{message.role}</div>\n          <div className=\"message-content\">\n            <pre>{message.content}</pre>\n          </div>\n        </div>\n      ))}\n    </div>\n  );\n};\n```\n\n### Progress Indicator Component\n\n```typescript\n// frontend/src/components/executions/ProgressIndicator.tsx\nimport React from 'react';\n\nexport interface Progress {\n  toolCalls: number;\n  filesChanged: string[];\n  currentActivity?: string;\n}\n\nexport interface ProgressIndicatorProps {\n  progress: Progress;\n}\n\nexport const ProgressIndicator: React.FC<ProgressIndicatorProps> = ({\n  progress,\n}) => {\n  return (\n    <div className=\"progress-indicator\">\n      {progress.currentActivity && (\n        <div className=\"current-activity\">\n          <span className=\"activity-icon\">⚙️</span>\n          <span className=\"activity-text\">{progress.currentActivity}</span>\n        </div>\n      )}\n\n      <div className=\"progress-stats\">\n        <div className=\"stat\">\n          <strong>Tool Calls:</strong> {progress.toolCalls}\n        </div>\n        <div className=\"stat\">\n          <strong>Files Changed:</strong> {progress.filesChanged.length}\n        </div>\n      </div>\n\n      {progress.filesChanged.length > 0 && (\n        <div className=\"files-changed\">\n          <strong>Modified Files:</strong>\n          <ul>\n            {progress.filesChanged.map((file, index) => (\n              <li key={index}>{file}</li>\n            ))}\n          </ul>\n        </div>\n      )}\n    </div>\n  );\n};\n```\n\n## Testing Strategy\n\n### Unit Tests\n\n```typescript\n// server/src/execution/output/ag-ui-adapter.test.ts\ndescribe('AgUiEventAdapter', () => {\n  it('should transform Claude assistant message to AG-UI events', () => {\n    const adapter = new AgUiEventAdapter();\n    const events: AgUiEvent[] = [];\n\n    adapter.onEvent(event => events.push(event));\n\n    const message: StreamMessage = {\n      type: 'assistant',\n      data: {\n        type: 'assistant',\n        message: {\n          content: [\n            { type: 'text', text: 'Hello world' }\n          ]\n        }\n      },\n      timestamp: new Date(),\n      raw: ''\n    };\n\n    adapter.transformStreamMessage(message, 'process-1');\n\n    expect(events.length).toBe(3);\n    expect(events[0].type).toBe(AgUiEventType.TEXT_MESSAGE_START);\n    expect(events[1].type).toBe(AgUiEventType.TEXT_MESSAGE_CONTENT);\n    expect(events[2].type).toBe(AgUiEventType.TEXT_MESSAGE_END);\n  });\n\n  it('should transform tool use to AG-UI tool call events', () => {\n    const adapter = new AgUiEventAdapter();\n    const events: AgUiEvent[] = [];\n\n    adapter.onEvent(event => events.push(event));\n\n    const message: StreamMessage = {\n      type: 'assistant',\n      data: {\n        type: 'assistant',\n        message: {\n          content: [\n            {\n              type: 'tool_use',\n              id: 'tool-123',\n              name: 'Read',\n              input: { file_path: '/path/to/file.ts' }\n            }\n          ]\n        }\n      },\n      timestamp: new Date(),\n      raw: ''\n    };\n\n    adapter.transformStreamMessage(message, 'process-1');\n\n    expect(events[0].type).toBe(AgUiEventType.TOOL_CALL_START);\n    expect(events[1].type).toBe(AgUiEventType.TOOL_CALL_ARGS);\n    expect(events[2].type).toBe(AgUiEventType.TOOL_CALL_END);\n  });\n});\n```\n\n### Integration Tests\n\n```typescript\n// server/src/execution/transport/sse-transport.test.ts\ndescribe('SseTransport', () => {\n  it('should send events to connected clients', (done) => {\n    const transport = new SseTransport();\n    const mockRes = {\n      writeHead: jest.fn(),\n      write: jest.fn(),\n      on: jest.fn(),\n    };\n\n    transport.handleConnection('client-1', mockRes as any);\n\n    const event: AgUiEvent = {\n      type: AgUiEventType.TEXT_MESSAGE_START,\n      messageId: 'msg-1',\n      role: 'assistant',\n      timestamp: Date.now(),\n    };\n\n    transport.sendToClient('client-1', event);\n\n    expect(mockRes.write).toHaveBeenCalledWith(\n      expect.stringContaining('TEXT_MESSAGE_START')\n    );\n\n    done();\n  });\n});\n```\n\n### E2E Tests\n\n```typescript\n// frontend/src/hooks/useAgUiStream.test.tsx\ndescribe('useAgUiStream', () => {\n  it('should receive and process AG-UI events', async () => {\n    const { result } = renderHook(() =>\n      useAgUiStream({ executionId: 'exec-1' })\n    );\n\n    // Wait for connection\n    await waitFor(() => {\n      expect(result.current.status).toBe('connected');\n    });\n\n    // Simulate events (mock EventSource)\n    // ...\n\n    await waitFor(() => {\n      expect(result.current.messages.length).toBeGreaterThan(0);\n    });\n  });\n});\n```\n\n## File Structure\n\n```\nserver/src/execution/\n├── output/\n│   ├── types.ts                    # SPEC-007: StreamMessage, ExecutionProgress types\n│   ├── processor.ts                # SPEC-007: IOutputProcessor interface\n│   ├── stream-json-processor.ts    # SPEC-007: Parses raw output → StreamMessage\n│   ├── ag-ui-types.ts              # SPEC-009: AG-UI event schemas (300 lines)\n│   ├── ag-ui-adapter.ts            # SPEC-009: StreamMessage → AgUiEvent (400 lines)\n│   └── ag-ui-integration.ts        # SPEC-009: Wire SPEC-007 to SPEC-009 (100 lines)\n├── transport/\n│   ├── sse-transport.ts            # SSE transport (200 lines)\n│   └── transport-manager.ts        # SSE coordinator (100 lines)\n├── workflow/\n│   └── linear-orchestrator.ts      # Modified to emit lifecycle events\n└── routes/\n    └── executions-stream.ts        # SSE endpoint (100 lines)\n\nfrontend/src/\n├── types/\n│   └── ag-ui.ts                    # Frontend AG-UI types (100 lines)\n├── hooks/\n│   └── useAgUiStream.ts            # React hook for SSE streaming (150 lines)\n└── components/executions/\n    ├── ExecutionMonitor.tsx        # Main dashboard (250 lines)\n    ├── ToolCallViewer.tsx          # Tool call display (150 lines)\n    ├── MessageStream.tsx           # Message streaming (150 lines)\n    └── ProgressIndicator.tsx       # Progress display (100 lines)\n\n.sudocode/specs/\n├── output_processing_layer_real_time_parsing.md  # SPEC-007\n└── ag_ui_protocol_integration.md                 # SPEC-009 (this spec)\n```\n\n**Key Files:**\n\n- **SPEC-007 Foundation** (`output/` dir): Parses agent output into `StreamMessage`\n- **SPEC-009 Protocol** (`ag-ui-*.ts`): Transforms `StreamMessage` into AG-UI events\n- **Integration** (`ag-ui-integration.ts`): Wires SPEC-007 → SPEC-009\n- **Transport** (`sse-transport.ts`): Streams AG-UI events to frontend via SSE\n\n## Implementation Checklist\n\n### Backend\n\n- Define AG-UI event types and Zod schemas\n- Implement AG-UI event adapter\n- Integrate adapter with StreamJsonProcessor\n- Integrate adapter with LinearOrchestrator\n- Implement SSE transport\n- Implement WebSocket transport\n- Create transport manager\n- Add SSE API endpoint\n- Add WebSocket endpoint\n- Write unit tests for adapter\n- Write integration tests for transports\n\n### Frontend\n\n- Define AG-UI types for frontend\n- Implement useAgUiStream hook\n- Create ExecutionMonitor component\n- Create ToolCallViewer component\n- Create MessageStream component\n- Create ProgressIndicator component\n- Add styling for components\n- Write unit tests for hook\n- Write E2E tests for components\n\n### Documentation\n\n- Write specification document\n- Add usage examples\n- Create API documentation\n- Update README with AG-UI integration\n\n## Usage Example\n\n### Backend Integration\n\n```typescript\n// server/src/index.ts\nimport { TransportManager } from './execution/transport/transport-manager.js';\nimport { AgUiEventAdapter } from './execution/output/ag-ui-adapter.js';\nimport { LinearOrchestrator } from './execution/workflow/linear-orchestrator.js';\n\n// Create transport manager\nconst transportManager = new TransportManager();\n\n// Create AG-UI adapter\nconst agUiAdapter = new AgUiEventAdapter();\n\n// Connect adapter to transports\ntransportManager.connectAdapter(agUiAdapter);\n\n// Create orchestrator with AG-UI support\nconst orchestrator = new LinearOrchestrator(\n  executor,\n  storage,\n  agUiAdapter\n);\n\n// Start workflow - events automatically stream to frontend\nconst executionId = await orchestrator.startWorkflow(workflow);\n```\n\n### Frontend Integration\n\n```typescript\n// App.tsx\nimport { ExecutionMonitor } from './components/executions/ExecutionMonitor';\n\nfunction App() {\n  const [executionId, setExecutionId] = useState<string | null>(null);\n\n  return (\n    <div>\n      {executionId && (\n        <ExecutionMonitor\n          executionId={executionId}\n          onComplete={() => console.log('Execution completed!')}\n        />\n      )}\n    </div>\n  );\n}\n```\n\n## Related Specs\n\n- [[SPEC-003]] - Process Layer (provides output streaming)\n- [[SPEC-004]] - Engine Layer (task execution)\n- [[SPEC-005]] - Task Execution Layer (resilience)\n- [[SPEC-006]] - Workflow Layer (orchestration, integrates lifecycle events)\n- [[SPEC-007]] - Output Processing Layer (provides StreamJsonProcessor)\n","priority":2,"archived":0,"archived_at":null,"created_at":"2025-10-30 08:17:27","updated_at":"2025-11-03T03:10:12.588Z","parent_id":null,"parent_uuid":null,"relationships":[{"from":"SPEC-009","from_type":"spec","to":"SPEC-003","to_type":"spec","type":"references"},{"from":"SPEC-009","from_type":"spec","to":"SPEC-004","to_type":"spec","type":"references"},{"from":"SPEC-009","from_type":"spec","to":"SPEC-006","to_type":"spec","type":"references"},{"from":"SPEC-009","from_type":"spec","to":"SPEC-007","to_type":"spec","type":"references"}],"tags":[]}
{"id":"SPEC-010","uuid":"ba3bb9ff-d3a2-403a-ac5c-8addf7064fb0","title":"Worktree Management Design","file_path":"specs/worktree_management_design.md","content":"# Worktree Management Design\n\n## Overview\n\nThis spec describes the design for managing git worktrees to isolate Claude Code execution sessions in sudocode. The design is informed by analysis of reference implementations:\n\n- **vibe-kanban**: Comprehensive worktree management with robust cleanup and state tracking\n- **CodeMachine-CLI**: No worktree management (not applicable)\n\n## Motivation\n\nCurrently, sudocode runs Claude Code sessions in the main working directory. To support:\n\n1. **Concurrent sessions** - Run multiple Claude Code sessions simultaneously without conflicts\n1. **Issue isolation** - Each issue gets its own isolated git environment\n1. **Branch management** - Automatically manage branches per issue/session\n1. **Cleanup** - Reliable cleanup of session artifacts\n\nWe need to implement git worktree management.\n\n## Architecture\n\n### Layer Structure\n\nBuilding on sudocode's existing execution architecture:\n\n```\n┌─────────────────────────────────────┐\n│   Workflow Layer                     │\n│   - orchestrates multi-step flows   │\n└──────────────┬──────────────────────┘\n               │\n┌──────────────▼──────────────────────┐\n│   Engine Layer                       │\n│   - manages task queue & lifecycle  │\n└──────────────┬──────────────────────┘\n               │\n┌──────────────▼──────────────────────┐\n│   Resilience Layer                   │\n│   - retry & circuit breaker logic   │\n└──────────────┬──────────────────────┘\n               │\n┌──────────────▼──────────────────────┐\n│   Process Layer                      │\n│   - spawns/manages processes        │\n└──────────────┬──────────────────────┘\n               │\n      ┌────────▼────────┐\n      │  Worktree Layer │  ← NEW\n      │  - git isolation│\n      └─────────────────┘\n```\n\n### Core Components\n\n#### 1\\. WorktreeManager\n\n**Location**: `server/src/execution/worktree/manager.ts`\n\n**Responsibilities**:\n\n- Create git worktrees for sessions\n- Ensure worktree existence (recreate if needed)\n- Cleanup worktrees and git metadata\n- Handle race conditions with locking\n- Prune orphaned worktree metadata\n- Read and apply configuration from `.sudocode/config.json`\n\n**Key Methods**:\n\n```typescript\ninterface IWorktreeManager {\n  /**\n   * Create a new worktree for a session\n   * @param repoPath - Path to the main git repository\n   * @param branchName - Branch name for the worktree\n   * @param worktreePath - Where to create the worktree\n   * @param baseBranch - Branch to base the new branch on\n   * @param createBranch - Whether to create the branch\n   */\n  createWorktree(\n    repoPath: string,\n    branchName: string,\n    worktreePath: string,\n    baseBranch: string,\n    createBranch: boolean\n  ): Promise<void>;\n\n  /**\n   * Ensure worktree exists, recreating if necessary\n   * Uses locking to prevent race conditions\n   */\n  ensureWorktreeExists(\n    repoPath: string,\n    branchName: string,\n    worktreePath: string\n  ): Promise<void>;\n\n  /**\n   * Clean up a worktree (filesystem + git metadata)\n   */\n  cleanupWorktree(\n    worktreePath: string,\n    repoPath?: string\n  ): Promise<void>;\n\n  /**\n   * Check if worktree is properly set up\n   */\n  isWorktreeValid(\n    repoPath: string,\n    worktreePath: string\n  ): Promise<boolean>;\n}\n```\n\n**Implementation Notes** (from vibe-kanban):\n\n- Use **git CLI** (not libgit2/nodegit) for reliability\n- Implement **per-path locking** to prevent concurrent creation conflicts\n- **Comprehensive cleanup**: Remove both filesystem and `.git/worktrees/<name>` metadata\n- **Retry logic**: If creation fails due to metadata conflicts, cleanup and retry\n- **Validation**: Check both filesystem existence AND git metadata registration\n- **Configuration**: Load settings from `.sudocode/config.json` on initialization\n\n#### 2\\. Session Model Extension\n\n**Location**: Database schema + models\n\n**New Fields**:\n\n```typescript\ninterface Session {\n  id: string;\n  issueId: string;\n\n  // NEW: Worktree tracking\n  worktreePath: string | null;        // Path to the worktree\n  branchName: string;                  // Git branch for this session\n  targetBranch: string;                // Base/target branch (e.g., 'main')\n  worktreeDeleted: boolean;            // Cleanup flag\n\n  // Existing fields...\n  status: SessionStatus;\n  createdAt: Date;\n  updatedAt: Date;\n}\n```\n\n**Database Migration**:\n\n```sql\n-- Add worktree fields to sessions table\nALTER TABLE sessions ADD COLUMN worktree_path TEXT;\nALTER TABLE sessions ADD COLUMN branch_name TEXT NOT NULL;\nALTER TABLE sessions ADD COLUMN target_branch TEXT NOT NULL;\nALTER TABLE sessions ADD COLUMN worktree_deleted BOOLEAN NOT NULL DEFAULT FALSE;\n\n-- Index for cleanup queries\nCREATE INDEX idx_sessions_worktree_deleted ON sessions(worktree_deleted);\n```\n\n#### 3\\. Git CLI Wrapper\n\n**Location**: `server/src/execution/worktree/git-cli.ts`\n\n**Purpose**: Wrap git commands for worktree operations\n\n```typescript\ninterface IGitCli {\n  /**\n   * Add a new worktree\n   * Equivalent to: git worktree add <path> <branch>\n   */\n  worktreeAdd(\n    repoPath: string,\n    worktreePath: string,\n    branch: string,\n    force?: boolean\n  ): Promise<void>;\n\n  /**\n   * Remove a worktree\n   * Equivalent to: git worktree remove <path> --force\n   */\n  worktreeRemove(\n    repoPath: string,\n    worktreePath: string,\n    force?: boolean\n  ): Promise<void>;\n\n  /**\n   * Prune worktree metadata\n   * Equivalent to: git worktree prune\n   */\n  worktreePrune(repoPath: string): Promise<void>;\n\n  /**\n   * List all worktrees\n   * Equivalent to: git worktree list\n   */\n  worktreeList(repoPath: string): Promise<WorktreeInfo[]>;\n\n  /**\n   * Create a branch\n   * Equivalent to: git branch <name> <base>\n   */\n  createBranch(\n    repoPath: string,\n    branchName: string,\n    baseBranch: string\n  ): Promise<void>;\n}\n```\n\n**Implementation**:\n\n- Use `child_process.exec` or `execa` for git commands\n- Proper error handling and output parsing\n- Shell command construction with proper escaping\n- Support for sparse-checkout if configured\n\n#### 4\\. ProcessConfig Extension\n\n**Location**: `server/src/execution/process/types.ts`\n\n**Extension**:\n\n```typescript\nexport interface ProcessConfig {\n  executablePath: string;\n  args: string[];\n\n  // CHANGED: workDir now optional, calculated from session\n  workDir?: string;\n\n  // NEW: Session reference for worktree lookup\n  sessionId?: string;\n\n  env?: Record<string, string>;\n  timeout?: number;\n  idleTimeout?: number;\n  retry?: {\n    maxAttempts: number;\n    backoffMs: number;\n  };\n}\n```\n\n#### 5\\. Session Lifecycle Integration\n\n**Location**: New service layer\n\n```typescript\ninterface ISessionService {\n  /**\n   * Create a new session with worktree\n   */\n  createSession(params: {\n    issueId: string;\n    baseBranch: string;\n    repoPath: string;\n  }): Promise<Session>;\n\n  /**\n   * Ensure session worktree is ready\n   */\n  ensureSessionReady(sessionId: string): Promise<void>;\n\n  /**\n   * Cleanup session and worktree\n   */\n  cleanupSession(sessionId: string): Promise<void>;\n\n  /**\n   * Get working directory for session\n   */\n  getSessionWorkDir(sessionId: string): Promise<string>;\n}\n```\n\n## Implementation Strategy\n\n### Phase 1: Foundation (Week 1)\n\n- Create worktree manager interface and basic implementation\n- Implement git CLI wrapper\n- Add configuration schema and loading from `.sudocode/config.json`\n- Add database schema for worktree tracking\n- Write unit tests for worktree operations\n\n### Phase 2: Integration (Week 2)\n\n- Integrate worktree manager with process layer\n- Update session lifecycle to create/cleanup worktrees\n- Modify process spawning to use worktree paths\n- Add worktree validation checks\n- Implement configuration-driven behavior (auto-create/delete branches)\n\n### Phase 3: Robustness (Week 3)\n\n- Implement locking mechanism\n- Add retry logic for creation failures\n- Implement comprehensive cleanup (filesystem + metadata)\n- Add orphaned worktree detection and cleanup\n- Implement sparse-checkout support\n\n### Phase 4: Testing & Polish (Week 4)\n\n- Integration tests for concurrent session scenarios\n- Cleanup on startup (handle crashed sessions)\n- Performance testing\n- Configuration validation and documentation\n\n## Key Design Decisions\n\n### 1\\. Worktree Naming Convention\n\n**Pattern**: `<project-name>-<session-id>-<branch-name>`\n\n**Example**: `sudocode-abc123-fix-issue-42`\n\n**Location**: Configurable via `worktreeStoragePath` in config (default: `.sudocode/worktrees/`)\n\n**Benefits**:\n\n- Easy to identify which session owns the worktree\n- Unique per session\n- Human-readable for debugging\n\n### 2\\. Branch Naming Convention\n\n**Pattern**: `<branchPrefix>/<session-id>/<issue-title>`\n\n**Example**: `sudocode/abc123/fix-authentication-bug`\n\n**Configuration**: `branchPrefix` is configurable (default: \"sudocode\")\n\n**Benefits**:\n\n- Clear namespace separation\n- Maps directly to session\n- Compatible with git best practices\n- Customizable prefix for team conventions\n\n### 3\\. Cleanup Strategy\n\n**When to cleanup**:\n\n1. **On session completion** - Normal cleanup path\n1. **On session failure** - Cleanup after errors\n1. **On server startup** - Cleanup orphaned worktrees (if `cleanupOrphanedWorktreesOnStartup` enabled)\n1. **Manual cleanup** - Admin tool for force cleanup\n\n**Cleanup process**:\n\n```typescript\nasync function cleanupWorktree(session: Session) {\n  // 1. Stop any running processes\n  await stopSessionProcesses(session.id);\n\n  // 2. Mark as deleted in DB (prevents race conditions)\n  await markWorktreeDeleted(session.id);\n\n  // 3. Remove git worktree registration\n  await gitCli.worktreeRemove(repoPath, session.worktreePath, true);\n\n  // 4. Force cleanup metadata directory\n  await forceCleanupMetadata(repoPath, session.branchName);\n\n  // 5. Remove filesystem directory\n  await fs.rm(session.worktreePath, { recursive: true, force: true });\n\n  // 6. Prune stale worktree entries\n  await gitCli.worktreePrune(repoPath);\n\n  // 7. Delete branch if configured to auto-delete\n  if (config.autoDeleteBranches) {\n    await gitCli.deleteBranch(repoPath, session.branchName);\n  }\n}\n```\n\n### 4\\. Race Condition Handling\n\n**Problem**: Multiple requests might try to create the same worktree concurrently.\n\n**Solution**: Per-path mutex using async locks\n\n```typescript\nimport { AsyncMutex } from 'async-mutex';\n\nclass WorktreeManager {\n  private locks = new Map<string, AsyncMutex>();\n\n  async ensureWorktreeExists(\n    repoPath: string,\n    branchName: string,\n    worktreePath: string\n  ): Promise<void> {\n    // Get or create lock for this specific path\n    let lock = this.locks.get(worktreePath);\n    if (!lock) {\n      lock = new AsyncMutex();\n      this.locks.set(worktreePath, lock);\n    }\n\n    // Acquire lock before proceeding\n    const release = await lock.acquire();\n    try {\n      // Check if already exists\n      if (await this.isWorktreeValid(repoPath, worktreePath)) {\n        return;\n      }\n\n      // Create worktree\n      await this.createWorktree(repoPath, branchName, worktreePath, baseBranch, false);\n    } finally {\n      release();\n    }\n  }\n}\n```\n\n### 5\\. Error Recovery\n\n**Scenarios to handle**:\n\n1. **Metadata exists but filesystem doesn't**\n\n- Solution: Force cleanup metadata, recreate\n\n1. **Filesystem exists but metadata doesn't**\n\n- Solution: Remove filesystem, recreate\n\n1. **Creation fails with \"already exists\"**\n\n- Solution: Cleanup completely, retry once\n\n1. **Git repository is locked**\n\n- Solution: Wait and retry with exponential backoff\n\n1. **Invalid configuration**\n\n- Solution: Validate config on load, use defaults for invalid values, warn user\n\n## API Design\n\n### REST Endpoints\n\n```typescript\n// Create session with worktree\nPOST /api/sessions\n{\n  \"issueId\": \"ISSUE-001\",\n  \"baseBranch\": \"main\"\n}\nResponse: {\n  \"sessionId\": \"abc123\",\n  \"worktreePath\": \"/tmp/sudocode-worktrees/...\",\n  \"branchName\": \"sudocode/abc123/fix-bug\"\n}\n\n// Get session info\nGET /api/sessions/:sessionId\nResponse: {\n  \"id\": \"abc123\",\n  \"issueId\": \"ISSUE-001\",\n  \"worktreePath\": \"/tmp/sudocode-worktrees/...\",\n  \"branchName\": \"sudocode/abc123/fix-bug\",\n  \"targetBranch\": \"main\",\n  \"status\": \"running\"\n}\n\n// Cleanup session\nDELETE /api/sessions/:sessionId\nResponse: { \"success\": true }\n\n// Admin: List all worktrees\nGET /api/admin/worktrees\nResponse: [\n  {\n    \"sessionId\": \"abc123\",\n    \"path\": \"/tmp/sudocode-worktrees/...\",\n    \"branch\": \"sudocode/abc123/fix-bug\",\n    \"createdAt\": \"2025-10-30T10:00:00Z\",\n    \"deleted\": false\n  }\n]\n\n// Admin: Cleanup orphaned worktrees\nPOST /api/admin/worktrees/cleanup\nResponse: {\n  \"cleaned\": 3,\n  \"failed\": 0\n}\n```\n\n## Testing Strategy\n\n### Unit Tests\n\n```typescript\ndescribe('WorktreeManager', () => {\n  it('should create a new worktree');\n  it('should handle concurrent creation requests');\n  it('should cleanup worktree completely');\n  it('should recover from partial cleanup');\n  it('should validate worktree existence');\n  it('should handle metadata conflicts');\n});\n\ndescribe('GitCli', () => {\n  it('should execute git worktree add');\n  it('should execute git worktree remove');\n  it('should parse git worktree list output');\n  it('should handle git errors gracefully');\n});\n```\n\n### Integration Tests\n\n```typescript\ndescribe('Session Lifecycle', () => {\n  it('should create session with worktree');\n  it('should run Claude Code in worktree');\n  it('should cleanup worktree on completion');\n  it('should handle multiple concurrent sessions');\n  it('should recover orphaned worktrees on startup');\n});\n```\n\n## Reference Implementation Insights\n\n### From vibe-kanban\n\n**Key Learnings**:\n\n1. **Use git CLI, not libgit2** - More reliable for worktree operations\n1. **Lock per path** - Prevents race conditions\n1. **Comprehensive cleanup** - Must remove both filesystem AND metadata\n1. **Retry logic** - Handle metadata conflicts by cleanup + retry\n1. **Database tracking** - `worktree_deleted` flag prevents double cleanup\n1. **Container abstraction** - Higher-level interface over worktree details\n\n**Code References**:\n\n- `crates/services/src/services/worktree_manager.rs` - Core worktree logic\n- `crates/services/src/services/container.rs` - Higher-level abstraction\n- `crates/db/src/models/task_attempt.rs` - Database model\n- Database migrations show evolution of worktree tracking\n\n## Configuration\n\nAll worktree settings will be configurable via `.sudocode/config.json`. This provides flexibility for different team workflows and repository sizes.\n\n### Configuration Schema\n\n```typescript\ninterface WorktreeConfig {\n  // Where to store worktrees\n  // Default: \".sudocode/worktrees\" (relative to project root)\n  // Can be absolute path like \"/tmp/sudocode-worktrees\"\n  worktreeStoragePath: string;\n\n  // Auto-create branches for new sessions\n  // Default: true\n  autoCreateBranches: boolean;\n\n  // Auto-delete branches when session is cleaned up\n  // Default: false (keep branches for history)\n  autoDeleteBranches: boolean;\n\n  // Use sparse-checkout for worktrees (for large repos)\n  // Default: false\n  enableSparseCheckout: boolean;\n\n  // Patterns for sparse-checkout (only if enableSparseCheckout=true)\n  // Example: [\"src/\", \"package.json\", \"tsconfig.json\"]\n  sparseCheckoutPatterns?: string[];\n\n  // Branch naming prefix\n  // Default: \"sudocode\"\n  branchPrefix: string;\n\n  // Cleanup orphaned worktrees on server startup\n  // Default: true\n  cleanupOrphanedWorktreesOnStartup: boolean;\n}\n```\n\n### Example config.json\n\n```json\n{\n  \"worktree\": {\n    \"worktreeStoragePath\": \".sudocode/worktrees\",\n    \"autoCreateBranches\": true,\n    \"autoDeleteBranches\": false,\n    \"enableSparseCheckout\": false,\n    \"branchPrefix\": \"sudocode\",\n    \"cleanupOrphanedWorktreesOnStartup\": true\n  }\n}\n```\n\n### Configuration Details\n\n**Storage Location**:\n\n- **Default**: `.sudocode/worktrees/` (relative to project root)\n- **Alternatives**: Absolute paths like `/tmp/sudocode-worktrees/` or `~/.sudocode/worktrees/`\n- **Benefits**: User-controlled, can optimize for disk I/O or temp cleanup needs\n\n**Concurrent Sessions**:\n\n- **Support**: Multiple sessions per issue allowed\n- **Design assumption**: Typically one session per issue at a time\n- **Benefit**: Worktrees enable safe concurrent sessions if needed (e.g., testing different approaches)\n\n**Branch Lifecycle**:\n\n- **Creation**: Configurable via `autoCreateBranches` (default: true)\n- **Deletion**: Configurable via `autoDeleteBranches` (default: false)\n- **Rationale**: Keep branches by default for git history; users can enable auto-deletion if preferred\n\n**Sparse Checkout**:\n\n- **Configurable**: Enable/disable via `enableSparseCheckout`\n- **Use case**: Large monorepos where full checkout is slow/wasteful\n- **Patterns**: Specify which paths to include in worktree\n\n**Future: Cloud Deployment**:\n\n- Design uses `container_ref` abstraction (like vibe-kanban)\n- Local implementation uses worktree paths\n- Future cloud implementation could use devcontainer IDs\n- Not in scope for initial implementation\n\n## Next Steps\n\n1. **Review this design** with team\n1. **Prototype** worktree manager with basic operations\n1. **Test** race condition handling\n1. **Integrate** with existing execution layers\n1. **Document** usage patterns for future developers\n\n## References\n\n- `/Users/alexngai/GitHub/sudocode/references/vibe-kanban/crates/services/src/services/worktree_manager.rs`\n- `/Users/alexngai/GitHub/sudocode/references/vibe-kanban/crates/services/src/services/container.rs`\n- [Git worktree documentation](https://git-scm.com/docs/git-worktree)\n","priority":2,"archived":0,"archived_at":null,"created_at":"2025-10-30 20:47:36","updated_at":"2025-11-03T03:10:12.586Z","parent_id":null,"parent_uuid":null,"relationships":[],"tags":[]}
{"id":"SPEC-011","uuid":"05ffaeb2-ee36-4155-836e-c49d583f5093","title":"Issue-to-Execution System Specification","file_path":"specs/issue_to_execution_system.md","content":"# Issue-to-Execution System Specification\n\n## Overview\n\nThe Issue-to-Execution System bridges sudocode's issue tracking with the execution infrastructure, enabling users to run AI agents directly on issues. This system transforms issues into executable workflows, manages execution lifecycle, supports iterative feedback loops, and provides real-time progress monitoring.\n\nThis spec integrates:\n- [[SPEC-003]] through [[SPEC-007]] - Execution infrastructure layers\n- [[SPEC-009]] - AG-UI protocol integration for real-time streaming\n- [[SPEC-010]] - Worktree management for execution isolation\n\n## Design Goals\n\n1. **Template-Driven**: Configurable prompt templates shown/edited before dispatch\n2. **Flexible Execution**: Support both isolated worktrees and local git tree\n3. **Configurable**: Execution settings modifiable before agent starts\n4. **Interactive**: Follow-up mechanism matching Claude Code's interaction flow\n5. **Observable**: Real-time progress via AG-UI event streaming\n6. **Resilient**: Auto-save, crash recovery, cleanup management\n\n## Architecture\n\n```\n┌───────────────────────────────────────────────────────────────────────┐\n│                        Frontend (React)                               │\n├───────────────────────────────────────────────────────────────────────┤\n│                                                                       │\n│  IssuePanel                                                          │\n│  ├─ [Run Agent] Button → ExecutionConfigDialog                      │\n│  │   ├─ Template Preview (editable)                                 │\n│  │   ├─ Execution Mode: [Worktree | Local]                         │\n│  │   ├─ Base Branch: [main ▼]                                      │\n│  │   ├─ Model: [claude-sonnet-4 ▼]                                 │\n│  │   └─ [Start Execution]                                          │\n│  │                                                                   │\n│  └─ ExecutionHistory                                                │\n│      └─ List of past executions with status                        │\n│                                                                       │\n│  ExecutionView                                                       │\n│  ├─ ExecutionMonitor (AG-UI streaming)                             │\n│  │   ├─ Real-time tool calls                                       │\n│  │   ├─ File changes                                               │\n│  │   └─ Progress indicators                                        │\n│  │                                                                   │\n│  └─ FollowUpPanel                                                   │\n│      ├─ Feedback textarea                                          │\n│      └─ [Send Follow-up]                                           │\n│                                                                       │\n└───────────────────────────────────────────────────────────────────────┘\n                                │\n                                ▼\n┌───────────────────────────────────────────────────────────────────────┐\n│                         Backend (Server)                              │\n├───────────────────────────────────────────────────────────────────────┤\n│                                                                       │\n│  API Routes                                                          │\n│  ├─ POST   /api/issues/:issueId/executions/prepare                 │\n│  │   → Returns template preview + defaults                          │\n│  │                                                                   │\n│  ├─ POST   /api/issues/:issueId/executions                         │\n│  │   → Creates and starts execution                                │\n│  │                                                                   │\n│  ├─ GET    /api/executions/:executionId                            │\n│  │   → Returns execution state                                      │\n│  │                                                                   │\n│  ├─ GET    /api/executions/:executionId/stream (SSE)               │\n│  │   → Real-time AG-UI events                                      │\n│  │                                                                   │\n│  ├─ POST   /api/executions/:executionId/follow-up                  │\n│  │   → Continues execution with user feedback                      │\n│  │                                                                   │\n│  └─ DELETE /api/executions/:executionId                            │\n│      → Cancels execution + cleanup                                  │\n│                                                                       │\n├───────────────────────────────────────────────────────────────────────┤\n│                                                                       │\n│  ExecutionService                                                    │\n│  ├─ prepareExecution(issueId, config?)                             │\n│  │   ├─ Load issue + related specs/feedback                        │\n│  │   ├─ Render prompt template                                     │\n│  │   └─ Return preview                                             │\n│  │                                                                   │\n│  ├─ createExecution(issueId, config)                               │\n│  │   ├─ Create DB record                                           │\n│  │   ├─ Setup execution environment                                │\n│  │   │   ├─ [Worktree Mode] Create isolated worktree              │\n│  │   │   └─ [Local Mode] Validate working directory               │\n│  │   ├─ Build workflow definition                                  │\n│  │   ├─ Start LinearOrchestrator                                   │\n│  │   └─ Return executionId                                         │\n│  │                                                                   │\n│  ├─ createFollowUp(executionId, feedback)                          │\n│  │   ├─ Load execution state                                       │\n│  │   ├─ Append feedback to context                                │\n│  │   ├─ Create follow-up workflow step                            │\n│  │   └─ Resume orchestrator                                        │\n│  │                                                                   │\n│  └─ cleanupExecution(executionId, mode)                            │\n│      ├─ [Auto] Cleanup on success                                  │\n│      ├─ [Manual] User-triggered cleanup                            │\n│      └─ [OnStartup] Orphaned worktree cleanup                      │\n│                                                                       │\n├───────────────────────────────────────────────────────────────────────┤\n│                                                                       │\n│  PromptTemplateEngine                                                │\n│  ├─ renderTemplate(template, context)                               │\n│  ├─ getDefaultTemplate(taskType)                                    │\n│  └─ validateTemplate(template)                                      │\n│                                                                       │\n│  WorktreeManager (SPEC-010)                                          │\n│  ├─ createWorktree(executionId, baseBranch)                        │\n│  ├─ getWorktreePath(executionId)                                   │\n│  └─ removeWorktree(executionId)                                    │\n│                                                                       │\n│  LinearOrchestrator + AgUiAdapter (SPEC-006, 009)                   │\n│  └─ Executes workflow with real-time event streaming               │\n│                                                                       │\n└───────────────────────────────────────────────────────────────────────┘\n```\n\n## Part 1: Core Types\n\n### Execution Database Entity\n\n```typescript\n/**\n * Execution - Persistent execution record\n *\n * Stored in database to track all agent executions for issues\n */\nexport interface Execution {\n  // Identity\n  id: string;                        // UUID\n  issueId: string;                   // Parent issue\n\n  // Configuration\n  mode: ExecutionMode;               // 'worktree' | 'local'\n  baseBranch: string;                // Base git branch\n  worktreePath?: string;             // Path if using worktree mode\n  prompt: string;                    // Rendered prompt sent to agent\n\n  // State\n  status: ExecutionStatus;\n  workflowExecutionId: string;       // Links to WorkflowExecution\n\n  // Metadata\n  model: string;                     // e.g., 'claude-sonnet-4'\n  config: ExecutionConfig;           // User-configurable settings\n\n  // Lifecycle\n  createdAt: Date;\n  startedAt?: Date;\n  completedAt?: Date;\n  cancelledAt?: Date;\n\n  // Results\n  filesChanged?: string[];\n  error?: string;\n\n  // Relationships\n  parentExecutionId?: string;        // If this is a follow-up\n  followUpExecutionIds?: string[];   // Child follow-ups\n}\n\nexport type ExecutionMode =\n  | 'worktree'  // Isolated git worktree\n  | 'local';    // Local working directory\n\nexport type ExecutionStatus =\n  | 'preparing'   // Template being prepared\n  | 'pending'     // Created, not yet started\n  | 'running'     // Agent executing\n  | 'paused'      // Execution paused (awaiting follow-up)\n  | 'completed'   // Successfully finished\n  | 'failed'      // Execution failed\n  | 'cancelled';  // User cancelled\n```\n\n### ExecutionConfig\n\n```typescript\n/**\n * ExecutionConfig - User-configurable execution settings\n */\nexport interface ExecutionConfig {\n  // Agent settings\n  model?: string;                    // Override default model\n  maxTokens?: number;\n  temperature?: number;\n\n  // Execution behavior\n  timeout?: number;                  // Overall timeout (ms)\n  retryPolicy?: RetryPolicy;         // From SPEC-005\n\n  // Worktree settings (if mode === 'worktree')\n  baseBranch?: string;               // Branch to base worktree on\n  branchName?: string;               // Override auto-generated branch name\n  cleanupMode?: CleanupMode;         // When to cleanup worktree\n\n  // Workflow settings\n  checkpointInterval?: number;       // Steps between checkpoints\n  continueOnStepFailure?: boolean;   // Continue after step failure\n\n  // Output settings\n  captureFileChanges?: boolean;\n  captureToolCalls?: boolean;\n}\n\nexport type CleanupMode =\n  | 'auto'       // Cleanup on successful completion\n  | 'manual'     // User must manually cleanup\n  | 'never';     // Never auto-cleanup (for debugging)\n```\n\n### PromptTemplate\n\n```typescript\n/**\n * PromptTemplate - Configurable template for generating agent prompts\n */\nexport interface PromptTemplate {\n  id: string;\n  name: string;\n  description: string;\n\n  // Template types\n  type: 'issue' | 'spec' | 'custom';\n\n  // Template content with variables\n  template: string;\n\n  // Available variables in template\n  variables: PromptVariable[];\n\n  // Metadata\n  isDefault?: boolean;\n  createdAt: Date;\n  updatedAt: Date;\n}\n\nexport interface PromptVariable {\n  name: string;                      // e.g., 'issueId', 'title', 'description'\n  description: string;\n  type: 'string' | 'number' | 'boolean' | 'array' | 'object';\n  required: boolean;\n  defaultValue?: any;\n}\n\n/**\n * Default issue prompt template\n */\nexport const DEFAULT_ISSUE_TEMPLATE = `Fix issue {{issueId}}: {{title}}\n\n## Description\n{{description}}\n\n{{#if relatedSpecs}}\n## Related Specifications\n{{#each relatedSpecs}}\n- [[{{id}}]]: {{title}}\n{{/each}}\n{{/if}}\n\n{{#if feedback}}\n## Feedback from Previous Attempts\n{{#each feedback}}\n- {{content}} (from {{issueId}})\n{{/each}}\n{{/if}}\n\nPlease implement a solution for this issue. Make sure to:\n1. Read and understand the issue requirements\n2. Check related specifications for context\n3. Write clean, well-tested code\n4. Update documentation if needed\n`;\n```\n\n### ExecutionPrepareResult\n\n```typescript\n/**\n * ExecutionPrepareResult - Preview before starting execution\n */\nexport interface ExecutionPrepareResult {\n  // Rendered preview\n  renderedPrompt: string;\n\n  // Issue context\n  issue: {\n    id: string;\n    title: string;\n    description: string;\n  };\n\n  // Related context\n  relatedSpecs: Array<{ id: string; title: string }>;\n  relatedFeedback: Array<{ issueId: string; content: string }>;\n\n  // Default configuration\n  defaultConfig: ExecutionConfig;\n\n  // Available options\n  availableModels: string[];\n  availableBranches: string[];\n  availableTemplates: PromptTemplate[];\n\n  // Validation\n  warnings?: string[];\n  errors?: string[];\n}\n```\n\n## Part 2: Service Layer\n\n### ExecutionService\n\n```typescript\nexport class ExecutionService {\n  constructor(\n    private db: Database,\n    private worktreeManager: WorktreeManager,\n    private orchestratorFactory: OrchestratorFactory,\n    private transportManager: TransportManager\n  ) {}\n\n  /**\n   * Prepare execution - render template and show preview\n   */\n  async prepareExecution(\n    issueId: string,\n    options?: {\n      templateId?: string;\n      config?: Partial<ExecutionConfig>;\n    }\n  ): Promise<ExecutionPrepareResult> {\n    // 1. Load issue\n    const issue = await this.db.issues.findById(issueId);\n    if (!issue) {\n      throw new Error(`Issue ${issueId} not found`);\n    }\n\n    // 2. Load related specs (via relationships)\n    const relatedSpecs = await this.db.relationships.getRelatedSpecs(issueId);\n\n    // 3. Load feedback from related issues\n    const relatedFeedback = await this.db.feedback.getForIssue(issueId);\n\n    // 4. Get template\n    const template = options?.templateId\n      ? await this.db.templates.findById(options.templateId)\n      : await this.getDefaultTemplate('issue');\n\n    // 5. Build context for template rendering\n    const context = {\n      issueId: issue.id,\n      title: issue.title,\n      description: issue.description,\n      relatedSpecs: relatedSpecs.map(s => ({\n        id: s.id,\n        title: s.title,\n      })),\n      feedback: relatedFeedback.map(f => ({\n        issueId: f.fromIssueId,\n        content: f.content,\n      })),\n    };\n\n    // 6. Render template\n    const renderedPrompt = this.templateEngine.render(\n      template.template,\n      context\n    );\n\n    // 7. Get default config\n    const defaultConfig: ExecutionConfig = {\n      model: 'claude-sonnet-4',\n      baseBranch: 'main',\n      cleanupMode: 'auto',\n      checkpointInterval: 1,\n      continueOnStepFailure: false,\n      captureFileChanges: true,\n      captureToolCalls: true,\n      ...options?.config,\n    };\n\n    // 8. Get available options\n    const availableModels = ['claude-sonnet-4', 'claude-opus-4'];\n    const availableBranches = await this.gitService.listBranches();\n    const availableTemplates = await this.db.templates.findByType('issue');\n\n    // 9. Validate\n    const warnings: string[] = [];\n    const errors: string[] = [];\n\n    if (!renderedPrompt.trim()) {\n      errors.push('Rendered prompt is empty');\n    }\n\n    // Check for uncommitted changes if using local mode\n    if (options?.config?.mode === 'local') {\n      const hasChanges = await this.gitService.hasUncommittedChanges();\n      if (hasChanges) {\n        warnings.push(\n          'Working directory has uncommitted changes. ' +\n          'Consider using worktree mode for isolation.'\n        );\n      }\n    }\n\n    return {\n      renderedPrompt,\n      issue: {\n        id: issue.id,\n        title: issue.title,\n        description: issue.description,\n      },\n      relatedSpecs,\n      relatedFeedback,\n      defaultConfig,\n      availableModels,\n      availableBranches,\n      availableTemplates,\n      warnings,\n      errors,\n    };\n  }\n\n  /**\n   * Create and start execution\n   */\n  async createExecution(\n    issueId: string,\n    config: ExecutionConfig,\n    prompt: string\n  ): Promise<Execution> {\n    // 1. Validate\n    if (!prompt.trim()) {\n      throw new Error('Prompt cannot be empty');\n    }\n\n    const issue = await this.db.issues.findById(issueId);\n    if (!issue) {\n      throw new Error(`Issue ${issueId} not found`);\n    }\n\n    // 2. Determine execution mode\n    const mode = config.mode || 'worktree';\n    let worktreePath: string | undefined;\n    let workDir: string;\n\n    if (mode === 'worktree') {\n      // Create isolated worktree\n      const executionId = generateId('exec');\n      worktreePath = await this.worktreeManager.createWorktree(\n        executionId,\n        config.baseBranch || 'main',\n        config.branchName\n      );\n      workDir = worktreePath;\n    } else {\n      // Use local working directory\n      workDir = process.cwd();\n    }\n\n    // 3. Create execution record\n    const execution: Execution = {\n      id: generateId('exec'),\n      issueId,\n      mode,\n      baseBranch: config.baseBranch || 'main',\n      worktreePath,\n      prompt,\n      status: 'pending',\n      workflowExecutionId: '', // Will be set below\n      model: config.model || 'claude-sonnet-4',\n      config,\n      createdAt: new Date(),\n    };\n\n    await this.db.executions.create(execution);\n\n    // 4. Build workflow definition\n    const workflow: WorkflowDefinition = {\n      id: `issue-${issueId}-workflow`,\n      steps: [\n        {\n          id: 'implement',\n          taskType: 'issue',\n          prompt,\n          dependencies: [],\n          retryPolicy: config.retryPolicy,\n          timeout: config.timeout,\n        },\n      ],\n      initialContext: {\n        issueId,\n        executionId: execution.id,\n        mode,\n      },\n      config: {\n        checkpointInterval: config.checkpointInterval,\n        continueOnStepFailure: config.continueOnStepFailure,\n      },\n      metadata: {\n        workDir,\n      },\n    };\n\n    // 5. Create AG-UI adapter for this execution\n    const agUiAdapter = new AgUiEventAdapter(\n      execution.id,\n      execution.id // threadId = executionId\n    );\n\n    // Connect to SSE transport\n    this.transportManager.connectAdapter(agUiAdapter, execution.id);\n\n    // 6. Create and start orchestrator\n    const orchestrator = this.orchestratorFactory.create(agUiAdapter);\n\n    const workflowExecutionId = await orchestrator.startWorkflow(\n      workflow,\n      workDir,\n      {\n        checkpointInterval: config.checkpointInterval,\n        initialContext: workflow.initialContext,\n      }\n    );\n\n    // 7. Update execution with workflow ID\n    execution.workflowExecutionId = workflowExecutionId;\n    execution.status = 'running';\n    execution.startedAt = new Date();\n    await this.db.executions.update(execution);\n\n    // 8. Setup completion handlers\n    orchestrator.onWorkflowComplete(async (executionId, result) => {\n      await this.handleWorkflowComplete(execution.id, result);\n    });\n\n    orchestrator.onWorkflowFailed(async (executionId, error) => {\n      await this.handleWorkflowFailed(execution.id, error);\n    });\n\n    return execution;\n  }\n\n  /**\n   * Create follow-up execution (continue in same worktree)\n   */\n  async createFollowUp(\n    executionId: string,\n    feedback: string\n  ): Promise<Execution> {\n    // 1. Load parent execution\n    const parentExecution = await this.db.executions.findById(executionId);\n    if (!parentExecution) {\n      throw new Error(`Execution ${executionId} not found`);\n    }\n\n    if (parentExecution.status === 'running') {\n      throw new Error('Cannot create follow-up while execution is running');\n    }\n\n    // 2. Build follow-up prompt\n    const followUpPrompt = `${parentExecution.prompt}\n\n---\n\nUser feedback: ${feedback}\n\nPlease address the feedback above and continue working on the issue.`;\n\n    // 3. Create follow-up execution (same mode, same worktree if applicable)\n    const followUpExecution: Execution = {\n      id: generateId('exec'),\n      issueId: parentExecution.issueId,\n      mode: parentExecution.mode,\n      baseBranch: parentExecution.baseBranch,\n      worktreePath: parentExecution.worktreePath, // Reuse same worktree\n      prompt: followUpPrompt,\n      status: 'pending',\n      workflowExecutionId: '',\n      model: parentExecution.model,\n      config: parentExecution.config,\n      parentExecutionId: parentExecution.id,\n      createdAt: new Date(),\n    };\n\n    await this.db.executions.create(followUpExecution);\n\n    // 4. Update parent to track this follow-up\n    parentExecution.followUpExecutionIds = [\n      ...(parentExecution.followUpExecutionIds || []),\n      followUpExecution.id,\n    ];\n    await this.db.executions.update(parentExecution);\n\n    // 5. Start execution (same as createExecution but reuse worktree)\n    const workDir = parentExecution.worktreePath || process.cwd();\n\n    const workflow: WorkflowDefinition = {\n      id: `issue-${parentExecution.issueId}-follow-up-workflow`,\n      steps: [\n        {\n          id: 'follow-up',\n          taskType: 'issue',\n          prompt: followUpPrompt,\n          dependencies: [],\n        },\n      ],\n      initialContext: {\n        issueId: parentExecution.issueId,\n        executionId: followUpExecution.id,\n        parentExecutionId: parentExecution.id,\n        mode: parentExecution.mode,\n      },\n    };\n\n    const agUiAdapter = new AgUiEventAdapter(\n      followUpExecution.id,\n      followUpExecution.id\n    );\n    this.transportManager.connectAdapter(agUiAdapter, followUpExecution.id);\n\n    const orchestrator = this.orchestratorFactory.create(agUiAdapter);\n    const workflowExecutionId = await orchestrator.startWorkflow(\n      workflow,\n      workDir\n    );\n\n    followUpExecution.workflowExecutionId = workflowExecutionId;\n    followUpExecution.status = 'running';\n    followUpExecution.startedAt = new Date();\n    await this.db.executions.update(followUpExecution);\n\n    return followUpExecution;\n  }\n\n  /**\n   * Cancel execution and cleanup\n   */\n  async cancelExecution(executionId: string): Promise<void> {\n    const execution = await this.db.executions.findById(executionId);\n    if (!execution) {\n      throw new Error(`Execution ${executionId} not found`);\n    }\n\n    // 1. Cancel workflow orchestrator\n    const orchestrator = this.orchestratorFactory.get(\n      execution.workflowExecutionId\n    );\n    if (orchestrator) {\n      await orchestrator.cancelWorkflow(execution.workflowExecutionId);\n    }\n\n    // 2. Update status\n    execution.status = 'cancelled';\n    execution.cancelledAt = new Date();\n    await this.db.executions.update(execution);\n\n    // 3. Cleanup if auto mode\n    if (execution.config.cleanupMode === 'auto' && execution.worktreePath) {\n      await this.cleanupExecution(executionId);\n    }\n  }\n\n  /**\n   * Cleanup execution resources\n   */\n  async cleanupExecution(executionId: string): Promise<void> {\n    const execution = await this.db.executions.findById(executionId);\n    if (!execution) {\n      throw new Error(`Execution ${executionId} not found`);\n    }\n\n    // Only cleanup if using worktree mode\n    if (execution.mode === 'worktree' && execution.worktreePath) {\n      await this.worktreeManager.removeWorktree(executionId);\n    }\n  }\n\n  /**\n   * Get execution by ID\n   */\n  async getExecution(executionId: string): Promise<Execution | null> {\n    return this.db.executions.findById(executionId);\n  }\n\n  /**\n   * List executions for an issue\n   */\n  async listExecutions(issueId: string): Promise<Execution[]> {\n    return this.db.executions.findByIssueId(issueId);\n  }\n\n  /**\n   * Handle workflow completion\n   */\n  private async handleWorkflowComplete(\n    executionId: string,\n    result: WorkflowResult\n  ): Promise<void> {\n    const execution = await this.db.executions.findById(executionId);\n    if (!execution) return;\n\n    execution.status = 'completed';\n    execution.completedAt = new Date();\n    execution.filesChanged = result.outputs.filesChanged || [];\n    await this.db.executions.update(execution);\n\n    // Auto-cleanup if configured\n    if (execution.config.cleanupMode === 'auto' && result.success) {\n      await this.cleanupExecution(executionId);\n    }\n  }\n\n  /**\n   * Handle workflow failure\n   */\n  private async handleWorkflowFailed(\n    executionId: string,\n    error: Error\n  ): Promise<void> {\n    const execution = await this.db.executions.findById(executionId);\n    if (!execution) return;\n\n    execution.status = 'failed';\n    execution.completedAt = new Date();\n    execution.error = error.message;\n    await this.db.executions.update(execution);\n  }\n\n  /**\n   * Get default template for task type\n   */\n  private async getDefaultTemplate(type: string): Promise<PromptTemplate> {\n    const defaultTemplates = await this.db.templates.findByType(type);\n    const defaultTemplate = defaultTemplates.find(t => t.isDefault);\n\n    if (!defaultTemplate) {\n      // Return built-in default\n      return {\n        id: 'default-issue',\n        name: 'Default Issue Template',\n        description: 'Default template for issue execution',\n        type: 'issue',\n        template: DEFAULT_ISSUE_TEMPLATE,\n        variables: [\n          {\n            name: 'issueId',\n            description: 'Issue identifier',\n            type: 'string',\n            required: true,\n          },\n          {\n            name: 'title',\n            description: 'Issue title',\n            type: 'string',\n            required: true,\n          },\n          {\n            name: 'description',\n            description: 'Issue description',\n            type: 'string',\n            required: true,\n          },\n        ],\n        isDefault: true,\n        createdAt: new Date(),\n        updatedAt: new Date(),\n      };\n    }\n\n    return defaultTemplate;\n  }\n}\n```\n\n### PromptTemplateEngine\n\n```typescript\n/**\n * Simple template engine with Handlebars-like syntax\n */\nexport class PromptTemplateEngine {\n  /**\n   * Render template with context variables\n   */\n  render(template: string, context: Record<string, any>): string {\n    let result = template;\n\n    // Replace simple variables: {{variable}}\n    result = result.replace(/\\{\\{([^}#/]+)\\}\\}/g, (match, key) => {\n      const value = this.getValue(context, key.trim());\n      return value !== undefined ? String(value) : match;\n    });\n\n    // Handle conditionals: {{#if variable}}...{{/if}}\n    result = result.replace(\n      /\\{\\{#if ([^}]+)\\}\\}([\\s\\S]*?)\\{\\{\\/if\\}\\}/g,\n      (match, key, content) => {\n        const value = this.getValue(context, key.trim());\n        return value ? content : '';\n      }\n    );\n\n    // Handle loops: {{#each array}}...{{/each}}\n    result = result.replace(\n      /\\{\\{#each ([^}]+)\\}\\}([\\s\\S]*?)\\{\\{\\/each\\}\\}/g,\n      (match, key, itemTemplate) => {\n        const array = this.getValue(context, key.trim());\n        if (!Array.isArray(array)) return '';\n\n        return array\n          .map(item => this.render(itemTemplate, item))\n          .join('');\n      }\n    );\n\n    return result;\n  }\n\n  /**\n   * Get nested value from context\n   */\n  private getValue(context: Record<string, any>, path: string): any {\n    const keys = path.split('.');\n    let value: any = context;\n\n    for (const key of keys) {\n      if (value === null || value === undefined) return undefined;\n      value = value[key];\n    }\n\n    return value;\n  }\n\n  /**\n   * Validate template syntax\n   */\n  validate(template: string): { valid: boolean; errors: string[] } {\n    const errors: string[] = [];\n\n    // Check for balanced tags\n    const ifCount = (template.match(/\\{\\{#if/g) || []).length;\n    const endIfCount = (template.match(/\\{\\{\\/if\\}\\}/g) || []).length;\n    if (ifCount !== endIfCount) {\n      errors.push(`Unbalanced {{#if}} tags (${ifCount} vs ${endIfCount})`);\n    }\n\n    const eachCount = (template.match(/\\{\\{#each/g) || []).length;\n    const endEachCount = (template.match(/\\{\\{\\/each\\}\\}/g) || []).length;\n    if (eachCount !== endEachCount) {\n      errors.push(`Unbalanced {{#each}} tags (${eachCount} vs ${endEachCount})`);\n    }\n\n    return {\n      valid: errors.length === 0,\n      errors,\n    };\n  }\n}\n```\n\n## Part 3: API Routes\n\n```typescript\n// server/src/routes/executions.ts\n\n/**\n * Prepare execution - preview before starting\n * POST /api/issues/:issueId/executions/prepare\n */\nrouter.post(\n  '/issues/:issueId/executions/prepare',\n  async (req: Request, res: Response) => {\n    const { issueId } = req.params;\n    const { templateId, config } = req.body;\n\n    const result = await executionService.prepareExecution(issueId, {\n      templateId,\n      config,\n    });\n\n    res.json(result);\n  }\n);\n\n/**\n * Create and start execution\n * POST /api/issues/:issueId/executions\n */\nrouter.post(\n  '/issues/:issueId/executions',\n  async (req: Request, res: Response) => {\n    const { issueId } = req.params;\n    const { config, prompt } = req.body;\n\n    const execution = await executionService.createExecution(\n      issueId,\n      config,\n      prompt\n    );\n\n    res.json(execution);\n  }\n);\n\n/**\n * Get execution by ID\n * GET /api/executions/:executionId\n */\nrouter.get(\n  '/executions/:executionId',\n  async (req: Request, res: Response) => {\n    const { executionId } = req.params;\n    const execution = await executionService.getExecution(executionId);\n\n    if (!execution) {\n      return res.status(404).json({ error: 'Execution not found' });\n    }\n\n    res.json(execution);\n  }\n);\n\n/**\n * Stream execution events (SSE)\n * GET /api/executions/:executionId/stream\n */\nrouter.get(\n  '/executions/:executionId/stream',\n  async (req: Request, res: Response) => {\n    const { executionId } = req.params;\n    const clientId = generateId('client');\n\n    // Get SSE transport from transport manager\n    const sseTransport = transportManager.getSseTransport();\n    sseTransport.handleConnection(clientId, res, executionId);\n  }\n);\n\n/**\n * Create follow-up execution\n * POST /api/executions/:executionId/follow-up\n */\nrouter.post(\n  '/executions/:executionId/follow-up',\n  async (req: Request, res: Response) => {\n    const { executionId } = req.params;\n    const { feedback } = req.body;\n\n    const followUpExecution = await executionService.createFollowUp(\n      executionId,\n      feedback\n    );\n\n    res.json(followUpExecution);\n  }\n);\n\n/**\n * Cancel execution\n * DELETE /api/executions/:executionId\n */\nrouter.delete(\n  '/executions/:executionId',\n  async (req: Request, res: Response) => {\n    const { executionId } = req.params;\n    await executionService.cancelExecution(executionId);\n    res.json({ message: 'Execution cancelled' });\n  }\n);\n\n/**\n * List executions for issue\n * GET /api/issues/:issueId/executions\n */\nrouter.get(\n  '/issues/:issueId/executions',\n  async (req: Request, res: Response) => {\n    const { issueId } = req.params;\n    const executions = await executionService.listExecutions(issueId);\n    res.json(executions);\n  }\n);\n```\n\n## Part 4: Frontend Components\n\n### ExecutionConfigDialog\n\n```typescript\n// frontend/src/components/executions/ExecutionConfigDialog.tsx\n\nexport interface ExecutionConfigDialogProps {\n  issueId: string;\n  onStart: (config: ExecutionConfig, prompt: string) => void;\n  onCancel: () => void;\n}\n\nexport const ExecutionConfigDialog: React.FC<ExecutionConfigDialogProps> = ({\n  issueId,\n  onStart,\n  onCancel,\n}) => {\n  const [preparing, setPreparing] = useState(true);\n  const [preview, setPreview] = useState<ExecutionPrepareResult | null>(null);\n  const [prompt, setPrompt] = useState('');\n  const [config, setConfig] = useState<ExecutionConfig>({\n    mode: 'worktree',\n    model: 'claude-sonnet-4',\n    baseBranch: 'main',\n    cleanupMode: 'auto',\n  });\n\n  // Load preview on mount\n  useEffect(() => {\n    async function loadPreview() {\n      const response = await fetch(\n        `/api/issues/${issueId}/executions/prepare`,\n        {\n          method: 'POST',\n          headers: { 'Content-Type': 'application/json' },\n          body: JSON.stringify({ config }),\n        }\n      );\n      const result = await response.json();\n      setPreview(result);\n      setPrompt(result.renderedPrompt);\n      setPreparing(false);\n    }\n    loadPreview();\n  }, [issueId]);\n\n  const handleStart = () => {\n    onStart(config, prompt);\n  };\n\n  if (preparing || !preview) {\n    return <div>Loading...</div>;\n  }\n\n  return (\n    <Dialog>\n      <DialogHeader>\n        <DialogTitle>Configure Execution</DialogTitle>\n      </DialogHeader>\n\n      <div className=\"space-y-4\">\n        {/* Warnings */}\n        {preview.warnings && preview.warnings.length > 0 && (\n          <div className=\"bg-yellow-50 p-3 rounded\">\n            {preview.warnings.map((w, i) => (\n              <div key={i} className=\"text-sm text-yellow-800\">\n                ⚠️ {w}\n              </div>\n            ))}\n          </div>\n        )}\n\n        {/* Execution Mode */}\n        <div>\n          <label className=\"block text-sm font-medium mb-2\">\n            Execution Mode\n          </label>\n          <select\n            value={config.mode}\n            onChange={(e) =>\n              setConfig({ ...config, mode: e.target.value as ExecutionMode })\n            }\n            className=\"w-full border rounded p-2\"\n          >\n            <option value=\"worktree\">Isolated Worktree (Recommended)</option>\n            <option value=\"local\">Local Working Directory</option>\n          </select>\n          <p className=\"text-xs text-gray-500 mt-1\">\n            {config.mode === 'worktree'\n              ? 'Creates isolated git worktree for safe execution'\n              : 'Runs in your current working directory'}\n          </p>\n        </div>\n\n        {/* Base Branch (if worktree mode) */}\n        {config.mode === 'worktree' && (\n          <div>\n            <label className=\"block text-sm font-medium mb-2\">\n              Base Branch\n            </label>\n            <select\n              value={config.baseBranch}\n              onChange={(e) =>\n                setConfig({ ...config, baseBranch: e.target.value })\n              }\n              className=\"w-full border rounded p-2\"\n            >\n              {preview.availableBranches.map((branch) => (\n                <option key={branch} value={branch}>\n                  {branch}\n                </option>\n              ))}\n            </select>\n          </div>\n        )}\n\n        {/* Model */}\n        <div>\n          <label className=\"block text-sm font-medium mb-2\">Model</label>\n          <select\n            value={config.model}\n            onChange={(e) => setConfig({ ...config, model: e.target.value })}\n            className=\"w-full border rounded p-2\"\n          >\n            {preview.availableModels.map((model) => (\n              <option key={model} value={model}>\n                {model}\n              </option>\n            ))}\n          </select>\n        </div>\n\n        {/* Cleanup Mode (if worktree) */}\n        {config.mode === 'worktree' && (\n          <div>\n            <label className=\"block text-sm font-medium mb-2\">\n              Worktree Cleanup\n            </label>\n            <select\n              value={config.cleanupMode}\n              onChange={(e) =>\n                setConfig({\n                  ...config,\n                  cleanupMode: e.target.value as CleanupMode,\n                })\n              }\n              className=\"w-full border rounded p-2\"\n            >\n              <option value=\"auto\">Auto (on success)</option>\n              <option value=\"manual\">Manual</option>\n              <option value=\"never\">Never (debugging)</option>\n            </select>\n          </div>\n        )}\n\n        {/* Prompt Preview (Editable) */}\n        <div>\n          <label className=\"block text-sm font-medium mb-2\">\n            Prompt (Editable)\n          </label>\n          <textarea\n            value={prompt}\n            onChange={(e) => setPrompt(e.target.value)}\n            className=\"w-full border rounded p-2 font-mono text-sm\"\n            rows={15}\n          />\n        </div>\n      </div>\n\n      <DialogFooter>\n        <button onClick={onCancel} className=\"btn-secondary\">\n          Cancel\n        </button>\n        <button\n          onClick={handleStart}\n          disabled={preview.errors && preview.errors.length > 0}\n          className=\"btn-primary\"\n        >\n          Start Execution\n        </button>\n      </DialogFooter>\n    </Dialog>\n  );\n};\n```\n\n### ExecutionView\n\n```typescript\n// frontend/src/components/executions/ExecutionView.tsx\n\nexport interface ExecutionViewProps {\n  executionId: string;\n}\n\nexport const ExecutionView: React.FC<ExecutionViewProps> = ({\n  executionId,\n}) => {\n  const [execution, setExecution] = useState<Execution | null>(null);\n  const [showFollowUp, setShowFollowUp] = useState(false);\n\n  const agUiStream = useAgUiStream({\n    executionId,\n    onEvent: {\n      onRunFinished: () => {\n        // Reload execution to get final state\n        loadExecution();\n      },\n    },\n  });\n\n  useEffect(() => {\n    loadExecution();\n  }, [executionId]);\n\n  const loadExecution = async () => {\n    const response = await fetch(`/api/executions/${executionId}`);\n    const data = await response.json();\n    setExecution(data);\n  };\n\n  const handleFollowUp = async (feedback: string) => {\n    await fetch(`/api/executions/${executionId}/follow-up`, {\n      method: 'POST',\n      headers: { 'Content-Type': 'application/json' },\n      body: JSON.stringify({ feedback }),\n    });\n    setShowFollowUp(false);\n  };\n\n  const handleCancel = async () => {\n    await fetch(`/api/executions/${executionId}`, {\n      method: 'DELETE',\n    });\n    loadExecution();\n  };\n\n  if (!execution) {\n    return <div>Loading...</div>;\n  }\n\n  return (\n    <div className=\"execution-view\">\n      {/* Header */}\n      <div className=\"flex items-center justify-between mb-4\">\n        <div>\n          <h2 className=\"text-xl font-semibold\">\n            Execution {execution.id}\n          </h2>\n          <div className=\"flex items-center gap-2 text-sm text-gray-600\">\n            <span>Mode: {execution.mode}</span>\n            <span>•</span>\n            <span>Model: {execution.model}</span>\n            <span>•</span>\n            <span className={`status-${execution.status}`}>\n              {execution.status}\n            </span>\n          </div>\n        </div>\n\n        <div className=\"flex gap-2\">\n          {execution.status === 'running' && (\n            <button onClick={handleCancel} className=\"btn-danger\">\n              Cancel\n            </button>\n          )}\n          {['completed', 'failed'].includes(execution.status) && (\n            <button\n              onClick={() => setShowFollowUp(true)}\n              className=\"btn-primary\"\n            >\n              Follow Up\n            </button>\n          )}\n        </div>\n      </div>\n\n      {/* Execution Monitor (AG-UI streaming) */}\n      <ExecutionMonitor\n        executionId={executionId}\n        onComplete={() => loadExecution()}\n      />\n\n      {/* Follow-up Dialog */}\n      {showFollowUp && (\n        <FollowUpDialog\n          onSubmit={handleFollowUp}\n          onCancel={() => setShowFollowUp(false)}\n        />\n      )}\n    </div>\n  );\n};\n```\n\n### FollowUpDialog\n\n```typescript\n// frontend/src/components/executions/FollowUpDialog.tsx\n\nexport interface FollowUpDialogProps {\n  onSubmit: (feedback: string) => void;\n  onCancel: () => void;\n}\n\nexport const FollowUpDialog: React.FC<FollowUpDialogProps> = ({\n  onSubmit,\n  onCancel,\n}) => {\n  const [feedback, setFeedback] = useState('');\n\n  const handleSubmit = () => {\n    if (feedback.trim()) {\n      onSubmit(feedback);\n    }\n  };\n\n  return (\n    <Dialog>\n      <DialogHeader>\n        <DialogTitle>Provide Follow-up Feedback</DialogTitle>\n      </DialogHeader>\n\n      <div className=\"space-y-4\">\n        <p className=\"text-sm text-gray-600\">\n          Describe what changes you'd like the agent to make, or ask questions\n          about the implementation.\n        </p>\n\n        <textarea\n          value={feedback}\n          onChange={(e) => setFeedback(e.target.value)}\n          placeholder=\"e.g., 'Please add error handling for edge cases' or 'Can you explain why you chose this approach?'\"\n          className=\"w-full border rounded p-3\"\n          rows={6}\n        />\n      </div>\n\n      <DialogFooter>\n        <button onClick={onCancel} className=\"btn-secondary\">\n          Cancel\n        </button>\n        <button\n          onClick={handleSubmit}\n          disabled={!feedback.trim()}\n          className=\"btn-primary\"\n        >\n          Send Follow-up\n        </button>\n      </DialogFooter>\n    </Dialog>\n  );\n};\n```\n\n## Part 5: Database Schema\n\n```sql\n-- Executions table\nCREATE TABLE executions (\n  id TEXT PRIMARY KEY,\n  issue_id TEXT NOT NULL REFERENCES issues(id),\n\n  -- Configuration\n  mode TEXT NOT NULL CHECK(mode IN ('worktree', 'local')),\n  base_branch TEXT NOT NULL,\n  worktree_path TEXT,\n  prompt TEXT NOT NULL,\n\n  -- State\n  status TEXT NOT NULL CHECK(status IN (\n    'preparing', 'pending', 'running', 'paused',\n    'completed', 'failed', 'cancelled'\n  )),\n  workflow_execution_id TEXT NOT NULL,\n\n  -- Metadata\n  model TEXT NOT NULL,\n  config JSONB NOT NULL,\n\n  -- Lifecycle\n  created_at TIMESTAMP NOT NULL DEFAULT NOW(),\n  started_at TIMESTAMP,\n  completed_at TIMESTAMP,\n  cancelled_at TIMESTAMP,\n\n  -- Results\n  files_changed JSONB,\n  error TEXT,\n\n  -- Relationships\n  parent_execution_id TEXT REFERENCES executions(id),\n\n  -- Indexes\n  INDEX idx_executions_issue_id (issue_id),\n  INDEX idx_executions_status (status),\n  INDEX idx_executions_parent (parent_execution_id)\n);\n\n-- Prompt templates table\nCREATE TABLE prompt_templates (\n  id TEXT PRIMARY KEY,\n  name TEXT NOT NULL,\n  description TEXT,\n  type TEXT NOT NULL CHECK(type IN ('issue', 'spec', 'custom')),\n  template TEXT NOT NULL,\n  variables JSONB NOT NULL,\n  is_default BOOLEAN DEFAULT FALSE,\n  created_at TIMESTAMP NOT NULL DEFAULT NOW(),\n  updated_at TIMESTAMP NOT NULL DEFAULT NOW(),\n\n  INDEX idx_templates_type (type),\n  INDEX idx_templates_default (is_default)\n);\n```\n\n## Testing Strategy\n\n### Unit Tests\n\n1. **PromptTemplateEngine**\n   - Variable substitution\n   - Conditional rendering\n   - Loop rendering\n   - Nested paths\n   - Template validation\n\n2. **ExecutionService**\n   - prepareExecution builds correct preview\n   - createExecution with worktree mode\n   - createExecution with local mode\n   - createFollowUp reuses worktree\n   - Cleanup modes work correctly\n\n### Integration Tests\n\n1. **End-to-end execution flow**\n   - Prepare → Create → Stream → Complete\n   - Follow-up workflow\n   - Cancel and cleanup\n\n2. **Worktree isolation**\n   - Multiple concurrent executions don't interfere\n   - Follow-ups work in same worktree\n\n### E2E Tests\n\n1. **Frontend workflow**\n   - Open config dialog → edit prompt → start\n   - Monitor real-time progress\n   - Submit follow-up\n   - View execution history\n\n## Implementation Checklist\n\n### Backend\n\n- [ ] Define Execution entity schema\n- [ ] Create database migrations\n- [ ] Implement PromptTemplateEngine\n- [ ] Implement ExecutionService\n- [ ] Add API routes for executions\n- [ ] Integrate with WorktreeManager\n- [ ] Wire up AG-UI streaming\n- [ ] Add default prompt templates\n- [ ] Write unit tests\n- [ ] Write integration tests\n\n### Frontend\n\n- [ ] Create ExecutionConfigDialog component\n- [ ] Create ExecutionView component\n- [ ] Create FollowUpDialog component\n- [ ] Add \"Run Agent\" button to IssuePanel\n- [ ] Add execution history to IssuePanel\n- [ ] Wire up SSE streaming with useAgUiStream\n- [ ] Add styling and animations\n- [ ] Write component tests\n- [ ] Write E2E tests\n\n### Documentation\n\n- [ ] API documentation\n- [ ] User guide for running executions\n- [ ] Template syntax documentation\n- [ ] Troubleshooting guide\n\n## Usage Example\n\n```typescript\n// 1. User clicks \"Run Agent\" on issue\n// Frontend opens ExecutionConfigDialog\n\n// 2. Dialog prepares execution\nconst preview = await fetch('/api/issues/ISSUE-001/executions/prepare', {\n  method: 'POST',\n  body: JSON.stringify({ config: { mode: 'worktree' } }),\n});\n\n// 3. User edits prompt, configures settings, clicks \"Start\"\nconst execution = await fetch('/api/issues/ISSUE-001/executions', {\n  method: 'POST',\n  body: JSON.stringify({\n    config: {\n      mode: 'worktree',\n      model: 'claude-sonnet-4',\n      baseBranch: 'main',\n      cleanupMode: 'auto',\n    },\n    prompt: editedPrompt,\n  }),\n});\n\n// 4. Frontend connects to SSE stream\nconst eventSource = new EventSource(\n  `/api/executions/${execution.id}/stream`\n);\n\n// 5. Real-time events flow via AG-UI protocol\n// RUN_STARTED → STEP_STARTED → TOOL_CALL_START → ... → RUN_FINISHED\n\n// 6. User provides feedback\nawait fetch(`/api/executions/${execution.id}/follow-up`, {\n  method: 'POST',\n  body: JSON.stringify({\n    feedback: 'Please add error handling for edge cases',\n  }),\n});\n\n// 7. New execution starts in same worktree with appended feedback\n```\n\n## Related Specs\n\n- [[SPEC-003]] - Process Layer (spawns Claude Code processes)\n- [[SPEC-004]] - Engine Layer (task queuing)\n- [[SPEC-005]] - Resilience Layer (retry logic)\n- [[SPEC-006]] - Workflow Layer (LinearOrchestrator)\n- [[SPEC-007]] - Output Processing (parses stream-json)\n- [[SPEC-009]] - AG-UI Integration (real-time events)\n- [[SPEC-010]] - Worktree Management (execution isolation)\n","priority":2,"archived":0,"archived_at":null,"created_at":"2025-10-31 04:41:21","updated_at":"2025-11-03T03:10:12.584Z","parent_id":null,"parent_uuid":null,"relationships":[{"from":"SPEC-011","from_type":"spec","to":"SPEC-003","to_type":"spec","type":"references"},{"from":"SPEC-011","from_type":"spec","to":"SPEC-007","to_type":"spec","type":"references"},{"from":"SPEC-011","from_type":"spec","to":"SPEC-009","to_type":"spec","type":"references"},{"from":"SPEC-011","from_type":"spec","to":"SPEC-010","to_type":"spec","type":"references"},{"from":"SPEC-011","from_type":"spec","to":"SPEC-004","to_type":"spec","type":"references"},{"from":"SPEC-011","from_type":"spec","to":"SPEC-006","to_type":"spec","type":"references"}],"tags":[]}
{"id":"SPEC-012","uuid":"a77d2a0d-bae8-4582-a1e0-fb42cad68d35","title":"Issue-to-Execution System","file_path":"specs/issue_to_execution_system_SPEC-012.md","content":"End-to-end system for running AI agents on issues with template-based prompts, configurable execution modes (worktree/local), follow-up interactions, and real-time progress monitoring via AG-UI streaming.\n\n**Key Features:**\n\n- Template-driven prompt generation with preview/edit\n- Isolated worktree execution OR local git tree\n- Configurable execution settings (model, cleanup, retries)\n- Follow-up mechanism like Claude Code interaction flow\n- Real-time progress via AG-UI + SSE\n- Auto/manual cleanup options\n\n**Architecture:**\n\n- ExecutionService orchestrates lifecycle\n- PromptTemplateEngine renders customizable templates\n- WorktreeManager provides execution isolation\n- LinearOrchestrator + AgUiAdapter stream real-time events\n- Frontend components for config, monitoring, follow-ups\n\nIntegrates with SPEC-003 through SPEC-010.\n","priority":0,"archived":1,"archived_at":"2025-10-31T08:15:16.563Z","created_at":"2025-10-31 04:41:30","updated_at":"2025-11-03T03:10:12.591Z","parent_id":null,"parent_uuid":null,"relationships":[],"tags":["ag-ui","execution","integration","issue-management","templates","worktree"]}
{"id":"SPEC-013","uuid":"a1df3333-a59c-424a-bc19-9b5cacdecc46","title":"Merge Conflict Resolution & Multi-Developer Improvements","file_path":"specs/merge_conflict_resolution_multi_developer_improvem.md","content":"Comprehensive improvements to sudocode's JSONL storage system to handle merge conflicts, ID collisions, and reference integrity in multi-developer, multi-branch environments.\n\n## Background\n\nSudocode uses a git-native storage model with JSONL files for specs and issues. While this approach works well for single-developer workflows, several problems emerge in multi-developer scenarios:\n\n1. **ID Collision Risk**: Sequential ID generation can create the same ID on different branches\n2. **Reference Corruption**: Inline `[[ID]]` references become orphaned after collision resolution\n3. **Manual Merge Burden**: No tooling to assist with JSONL merge conflicts\n4. **Limited Collision Resolution**: Only one strategy (renumber incoming), not always optimal\n5. **No Reference Validation**: Broken references go undetected\n\nThis spec addresses all identified issues with a phased improvement plan. See full spec at `specs/merge_conflict_resolution.md` for complete details.\n\n## Problem Analysis\n\n### P1: ID Collision on Concurrent Creation (HIGH)\n- Sequential ID generation causes race conditions across branches\n- Example: Two branches both create ISSUE-042 with different UUIDs\n- Results in merge conflicts requiring manual resolution\n\n### P2: Inline Reference Corruption (HIGH)\n- When IDs are renumbered, `[[ID]]` references in markdown aren't updated\n- Silent corruption - references appear valid but point to wrong entity\n- No validation catches these broken references\n\n### P3: JSONL Merge Conflicts (MEDIUM-HIGH)\n- Large JSONL files (308KB+) with line-by-line conflicts\n- No tooling to assist resolution\n- Manual editing error-prone and time-consuming\n\n### P4: Limited Collision Detection & Resolution (MEDIUM)\n- Only one strategy: always renumber incoming entity\n- Doesn't consider age, reference count, or branch hierarchy\n- No user notification or choice\n\n### P5: Reference Integrity Issues (MEDIUM)\n- References stored in 3 places: SQLite, JSONL, markdown\n- No validation ensures consistency\n- Stale references go undetected\n\n### P6: Lack of Merge Tooling (MEDIUM)\n- Zero automation for conflict resolution\n- No pre-commit validation\n- No post-merge validation\n\n## Proposed Solutions\n\n### Solution 1: Pre-Commit ID Collision Detection\n- New command: `sudocode validate-ids`\n- Git pre-commit hook to catch collisions early\n- Zero runtime overhead (only on commit)\n\n### Solution 2: Reference Validation & Repair\n- New command: `sudocode validate-refs --fix`\n- Scans markdown for broken `[[ID]]` references\n- Automated reference updates after ID renumbering\n- Can suggest replacements for broken references\n\n### Solution 3: Interactive Conflict Resolution\n- New command: `sudocode conflicts detect`\n- New command: `sudocode conflicts resolve --interactive`\n- Guided resolution with metadata display\n- Auto-resolution with configurable strategies\n\n### Solution 4: Custom Git Merge Driver\n- Teach git to merge JSONL files intelligently\n- UUID-aware merging\n- Automatic collision resolution\n- Fallback to manual resolution on conflicts\n\n### Solution 5: Improved Collision Resolution Strategy\n- Multiple strategies: older-wins, more-refs-wins, main-wins, etc.\n- Configurable via `config.json`\n- User choice and control\n\n### Solution 6: Collision Audit Log\n- New table: `collision_log` in database\n- Tracks all collisions and resolutions\n- New command: `sudocode collisions show`\n- Complete audit trail for debugging\n\n## Implementation Phases\n\n### Phase 1: Detection & Validation (Week 1)\n- Pre-commit ID validation\n- Reference validation command\n- Documentation\n\n**Issues**:\n- Implement pre-commit ID validation\n- Implement reference validation command\n- Write multi-developer workflow docs\n\n### Phase 2: Automated Repair (Week 2)\n- Automated reference updates\n- Collision logging\n- Integration tests\n\n**Issues**:\n- Automated reference updates on collision\n- Add collision_log table\n- Implement collision logging\n- Integration tests\n\n### Phase 3: Interactive Resolution (Week 3)\n- Conflict detection and resolution commands\n- Collision resolution strategies\n- Strategy configuration\n\n**Issues**:\n- Implement conflict detection command\n- Implement interactive conflict resolver\n- Implement auto-resolution strategies\n- Add collision strategy to config\n\n### Phase 4: Git Integration (Week 4)\n- Custom git merge driver\n- E2E tests\n- Polish and edge cases\n\n**Issues**:\n- Implement custom git merge driver\n- Document merge driver setup\n- E2E test: Multi-developer workflow\n\n## Configuration\n\nNew config options in `config.json`:\n```json\n{\n  \"collision_resolution\": {\n    \"strategy\": \"older-wins\",\n    \"prompt_on_conflict\": true,\n    \"auto_update_references\": true\n  },\n  \"validation\": {\n    \"pre_commit_check\": true,\n    \"warn_on_broken_refs\": true\n  },\n  \"merge_driver\": {\n    \"enabled\": true,\n    \"fallback_to_manual\": true\n  }\n}\n```\n\n## Success Metrics\n\n- **Collision Detection Rate**: % caught pre-commit\n- **Automatic Merge Success**: % of JSONL merges without manual intervention\n- **Reference Validation**: % of broken references detected and fixed\n- **Developer Satisfaction**: Survey feedback on conflict resolution\n- **Merge Velocity**: Time from PR creation to merge\n\n## Risks & Mitigation\n\n- **Breaking Workflows**: All features opt-in, backward compatible\n- **Performance**: Validation is optional, runs only on changed files\n- **Merge Driver Complexity**: Extensive testing, clear fallback\n- **User Confusion**: Documentation, training, gradual rollout\n\n## Future Enhancements\n\n- Predictive collision avoidance\n- Distributed ID generation\n- Semantic merge with LLM\n- Web-based conflict visualization UI\n- Branch-aware workflows\n","priority":0,"archived":0,"archived_at":null,"created_at":"2025-10-31 07:22:36","updated_at":"2025-11-03T03:10:12.590Z","parent_id":null,"parent_uuid":null,"relationships":[],"tags":["data-integrity","git","infrastructure","multi-developer"]}
{"id":"SPEC-014","uuid":"52d430bc-c5be-4b16-9de9-d0af3ff9726f","title":"Execution Logs Design","file_path":"specs/execution_logs_design.md","content":"# Execution Logs Design\n\n## Overview\n\nExecution logs provide full history replay and debugging capabilities for agent executions. The design is inspired by vibe-kanban's approach but adapted for sudocode's durable file storage model.\n\n## Architecture\n\n### Storage Layers\n\n```\n┌─────────────────────────────────────────────────────────┐\n│                    Execution Logs                        │\n├─────────────────────────────────────────────────────────┤\n│                                                          │\n│  Layer 1: Real-time Streaming (AG-UI Protocol)          │\n│  ├─ SSE/WebSocket to frontend                           │\n│  ├─ Tool calls, file changes, progress                  │\n│  └─ Ephemeral - not persisted                           │\n│                                                          │\n│  Layer 2: Database Cache (execution_logs table)         │\n│  ├─ JSONL format in SQLite                              │\n│  ├─ Append-only for efficiency                          │\n│  ├─ One record per execution                            │\n│  └─ Fast local access                                   │\n│                                                          │\n│  Layer 3: Durable File Storage (executions.jsonl)       │\n│  ├─ Newline-delimited JSON file                         │\n│  ├─ Version controlled with git                         │\n│  ├─ Includes execution metadata + full logs             │\n│  └─ Similar to issues.jsonl and specs.jsonl             │\n│                                                          │\n└─────────────────────────────────────────────────────────┘\n```\n\n## Database Schema\n\n### execution_logs Table\n\n```sql\nCREATE TABLE execution_logs (\n    execution_id TEXT PRIMARY KEY,\n    logs TEXT NOT NULL DEFAULT '',          -- JSONL format\n    byte_size INTEGER NOT NULL DEFAULT 0,\n    created_at INTEGER NOT NULL DEFAULT (unixepoch()),\n    updated_at INTEGER NOT NULL DEFAULT (unixepoch()),\n    FOREIGN KEY (execution_id) REFERENCES executions(id) ON DELETE CASCADE\n);\n\n-- Indexes\nCREATE INDEX idx_execution_logs_updated_at ON execution_logs(updated_at);\nCREATE INDEX idx_execution_logs_byte_size ON execution_logs(byte_size);\n```\n\n### Relationship\n\n```\nexecutions (1) ←→ (0..1) execution_logs\n```\n\n- One execution can have zero or one log record\n- Logs are optional - only created when detailed logging is enabled\n- Foreign key ensures cascade delete when execution is removed\n\n## Log Message Format\n\n### JSONL Structure\n\nEach line in the `logs` field is a JSON object:\n\n```jsonl\n{\"type\":\"stdout\",\"data\":\"Starting execution...\\n\",\"timestamp\":1730361234567}\n{\"type\":\"ag_ui_event\",\"data\":{\"event\":\"tool_call\",\"payload\":{...}},\"timestamp\":1730361235789}\n{\"type\":\"tool_call\",\"data\":{\"tool\":\"Read\",\"input\":{...},\"output\":{...}},\"timestamp\":1730361236012}\n{\"type\":\"stderr\",\"data\":\"Warning: deprecated API\\n\",\"timestamp\":1730361237345}\n{\"type\":\"user_input\",\"data\":\"Please add error handling\",\"timestamp\":1730361240000}\n{\"type\":\"finished\",\"data\":{\"exitCode\":0},\"timestamp\":1730361250123}\n```\n\n### Message Types\n\n| Type | Description | Data Format |\n|------|-------------|-------------|\n| `stdout` | Standard output | String |\n| `stderr` | Standard error | String |\n| `tool_call` | Tool invocation | `{tool, input, output?, error?}` |\n| `ag_ui_event` | AG-UI protocol event | `{event, payload}` |\n| `user_input` | User feedback/follow-up | String |\n| `system` | System messages | String |\n| `finished` | Completion marker | `{exitCode?, error?}` |\n\n## Append-Only Operations\n\n### Efficient Incremental Updates\n\n```sql\n-- Append a new log line\nUPDATE execution_logs\nSET logs = logs || $new_line,\n    byte_size = byte_size + $line_byte_size,\n    updated_at = unixepoch()\nWHERE execution_id = $execution_id;\n```\n\nBenefits:\n- No need to load entire log into memory\n- Efficient for streaming scenarios\n- Works well with SQLite's page-based storage\n\n## Integration Points\n\n### 1. During Execution (Real-time)\n\n```typescript\n// As execution runs, append log messages\nawait executionLogsService.appendLog(executionId, {\n  type: \"tool_call\",\n  data: { tool: \"Read\", input: { file_path: \"...\" } },\n  timestamp: Date.now()\n});\n```\n\n### 2. After Execution (Sync to File)\n\n```typescript\n// Sync execution and logs to executions.jsonl\nawait syncExecutionToDisk(executionId);\n\n// Format in executions.jsonl:\n{\n  \"execution\": {\n    \"id\": \"exec-123\",\n    \"issueId\": \"ISSUE-001\",\n    \"status\": \"completed\",\n    ...\n  },\n  \"logs\": [\n    {\"type\":\"stdout\",\"data\":\"...\",\"timestamp\":...},\n    ...\n  ]\n}\n```\n\n### 3. Import/Export\n\n```typescript\n// Export executions from cache.db to executions.jsonl\nsudocode export --executions\n\n// Import executions from executions.jsonl to cache.db\nsudocode import --executions\n```\n\n## Use Cases\n\n### 1. Debugging Failed Executions\n\n```typescript\n// Load full execution history\nconst execution = await db.executions.findById('exec-123');\nconst logs = await db.executionLogs.findById('exec-123');\nconst messages = ExecutionLogsUtil.parseJsonl(logs.logs);\n\n// Filter for errors\nconst errors = messages.filter(m => m.type === 'stderr');\n```\n\n### 2. Replay Execution in UI\n\n```typescript\n// Stream historical logs to frontend\nconst messages = ExecutionLogsUtil.parseJsonl(logs.logs);\nfor (const msg of messages) {\n  // Send to UI with original timing\n  await delay(msg.timestamp - prevTimestamp);\n  socket.send(JSON.stringify(msg));\n}\n```\n\n### 3. Generate Execution Report\n\n```typescript\n// Summarize execution activity\nconst logs = ExecutionLogsUtil.parseJsonl(logs.logs);\nconst toolCalls = ExecutionLogsUtil.filterByType(logs, 'tool_call');\nconst filesChanged = toolCalls\n  .filter(t => t.data.tool === 'Write' || t.data.tool === 'Edit')\n  .length;\n```\n\n## Storage Management\n\n### Size Limits\n\n- Default: Store last 10MB of logs per execution\n- Configurable via execution config\n- Old logs can be truncated or archived to file storage\n\n### Cleanup Strategy\n\n```typescript\n// After successful sync to executions.jsonl\nif (config.cleanupLogsAfterSync) {\n  await db.executionLogs.delete(executionId);\n}\n\n// Or compress to summary\nconst summary = summarizeLogs(logs);\nawait db.executions.update(executionId, { summary });\nawait db.executionLogs.delete(executionId);\n```\n\n## Comparison with Vibe-Kanban\n\n| Aspect | Vibe-Kanban | Sudocode |\n|--------|-------------|----------|\n| **Storage Format** | JSONL in SQLite | JSONL in SQLite + file |\n| **Message Types** | Stdout, Stderr, JsonPatch, SessionId | Extended set including tool_call, ag_ui_event |\n| **Append Method** | SQL concatenation | SQL concatenation |\n| **Durable Storage** | SQLite only | SQLite + executions.jsonl |\n| **One-to-One** | execution_process ↔ logs | execution ↔ logs |\n\n## Future Enhancements\n\n1. **Compression**: Gzip logs in database to save space\n2. **Streaming API**: `/api/executions/:id/logs/stream` endpoint\n3. **Search**: Full-text search across logs\n4. **Retention Policy**: Auto-archive old logs to file storage\n5. **Log Levels**: Add severity levels (debug, info, warn, error)\n\n## Implementation Checklist\n\n- [x] Schema definition (`execution_logs` table)\n- [x] TypeScript types (`execution-logs.ts`)\n- [x] Design documentation\n- [ ] Database service layer (`ExecutionLogsService`)\n- [ ] Integration with `ExecutionService`\n- [ ] SSE streaming endpoint\n- [ ] Sync to `executions.jsonl`\n- [ ] Import/export CLI commands\n- [ ] Frontend log viewer component\n","priority":2,"archived":0,"archived_at":null,"created_at":"2025-10-31 09:58:18","updated_at":"2025-11-03T03:10:12.582Z","parent_id":null,"parent_uuid":null,"relationships":[],"tags":[]}
{"id":"SPEC-015","uuid":"9e5b7f07-5fc0-424b-858b-349df045dee0","title":"Git Synchronization Architecture for Multi-Remote and Multi-Worktree","file_path":"specs/git_synchronization_architecture_for_multi_remote_.md","content":"Comprehensive architecture for managing sudocode state across two collaboration scenarios:\n\n**Tier 1: Multi-Remote Synchronization** - Multiple developers on separate machines pushing/pulling to shared remote, with focus on minimizing conflicts through CRDT-inspired structures, ID lock files, and custom merge drivers.\n\n**Tier 2: Local Multi-Worktree Management** - Single developer managing multiple git worktrees locally, with main worktree as leader and centralized coordination for consistency.\n\n## Key Innovations\n\n### Multi-Remote (Tier 1)\n- **CRDT-Inspired Entity Schema**: LWW fields, vector clocks, lamport timestamps for deterministic merging\n- **ID Lock File**: `.sudocode/id-lock.json` with custom merge driver for tracking ID allocations\n- **Custom JSONL Merge Driver**: UUID-based merging with automatic collision resolution\n- **ID Range Reservation**: Developers can reserve ID ranges to prevent collisions\n- **Lamport Clock Resolution**: Deterministic collision resolution without coordination\n\n### Multi-Worktree (Tier 2)\n- **Coordination File**: `.git/sudocode-coordination.json` shared across all worktrees\n- **Main as Leader**: Main worktree is authoritative for ID allocation\n- **Pessimistic Locking**: Claim issues to prevent concurrent work\n- **Fast Sync**: Local filesystem sync without network roundtrips\n- **Guided Merge**: Automated merge-to-main workflow with conflict detection\n\n## Architecture Highlights\n\n**Enhanced Entity Structure**:\n```typescript\n{\n  id: \"ISSUE-043\",           // Display ID\n  uuid: \"aaa-111\",           // True identity\n  version: 5,                // Edit counter\n  lamport_clock: 17,         // Total ordering\n  vector_clock: {...},       // Causality tracking\n  title: LWWField<string>,   // CRDT field\n  content: LWWField<string>, // CRDT field\n}\n```\n\n**ID Lock File** for collision tracking\n**Custom Merge Drivers** for JSONL and lock files\n**Worktree Coordination** for local management\n\n## Implementation Plan\n\n5-week phased rollout:\n1. Enhanced entity schema with CRDT metadata\n2. ID lock file and merge driver\n3. JSONL merge driver with collision resolution\n4. Worktree coordination system\n5. Multi-remote validation and auto-resolution\n\nSee full spec at `specs/git_synchronization_architecture.md` for complete details.\n","priority":0,"archived":0,"archived_at":null,"created_at":"2025-11-01 04:52:31","updated_at":"2025-11-03T03:10:12.589Z","parent_id":null,"parent_uuid":null,"relationships":[],"tags":["crdt","distributed-systems","git","infrastructure","synchronization","worktree"]}
{"id":"SPEC-016","uuid":"def61b37-9524-4c17-8857-a35885619d2a","title":"Durable Execution Event Storage","file_path":"specs/durable_execution_event_storage.md","content":"# Durable Execution Event Storage\n\n## Overview\n\nEnhance the execution event system to persist both raw agent output AND AG-UI protocol events to the database, enabling complete durable storage that survives server restarts and allows historical access to execution data.\n\n## Problem Statement\n\nCurrently, execution events are only stored in an in-memory `EventBuffer` which has several limitations:\n\n1. **Ephemeral**: Events are lost on server restart\n2. **Limited History**: Buffer is pruned after 1 hour of inactivity\n3. **Race Conditions**: Clients connecting late may miss events if buffer is cleared\n4. **Memory Constraints**: Unbounded growth for long-running executions\n5. **No Persistence**: Cannot view execution details after server restart\n6. **Incomplete Data**: AG-UI events lose some original agent message context\n\n## Goals\n\n1. **Durability**: Execution events survive server restarts\n2. **Completeness**: Store both raw agent messages and AG-UI events\n3. **Historical Access**: View execution details days/weeks after completion\n4. **Efficient Storage**: Indexed, queryable database storage\n5. **Performance**: Maintain fast event delivery to active clients\n6. **Backwards Compatible**: Work with existing EventBuffer for active executions\n\n## Storage Strategy: Two-Track Approach\n\n### Track 1: Raw Agent Output (Complete)\nStore original agent messages as-is for debugging and regeneration:\n- Full Claude stream-json messages\n- Preserves all metadata (message IDs, model, stop reasons)\n- Appendable (newline-delimited JSON)\n- Useful for debugging and audit trails\n\n### Track 2: AG-UI Events (Structured)\nStore transformed AG-UI events for fast replay:\n- Pre-processed events ready for frontend\n- Indexed by sequence and type\n- Queryable by event type, time range\n- Optimized for SSE streaming\n\n## Architecture\n\n**Dual-Write with Dual-Track Storage**:\n```\n┌───────────────────────────────────────────────────────────┐\n│              ClaudeCodeOutputProcessor                     │\n│                                                            │\n│  Raw Line ──┬──> Parse ──> OutputMessage                  │\n│             │                    │                         │\n│             │                    ▼                         │\n│             │            AG-UI Transformation             │\n│             │                    │                         │\n└─────────────┼────────────────────┼─────────────────────────┘\n              │                    │\n              │                    │\n              ▼                    ▼\n      ┌──────────────┐    ┌──────────────┐\n      │ Raw Logs     │    │ AG-UI Events │\n      │ (append)     │    │ (structured) │\n      └──────────────┘    └──────────────┘\n              │                    │\n              └────────┬───────────┘\n                       ▼\n            ┌────────────────────┐\n            │  execution_logs    │\n            │   (database)       │\n            └────────────────────┘\n                       │\n                       ▼\n               ┌──────────────┐\n               │ EventBuffer  │\n               │ (in-memory)  │\n               └──────────────┘\n                       │\n                       ▼\n                 SSE Clients\n```\n\n## Database Schema\n\n### Updated `execution_logs` Table\n\n**Current Schema**:\n```sql\nCREATE TABLE IF NOT EXISTS execution_logs (\n    execution_id TEXT PRIMARY KEY,\n    logs TEXT NOT NULL DEFAULT '',\n    byte_size INTEGER NOT NULL DEFAULT 0,\n    created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,\n    updated_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,\n    FOREIGN KEY (execution_id) REFERENCES executions(id) ON DELETE CASCADE\n);\n```\n\n**Updated Schema**:\n```sql\nCREATE TABLE IF NOT EXISTS execution_logs (\n    execution_id TEXT PRIMARY KEY,\n    \n    -- Raw agent output (append-only, newline-delimited JSON)\n    raw_logs TEXT NOT NULL DEFAULT '',\n    raw_logs_byte_size INTEGER NOT NULL DEFAULT 0,\n    raw_logs_line_count INTEGER NOT NULL DEFAULT 0,\n    \n    -- AG-UI events (JSON array of structured events)\n    ag_ui_events TEXT NOT NULL DEFAULT '[]',\n    ag_ui_events_count INTEGER NOT NULL DEFAULT 0,\n    \n    -- Metadata\n    last_sequence_number INTEGER NOT NULL DEFAULT -1,\n    created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,\n    updated_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,\n    \n    FOREIGN KEY (execution_id) REFERENCES executions(id) ON DELETE CASCADE\n);\n```\n\n**Design Decisions**:\n- **Single table**: All execution logs/events in one place\n- **`raw_logs`**: Newline-delimited JSON, append-only, preserves everything\n- **`ag_ui_events`**: JSON array of AG-UI events with sequence numbers\n- **Counts**: Track line/event counts for fast metadata queries\n- **`last_sequence_number`**: Track latest sequence for appending\n- **One row per execution**: Simple PRIMARY KEY, no pagination needed for typical executions\n\n### Indexes\n\n```sql\nCREATE INDEX IF NOT EXISTS idx_execution_logs_updated_at \n    ON execution_logs(updated_at);\nCREATE INDEX IF NOT EXISTS idx_execution_logs_byte_size \n    ON execution_logs(raw_logs_byte_size);\nCREATE INDEX IF NOT EXISTS idx_execution_logs_event_count \n    ON execution_logs(ag_ui_events_count);\n```\n\n## Data Format Examples\n\n### Raw Logs Format\nNewline-delimited JSON (NDJSON), one Claude message per line:\n```\n{\"type\":\"assistant\",\"message\":{\"id\":\"msg_1\",\"content\":[{\"type\":\"text\",\"text\":\"Let me help\"}]}}\n{\"type\":\"assistant\",\"message\":{\"id\":\"msg_2\",\"content\":[{\"type\":\"tool_use\",\"id\":\"tool_1\",\"name\":\"Read\",\"input\":{...}}]}}\n{\"type\":\"tool_result\",\"result\":{\"tool_use_id\":\"tool_1\",\"content\":[{\"type\":\"text\",\"text\":\"...\"}]}}\n```\n\n### AG-UI Events Format\nJSON array with sequence numbers:\n```json\n[\n  {\"sequence\": 0, \"event\": {\"type\": \"RUN_STARTED\", \"runId\": \"...\", \"timestamp\": 123}},\n  {\"sequence\": 1, \"event\": {\"type\": \"TOOL_CALL_START\", \"toolCallId\": \"tool_1\", \"timestamp\": 124}},\n  {\"sequence\": 2, \"event\": {\"type\": \"TOOL_CALL_ARGS\", \"toolCallId\": \"tool_1\", \"delta\": \"...\", \"timestamp\": 125}}\n]\n```\n\n## Component Design\n\n### 1. ExecutionLogsStore Service\n\n**File**: `server/src/services/execution-logs-store.ts`\n\n**Responsibilities**:\n- Append raw agent output lines\n- Append AG-UI events with sequence numbers\n- Query logs and events\n- Provide statistics\n\n**Key Methods**:\n```typescript\nclass ExecutionLogsStore {\n  // Initialize logs for new execution\n  initializeLogs(executionId: string): void\n  \n  // Append raw agent output\n  appendRawLog(executionId: string, line: string): void\n  appendRawLogs(executionId: string, lines: string[]): void\n  \n  // Append AG-UI events\n  appendEvent(executionId: string, event: AgUiEvent): number  // Returns sequence number\n  appendEvents(executionId: string, events: AgUiEvent[]): number[]\n  \n  // Read operations\n  getRawLogs(executionId: string): string[]\n  getAgUiEvents(executionId: string, fromSequence?: number): BufferedEvent[]\n  getLogMetadata(executionId: string): LogMetadata\n  \n  // Cleanup\n  deleteLogs(executionId: string): void\n  pruneOldLogs(olderThanMs: number): number\n  \n  // Statistics\n  getStats(): StorageStats\n}\n```\n\n**Performance Considerations**:\n- Use SQLite transactions for batch appends\n- Parse JSON only when needed\n- Keep metadata (counts, sizes) updated incrementally\n- Consider JSONB extension for event queries (future)\n\n### 2. Dual Persistence in ExecutionService\n\n**File**: `server/src/services/execution-service.ts`\n\n**Changes**:\n```typescript\n// In createExecution(), capture both raw output and AG-UI events\n\nlet lineBuffer = '';\nengine = new SimpleExecutionEngine(processManager, {\n  maxConcurrent: 1,\n  onOutput: (data, type) => {\n    if (type === 'stdout') {\n      lineBuffer += data.toString();\n      let newlineIndex;\n      while ((newlineIndex = lineBuffer.indexOf('\\n')) !== -1) {\n        const line = lineBuffer.slice(0, newlineIndex);\n        lineBuffer = lineBuffer.slice(newlineIndex + 1);\n        \n        if (line.trim()) {\n          // 1. Store raw line immediately\n          logsStore.appendRawLog(execution.id, line).catch(err => {\n            console.error('Failed to store raw log:', err);\n          });\n          \n          // 2. Process through AG-UI pipeline\n          agUiSystem.processor.processLine(line).catch((err) => {\n            console.error('[ExecutionService] Error processing output line:', err);\n          });\n        }\n      }\n    }\n  },\n});\n\n// Connect processor to adapter - adapter will persist AG-UI events\nagUiSystem.adapter.onEvent((event) => {\n  logsStore.appendEvent(execution.id, event).catch(err => {\n    console.error('Failed to store AG-UI event:', err);\n  });\n});\n```\n\n### 3. TransportManager Integration\n\n**File**: `server/src/execution/transport/transport-manager.ts`\n\n**Changes**:\n```typescript\nclass TransportManager {\n  private logsStore: ExecutionLogsStore | null;\n  \n  constructor(config?: { enablePersistence?: boolean }) {\n    if (config?.enablePersistence) {\n      this.logsStore = new ExecutionLogsStore(getDatabase());\n    }\n  }\n  \n  broadcastToRun(runId: string, event: AgUiEvent): void {\n    // 1. Add to in-memory buffer (fast, for active clients)\n    this.eventBuffer.addEvent(runId, event);\n    \n    // 2. Events are persisted by ExecutionService listener (see above)\n    \n    // 3. Broadcast to connected clients\n    this.sseTransport.broadcastToRun(runId, event);\n  }\n  \n  getBufferedEvents(runId: string, fromSequence?: number): BufferedEvent[] {\n    // Try database first (durable), fallback to memory\n    if (this.logsStore) {\n      try {\n        const dbEvents = this.logsStore.getAgUiEvents(runId, fromSequence);\n        if (dbEvents.length > 0) {\n          console.log('[TransportManager] Loaded events from database', {\n            runId, eventCount: dbEvents.length, fromSequence\n          });\n          return dbEvents;\n        }\n      } catch (err) {\n        console.warn('[TransportManager] Database load failed, using buffer:', err);\n      }\n    }\n    return this.eventBuffer.getEvents(runId, fromSequence);\n  }\n}\n```\n\n### 4. SSE Endpoint\n\n**File**: `server/src/routes/executions-stream.ts`\n\n**No changes needed** - existing code already uses `transportManager.getBufferedEvents()`\n\n### 5. Cleanup Service\n\n**File**: `server/src/services/execution-logs-cleanup.ts`\n\n```typescript\nexport class ExecutionLogsCleanup {\n  private store: ExecutionLogsStore;\n  \n  start(intervalMs: number, retentionMs: number): void {\n    setInterval(() => this.runCleanup(retentionMs), intervalMs);\n    this.runCleanup(retentionMs); // Run immediately\n  }\n  \n  private runCleanup(retentionMs: number): void {\n    const pruned = this.store.pruneOldLogs(retentionMs);\n    const stats = this.store.getStats();\n    console.log('[ExecutionLogsCleanup] Cleanup completed', {\n      prunedExecutions: pruned,\n      totalExecutions: stats.totalExecutions,\n      avgEventsPerExecution: stats.avgEventsPerExecution.toFixed(2),\n    });\n  }\n}\n```\n\n**Cleanup Strategy**:\n- Delete all logs for completed executions older than retention period\n- Optionally keep only raw logs (smaller) or only AG-UI events (structured)\n- Configurable per-execution retention in future\n\n## Migration Plan\n\n### Phase 1: Schema Update\n1. Update `EXECUTION_LOGS_TABLE` in `types/src/schema.ts`\n2. Create migration function in `server/src/services/db.ts`\n3. Handle existing data (if any - likely none since table unused)\n\n### Phase 2: Storage Service\n1. Implement `ExecutionLogsStore` service\n2. Add methods for raw logs and AG-UI events\n3. Write comprehensive unit tests\n\n### Phase 3: Integration\n1. Update `ExecutionService` to capture raw output\n2. Add event listener to persist AG-UI events\n3. Update `TransportManager` to read from database\n4. Initialize `logsStore` in server startup\n\n### Phase 4: Cleanup\n1. Implement `ExecutionLogsCleanup` service\n2. Start cleanup job on server init\n3. Add graceful shutdown handling\n\n### Phase 5: Testing\n1. Unit tests for `ExecutionLogsStore`\n2. Integration tests for end-to-end persistence\n3. Test server restart scenarios\n4. Test cleanup and pruning logic\n5. Verify both raw logs and AG-UI events are persisted\n\n## Storage Size Analysis\n\n**Typical Execution**:\n- 100 Claude messages × 500 bytes = 50 KB raw logs\n- 500 AG-UI events × 200 bytes = 100 KB events\n- **Total: ~150 KB per execution**\n\n**1000 Executions**: ~150 MB (manageable)\n**With 30-day retention**: Depends on execution frequency\n\n**Optimization Options**:\n1. Compress old logs (gzip can achieve 5-10x compression on JSON)\n2. Prune detailed events, keep summaries\n3. Move to separate archive table after N days\n4. Use SQLite's JSON features for selective queries\n\n## Configuration\n\n```typescript\ninterface ServerConfig {\n  executionLogs: {\n    enablePersistence: boolean;      // Default: true\n    storeRawLogs: boolean;           // Default: true\n    storeAgUiEvents: boolean;        // Default: true\n    cleanupIntervalMs: number;       // Default: 3600000 (1 hour)\n    retentionMs: number;             // Default: 2592000000 (30 days)\n    compressOldLogs: boolean;        // Default: false (future)\n  }\n}\n```\n\n## Success Criteria\n\n1. ✅ Both raw logs and AG-UI events persist across server restarts\n2. ✅ Frontend can load execution history from any point in time\n3. ✅ Can regenerate AG-UI events from raw logs if needed\n4. ✅ No performance degradation for active executions\n5. ✅ Database queries complete in < 100ms for typical executions\n6. ✅ Storage grows predictably with configurable cleanup\n7. ✅ All tests pass including new persistence tests\n\n## Benefits of Two-Track Storage\n\n✅ **Completeness**: Raw logs preserve everything for debugging\n✅ **Performance**: AG-UI events ready for instant replay\n✅ **Flexibility**: Can regenerate different event formats from raw logs\n✅ **Audit Trail**: Complete record of agent interactions\n✅ **Simple Schema**: Single table, one row per execution\n✅ **Efficient**: Text storage is cheap, JSON is queryable\n\n## Trade-offs\n\n**Pros**:\n- Complete data retention\n- Fast event replay\n- Debugging capabilities\n- Future-proof (can regenerate events)\n\n**Cons**:\n- ~2x storage (raw + events)\n- Slightly more complex append logic\n- Need to parse JSON on read\n\n**Mitigation**:\n- Prune old executions aggressively\n- Compress archived logs\n- Store only critical events after N days\n\n## Non-Goals\n\n- Real-time log streaming (use SSE for active executions)\n- Full-text search on logs (can be added later)\n- Multi-server log synchronization (single server for now)\n- Log compression (future optimization)\n\n## Future Enhancements\n\n1. **Selective Storage**: Option to store only raw OR only events\n2. **Compression**: Gzip old logs for 5-10x space savings\n3. **Archive Table**: Move old logs to separate table\n4. **Log Export**: Download execution logs as JSON/text\n5. **Log Replay**: Regenerate AG-UI events from raw logs\n6. **Filtering API**: REST endpoint to query logs/events\n7. **JSONB**: Use SQLite JSON functions for event queries\n\n## Related Components\n\n- [[SPEC-007]]: Output Processing Layer (generates events)\n- [[SPEC-009]]: AG-UI Protocol (event format)\n- Event Buffer (`server/src/execution/transport/event-buffer.ts`)\n- Transport Manager (`server/src/execution/transport/transport-manager.ts`)\n- Database Schema (`types/src/schema.ts`)\n\n## References\n\n- AG-UI Protocol: https://github.com/anthropics/anthropic-quickstarts/tree/main/computer-use-demo/ui\n- Claude Stream JSON Format: Claude Code CLI output format\n- NDJSON: http://ndjson.org/\n- SQLite JSON: https://www.sqlite.org/json1.html","priority":1,"archived":0,"archived_at":null,"created_at":"2025-11-03 10:03:41","updated_at":"2025-11-03 10:22:11","parent_id":null,"parent_uuid":null,"relationships":[],"tags":["ag-ui","database","events","execution","persistence"]}
{"id":"SPEC-017","uuid":"193cbc9e-9a6f-4db4-b93b-1e7f2e414d66","title":"CopilotKit UI Migration Specification","file_path":"specs/copilotkit_ui_migration_specification.md","content":"# CopilotKit UI Migration Specification\n\n## Overview\nThis specification outlines the migration from custom AG-UI React components to CopilotKit's pre-built UI library. CopilotKit, created by the AG-UI protocol authors, provides production-ready React components that natively consume AG-UI events, allowing us to reduce ~85% of our custom UI code while gaining additional features.\n\n## Background\n\n### Current Implementation\n- **Custom Components**: `ExecutionMonitor`, `AgentTrajectory`, `MessageStream` (~1,500 LOC)\n- **Custom Hook**: `useAgUiStream` for AG-UI event consumption (~650 LOC)\n- **Manual SSE**: Direct EventSource connection management\n- **Custom State Management**: Manual tracking of messages, tool calls, execution state\n\n### Problems with Current Approach\n1. **High Maintenance Burden**: Custom UI code requires ongoing maintenance\n2. **Missing Features**: Lack of built-in threading, error handling, accessibility\n3. **Code Duplication**: Reimplementing patterns that CopilotKit provides\n4. **Limited Resources**: Team time better spent on core features\n\n## Goals\n\n### Primary Goals\n1. **Reduce UI Code by 85%+**: Replace custom components with CopilotKit\n2. **Improve UX**: Leverage CopilotKit's polished, battle-tested UI\n3. **Maintain Compatibility**: Keep AG-UI protocol integration intact\n4. **Zero Downtime**: Migrate incrementally without breaking existing features\n\n### Secondary Goals\n1. **Better Accessibility**: WCAG-compliant components out of the box\n2. **Responsive Design**: Mobile-friendly execution monitoring\n3. **Extensibility**: Easier to add new features using CopilotKit patterns\n4. **Developer Experience**: Reduce onboarding time for new developers\n\n## Architecture\n\n### Component Mapping\n\n| Current Component | CopilotKit Replacement | Lines Saved |\n|-------------------|------------------------|-------------|\n| `ExecutionMonitor` | `CopilotSidebar` or `CopilotChat` | ~350 |\n| `AgentTrajectory` | `useCopilotChatHeadless_c` + built-in rendering | ~280 |\n| `MessageStream` | Built-in message rendering | ~125 |\n| `useAgUiStream` | `useCoAgent` + `useCoAgentStateRender` | ~650 |\n| Tool call rendering | `useCopilotAction` with `render` | ~200 |\n| **Total** | | **~1,605 LOC** |\n\n### New Architecture\n\n```\n┌─────────────────────────────────────────┐\n│         CopilotKit Provider             │\n│  (Handles AG-UI connection & state)     │\n└──────────────┬──────────────────────────┘\n               │\n       ┌───────┴────────┐\n       │                │\n   ┌───▼────┐      ┌────▼────┐\n   │ UI     │      │ Headless│\n   │ Layer  │      │ Hooks   │\n   └────────┘      └─────────┘\n       │                │\n   ┌───▼────────────────▼───┐\n   │   Your Application     │\n   │   - Execution Pages    │\n   │   - Issue Management   │\n   └────────────────────────┘\n```\n\n### Runtime Connection\n\n```\nFrontend (React)              Backend (Node.js)\n┌──────────────┐             ┌──────────────┐\n│ CopilotKit   │             │ AG-UI Events │\n│   Provider   │─────HTTP────▶ SSE Stream   │\n└──────────────┘             └──────────────┘\n       │                            │\n       │ AG-UI Protocol             │\n       ▼                            ▼\n┌──────────────┐             ┌──────────────┐\n│ CopilotChat  │             │ Execution    │\n│ Component    │             │ Monitor      │\n└──────────────┘             └──────────────┘\n```\n\n## Implementation Plan\n\n### Phase 1: Setup & Proof of Concept (1-2 days)\n\n#### 1.1 Install Dependencies\n```bash\nnpm install @copilotkit/react-ui @copilotkit/react-core @copilotkit/runtime\n```\n\n**Dependencies Added:**\n- `@copilotkit/react-ui`: Pre-built UI components\n- `@copilotkit/react-core`: Headless hooks and core functionality\n- `@copilotkit/runtime`: Runtime for AG-UI integration\n\n#### 1.2 Create Runtime Endpoint\nCreate `/api/copilotkit/route.ts` to bridge CopilotKit with existing AG-UI streams.\n\n**Key Components:**\n- `CopilotRuntime`: Manages agent connections\n- `HttpAgent`: Connects to existing AG-UI SSE endpoints\n- Route handler for POST requests\n\n#### 1.3 Create Proof-of-Concept Page\nCreate `ExecutionPageCopilotKit.tsx` to demonstrate CopilotKit working alongside existing implementation.\n\n**Success Criteria:**\n- CopilotKit connects to existing AG-UI stream\n- Messages display in CopilotKit UI\n- Tool calls render properly\n- No regressions in existing execution page\n\n### Phase 2: Component Migration (2-3 days)\n\n#### 2.1 Migrate ExecutionMonitor\nReplace `<ExecutionMonitor>` with `<CopilotSidebar>`.\n\n**Before:**\n```tsx\n<ExecutionMonitor \n  executionId={id} \n  onComplete={handleComplete}\n  onError={handleError}\n/>\n```\n\n**After:**\n```tsx\n<CopilotSidebar\n  labels={{\n    title: \"Execution Monitor\",\n    initial: \"Monitoring execution...\"\n  }}\n  defaultOpen={true}\n/>\n```\n\n**Changes Required:**\n- Update `ExecutionView.tsx`\n- Add CopilotKit provider wrapper\n- Map callbacks to CopilotKit events\n- Update tests\n\n#### 2.2 Migrate Tool Call Rendering\nReplace custom tool call UI with `useCopilotAction`.\n\n**For Each Tool Type:**\n- `Read` → Custom render component\n- `Write` → Custom render component\n- `Edit` → Custom render component\n- `Bash` → Custom render component\n- Issue/Spec operations → Custom render components\n\n**Example:**\n```tsx\nuseCopilotAction({\n  name: \"read_file\",\n  available: \"disabled\", // Render only\n  render: ({ status, args, result }) => (\n    <ToolCallCard\n      name=\"Read\"\n      status={status}\n      args={args}\n      result={result}\n    />\n  )\n});\n```\n\n#### 2.3 Migrate State Management\nReplace `useAgUiStream` with `useCoAgent`.\n\n**Migration Steps:**\n1. Create agent state interface\n2. Replace hook calls\n3. Update state access patterns\n4. Migrate event handlers\n\n### Phase 3: Cleanup & Optimization (1 day)\n\n#### 3.1 Remove Deprecated Components\n- Delete `ExecutionMonitor.tsx`\n- Delete `AgentTrajectory.tsx`\n- Delete `MessageStream.tsx`\n- Delete `useAgUiStream.ts`\n\n#### 3.2 Update Tests\n- Migrate component tests to CopilotKit patterns\n- Add integration tests for runtime endpoint\n- Update E2E tests\n\n#### 3.3 Documentation\n- Update component documentation\n- Add CopilotKit setup guide\n- Create migration guide for future features\n\n### Phase 4: Polish & Launch (1 day)\n\n#### 4.1 Styling & Customization\n- Apply custom theme to CopilotKit components\n- Add custom markdown renderers if needed\n- Adjust layout and spacing\n\n#### 4.2 Performance Optimization\n- Lazy load CopilotKit components\n- Optimize bundle size\n- Add loading states\n\n#### 4.3 Launch\n- Deploy to staging\n- User acceptance testing\n- Deploy to production\n\n## Technical Specifications\n\n### API Surface Changes\n\n#### New Exports\n```typescript\n// src/components/copilotkit/ExecutionCopilot.tsx\nexport function ExecutionCopilot({ executionId }: Props)\n\n// src/components/copilotkit/ToolRenderers.tsx\nexport function useToolRenderers()\nexport function ReadFileRenderer({ args, status, result }: Props)\nexport function WriteFileRenderer({ args, status, result }: Props)\n// ... more renderers\n```\n\n#### Deprecated Exports (Mark for Phase 3 removal)\n```typescript\n// src/components/executions/ExecutionMonitor.tsx (deprecated)\n// src/components/executions/AgentTrajectory.tsx (deprecated)\n// src/components/executions/MessageStream.tsx (deprecated)\n// src/hooks/useAgUiStream.ts (deprecated)\n```\n\n### Configuration\n\n#### Environment Variables\n```bash\n# .env\nCOPILOTKIT_PUBLIC_API_KEY=optional_for_cloud_features\nNEXT_PUBLIC_COPILOTKIT_ENDPOINT=/api/copilotkit\n```\n\n#### CopilotKit Config\n```typescript\n// src/config/copilotkit.ts\nexport const copilotKitConfig = {\n  runtimeUrl: process.env.NEXT_PUBLIC_COPILOTKIT_ENDPOINT,\n  agents: {\n    execution: \"execution_agent\",\n    planning: \"planning_agent\",\n  },\n  theme: {\n    primaryColor: \"#your-brand-color\",\n    borderRadius: \"8px\",\n  },\n};\n```\n\n### Data Flow\n\n#### AG-UI Event Flow\n```\nBackend (Python/Node)\n  │\n  ├─ Emit AG-UI Events\n  │   ├─ TEXT_MESSAGE_START\n  │   ├─ TEXT_MESSAGE_CONTENT\n  │   ├─ TEXT_MESSAGE_END\n  │   ├─ TOOL_CALL_START\n  │   ├─ TOOL_CALL_ARGS\n  │   ├─ TOOL_CALL_END\n  │   └─ TOOL_CALL_RESULT\n  │\n  ▼\nSSE Stream (/api/executions/:id/stream)\n  │\n  ▼\nCopilotKit Runtime (/api/copilotkit)\n  │\n  ├─ Parse AG-UI events\n  ├─ Maintain conversation state\n  └─ Stream to frontend\n  │\n  ▼\nFrontend (React)\n  │\n  ├─ CopilotKit Provider\n  │   ├─ useCoAgent (state management)\n  │   ├─ useCopilotAction (tool rendering)\n  │   └─ useCoAgentStateRender (custom UI)\n  │\n  ▼\nUI Components\n  ├─ CopilotSidebar (execution monitor)\n  ├─ Custom tool renderers\n  └─ Status indicators\n```\n\n## Testing Strategy\n\n### Unit Tests\n- **Tool Renderers**: Test each `useCopilotAction` render function\n- **State Hooks**: Test `useCoAgent` state management\n- **Runtime Endpoint**: Test AG-UI event parsing\n\n### Integration Tests\n- **End-to-End Flow**: Create execution → monitor → complete\n- **Error Handling**: Network errors, AG-UI errors\n- **Real-time Updates**: Verify SSE connection and updates\n\n### Migration Tests\n- **Side-by-Side Comparison**: Run old and new UI in parallel\n- **Feature Parity**: Verify all existing features work\n- **Performance**: Compare bundle size and render performance\n\n## Risks & Mitigations\n\n### Risk 1: CopilotKit Incompatibility\n**Probability**: Low  \n**Impact**: High  \n**Mitigation**: \n- CopilotKit created AG-UI protocol (perfect compatibility)\n- Proof-of-concept in Phase 1 validates compatibility\n- Fallback: Continue with current implementation\n\n### Risk 2: Missing Features\n**Probability**: Medium  \n**Impact**: Medium  \n**Mitigation**:\n- Headless hooks provide full control if needed\n- Custom renderers for specialized requirements\n- Community support for feature requests\n\n### Risk 3: Learning Curve\n**Probability**: Low  \n**Impact**: Low  \n**Mitigation**:\n- Comprehensive documentation available\n- Incremental migration reduces complexity\n- POC phase allows team learning\n\n### Risk 4: Bundle Size Increase\n**Probability**: Medium  \n**Impact**: Low  \n**Mitigation**:\n- Tree-shaking removes unused components\n- Lazy loading for execution pages\n- Monitor bundle size throughout migration\n\n## Success Metrics\n\n### Quantitative Metrics\n- **Code Reduction**: Achieve ≥80% reduction in UI code\n- **Bundle Size**: Maintain or reduce current bundle size\n- **Performance**: Page load time ≤ current implementation\n- **Test Coverage**: Maintain ≥90% test coverage\n\n### Qualitative Metrics\n- **Developer Velocity**: Reduce time to add new features by 50%\n- **Bug Reports**: No increase in UI-related bugs\n- **User Satisfaction**: Equal or better UX feedback\n- **Code Maintainability**: Improved code readability scores\n\n## Timeline\n\n| Phase | Duration | Dependencies |\n|-------|----------|--------------|\n| Phase 1: POC | 1-2 days | None |\n| Phase 2: Migration | 2-3 days | Phase 1 complete |\n| Phase 3: Cleanup | 1 day | Phase 2 complete |\n| Phase 4: Polish | 1 day | Phase 3 complete |\n| **Total** | **5-7 days** | |\n\n**Milestone Dates** (assuming start date):\n- Day 0: Spec approved, begin implementation\n- Day 2: POC complete, decision point\n- Day 5: Migration complete\n- Day 6: Cleanup and tests complete\n- Day 7: Production deployment\n\n## Decision Points\n\n### Day 2: POC Review\n**Decision**: Continue with migration or revert?  \n**Criteria**:\n- ✅ CopilotKit successfully displays AG-UI events\n- ✅ Tool calls render correctly\n- ✅ Performance acceptable\n- ✅ Team comfortable with CopilotKit patterns\n\n**If NO → Abort migration, keep current implementation**  \n**If YES → Proceed to Phase 2**\n\n### Day 5: Feature Parity Check\n**Decision**: Deploy to staging or continue development?  \n**Criteria**:\n- ✅ All existing features working\n- ✅ Tests passing\n- ✅ No performance regressions\n\n## Rollback Plan\n\n### If Issues Found in Production\n1. **Immediate**: Feature flag to show old UI\n2. **Short-term**: Revert to previous deployment\n3. **Long-term**: Fix issues and redeploy\n\n### Rollback Triggers\n- Critical bugs affecting > 10% of users\n- Performance degradation > 20%\n- Data loss or corruption\n- Security vulnerabilities\n\n## Maintenance Plan\n\n### Post-Migration\n1. **Monitor**: Track error rates and performance\n2. **Optimize**: Profile and optimize as needed\n3. **Document**: Update all documentation\n4. **Train**: Team knowledge sharing session\n\n### Long-term\n1. **Updates**: Keep CopilotKit updated quarterly\n2. **Feedback**: Gather user feedback on new UI\n3. **Iterate**: Continuous improvement based on feedback\n4. **Contribute**: Contribute improvements back to CopilotKit\n\n## Approval\n\n### Stakeholders\n- [ ] Engineering Lead - Technical approval\n- [ ] Product Manager - Feature parity approval  \n- [ ] Designer - UX/UI approval\n- [ ] QA Lead - Testing strategy approval\n\n### Sign-off Required From\n- [ ] **Technical Owner**: Confirms architecture soundness\n- [ ] **Product Owner**: Confirms feature requirements met\n- [ ] **Security Team**: Confirms no security concerns\n\n---\n\n## Appendix\n\n### A. CopilotKit Component Reference\n- `CopilotKit`: Root provider component\n- `CopilotChat`: Full-featured chat interface\n- `CopilotSidebar`: Collapsible sidebar chat\n- `CopilotPopup`: Floating popup chat\n- `useCoAgent`: Shared state management hook\n- `useCopilotAction`: Define tools with custom rendering\n- `useCoAgentStateRender`: Custom UI for agent state\n\n### B. AG-UI Event Types Supported\n- ✅ `TEXT_MESSAGE_START`, `TEXT_MESSAGE_CONTENT`, `TEXT_MESSAGE_END`\n- ✅ `TOOL_CALL_START`, `TOOL_CALL_ARGS`, `TOOL_CALL_END`, `TOOL_CALL_RESULT`\n- ✅ `RUN_STARTED`, `RUN_FINISHED`, `RUN_ERROR`\n- ✅ `STEP_STARTED`, `STEP_FINISHED`\n- ✅ `STATE_SNAPSHOT`, `STATE_DELTA`\n- ✅ `CUSTOM` events\n\n### C. Resources\n- **CopilotKit Docs**: https://docs.copilotkit.ai\n- **AG-UI Protocol**: https://www.copilotkit.ai/ag-ui\n- **GitHub Repository**: https://github.com/CopilotKit/CopilotKit\n- **Example Apps**: https://github.com/CopilotKit/CopilotKit/tree/main/examples\n\n### D. Questions & Answers\n\n**Q: Will this break our existing AG-UI backend?**  \nA: No. CopilotKit consumes AG-UI events without requiring backend changes.\n\n**Q: Can we customize the UI?**  \nA: Yes. Deep customization via CSS, custom components, and headless hooks.\n\n**Q: What about our custom tool renderers?**  \nA: Preserved via `useCopilotAction` with custom render functions.\n\n**Q: Is CopilotKit free?**  \nA: Yes, open-source under MIT license. Optional paid cloud features available.\n\n**Q: What if CopilotKit doesn't meet our needs?**  \nA: Fallback to headless hooks for full control, or keep current implementation.","priority":0,"archived":0,"archived_at":null,"created_at":"2025-11-03 18:21:32","updated_at":"2025-11-03 18:21:32","parent_id":null,"parent_uuid":null,"relationships":[],"tags":["architecture","copilotkit","migration","ui"]}
{"id":"SPEC-018","uuid":"eadaa9cf-3f5c-433c-ac46-e8d252b4b515","title":"Hash-Based ID System Migration","file_path":"specs/hash_based_id_system_migration.md","content":"# Overview\n\nMigrate sudocode's ID generation system from sequential IDs (`SPEC-001`, `ISSUE-001`) to hash-based IDs (`s-x7k9`, `i-a3f2`) while maintaining backward compatibility. The new system derives short, stable hash IDs from UUIDs to provide better distributed workflow support while keeping dual ID architecture.\n\n# Motivation\n\n- **Reduce merge conflicts**: Sequential IDs cause conflicts in multi-branch/multi-agent workflows\n- **Stable IDs**: Hash derived from UUID means content changes don't affect ID\n- **Shorter format**: 4-8 character hash IDs vs full 36-character UUIDs for human-facing references\n- **Backwards compatible**: Legacy IDs (`SPEC-001`, `ISSUE-001`) continue to work\n- **Simpler than content-based**: No need for collision remapping since UUID guarantees uniqueness\n\n# Design\n\n## ID Format\n\n### New Format (Hash-Based)\n- **Issues**: `i-{hash}` (e.g., `i-x7k9`, `i-a3f2dd`)\n- **Specs**: `s-{hash}` (e.g., `s-14sh`, `s-9k2p7a`)\n- **Hash length**: Adaptive 4-8 characters based on entity count\n\n### Legacy Format (Sequential)\n- **Issues**: `ISSUE-001`, `ISSUE-042`\n- **Specs**: `SPEC-001`, `SPEC-042`\n- **Support**: Maintained indefinitely, no migration required\n\n## Hash Generation Algorithm\n\n```typescript\n// 1. Generate UUID (once per entity, never changes)\nuuid = crypto.randomUUID()  // \"a3f2e4d1-8c9b-4a5e-9d2f-1b3c4e5a6b7c\"\n\n// 2. Hash the UUID (SHA256 for distribution)\nhash = SHA256(uuid)  // deterministic from UUID\n\n// 3. Convert to base36 (0-9, a-z)\nbase36 = hash.toString(36)  // more compact than hex\n\n// 4. Take first N characters (adaptive length)\nshortHash = base36.substring(0, adaptiveLength(count))\n\n// 5. Format with prefix\nid = prefix + \"-\" + shortHash  // \"i-x7k9p\"\n```\n\n## Adaptive Length Strategy\n\nHash length grows proportionally with entity count to maintain collision probability under 25% (birthday paradox):\n\n| Entity Count | Hash Length | Example ID | Namespace Size |\n|--------------|-------------|------------|----------------|\n| 0-979        | 4 chars     | `i-x7k9`   | ~1.7M          |\n| 980-5,899    | 5 chars     | `i-x7k9p`  | ~60M           |\n| 5,900-34,999 | 6 chars     | `i-x7k9p1` | ~2.2B          |\n| 35,000-211,999 | 7 chars   | `i-x7k9p1a` | ~78B          |\n| 212,000+     | 8 chars     | `i-x7k9p1a4` | ~2.8T         |\n\n**Formula**: Based on birthday paradox probability calculation\n```\nP(collision) ≈ 1 - e^(-n²/2N)\nwhere n = number of items, N = namespace size (36^length)\n```\n\n## Collision Handling\n\nAlthough UUID-based hashing makes collisions extremely rare, the system handles them by trying progressively longer hashes:\n\n```typescript\nfor (let length = baseLength; length <= 8; length++) {\n  candidate = generateHash(uuid, length)\n  if (!exists(candidate)) {\n    return candidate\n  }\n}\nthrow Error(\"Failed to generate unique ID\")\n```\n\n## Database Schema\n\n**No changes required** - the existing dual-ID schema supports both formats:\n\n```typescript\ninterface Issue {\n  id: string;        // \"i-x7k9p\" (new) or \"ISSUE-001\" (legacy)\n  uuid: string;      // \"a3f2e4d1-...\" (unchanged)\n  title: string;\n  content: string;\n  // ... rest unchanged\n}\n\ninterface Spec {\n  id: string;        // \"s-14sh\" (new) or \"SPEC-001\" (legacy)\n  uuid: string;      // \"a3f2e4d1-...\" (unchanged)\n  title: string;\n  content: string;\n  // ... rest unchanged\n}\n```\n\n## ID Validation\n\nSupport both legacy and hash formats:\n\n```typescript\n// Legacy format: SPEC-001, ISSUE-001\nisLegacyID(id) = /^(SPEC|ISSUE)-\\d+$/.test(id)\n\n// Hash format: i-x7k9, s-14sh\nisHashID(id) = /^[is]-[0-9a-z]{4,8}$/.test(id)\n\n// Accept both in all CLI commands and API endpoints\n```\n\n# Implementation Plan\n\n## Phase 1: Core ID Generator\n**Files**: `cli/src/id-generator.ts`\n\n1. Add `getAdaptiveHashLength(count: number): number`\n2. Add `hashUUIDToBase36(uuid: string, length: number): string`\n3. Add `generateHashIDFromUUID(db, uuid, entityType, count): string`\n4. Add `isLegacyID(id: string): boolean`\n5. Add `isHashID(id: string): boolean`\n6. Update `generateSpecId()` to return `{id, uuid}` with hash-based ID\n7. Update `generateIssueId()` to return `{id, uuid}` with hash-based ID\n\n## Phase 2: CLI Operations\n**Files**: `cli/src/operations/*.ts`\n\nUpdate all operations that create issues/specs:\n1. `cli/src/operations/issue.ts` - `createIssue()`\n2. `cli/src/operations/spec.ts` - `createSpec()`\n3. Handle returned `{id, uuid}` tuple from generator\n4. Support both legacy and hash IDs in lookups\n\n## Phase 3: MCP Server\n**Files**: `mcp/src/sudocode.ts`\n\nUpdate MCP tools to handle both ID formats:\n1. `upsert_issue` - use new generator\n2. `upsert_spec` - use new generator\n3. `show_issue`, `show_spec` - support both formats\n4. `list_issues`, `list_specs` - display both formats\n\n## Phase 4: Frontend\n**Files**: `frontend/src/components/**/*.tsx`\n\nUpdate UI components to handle both formats:\n1. ID parsing and validation\n2. Display formatting (no prefix confusion)\n3. Search/filter by either format\n\n## Phase 5: Server\n**Files**: `server/src/services/db.ts`, `server/src/routes/*.ts`\n\n1. Update database service to use new generator\n2. Support both formats in all API endpoints\n3. Update TypeScript types if needed\n\n## Phase 6: Tests\nUpdate all test files to:\n1. Test hash ID generation\n2. Test adaptive length scaling\n3. Test collision handling\n4. Test legacy ID compatibility\n5. Test both formats in all operations\n\n# Migration Strategy\n\n## For Users\n\n**No action required** - the migration is transparent:\n\n1. **Existing entities**: Keep their legacy IDs (`SPEC-001`, `ISSUE-001`) forever\n2. **New entities**: Automatically get hash IDs (`s-x7k9`, `i-a3f2`)\n3. **References**: Both formats work in all commands and content\n4. **No data migration**: System supports both formats simultaneously\n\n## For Content References\n\nContent references remain stable:\n\n```markdown\n# In a spec or issue:\nSee [[ISSUE-001]] for details  ✅ works\nSee [[i-x7k9p]] for details     ✅ works\n```\n\nLegacy IDs in existing content continue to work since those entities keep their IDs.\n\n## Optional Migration Command\n\nFor users who want uniform IDs, provide optional migration:\n\n```bash\n# NOT implemented in Phase 1, but possible future enhancement\n$ sudocode migrate --to-hash-ids\n\n# Would update:\n# 1. Regenerate hash IDs from existing UUIDs\n# 2. Update all content references\n# 3. Provide rollback capability\n```\n\n# Benefits\n\n1. **Stability**: Hash from UUID means content changes don't affect ID\n2. **Uniqueness**: UUID guarantees no collisions (simpler than beads)\n3. **Brevity**: 4-8 chars vs 36-char UUID\n4. **Backwards compatible**: Legacy IDs continue working\n5. **Adaptive**: Grows with database size\n6. **Distributed-friendly**: No counter coordination needed\n7. **Simpler implementation**: No nonce/remapping logic needed\n\n# Trade-offs\n\n## Advantages over Current System\n- ✅ Fewer merge conflicts in multi-branch workflows\n- ✅ No sequential counter coordination\n- ✅ Shorter than displaying full UUIDs\n\n## Advantages over Beads' System\n- ✅ Stable IDs (content changes don't affect hash)\n- ✅ Simpler (no nonce, no remapping)\n- ✅ UUID guarantees uniqueness\n\n## Disadvantages\n- ❌ Loss of chronological ordering (can't tell `i-x7k9` is newer than `i-a3f2`)\n- ❌ Slightly less human-readable than sequential numbers\n- ❌ Migration adds complexity to codebase\n\n# Testing Strategy\n\n## Unit Tests\n1. Hash generation from UUID\n2. Base36 encoding correctness\n3. Adaptive length calculation\n4. Collision detection and handling\n5. Legacy ID detection\n6. Hash ID validation\n\n## Integration Tests\n1. Create issue with hash ID\n2. Create spec with hash ID\n3. Lookup by hash ID\n4. Lookup by legacy ID\n5. Mixed format in relationships\n6. Content references with both formats\n\n## Property Tests\n1. Hash determinism (same UUID → same hash)\n2. Collision probability matches theory\n3. Hash length increases correctly with count\n4. All generated IDs pass validation\n\n# Rollout Plan\n\n1. **Alpha**: Merge to main, flag as experimental\n2. **Beta**: Test with development team for 1-2 weeks\n3. **Release**: Include in next minor version with migration guide\n4. **Documentation**: Update README and docs with new ID format\n\n# Future Enhancements\n\n1. **Substring matching**: Support `sudocode show x7k9` (no prefix)\n2. **Migration command**: Optional tool to migrate legacy IDs\n3. **ID analytics**: Track hash length distribution\n4. **Custom prefixes**: Allow users to configure prefixes beyond `i-` and `s-`","priority":1,"archived":0,"archived_at":null,"created_at":"2025-11-04 18:53:23","updated_at":"2025-11-04 18:53:23","parent_id":null,"parent_uuid":null,"relationships":[],"tags":[]}
{"id":"SPEC-019","uuid":"2dd21db4-c6d4-4de3-a1ff-8d3bc586af41","title":"JSONL Merge Conflict Resolver","file_path":"specs/jsonl_merge_conflict_resolver.md","content":"\n# JSONL Merge Conflict Resolver\n\n## Overview\n\nImplement automatic merge conflict resolution for `issues.jsonl` and `specs.jsonl` files. This utility will resolve git merge conflicts deterministically using UUID-based deduplication and timestamp-based prioritization. The implementation includes both a manual CLI command and an optional git merge driver for seamless integration with git workflows.\n\n## Problem Statement\n\nWhen multiple developers work on separate branches and modify issues or specs, git merges can produce conflicts in JSONL files:\n\n```jsonl\n{\"id\":\"ISSUE-001\",\"uuid\":\"abc-123\",...}\n<<<<<<< HEAD\n{\"id\":\"ISSUE-002\",\"uuid\":\"def-456\",\"title\":\"Feature A\",\"updated_at\":\"2025-11-01T10:00:00Z\"}\n=======\n{\"id\":\"ISSUE-002\",\"uuid\":\"ghi-789\",\"title\":\"Feature B\",\"updated_at\":\"2025-11-04T10:00:00Z\"}\n>>>>>>> feature-branch\n{\"id\":\"ISSUE-003\",\"uuid\":\"jkl-012\",...}\n```\n\nManual resolution is error-prone and time-consuming. This spec defines an automatic resolution strategy that:\n- Preserves all unique data (no data loss)\n- Resolves conflicts deterministically (same result on any machine)\n- Maintains git-friendly JSONL sorting by `created_at`\n\n## Resolution Strategy\n\n### Core Rules\n\n1. **Different UUIDs** → Keep both entries (they represent different entities)\n   - If IDs conflict, rename the older one deterministically\n   - Example: `ISSUE-042` → `ISSUE-042-conflict-{first-8-chars-of-uuid}`\n\n2. **Same UUID, Same ID** → Keep the entry with most recent `updated_at` timestamp\n   - Merge metadata (relationships, tags) from both versions\n\n3. **Same UUID, Different IDs** → Keep both, rename the older one\n   - This handles race conditions where same entity got different IDs\n\n4. **Sort Result** → All entries sorted by `created_at` after resolution\n\n### Metadata Merging\n\nWhen resolving entries with same UUID/ID, merge:\n- **Relationships**: Union of all unique relationships from both versions\n- **Tags**: Union of all unique tags from both versions\n- **Content**: Use content from entry with most recent `updated_at`\n- **All other fields**: Use values from most recent entry\n\n### Deterministic ID Renaming\n\n```typescript\nfunction generateConflictId(originalId: string, uuid: string): string {\n  // Use first 8 chars of UUID for consistency\n  return `${originalId}-conflict-${uuid.slice(0, 8)}`;\n}\n```\n\nThis ensures:\n- Same UUID always generates same conflict ID\n- Conflict IDs are human-readable\n- No random elements (fully deterministic)\n\n## Implementation Architecture\n\n### File Structure\n\n```\ncli/src/\n├── merge-resolver.ts          # Core resolution logic\n├── cli/\n│   └── merge-commands.ts      # CLI command handlers\n└── cli.ts                     # Register commands\n\ncli/tests/\n└── unit/\n    └── merge-resolver.test.ts # Unit tests\n```\n\n### Core Module: `merge-resolver.ts`\n\n**Responsibilities:**\n- Parse JSONL files with git conflict markers\n- Apply resolution rules to deduplicate entries\n- Merge metadata from conflicting versions\n- Sort final result by `created_at`\n\n**Key Functions:**\n\n```typescript\n/**\n * Parse JSONL file containing git conflict markers\n * Returns structured representation of clean sections and conflicts\n */\nexport function parseMergeConflictFile(content: string): ConflictSection[]\n\ninterface ConflictSection {\n  type: 'clean' | 'conflict';\n  lines: string[];           // Lines without conflict markers\n  ours?: string[];          // Lines from HEAD (between <<<<<<< and =======)\n  theirs?: string[];        // Lines from incoming (between ======= and >>>>>>>)\n  marker?: ConflictMarker;  // Original marker info for debugging\n}\n\ninterface ConflictMarker {\n  start: number;  // Line number of <<<<<<<\n  middle: number; // Line number of =======\n  end: number;    // Line number of >>>>>>>\n  oursLabel: string;   // Label after <<<<<<< (e.g., \"HEAD\")\n  theirsLabel: string; // Label after >>>>>>> (e.g., \"feature-branch\")\n}\n\n/**\n * Resolve all entities using UUID-based deduplication\n * Handles different UUIDs, same UUID conflicts, and metadata merging\n */\nexport function resolveEntities<T extends JSONLEntity>(\n  entities: T[],\n  options?: ResolveOptions\n): ResolvedResult<T>\n\ninterface ResolveOptions {\n  verbose?: boolean;  // Include detailed resolution info\n}\n\ninterface ResolvedResult<T> {\n  entities: T[];           // Deduplicated and sorted entities\n  stats: ResolutionStats;  // What happened during resolution\n}\n\ninterface ResolutionStats {\n  totalInput: number;\n  totalOutput: number;\n  conflicts: ConflictResolution[];\n}\n\ninterface ConflictResolution {\n  type: 'different-uuids' | 'same-uuid-different-id' | 'same-uuid-same-id';\n  uuid: string;\n  originalIds: string[];\n  resolvedIds: string[];\n  action: string;  // Human-readable description\n}\n\n/**\n * Merge metadata from multiple versions of same entity\n */\nexport function mergeMetadata<T extends JSONLEntity>(\n  entities: T[]\n): T\n\n/**\n * Check if file contains git conflict markers\n */\nexport function hasGitConflictMarkers(filePath: string): boolean\n\n/**\n * Three-way merge for git merge driver\n * Merges base, ours, and theirs versions\n */\nexport function mergeThreeWay<T extends JSONLEntity>(\n  base: T[],\n  ours: T[],\n  theirs: T[]\n): ResolvedResult<T>\n```\n\n**Algorithm Details:**\n\n```typescript\nexport function resolveEntities<T extends JSONLEntity>(\n  entities: T[],\n  options: ResolveOptions = {}\n): ResolvedResult<T> {\n  const stats: ResolutionStats = {\n    totalInput: entities.length,\n    totalOutput: 0,\n    conflicts: []\n  };\n\n  // Group entities by UUID\n  const byUuid = new Map<string, T[]>();\n  for (const entity of entities) {\n    if (!byUuid.has(entity.uuid)) {\n      byUuid.set(entity.uuid, []);\n    }\n    byUuid.get(entity.uuid)!.push(entity);\n  }\n\n  const resolved: T[] = [];\n\n  // Process each UUID group\n  for (const [uuid, group] of byUuid) {\n    if (group.length === 1) {\n      // No conflict - single entity with this UUID\n      resolved.push(group[0]);\n      continue;\n    }\n\n    // Check if all have same ID\n    const ids = new Set(group.map(e => e.id));\n\n    if (ids.size === 1) {\n      // Same UUID, same ID → Keep most recent, merge metadata\n      const merged = mergeMetadata(group);\n      resolved.push(merged);\n\n      stats.conflicts.push({\n        type: 'same-uuid-same-id',\n        uuid,\n        originalIds: [group[0].id],\n        resolvedIds: [merged.id],\n        action: `Kept most recent version, merged ${group.length} versions`\n      });\n    } else {\n      // Same UUID, different IDs → Keep all, rename duplicates\n      const sorted = [...group].sort((a, b) =>\n        compareTimestamps(a.updated_at, b.updated_at)\n      );\n\n      // Keep most recent ID as-is\n      const keeper = sorted[sorted.length - 1];\n      resolved.push(keeper);\n\n      const originalIds = [];\n      const resolvedIds = [keeper.id];\n\n      // Rename older versions\n      for (let i = 0; i < sorted.length - 1; i++) {\n        const entity = { ...sorted[i] };\n        originalIds.push(entity.id);\n\n        if (entity.id !== keeper.id) {\n          entity.id = generateConflictId(entity.id, uuid);\n        } else {\n          entity.id = generateConflictId(entity.id, uuid);\n        }\n\n        resolvedIds.push(entity.id);\n        resolved.push(entity);\n      }\n\n      stats.conflicts.push({\n        type: 'same-uuid-different-id',\n        uuid,\n        originalIds,\n        resolvedIds,\n        action: `Renamed ${sorted.length - 1} conflicting IDs`\n      });\n    }\n  }\n\n  // Sort by created_at (git-friendly)\n  resolved.sort((a, b) => {\n    const aDate = a.created_at || '';\n    const bDate = b.created_at || '';\n    if (aDate < bDate) return -1;\n    if (aDate > bDate) return 1;\n    return (a.id || '').localeCompare(b.id || '');\n  });\n\n  stats.totalOutput = resolved.length;\n\n  return { entities: resolved, stats };\n}\n\nexport function mergeMetadata<T extends JSONLEntity>(\n  entities: T[]\n): T {\n  // Sort by updated_at, keep most recent as base\n  const sorted = [...entities].sort((a, b) =>\n    compareTimestamps(b.updated_at, a.updated_at)\n  );\n\n  const base = { ...sorted[0] };\n\n  // Merge relationships (union of unique)\n  const relationshipSet = new Set<string>();\n  for (const entity of entities) {\n    if (entity.relationships) {\n      for (const rel of entity.relationships) {\n        relationshipSet.add(JSON.stringify(rel));\n      }\n    }\n  }\n  base.relationships = Array.from(relationshipSet).map(r => JSON.parse(r));\n\n  // Merge tags (union of unique)\n  const tagSet = new Set<string>();\n  for (const entity of entities) {\n    if (entity.tags) {\n      for (const tag of entity.tags) {\n        tagSet.add(tag);\n      }\n    }\n  }\n  base.tags = Array.from(tagSet);\n\n  return base;\n}\n\nfunction compareTimestamps(a: string | undefined, b: string | undefined): number {\n  if (!a && !b) return 0;\n  if (!a) return -1;\n  if (!b) return 1;\n\n  // Normalize timestamps to ISO format\n  const normalizeTs = (ts: string) => {\n    const hasZone = ts.endsWith('Z') || ts.includes('+') || /[+-]\\d{2}:\\d{2}$/.test(ts);\n    return hasZone ? ts : ts.replace(' ', 'T') + 'Z';\n  };\n\n  const dateA = new Date(normalizeTs(a));\n  const dateB = new Date(normalizeTs(b));\n\n  return dateA.getTime() - dateB.getTime();\n}\n\nfunction generateConflictId(originalId: string, uuid: string): string {\n  return `${originalId}-conflict-${uuid.slice(0, 8)}`;\n}\n```\n\n### CLI Commands Module: `merge-commands.ts`\n\n**Responsibilities:**\n- Handle manual conflict resolution command\n- Handle git merge driver command\n- Provide user-friendly output and error messages\n- Support dry-run mode for safety\n\n**Manual Resolution Command:**\n\n```typescript\nexport async function handleResolveConflicts(\n  db: Database.Database,\n  outputDir: string,\n  options: {\n    dryRun?: boolean;\n    verbose?: boolean;\n    json?: boolean;\n  }\n): Promise<void> {\n  const issuesPath = path.join(outputDir, 'issues.jsonl');\n  const specsPath = path.join(outputDir, 'specs.jsonl');\n\n  // Check for conflicts\n  const issuesHasConflict = fs.existsSync(issuesPath) && hasGitConflictMarkers(issuesPath);\n  const specsHasConflict = fs.existsSync(specsPath) && hasGitConflictMarkers(specsPath);\n\n  if (!issuesHasConflict && !specsHasConflict) {\n    if (!options.json) {\n      console.log(chalk.green('✓ No merge conflicts found in JSONL files'));\n    } else {\n      console.log(JSON.stringify({ success: true, conflicts: 0 }));\n    }\n    return;\n  }\n\n  const results: any[] = [];\n\n  // Resolve issues.jsonl\n  if (issuesHasConflict) {\n    const result = await resolveFile(issuesPath, 'issue', options);\n    results.push({ file: 'issues.jsonl', ...result });\n  }\n\n  // Resolve specs.jsonl\n  if (specsHasConflict) {\n    const result = await resolveFile(specsPath, 'spec', options);\n    results.push({ file: 'specs.jsonl', ...result });\n  }\n\n  // Re-sync to database if not dry-run\n  if (!options.dryRun) {\n    await syncMarkdownToDatabase(db, { outputDir });\n\n    if (!options.json) {\n      console.log(chalk.green('✓ Re-synced to database'));\n    }\n  }\n\n  // Output results\n  if (options.json) {\n    console.log(JSON.stringify({ success: true, results }));\n  } else {\n    printResolveResults(results, options);\n  }\n}\n\nasync function resolveFile(\n  filePath: string,\n  entityType: 'issue' | 'spec',\n  options: { dryRun?: boolean; verbose?: boolean }\n): Promise<any> {\n  // Read file with conflict markers\n  const content = fs.readFileSync(filePath, 'utf8');\n\n  // Parse conflicts\n  const sections = parseMergeConflictFile(content);\n\n  // Extract all entities (from both clean and conflict sections)\n  const allEntities: JSONLEntity[] = [];\n\n  for (const section of sections) {\n    if (section.type === 'clean') {\n      for (const line of section.lines) {\n        if (line.trim()) {\n          try {\n            allEntities.push(JSON.parse(line));\n          } catch (e) {\n            console.warn(chalk.yellow(`Warning: Skipping malformed line: ${line.slice(0, 50)}...`));\n          }\n        }\n      }\n    } else {\n      // Conflict section - include both ours and theirs\n      for (const line of [...(section.ours || []), ...(section.theirs || [])]) {\n        if (line.trim()) {\n          try {\n            allEntities.push(JSON.parse(line));\n          } catch (e) {\n            console.warn(chalk.yellow(`Warning: Skipping malformed line: ${line.slice(0, 50)}...`));\n          }\n        }\n      }\n    }\n  }\n\n  // Resolve conflicts\n  const { entities: resolved, stats } = resolveEntities(allEntities, { verbose: options.verbose });\n\n  // Write back if not dry-run\n  if (!options.dryRun) {\n    await writeJSONL(filePath, resolved);\n  }\n\n  return { stats, entityType };\n}\n\nfunction printResolveResults(results: any[], options: { verbose?: boolean; dryRun?: boolean }): void {\n  for (const result of results) {\n    const { file, stats, entityType } = result;\n\n    console.log(chalk.bold(`\\n${file}:`));\n    console.log(`  Input:  ${stats.totalInput} ${entityType}s`);\n    console.log(`  Output: ${stats.totalOutput} ${entityType}s`);\n\n    if (stats.conflicts.length > 0) {\n      console.log(chalk.yellow(`  Resolved ${stats.conflicts.length} conflict(s):`));\n\n      for (const conflict of stats.conflicts) {\n        if (options.verbose) {\n          console.log(`    - ${conflict.action}`);\n          console.log(`      UUID: ${conflict.uuid}`);\n          console.log(`      IDs: ${conflict.originalIds.join(', ')} → ${conflict.resolvedIds.join(', ')}`);\n        } else {\n          console.log(`    - ${conflict.action}`);\n        }\n      }\n    }\n\n    if (options.dryRun) {\n      console.log(chalk.gray('  (dry-run - no changes written)'));\n    } else {\n      console.log(chalk.green('  ✓ Resolved and written'));\n    }\n  }\n}\n```\n\n**Git Merge Driver Command:**\n\n```typescript\nexport async function handleMergeDriver(options: {\n  base: string;    // Common ancestor version\n  ours: string;    // HEAD version (also used as output)\n  theirs: string;  // Incoming version\n  marker?: number; // Conflict marker size (provided by git)\n}): Promise<void> {\n  try {\n    // Log merge attempt for debugging\n    const logPath = path.join(process.cwd(), '.sudocode', 'merge-driver.log');\n    fs.appendFileSync(\n      logPath,\n      `[${new Date().toISOString()}] Merging: ${options.ours}\\n`\n    );\n\n    // Read all three versions\n    const baseEntities = fs.existsSync(options.base)\n      ? await readJSONL(options.base, { skipErrors: true })\n      : [];\n    const ourEntities = await readJSONL(options.ours, { skipErrors: true });\n    const theirEntities = await readJSONL(options.theirs, { skipErrors: true });\n\n    // Perform three-way merge\n    const { entities: merged, stats } = mergeThreeWay(\n      baseEntities,\n      ourEntities,\n      theirEntities\n    );\n\n    // Write result to output (ours file)\n    await writeJSONL(options.ours, merged);\n\n    // Log success\n    fs.appendFileSync(\n      logPath,\n      `  ✓ Success: ${baseEntities.length} (base) + ${ourEntities.length} (ours) + ${theirEntities.length} (theirs) → ${merged.length} (merged)\\n`\n    );\n\n    // Exit 0 = success, git will use this result\n    process.exit(0);\n\n  } catch (error) {\n    // Log failure\n    const logPath = path.join(process.cwd(), '.sudocode', 'merge-driver.log');\n    fs.appendFileSync(\n      logPath,\n      `  ✗ Failed: ${error instanceof Error ? error.message : String(error)}\\n`\n    );\n\n    // Exit 1 = failure, git will leave conflict markers\n    console.error('Merge driver failed:', error);\n    process.exit(1);\n  }\n}\n```\n\n**Init Merge Driver Setup Command:**\n\n```typescript\nexport async function handleInitMergeDriver(options: {\n  global?: boolean;  // Install globally vs per-repo\n}): Promise<void> {\n  const configFile = options.global\n    ? path.join(os.homedir(), '.gitconfig')\n    : path.join(process.cwd(), '.git', 'config');\n\n  // Check if .git exists (not in global mode)\n  if (!options.global && !fs.existsSync(path.join(process.cwd(), '.git'))) {\n    console.error(chalk.red('Error: Not in a git repository'));\n    console.error('Run this command from a git repository, or use --global');\n    process.exit(1);\n  }\n\n  // Add merge driver config\n  const configSection = `\n[merge \"sudocode-jsonl\"]\n\\tname = Sudocode JSONL automatic merge resolver\n\\tdriver = sudocode merge-driver --base=%O --ours=%A --theirs=%B\n\\trecursive = binary\n`;\n\n  // Check if already configured\n  if (fs.existsSync(configFile)) {\n    const content = fs.readFileSync(configFile, 'utf8');\n    if (content.includes('[merge \"sudocode-jsonl\"]')) {\n      console.log(chalk.yellow('Merge driver already configured in git config'));\n    } else {\n      fs.appendFileSync(configFile, configSection);\n      console.log(chalk.green(`✓ Added merge driver to ${configFile}`));\n    }\n  } else {\n    fs.writeFileSync(configFile, configSection);\n    console.log(chalk.green(`✓ Created ${configFile} with merge driver`));\n  }\n\n  // Add .gitattributes (only for local, not global)\n  if (!options.global) {\n    const gitattributesPath = path.join(process.cwd(), '.gitattributes');\n    const attributesLine = '.sudocode/*.jsonl merge=sudocode-jsonl\\n';\n\n    if (fs.existsSync(gitattributesPath)) {\n      const content = fs.readFileSync(gitattributesPath, 'utf8');\n      if (!content.includes('merge=sudocode-jsonl')) {\n        fs.appendFileSync(gitattributesPath, attributesLine);\n        console.log(chalk.green('✓ Added merge driver to .gitattributes'));\n      } else {\n        console.log(chalk.yellow('Merge driver already configured in .gitattributes'));\n      }\n    } else {\n      fs.writeFileSync(gitattributesPath, attributesLine);\n      console.log(chalk.green('✓ Created .gitattributes with merge driver'));\n    }\n\n    console.log(chalk.cyan('\\nℹ  Remember to commit .gitattributes to share with your team!'));\n  }\n\n  // Test the setup\n  console.log(chalk.bold('\\nTesting merge driver setup...'));\n  const testResult = await testMergeDriver();\n\n  if (testResult.success) {\n    console.log(chalk.green('✓ Merge driver is working correctly'));\n  } else {\n    console.log(chalk.red('✗ Merge driver test failed:'));\n    console.log(chalk.red(`  ${testResult.error}`));\n  }\n}\n\nasync function testMergeDriver(): Promise<{ success: boolean; error?: string }> {\n  // Create temp files for testing\n  const tmpDir = fs.mkdtempSync(path.join(os.tmpdir(), 'sudocode-merge-test-'));\n\n  try {\n    const base = path.join(tmpDir, 'base.jsonl');\n    const ours = path.join(tmpDir, 'ours.jsonl');\n    const theirs = path.join(tmpDir, 'theirs.jsonl');\n\n    // Write test data\n    const testEntity = {\n      id: 'TEST-001',\n      uuid: 'test-uuid-123',\n      title: 'Test',\n      content: 'Test',\n      created_at: '2025-01-01T00:00:00Z',\n      updated_at: '2025-01-01T00:00:00Z',\n      relationships: [],\n      tags: []\n    };\n\n    await writeJSONL(base, [testEntity]);\n    await writeJSONL(ours, [testEntity]);\n    await writeJSONL(theirs, [testEntity]);\n\n    // Test merge driver\n    await handleMergeDriver({ base, ours, theirs });\n\n    // Check result\n    const result = await readJSONL(ours);\n    if (result.length !== 1 || result[0].id !== 'TEST-001') {\n      throw new Error('Unexpected merge result');\n    }\n\n    return { success: true };\n  } catch (error) {\n    return {\n      success: false,\n      error: error instanceof Error ? error.message : String(error)\n    };\n  } finally {\n    // Cleanup\n    fs.rmSync(tmpDir, { recursive: true, force: true });\n  }\n}\n```\n\n### CLI Registration in `cli.ts`\n\n```typescript\n// Import merge command handlers\nimport {\n  handleResolveConflicts,\n  handleMergeDriver,\n  handleInitMergeDriver,\n} from \"./cli/merge-commands.js\";\n\n// Manual conflict resolution command\nprogram\n  .command('resolve-conflicts')\n  .description('Automatically resolve merge conflicts in JSONL files')\n  .option('--dry-run', 'Show what would be done without making changes')\n  .option('--verbose', 'Show detailed resolution information')\n  .action(async (options) => {\n    initDB();\n    await handleResolveConflicts(db!, outputDir, { ...options, json: jsonOutput });\n  });\n\n// Git merge driver command (called by git)\nprogram\n  .command('merge-driver')\n  .description('Git merge driver for JSONL files (called automatically by git)')\n  .requiredOption('--base <path>', 'Base/ancestor version file path')\n  .requiredOption('--ours <path>', 'Our version file path (HEAD)')\n  .requiredOption('--theirs <path>', 'Their version file path (incoming branch)')\n  .option('--marker-size <size>', 'Conflict marker size (provided by git)', parseInt)\n  .action(async (options) => {\n    // Don't call initDB - this runs during git merge, might not have db access\n    await handleMergeDriver(options);\n  });\n\n// Setup merge driver configuration\nprogram\n  .command('init-merge-driver')\n  .description('Configure git to use sudocode for automatic JSONL merge resolution')\n  .option('--global', 'Install globally (all repos) instead of just current repo')\n  .action(async (options) => {\n    await handleInitMergeDriver(options);\n  });\n```\n\n## Testing Strategy\n\n### Unit Tests (`cli/tests/unit/merge-resolver.test.ts`)\n\n**Test Cases:**\n\n```typescript\ndescribe('parseMergeConflictFile', () => {\n  it('should parse file with no conflicts', () => {\n    const content = '{\"id\":\"A\"}\\n{\"id\":\"B\"}\\n';\n    const sections = parseMergeConflictFile(content);\n\n    expect(sections).toHaveLength(1);\n    expect(sections[0].type).toBe('clean');\n    expect(sections[0].lines).toHaveLength(2);\n  });\n\n  it('should parse file with single conflict', () => {\n    const content = `{\"id\":\"A\"}\n<<<<<<< HEAD\n{\"id\":\"B\",\"uuid\":\"uuid-1\"}\n=======\n{\"id\":\"B\",\"uuid\":\"uuid-2\"}\n>>>>>>> feature\n{\"id\":\"C\"}`;\n\n    const sections = parseMergeConflictFile(content);\n\n    expect(sections).toHaveLength(3);\n    expect(sections[0].type).toBe('clean');\n    expect(sections[1].type).toBe('conflict');\n    expect(sections[1].ours).toEqual(['{\"id\":\"B\",\"uuid\":\"uuid-1\"}']);\n    expect(sections[1].theirs).toEqual(['{\"id\":\"B\",\"uuid\":\"uuid-2\"}']);\n    expect(sections[2].type).toBe('clean');\n  });\n\n  it('should handle multiple conflicts', () => {\n    // Test with multiple conflict sections\n  });\n\n  it('should handle nested conflict markers', () => {\n    // Test with conflict markers in content (rare edge case)\n  });\n});\n\ndescribe('resolveEntities', () => {\n  it('should keep single entity unchanged', () => {\n    const entities = [\n      { id: 'A', uuid: 'uuid-1', created_at: '2025-01-01T00:00:00Z', updated_at: '2025-01-01T00:00:00Z' }\n    ];\n\n    const { entities: resolved, stats } = resolveEntities(entities);\n\n    expect(resolved).toHaveLength(1);\n    expect(resolved[0].id).toBe('A');\n    expect(stats.conflicts).toHaveLength(0);\n  });\n\n  it('should keep both entities with different UUIDs', () => {\n    const entities = [\n      { id: 'A', uuid: 'uuid-1', created_at: '2025-01-01', updated_at: '2025-01-01' },\n      { id: 'A', uuid: 'uuid-2', created_at: '2025-01-02', updated_at: '2025-01-02' }\n    ];\n\n    const { entities: resolved, stats } = resolveEntities(entities);\n\n    expect(resolved).toHaveLength(2);\n    expect(resolved[0].id).toBe('A-conflict-uuid-1'); // Older one renamed\n    expect(resolved[1].id).toBe('A'); // Newer one keeps ID\n    expect(stats.conflicts).toHaveLength(1);\n    expect(stats.conflicts[0].type).toBe('same-uuid-different-id');\n  });\n\n  it('should keep most recent when same UUID and ID', () => {\n    const entities = [\n      {\n        id: 'A',\n        uuid: 'uuid-1',\n        title: 'Old',\n        created_at: '2025-01-01T00:00:00Z',\n        updated_at: '2025-01-01T00:00:00Z',\n        relationships: [],\n        tags: ['old']\n      },\n      {\n        id: 'A',\n        uuid: 'uuid-1',\n        title: 'New',\n        created_at: '2025-01-01T00:00:00Z',\n        updated_at: '2025-01-02T00:00:00Z',\n        relationships: [],\n        tags: ['new']\n      }\n    ];\n\n    const { entities: resolved } = resolveEntities(entities);\n\n    expect(resolved).toHaveLength(1);\n    expect(resolved[0].title).toBe('New'); // Most recent\n    expect(resolved[0].tags).toEqual(['old', 'new']); // Merged\n  });\n\n  it('should merge relationships from multiple versions', () => {\n    const entities = [\n      {\n        id: 'A',\n        uuid: 'uuid-1',\n        updated_at: '2025-01-01T00:00:00Z',\n        relationships: [{ from: 'A', to: 'B', type: 'blocks' }]\n      },\n      {\n        id: 'A',\n        uuid: 'uuid-1',\n        updated_at: '2025-01-02T00:00:00Z',\n        relationships: [{ from: 'A', to: 'C', type: 'related' }]\n      }\n    ];\n\n    const { entities: resolved } = resolveEntities(entities);\n\n    expect(resolved).toHaveLength(1);\n    expect(resolved[0].relationships).toHaveLength(2);\n  });\n\n  it('should sort result by created_at', () => {\n    const entities = [\n      { id: 'C', uuid: 'uuid-3', created_at: '2025-03-01', updated_at: '2025-03-01' },\n      { id: 'A', uuid: 'uuid-1', created_at: '2025-01-01', updated_at: '2025-01-01' },\n      { id: 'B', uuid: 'uuid-2', created_at: '2025-02-01', updated_at: '2025-02-01' }\n    ];\n\n    const { entities: resolved } = resolveEntities(entities);\n\n    expect(resolved.map(e => e.id)).toEqual(['A', 'B', 'C']);\n  });\n});\n\ndescribe('mergeThreeWay', () => {\n  it('should handle clean three-way merge', () => {\n    const base = [\n      { id: 'A', uuid: 'uuid-1', title: 'Base', updated_at: '2025-01-01' }\n    ];\n    const ours = [\n      { id: 'A', uuid: 'uuid-1', title: 'Ours', updated_at: '2025-01-02' }\n    ];\n    const theirs = [\n      { id: 'A', uuid: 'uuid-1', title: 'Theirs', updated_at: '2025-01-03' }\n    ];\n\n    const { entities: merged } = mergeThreeWay(base, ours, theirs);\n\n    expect(merged).toHaveLength(1);\n    expect(merged[0].title).toBe('Theirs'); // Most recent\n  });\n\n  it('should handle additions on both sides', () => {\n    const base = [\n      { id: 'A', uuid: 'uuid-1', created_at: '2025-01-01', updated_at: '2025-01-01' }\n    ];\n    const ours = [\n      ...base,\n      { id: 'B', uuid: 'uuid-2', created_at: '2025-01-02', updated_at: '2025-01-02' }\n    ];\n    const theirs = [\n      ...base,\n      { id: 'C', uuid: 'uuid-3', created_at: '2025-01-03', updated_at: '2025-01-03' }\n    ];\n\n    const { entities: merged } = mergeThreeWay(base, ours, theirs);\n\n    expect(merged).toHaveLength(3);\n    expect(merged.map(e => e.id).sort()).toEqual(['A', 'B', 'C']);\n  });\n});\n\ndescribe('hasGitConflictMarkers', () => {\n  it('should detect conflict markers', () => {\n    const tmpFile = path.join(os.tmpdir(), 'test-conflict.jsonl');\n    fs.writeFileSync(tmpFile, '<<<<<<< HEAD\\n{\"id\":\"A\"}\\n=======\\n{\"id\":\"B\"}\\n>>>>>>>\\n');\n\n    expect(hasGitConflictMarkers(tmpFile)).toBe(true);\n\n    fs.unlinkSync(tmpFile);\n  });\n\n  it('should return false for clean file', () => {\n    const tmpFile = path.join(os.tmpdir(), 'test-clean.jsonl');\n    fs.writeFileSync(tmpFile, '{\"id\":\"A\"}\\n{\"id\":\"B\"}\\n');\n\n    expect(hasGitConflictMarkers(tmpFile)).toBe(false);\n\n    fs.unlinkSync(tmpFile);\n  });\n});\n```\n\n### Integration Tests\n\n```typescript\ndescribe('resolve-conflicts command integration', () => {\n  it('should resolve conflicts in issues.jsonl', async () => {\n    // Setup: Create test repo with conflict\n    // Execute: Run resolve-conflicts command\n    // Verify: Check file is clean and entities are correct\n  });\n\n  it('should handle dry-run mode', async () => {\n    // Verify no files are modified in dry-run\n  });\n});\n\ndescribe('merge-driver integration', () => {\n  it('should successfully merge via git', async () => {\n    // Setup: Create git repo with two branches\n    // Create conflicting changes\n    // Verify: Git merge succeeds automatically\n  });\n});\n```\n\n## Usage Documentation\n\n### Manual Conflict Resolution\n\n**Basic usage:**\n```bash\n# After git merge produces conflicts\ngit merge feature-branch\n# Conflict in .sudocode/issues.jsonl!\n\n# Resolve automatically\nsudocode resolve-conflicts\n\n# Review and commit\ngit add .sudocode/issues.jsonl\ngit commit\n```\n\n**Dry-run mode:**\n```bash\n# Preview what would happen without making changes\nsudocode resolve-conflicts --dry-run\n```\n\n**Verbose output:**\n```bash\n# See detailed information about each conflict resolution\nsudocode resolve-conflicts --verbose\n```\n\n**Example output:**\n```\nissues.jsonl:\n  Input:  248 issues\n  Output: 246 issues\n  Resolved 3 conflict(s):\n    - Kept most recent version, merged 2 versions\n    - Renamed 1 conflicting IDs\n    - Kept both ISSUE-042 (different UUIDs)\n  ✓ Resolved and written\n\nspecs.jsonl:\n  Input:  87 specs\n  Output: 87 specs\n  No conflicts\n  ✓ Resolved and written\n\n✓ Re-synced to database\n```\n\n### Git Merge Driver Setup\n\n**One-time setup (per repository):**\n```bash\n# Configure git to use sudocode merge driver\nsudocode init-merge-driver\n\n# Output:\n# ✓ Added merge driver to .git/config\n# ✓ Created .gitattributes with merge driver\n# ℹ  Remember to commit .gitattributes to share with your team!\n# Testing merge driver setup...\n# ✓ Merge driver is working correctly\n```\n\n**Global setup (all repositories):**\n```bash\n# Install for all your git repositories\nsudocode init-merge-driver --global\n\n# Output:\n# ✓ Added merge driver to ~/.gitconfig\n# ℹ  Each repository will need .gitattributes configured separately\n```\n\n**After setup, merges are automatic:**\n```bash\n# Normal git workflow - conflicts are auto-resolved\ngit merge feature-branch\n# Merge completed successfully!\n```\n\n**Check merge driver logs:**\n```bash\n# View merge driver activity\ncat .sudocode/merge-driver.log\n\n# Example output:\n# [2025-11-04T10:30:00.000Z] Merging: .sudocode/issues.jsonl\n#   ✓ Success: 245 (base) + 246 (ours) + 247 (theirs) → 246 (merged)\n```\n\n## Error Handling\n\n### Malformed JSON Lines\n\n```typescript\n// Skip malformed lines with warning\ntry {\n  entity = JSON.parse(line);\n} catch (error) {\n  if (!options.skipErrors) {\n    throw new Error(`Malformed JSON at line ${lineNum}: ${error.message}`);\n  }\n  console.warn(chalk.yellow(`Warning: Skipping malformed line ${lineNum}`));\n  continue;\n}\n```\n\n### Missing Timestamps\n\n```typescript\n// Fall back to created_at if updated_at is missing\nfunction getComparisonTimestamp(entity: JSONLEntity): string {\n  return entity.updated_at || entity.created_at || '1970-01-01T00:00:00Z';\n}\n```\n\n### Parent Reference Updates\n\nIf an entity's ID is renamed due to conflict, update any parent_id references:\n\n```typescript\nfunction updateParentReferences(entities: JSONLEntity[], idMap: Map<string, string>): void {\n  for (const entity of entities) {\n    if (entity.parent_id && idMap.has(entity.parent_id)) {\n      entity.parent_id = idMap.get(entity.parent_id);\n    }\n  }\n}\n```\n\n### Merge Driver Failures\n\nIf merge driver fails (exit 1), git will leave conflict markers for manual review:\n\n```typescript\ntry {\n  // Attempt automatic merge\n  await handleMergeDriver(options);\n  process.exit(0);\n} catch (error) {\n  // Log error and let git handle it manually\n  logError(error);\n  process.exit(1); // Git will show conflict markers\n}\n```\n\n## Edge Cases\n\n### 1. Nested Conflict Markers\nIf conflict markers appear in JSON content (rare), escape them during parsing.\n\n### 2. Empty Conflict Sections\n```jsonl\n<<<<<<< HEAD\n=======\n{\"id\":\"NEW\",\"uuid\":\"new-uuid\"}\n>>>>>>> feature\n```\nHandle empty sections by treating as deletion vs. addition.\n\n### 3. Relationship Cycles\nAfter ID renaming, check for and warn about relationship cycles.\n\n### 4. Binary Files\nDetect and skip binary files with warning:\n```typescript\nif (isBinaryFile(filePath)) {\n  console.warn('Skipping binary file');\n  return;\n}\n```\n\n## Performance Considerations\n\n- **Streaming**: Use streaming reads for large JSONL files (>10MB)\n- **Memory**: Process entities in batches if memory is constrained\n- **Atomic writes**: Use temp file + rename to prevent corruption\n- **Database sync**: Only sync once after resolving all files\n\n## Success Criteria\n\n✅ Resolves conflicts in issues.jsonl and specs.jsonl automatically\n✅ Preserves all unique data (no data loss)\n✅ Deterministic results (same input → same output)\n✅ Maintains git-friendly sorting by created_at\n✅ Merges metadata (relationships, tags) correctly\n✅ Supports dry-run mode for safety\n✅ Provides clear, actionable output\n✅ Integrates with git as merge driver\n✅ Handles malformed JSON gracefully\n✅ Passes all unit and integration tests\n\n## Future Enhancements\n\n1. **Interactive Mode**: Let user choose between conflicting versions\n2. **Custom Rules**: Allow project-specific resolution strategies via config\n3. **Merge Summaries**: Generate markdown summary of what was merged\n4. **Pre-commit Hook**: Warn if committing files with conflict markers\n5. **GUI**: Visual diff tool for complex conflicts\n","priority":1,"archived":0,"archived_at":null,"created_at":"2025-11-05 00:13:21","updated_at":"2025-11-05T00:16:01.867Z","parent_id":null,"parent_uuid":null,"relationships":[],"tags":["cli","git","jsonl","merge"]}
{"id":"s-6hl1","uuid":"e205fb13-dc67-4b8e-9ee2-130bf48febd2","title":"Migrate server to use agent-execution-engine npm package","file_path":"specs/migrate_server_to_use_agent_execution_engine_npm_p.md","content":"# Migrate server to use agent-execution-engine npm package\n\n## Overview\n\nRefactor the server codebase to use the `agent-execution-engine` npm package instead of duplicated code in `server/src/execution/`. This will eliminate code duplication, improve maintainability, and ensure consistency with the standalone execution engine library.\n\n## Background\n\nThe `agent-execution-engine` was recently extracted from this repository into a standalone package available at `https://github.com/alexngai/agent-execution-engine`. The server currently has duplicated copies of:\n\n- Process management layer (`process/`)\n- Execution engine layer (`engine/`)\n- Resilience layer (`resilience/`)\n- Workflow orchestration layer (`workflow/`)\n\nThese layers are identical (or nearly identical) to the agent-execution-engine package and should be replaced with npm imports.\n\n## Architecture Analysis\n\n### Code to Replace (use npm package)\n\n**Current duplicated code in `server/src/execution/`:**\n\n1. **Process Layer** (`process/`)\n   - `simple-manager.ts` - SimpleProcessManager implementation\n   - `manager.ts` - IProcessManager interface\n   - `types.ts` - Process types\n   - `utils.ts` - Process utilities\n   - **Exception**: Keep `process/builders/` subdirectory (server-specific Claude config builders)\n\n2. **Engine Layer** (`engine/`)\n   - `simple-engine.ts` - SimpleExecutionEngine implementation\n   - `engine.ts` - IExecutionEngine interface\n   - `types.ts` - Engine types\n\n3. **Resilience Layer** (`resilience/`)\n   - `resilient-executor.ts` - ResilientExecutor implementation\n   - `circuit-breaker.ts` - CircuitBreakerManager\n   - `retry.ts` - Retry utilities\n   - `executor.ts` - IResilientExecutor interface\n   - `types.ts` - Resilience types\n\n4. **Workflow Layer** (`workflow/`)\n   - `linear-orchestrator.ts` - LinearOrchestrator implementation\n   - `orchestrator.ts` - IWorkflowOrchestrator interface\n   - `memory-storage.ts` - InMemoryWorkflowStorage\n   - `types.ts` - Workflow types\n   - `utils.ts` - Workflow utilities\n\n### Code to Keep (server-specific)\n\n**Server-specific components in `server/src/execution/`:**\n\n1. **Worktree Management** (`worktree/`)\n   - Git worktree isolation for concurrent executions\n   - Race condition prevention with per-path mutex locks\n   - Local database setup per worktree\n   - JSONL syncing from main repo\n   - Comprehensive cleanup and validation\n\n2. **Output Processing** (`output/`)\n   - `claude-code-output-processor.ts` - Parses Claude's stream-json output\n   - `ag-ui-adapter.ts` - Transforms domain events to AG-UI protocol\n   - `ag-ui-integration.ts` - Factory functions and wiring\n   - `claude-to-ag-ui.ts` - Transformation helpers (shareable with frontend)\n   - `types.ts` - Output processing types\n\n3. **Transport Layer** (`transport/`)\n   - `sse-transport.ts` - Server-sent events connection management\n   - `event-buffer.ts` - In-memory event buffering for late-joining clients\n   - `transport-manager.ts` - Facade between adapters and SSE transport\n\n4. **Process Builders** (`process/builders/`)\n   - `claude.ts` - Claude-specific process configuration\n\n## Verified Compatibility\n\nThe agent-execution-engine's `LinearOrchestrator` **already supports** the server's custom dependencies:\n\n```typescript\n// From agent-execution-engine/src/workflow/linear-orchestrator.ts:85-86\nconstructor(\n  executor: IResilientExecutor,\n  storage?: IWorkflowStorage,\n  agUiAdapter?: any, // AgUiEventAdapter from server (optional)\n  lifecycleService?: any // ExecutionLifecycleService from server (optional)\n)\n```\n\nThis means we can do a **direct replacement** without any compatibility issues.\n\n## Migration Plan\n\n### Phase 1: Add npm Dependency\n\n**Update `server/package.json`:**\n\n```json\n{\n  \"dependencies\": {\n    \"agent-execution-engine\": \"^0.0.2\",\n    // ... existing dependencies\n  }\n}\n```\n\n**Run installation:**\n```bash\nnpm --prefix server install\n```\n\n### Phase 2: Update Imports\n\n**Primary file to update: `server/src/services/execution-service.ts`**\n\n**Before:**\n```typescript\nimport { SimpleProcessManager } from \"../execution/process/simple-manager.js\";\nimport { SimpleExecutionEngine } from \"../execution/engine/simple-engine.js\";\nimport { ResilientExecutor } from \"../execution/resilience/resilient-executor.js\";\nimport { LinearOrchestrator } from \"../execution/workflow/linear-orchestrator.js\";\nimport type { WorkflowDefinition } from \"../execution/workflow/types.js\";\n```\n\n**After:**\n```typescript\nimport { \n  SimpleProcessManager,\n  SimpleExecutionEngine,\n  ResilientExecutor,\n  LinearOrchestrator,\n  type WorkflowDefinition\n} from \"agent-execution-engine\";\n```\n\n**Other files to update:**\n- Search for all imports from `../execution/process/`, `../execution/engine/`, `../execution/resilience/`, `../execution/workflow/`\n- Replace with imports from `agent-execution-engine`\n- Update relative paths accordingly\n\n### Phase 3: Remove Duplicated Directories\n\n**Remove these directories from `server/src/execution/`:**\n\n```bash\n# From server/ directory\nrm -rf src/execution/process/simple-manager.ts\nrm -rf src/execution/process/manager.ts\nrm -rf src/execution/process/types.ts\nrm -rf src/execution/process/utils.ts\n# Keep: src/execution/process/builders/\n\nrm -rf src/execution/engine/\nrm -rf src/execution/resilience/\nrm -rf src/execution/workflow/\n```\n\n**Keep these directories:**\n- `src/execution/worktree/` - Server-specific git worktree management\n- `src/execution/output/` - Server-specific output processing\n- `src/execution/transport/` - Server-specific SSE streaming\n- `src/execution/process/builders/` - Server-specific process configuration\n\n### Phase 4: Update Output Processing Layer\n\n**Files to update for type imports:**\n\n- `server/src/execution/output/claude-code-output-processor.ts`\n- `server/src/execution/output/ag-ui-adapter.ts`\n\n**Example type import updates:**\n```typescript\n// Before\nimport type { ExecutionTask } from \"../engine/types.js\";\n\n// After\nimport type { ExecutionTask } from \"agent-execution-engine\";\n```\n\n### Phase 5: Verify Integration\n\n**Update tests:**\n- Check all test files in `server/tests/` that import execution layer types\n- Update imports to use `agent-execution-engine`\n\n**Type checking:**\n```bash\nnpm --prefix server run typecheck\n```\n\n**Unit tests:**\n```bash\nnpm --prefix server test -- --run\n```\n\n**E2E tests:**\n```bash\nnpm --prefix server test:e2e\n```\n\n## Expected File Structure After Migration\n\n```\nserver/src/execution/\n├── worktree/           # Server-specific (KEEP)\n│   ├── manager.ts\n│   ├── git-cli.ts\n│   ├── config.ts\n│   ├── types.ts\n│   └── index.ts\n├── output/             # Server-specific (KEEP)\n│   ├── claude-code-output-processor.ts\n│   ├── ag-ui-adapter.ts\n│   ├── ag-ui-integration.ts\n│   ├── claude-to-ag-ui.ts\n│   ├── types.ts\n│   └── index.ts\n├── transport/          # Server-specific (KEEP)\n│   ├── sse-transport.ts\n│   ├── event-buffer.ts\n│   ├── transport-manager.ts\n│   └── index.ts\n└── process/            # Partial (KEEP builders only)\n    └── builders/\n        └── claude.ts\n```\n\n## Import Map\n\n| Old Import | New Import |\n|-----------|-----------|\n| `../execution/process/simple-manager` | `agent-execution-engine` |\n| `../execution/process/manager` | `agent-execution-engine` |\n| `../execution/process/types` | `agent-execution-engine` |\n| `../execution/engine/simple-engine` | `agent-execution-engine` |\n| `../execution/engine/engine` | `agent-execution-engine` |\n| `../execution/engine/types` | `agent-execution-engine` |\n| `../execution/resilience/resilient-executor` | `agent-execution-engine` |\n| `../execution/resilience/circuit-breaker` | `agent-execution-engine` |\n| `../execution/resilience/retry` | `agent-execution-engine` |\n| `../execution/resilience/executor` | `agent-execution-engine` |\n| `../execution/resilience/types` | `agent-execution-engine` |\n| `../execution/workflow/linear-orchestrator` | `agent-execution-engine` |\n| `../execution/workflow/orchestrator` | `agent-execution-engine` |\n| `../execution/workflow/memory-storage` | `agent-execution-engine` |\n| `../execution/workflow/types` | `agent-execution-engine` |\n| `../execution/workflow/utils` | `agent-execution-engine` |\n\n## Risk Mitigation\n\n### Low Risk\n\nThe migration is **low risk** because:\n\n1. **Code is identical** - The agent-execution-engine was extracted from this exact codebase\n2. **Interfaces match** - All types and interfaces are the same\n3. **Dependencies are optional** - LinearOrchestrator accepts server-specific dependencies as `any` types\n4. **No breaking changes** - The package exports are compatible with current usage\n\n### Testing Strategy\n\n1. **Type checking first** - Verify all imports resolve correctly\n2. **Unit tests** - Ensure isolated components still work\n3. **Integration tests** - Verify service layer integration\n4. **E2E tests** - Test full execution flow end-to-end\n5. **Manual testing** - Run actual executions through the UI\n\n## Success Criteria\n\n- [ ] `agent-execution-engine` added as npm dependency\n- [ ] All imports updated to use `agent-execution-engine` package\n- [ ] Duplicated directories removed from `server/src/execution/`\n- [ ] Server-specific code (`worktree/`, `output/`, `transport/`) unchanged\n- [ ] Type checking passes (`npm run typecheck`)\n- [ ] All unit tests pass (`npm test`)\n- [ ] All E2E tests pass (`npm test:e2e`)\n- [ ] Manual execution testing confirms functionality\n- [ ] No regression in execution performance or reliability\n\n## Benefits\n\n1. **Eliminate code duplication** - Single source of truth for execution engine\n2. **Easier maintenance** - Updates to execution engine only need to happen in one place\n3. **Version control** - Can independently version and release execution engine\n4. **Reusability** - Other projects can use the same execution engine\n5. **Clearer boundaries** - Explicit separation between generic engine and server-specific code\n\n## Future Considerations\n\nAfter this migration:\n\n1. **Process builders** - Consider moving `process/builders/claude.ts` into the agent-execution-engine package as an example agent adapter\n2. **Output processing** - Consider extracting output processing layer into separate `@sudocode-ai/output-processing` package\n3. **Worktree management** - Consider extracting worktree layer into separate `@sudocode-ai/worktree-manager` package","priority":1,"archived":0,"archived_at":null,"created_at":"2025-11-19 06:04:21","updated_at":"2025-11-19 06:04:21","parent_id":null,"parent_uuid":null,"relationships":[],"tags":["architecture","dependencies","execution-engine","refactor"]}
{"id":"s-5d2c","uuid":"bc47487d-b14f-428e-a705-65395e87860e","title":"Multi-Project Server Architecture","file_path":"specs/multi_project_server_architecture.md","content":"# Multi-Project Server Architecture\n\nTransform the sudocode server from a single-project architecture to a project-agnostic server capable of managing multiple projects simultaneously.\n\n## Executive Summary\n\nThe server will run from any directory and allow users to open, switch between, and manage different sudocode projects across different repositories.\n\n### Key Goals\n\n1. Run server from any directory (not tied to a specific project)\n1. Support opening multiple projects simultaneously\n1. Maintain file watching and execution services for all active projects\n1. Provide project management UI for browsing, creating, and switching projects\n1. Ensure backward compatibility with existing single-project usage\n\n## Architecture Overview\n\n### Hybrid Architecture: Monolithic Core + Worker Executions\n\nThe server uses a **hybrid architecture** that combines the simplicity of a monolithic server with the isolation benefits of worker processes:\n\n**Monolithic Core** (single server process):\n\n- HTTP/WebSocket server (single port)\n- Project registry and management\n- Database connections (all projects)\n- File watchers (all projects)\n- Transport managers (SSE streaming)\n\n**Worker Executions** (isolated child processes):\n\n- Each Claude Code execution runs in a separate Node.js process\n- Workers are spawned on-demand and terminated after completion\n- Workers communicate with main server via IPC (Inter-Process Communication)\n- Workers have independent memory/CPU resources\n\n**Rationale**: This hybrid approach provides:\n\n1. **Execution isolation** - One execution crash doesn't affect others or the main server\n1. **Memory isolation** - Long-running executions don't exhaust main process heap\n1. **Resource limits** - Can cap CPU/memory per execution\n1. **Simpler than full hub-spoke** - Most services remain in main process\n1. **Future-proof** - Can evolve to full hub-and-spoke later if remote execution is needed\n\n```typescript\n// Main Server Process\nProjectManager\n├── Project Context 1 (sudocode-a1b2c3d4)\n│   ├── Database connection\n│   ├── File watcher\n│   ├── Transport manager\n│   └── ExecutionWorkerPool ───→ [Worker Process 1: Execution exec-abc]\n│                           └──→ [Worker Process 2: Execution exec-xyz]\n└── Project Context 2 (myapp-x7y8z9)\n    └── ExecutionWorkerPool ───→ [Worker Process 3: Execution exec-def]\n```\n\n### Project Identification\n\nProjects are identified using deterministic, human-readable IDs:\n\n```typescript\nfunction generateProjectId(projectPath: string): string {\n  const repoName = path.basename(projectPath)\n  const safeName = repoName.toLowerCase()\n    .replace(/[^a-z0-9-]/g, '-')\n    .replace(/-+/g, '-')\n    .slice(0, 32)\n  \n  const hash = crypto.createHash('sha256')\n    .update(projectPath)\n    .digest('hex')\n    .slice(0, 8)\n  \n  return `${safeName}-${hash}`\n}\n// Example: /Users/alex/repos/sudocode → \"sudocode-a1b2c3d4\"\n```\n\n### Configuration Storage\n\nProject registry stored at `~/.config/sudocode/projects.json`:\n\n```json\n{\n  \"version\": 1,\n  \"projects\": {\n    \"sudocode-a1b2c3d4\": {\n      \"id\": \"sudocode-a1b2c3d4\",\n      \"name\": \"sudocode\",\n      \"path\": \"/Users/alex/repos/sudocode\",\n      \"sudocodeDir\": \"/Users/alex/repos/sudocode/.sudocode\",\n      \"registeredAt\": \"2025-01-20T10:00:00Z\",\n      \"lastOpenedAt\": \"2025-01-20T15:30:00Z\",\n      \"favorite\": false\n    }\n  },\n  \"recentProjects\": [\"sudocode-a1b2c3d4\"],\n  \"settings\": {\n    \"maxRecentProjects\": 10,\n    \"autoOpenLastProject\": false\n  }\n}\n```\n\n### Multi-Project Service Architecture\n\n```typescript\nclass ProjectManager {\n  private projects: Map<string, ProjectContext> = new Map()\n  \n  async openProject(projectPath: string): Promise<ProjectContext>\n  async closeProject(projectId: string): Promise<void>\n  \n  getProject(projectId: string): ProjectContext | null\n  getAllOpenProjects(): ProjectContext[]\n  isProjectOpen(projectId: string): boolean\n}\n\nclass ProjectContext {\n  id: string\n  path: string\n  sudocodeDir: string\n\n  // Each project has independent services\n  db: Database.Database\n  transportManager: TransportManager\n  executionWorkerPool: ExecutionWorkerPool  // NEW: Manages worker processes\n  logsStore: ExecutionLogsStore\n  watcher: ServerWatcherControl\n  worktreeManager: WorktreeManager\n}\n\nclass ExecutionWorkerPool {\n  private workers: Map<executionId, WorkerProcess>\n  private projectId: string\n\n  // Spawn isolated worker process for execution\n  async startExecution(execution: Execution): Promise<void>\n\n  // Cancel execution (kills worker process)\n  async cancelExecution(executionId: string): Promise<void>\n\n  // Monitor worker health, restart on crash\n  private handleWorkerExit(executionId: string, exitCode: number): void\n\n  // Resource limits per worker (optional)\n  private readonly maxMemoryMB: number = 512\n  private readonly maxConcurrentWorkers: number = 3\n}\n```\n\n**Key Design**:\n\n- All open projects run services simultaneously in the main process\n- Executions are isolated in worker processes for crash protection and resource isolation\n- Workers are ephemeral (spawn on start, terminate on completion)\n\n### API Design\n\nUses `X-Project-ID` header for stateless project context:\n\n```typescript\n// Client sends header with every request\nGET /api/issues\nHeaders: { \"X-Project-ID\": \"sudocode-a1b2c3d4\" }\n\n// Server middleware extracts project context\napp.use((req, res, next) => {\n  const projectId = req.headers['x-project-id']\n  if (projectId) {\n    req.project = projectManager.getProject(projectId)\n  }\n  next()\n})\n\n// Routes use project context\nrouter.get('/issues', (req, res) => {\n  const issues = getIssues(req.project!.db)\n  res.json(issues)\n})\n```\n\n### Frontend Architecture\n\n**Project Context Management**:\n\n- React context tracks `currentProjectId`\n- Persists to localStorage\n- API client automatically injects `X-Project-ID` header\n\n**UI Components**:\n\n1. `/projects` page - Full project management interface\n1. Navbar quick-switcher - Dropdown with recent projects (Cmd+P shortcut)\n1. Empty state - Onboarding for new users\n\n**Project Switching Flow**:\n\n1. User selects project from switcher\n1. Update `currentProjectId` in context\n1. Update `X-Project-ID` header in API client\n1. Resubscribe WebSocket to new project\n1. Invalidate React Query cache\n1. Refetch all data (~500ms total)\n\n### WebSocket Strategy\n\n**Project-Scoped Subscriptions**:\n\n```typescript\n// Client subscribes to specific project\nwsClient.subscribe({\n  projectId: 'sudocode-a1b2c3d4',\n  entityType: 'all' // or 'issue', 'spec', 'execution'\n})\n\n// All messages include projectId\n{\n  type: 'issue_updated',\n  projectId: 'sudocode-a1b2c3d4',\n  entityId: 'i-abc123',\n  data: { ... }\n}\n\n// New project lifecycle messages\n{ type: 'project_opened', data: { projectId, name, path } }\n{ type: 'project_closed', data: { projectId } }\n```\n\n### Database Connection Management\n\n**Caching Strategy**:\n\n- Database connections cached with 30-minute TTL\n- Fast project switching (reuse existing connections)\n- Memory-efficient (evict unused connections)\n- SQLite databases are small (~few MB each)\n\n### Execution Worker Pool Architecture\n\n**Worker Lifecycle**:\n\n```typescript\n// Main server spawns worker on execution start\nclass ExecutionWorkerPool {\n  async startExecution(execution: Execution): Promise<void> {\n    const worker = spawn('node', ['dist/workers/execution-worker.js'], {\n      detached: false,  // Kill with parent\n      stdio: ['ipc'],   // IPC for bidirectional communication\n      env: {\n        EXECUTION_ID: execution.id,\n        PROJECT_ID: this.projectId,\n        REPO_PATH: execution.worktree_path,\n        DB_PATH: this.dbPath,\n        MAX_MEMORY_MB: '512',\n        NODE_OPTIONS: '--max-old-space-size=512'  // Hard memory limit\n      }\n    });\n\n    // Forward logs from worker to transport manager\n    worker.on('message', (msg: WorkerMessage) => {\n      if (msg.type === 'log') {\n        this.transportManager.sendEvent(execution.id, msg.data);\n      } else if (msg.type === 'status') {\n        this.updateExecutionStatus(execution.id, msg.status);\n      }\n    });\n\n    // Handle worker crash/exit\n    worker.on('exit', (code, signal) => {\n      if (code !== 0) {\n        this.handleWorkerFailure(execution.id, code, signal);\n      }\n      this.workers.delete(execution.id);\n    });\n\n    this.workers.set(execution.id, worker);\n  }\n}\n\n// Worker process runs execution independently\n// server/src/workers/execution-worker.ts\nasync function main() {\n  const { EXECUTION_ID, REPO_PATH, DB_PATH } = process.env;\n\n  // Worker has isolated database connection\n  const db = initDatabase({ path: DB_PATH });\n  const execution = getExecution(db, EXECUTION_ID);\n\n  // Run Claude Code execution\n  const orchestrator = new LinearOrchestrator(/* ... */);\n  const result = await orchestrator.execute(/* ... */);\n\n  // Report completion to main process\n  process.send!({ type: 'complete', result });\n  process.exit(0);\n}\n```\n\n**IPC Message Protocol**:\n\n```typescript\n// Worker → Main\ntype WorkerMessage =\n  | { type: 'log', data: OutputEvent }\n  | { type: 'status', status: ExecutionStatus }\n  | { type: 'complete', result: ExecutionResult }\n  | { type: 'error', error: string }\n\n// Main → Worker\ntype MainMessage =\n  | { type: 'cancel' }\n  | { type: 'ping' }\n```\n\n**Resource Limits**:\n\n- Memory: 512MB per worker (via `--max-old-space-size`)\n- Concurrent workers per project: 3 (configurable)\n- Worker spawn timeout: 10 seconds\n- Worker idle timeout: None (terminates on completion)\n\n**Crash Handling**:\n\n- Worker exit code 0: Normal completion\n- Worker exit code 1: Execution failed (expected)\n- Worker exit code 137: OOM killed (log warning, mark execution failed)\n- Worker killed by signal: Unexpected crash (mark execution failed, log error)\n\n## Requirements\n\n### Functional Requirements\n\n**FR1: Project Registration**\n\n- Browse filesystem for `.sudocode` directories\n- Initialize new sudocode projects\n- Validate project structure\n- Persist registered projects\n\n**FR2: Multi-Project Operations**\n\n- Maintain connections to all open projects\n- Independent file watchers per project\n- Concurrent executions across projects\n- Isolated database connections\n\n**FR3: Project Switching (UI-level)**\n\n- Display current active project\n- Switch between open projects\n- Project-scoped WebSocket subscriptions\n- Project-scoped React Query cache\n\n**FR4: Project Management UI**\n\n- Dedicated `/projects` page\n- Quick project switcher in navbar\n- Recent projects display\n- Project status indicators\n\n**FR5: Backward Compatibility**\n\n- Auto-detect project in cwd if no projects configured\n- Existing CLI workflows continue to work\n- Database schema unchanged\n\n### Non-Functional Requirements\n\n**NFR1: Performance**\n\n- Project switching < 500ms\n- Database connection caching\n- Minimal CPU/memory per file watcher\n\n**NFR2: Reliability**\n\n- Graceful handling of deleted/moved projects\n- Proper resource cleanup\n- No memory leaks\n- Execution isolation (one crash doesn't affect others)\n- Worker process supervision (restart on failure)\n\n**NFR3: Resource Limits**\n\n- Cap memory per execution worker (512MB default)\n- Limit concurrent executions per project (3 default)\n- Main server process remains responsive during heavy executions\n- Prevent OOM crashes from long-running executions\n\n**NFR4: Usability**\n\n- Clear visual indication of current project\n- Obvious error messages\n- Intuitive project creation flow\n\n## Implementation Phases\n\n### Phase 1: Multi-Project Server Core (Current Scope)\n\n**Deliverables**:\n\n1. Project registry with persistent storage\n1. Project management API endpoints\n1. Multi-project service architecture\n1. Header-based project routing\n1. Database connection caching\n1. Project-scoped file watchers\n1. **Execution worker pool** (isolated execution processes)\n1. **Worker-to-main IPC** (execution logs, status updates)\n1. Frontend project management page\n1. Frontend navbar quick-switcher\n1. WebSocket project subscriptions\n1. React Query cache invalidation on project switch\n\n**Success Criteria**:\n\n- Can register multiple projects from UI\n- Can switch between projects in < 500ms\n- File watchers run independently per project\n- Executions run concurrently across projects (isolated in workers)\n- Worker crashes don't affect main server or other executions\n- No memory leaks after switching projects 10+ times\n- Main server remains responsive during 3+ concurrent long-running executions\n- Backward compatible with single-project CLI usage\n\n**Estimated Effort**: 8-10 days (added 3 days for worker pool implementation)\n\n### Phase 2: Enhanced Project Management (Future)\n\n- Project initialization wizard\n- Project templates\n- Project search/filtering\n- Project favorites/pinning\n- Project metadata editing\n- Bulk operations\n\n**Estimated Effort**: 3-4 days\n\n### Phase 3: URL-Based Multi-Project Routing (Future)\n\n- URL structure: `/projects/:projectId/issues`\n- Browser tabs for different projects\n- Split-view mode (side-by-side projects)\n- Per-project browser history\n- Deep linking\n\n**Estimated Effort**: 4-5 days\n\n## File Structure Changes\n\n### Server\n\n```\nserver/src/\n├── services/\n│   ├── project-registry.ts        [NEW] Config file management\n│   ├── project-context.ts         [NEW] ProjectContext class\n│   ├── project-manager.ts         [NEW] ProjectManager orchestration\n│   ├── execution-worker-pool.ts   [NEW] Worker process management\n│   ├── db.ts                      [MODIFIED] Accept sudocodeDir param\n│   ├── watcher.ts                 [MODIFIED] Accept sudocodeDir param\n│   └── websocket.ts               [MODIFIED] Add projectId to messages\n├── workers/\n│   ├── execution-worker.ts        [NEW] Worker entry point\n│   └── worker-ipc.ts              [NEW] IPC message protocol\n├── routes/\n│   ├── projects.ts                [NEW] Project management endpoints\n│   ├── issues.ts                  [MODIFIED] Use req.project\n│   ├── specs.ts                   [MODIFIED] Use req.project\n│   ├── relationships.ts           [MODIFIED] Use req.project\n│   ├── feedback.ts                [MODIFIED] Use req.project\n│   └── executions.ts              [MODIFIED] Use req.project, worker pool\n├── middleware/\n│   └── project-context.ts         [NEW] Inject project from header\n├── types/\n│   └── project.ts                 [NEW] Project-related types\n└── index.ts                       [MODIFIED] Initialize ProjectManager\n```\n\n### Frontend\n\n```\nfrontend/src/\n├── contexts/\n│   └── ProjectContext.tsx         [NEW] Current project state\n├── hooks/\n│   ├── useProject.ts              [NEW] Access project context\n│   └── useProjects.ts             [NEW] Fetch projects\n├── pages/\n│   └── ProjectsPage.tsx           [NEW] Project management page\n├── components/\n│   ├── projects/\n│   │   ├── ProjectCard.tsx        [NEW] Project card component\n│   │   ├── ProjectBrowser.tsx     [NEW] File browser\n│   │   ├── ProjectSwitcher.tsx    [NEW] Navbar dropdown\n│   │   └── EmptyState.tsx         [NEW] No projects state\n│   └── layout/\n│       └── MainLayout.tsx         [MODIFIED] Add ProjectSwitcher\n├── lib/\n│   └── api.ts                     [MODIFIED] Add project endpoints\n└── App.tsx                        [MODIFIED] Add ProjectProvider\n```\n\n### Types\n\n```\ntypes/src/\n├── project.ts                     [NEW] Shared project types\n└── websocket.ts                   [MODIFIED] Add project message types\n```\n\n## API Endpoints\n\n### Project Management\n\n```\nGET    /api/projects               List all registered projects\nGET    /api/projects/open          List currently open projects\nPOST   /api/projects/open          Open a project by path\nPOST   /api/projects/:id/close     Close an open project\nDELETE /api/projects/:id           Unregister a project\nGET    /api/projects/recent        Get recent projects\nPOST   /api/projects/validate      Validate a project path\nPOST   /api/projects/init          Initialize new sudocode project\n```\n\n### Entity Routes (Require X-Project-ID header)\n\n```\nGET/POST/PUT/DELETE /api/issues\nGET/POST/PUT/DELETE /api/specs\nGET/POST/DELETE     /api/relationships\nGET/POST/PUT/DELETE /api/feedback\nPOST/GET/DELETE     /api/executions\n```\n\n## Testing Strategy\n\n### Unit Tests\n\n- ProjectRegistry config management\n- ProjectManager open/close/validate\n- Project ID generation\n- Database caching and TTL eviction\n- Middleware project context injection\n- Frontend ProjectContext state management\n- API client header injection\n- **ExecutionWorkerPool spawn/cancel/monitor**\n- **Worker IPC message protocol**\n\n### Integration Tests\n\n- Project lifecycle (open → file watch → edit → WebSocket)\n- Project switching (watchers stop/start correctly)\n- Multi-project executions (independent operation, worker isolation)\n- **Worker crash recovery** (main server stays healthy)\n- **Worker memory limits** (process terminates on OOM)\n- Resource cleanup (no memory leaks, no orphaned workers)\n- Invalid project handling\n\n### E2E Tests\n\n- New user onboarding flow\n- Project switching with data verification\n- Multi-project concurrent operations\n- Server restart persistence\n\n### Performance Tests\n\n- Opening 10 projects < 5 seconds\n- Project switching < 500ms\n- Memory with 5 open projects < 500MB (main process only)\n- Database cache eviction performance\n- **Worker spawn time < 500ms**\n- **3+ concurrent executions across projects don't saturate event loop**\n- **Main server API latency < 100ms during heavy executions**\n\n## Success Metrics\n\n**Functional**:\n\n- Register and open 3+ projects\n- Switch between projects in < 500ms\n- Independent file watchers per project\n- Concurrent executions across projects (worker-isolated)\n- Worker crashes don't affect main server\n- Correct WebSocket subscriptions\n\n**Quality**:\n\n- 90%+ test coverage on new code\n- Zero memory leaks in main process (30+ minute test)\n- No orphaned worker processes after shutdown\n- No regressions in single-project usage\n- Clear error messages for all failures\n\n**User Experience**:\n\n- Intuitive project management UI\n- Instant-feeling project switching\n- Clear indication of current project\n- Easy project discovery and registration\n\n## Future Evolution: Hub-and-Spoke Architecture\n\nThe hybrid architecture is designed to evolve into a full **hub-and-spoke** model when remote execution becomes a requirement:\n\n**Hub-and-Spoke Model** (Phase 4, future):\n\n```\nHub Server (Port 3000)\n├── HTTP Gateway (proxy to spokes)\n├── WebSocket Multiplexer\n├── Spoke Manager (spawn/monitor spokes)\n└── Routes to:\n    ├── Local Spoke 1 (Port 3001) → Project A\n    ├── Local Spoke 2 (Port 3002) → Project B\n    └── Remote Spoke (tcp://server:3000) → Project C on remote machine\n```\n\n**Migration Path**:\n\n1. **Phase 1** (Current): Hybrid architecture (monolithic + worker executions)\n1. **Phase 2**: Refactor services to be \"spoke-compatible\" (pass projectId everywhere)\n1. **Phase 3**: Extract ProjectContext into standalone runnable spoke server\n1. **Phase 4**: Add hub layer for spoke orchestration and remote registration\n\n**When to Migrate**:\n\n- Users need remote execution (run sudocode server on cloud VM)\n- Projects are too large/numerous for single machine (10+ projects)\n- Need true process isolation for entire project services (not just executions)\n- Resource contention becomes issue even with worker isolation\n\n**Design Decisions for Future-Proofing**:\n\n- ProjectContext is self-contained (all state in one object)\n- Services take `projectId` parameter (IPC-ready)\n- Transport layer is abstract (can swap HTTP/IPC later)\n- Worker pool pattern can extend to full spoke processes\n\n## Reference\n\nSee `references/multi-project-server-spec.md` for complete implementation details, code examples, and step-by-step guide.","priority":0,"archived":0,"archived_at":null,"created_at":"2025-11-20 09:46:58","updated_at":"2025-11-20 11:01:00","parent_id":null,"parent_uuid":null,"relationships":[],"tags":[]}
{"id":"s-87x7","uuid":"3a11c617-7ae9-459d-aaa7-26b05b580e81","title":"Migrate to Direct Execution Pattern with ClaudeCodeExecutor","file_path":"specs/migrate_to_direct_execution_pattern_with_claudecod.md","content":"# Migration to Direct Execution Pattern with ClaudeCodeExecutor\n\n## Context\n\nThe current execution system uses a **manual layer-by-layer approach** to spawn and manage Claude Code CLI processes. With the upgrade to `agent-execution-engine` 0.0.6, a new **direct execution pattern** is available via `ClaudeCodeExecutor` that provides significant architectural improvements.\n\n### Current Architecture (Manual Stacking)\n\n```\nExecutionService\n  └─→ SimpleProcessManager (spawn process, manage I/O)\n      └─→ SimpleExecutionEngine (task queueing)\n          └─→ ResilientExecutor (retry logic)\n              └─→ LinearOrchestrator (workflow lifecycle)\n                  └─→ Manual CLI arg building\n                  └─→ Custom stream-json parsing (AG-UI processor)\n```\n\n**Current Implementation**:\n- **Location**: `server/src/services/execution-service.ts:335-582` (createExecution)\n- **Location**: `server/src/workers/execution-worker.ts:145-300` (worker process)\n- **Lines of code**: ~500 lines (duplicated between service + worker)\n- **Manual responsibilities**:\n  - Build Claude CLI arguments manually (lines 370-376, 708-714)\n  - Parse stdout line-by-line with `ClaudeCodeOutputProcessor`\n  - Buffer incomplete lines for stream-json parsing\n  - Wire AG-UI events manually\n  - Handle process lifecycle events across 4 layers\n\n### New Architecture (Direct Execution)\n\n```\nClaudeCodeExecutor\n  ├─→ Spawns Claude process with bidirectional protocol\n  ├─→ ProtocolPeer (stdin/stdout communication)\n  ├─→ ClaudeAgentClient (control request/response handling)\n  └─→ normalizeOutput() → NormalizedEntry stream\n```\n\n**New Capabilities**:\n- **Bidirectional protocol**: Built-in control request/response handling\n- **Normalized output**: Consistent `NormalizedEntry` format across agents\n- **Session management**: Built-in `resumeTask()` for session resumption\n- **Approval services**: `IApprovalService` interface for tool approvals\n- **Protocol-level error handling**: Automatic retries, timeouts\n- **No manual arg building**: Config-driven execution\n\n## Problems with Current Approach\n\n### 1. Code Duplication\n- Execution logic duplicated between:\n  - `server/src/services/execution-service.ts` (in-process path)\n  - `server/src/workers/execution-worker.ts` (worker pool path)\n- Same layer stacking pattern repeated in both locations\n- Maintenance burden: bug fixes require changes in 2 places\n\n### 2. Manual Protocol Handling\n- Manual CLI argument construction\n- Manual stream-json parsing with line buffering\n- Custom AG-UI event mapping from parsed output\n- Error-prone: easy to miss edge cases in parsing\n\n### 3. Limited Session Management\n- Session resumption requires manual worktree recreation\n- No built-in session ID tracking\n- Complex follow-up execution logic (lines 594-906)\n\n### 4. Missing Features\n- No approval service integration\n- Cannot leverage bidirectional protocol capabilities\n- Limited error recovery at protocol level\n\n### 5. Complexity\n- 4 layer abstractions to understand\n- Event handlers registered across multiple components\n- Difficult to trace execution flow\n\n## Goals\n\n### Primary Goals\n1. **Reduce code complexity**: Eliminate manual layer stacking\n2. **Remove duplication**: Single execution implementation shared by service + worker\n3. **Leverage protocol features**: Use bidirectional communication, approval services\n4. **Enable session resumption**: Use built-in `resumeTask()` API\n5. **Improve maintainability**: Clear separation of concerns\n\n### Secondary Goals\n6. **Prepare for multi-agent support**: Normalized output format works across agents\n7. **Better error handling**: Protocol-level error recovery\n8. **Performance**: Reduce overhead from multiple layers\n\n### Non-Goals\n- **NOT changing AG-UI protocol**: Keep existing SSE streaming interface\n- **NOT modifying database schema**: Maintain current execution records\n- **NOT breaking existing APIs**: Keep ExecutionService public interface\n\n## Requirements\n\n### Functional Requirements\n\n#### FR1: Execution Lifecycle\n- MUST support creating executions with worktree isolation\n- MUST support follow-up executions with session resumption\n- MUST support cancellation of running executions\n- MUST maintain existing status transitions (pending → running → completed/failed/stopped)\n\n#### FR2: Output Processing\n- MUST convert normalized output to AG-UI events\n- MUST persist raw logs to `ExecutionLogsStore`\n- MUST broadcast events via `TransportManager` for SSE streaming\n- MUST maintain compatibility with existing AG-UI frontend\n\n#### FR3: Lifecycle Integration\n- MUST integrate with `ExecutionLifecycleService` for:\n  - Worktree creation/cleanup\n  - Execution status updates in database\n  - WebSocket broadcast notifications\n- MUST support both in-process and worker pool execution\n\n#### FR4: Worker Pool Compatibility\n- MUST support isolated execution in worker processes\n- MUST maintain IPC protocol with main process\n- MUST handle worker cancellation gracefully\n\n#### FR5: Session Management\n- MUST support session resumption via `resumeTask()`\n- SHOULD track session IDs for follow-up executions\n- SHOULD recreate worktrees if they don't exist\n\n### Non-Functional Requirements\n\n#### NFR1: Performance\n- MUST NOT regress execution latency\n- SHOULD reduce memory overhead (fewer layer instances)\n- Target: <5% latency increase acceptable\n\n#### NFR2: Reliability\n- MUST maintain >99% success rate for executions\n- MUST handle process crashes gracefully\n- MUST not lose output logs during failures\n\n#### NFR3: Maintainability\n- MUST reduce lines of code by >30%\n- MUST eliminate code duplication between service/worker\n- MUST improve code clarity (single execution path)\n\n#### NFR4: Testability\n- MUST maintain test coverage >80%\n- MUST add integration tests for new adapter components\n\n#### NFR5: Backward Compatibility\n- MUST maintain existing ExecutionService API\n- MUST support existing execution configurations\n- MUST NOT break existing frontend integrations\n\n## Architecture Design\n\n### Component Overview\n\n```\n┌─────────────────────────────────────────────────────────────┐\n│                    ExecutionService                         │\n│  ┌───────────────────────────────────────────────────────┐  │\n│  │              ClaudeExecutorWrapper                    │  │\n│  │  ┌─────────────────────────────────────────────────┐  │  │\n│  │  │          ClaudeCodeExecutor                     │  │  │\n│  │  │  - executeTask()                                │  │  │\n│  │  │  - resumeTask()                                 │  │  │\n│  │  │  - normalizeOutput()                            │  │  │\n│  │  └─────────────────────────────────────────────────┘  │  │\n│  │                                                         │  │\n│  │  ┌─────────────────────────────────────────────────┐  │  │\n│  │  │    NormalizedEntryToAgUiAdapter                 │  │  │\n│  │  │  - processEntry(NormalizedEntry)                │  │  │\n│  │  │  - Convert to AG-UI events                      │  │  │\n│  │  └─────────────────────────────────────────────────┘  │  │\n│  │                                                         │  │\n│  │  Integrations:                                          │  │\n│  │  - ExecutionLifecycleService (worktrees, DB)           │  │\n│  │  - ExecutionLogsStore (log persistence)                │  │\n│  │  - TransportManager (SSE streaming)                    │  │\n│  │  - WebSocket broadcasts (status updates)               │  │\n│  └───────────────────────────────────────────────────────┘  │\n└─────────────────────────────────────────────────────────────┘\n```\n\n### New Components\n\n#### 1. NormalizedEntryToAgUiAdapter\n**Purpose**: Convert `NormalizedEntry` stream to AG-UI events\n\n**Location**: `server/src/execution/output/normalized-to-ag-ui-adapter.ts`\n\n**Responsibilities**:\n- Parse `NormalizedEntry` discriminated union\n- Map entry types to AG-UI event types:\n  - `assistant_message` → `TextMessageStart/Content/End`\n  - `tool_use` → `ToolCallStart/Args/End`\n  - `tool_result` → `ToolCallResult`\n  - `error` → `RunError`\n- Maintain message ID tracking for AG-UI protocol\n- Handle thinking blocks (convert to text messages)\n\n**Interface**:\n```typescript\nclass NormalizedEntryToAgUiAdapter {\n  constructor(private agUiAdapter: AgUiEventAdapter);\n  \n  async processEntry(entry: NormalizedEntry): Promise<void>;\n  private handleAssistantMessage(entry: NormalizedEntry): Promise<void>;\n  private handleToolUse(entry: NormalizedEntry): Promise<void>;\n  private extractToolArgs(action: ActionType): any;\n}\n```\n\n#### 2. ClaudeExecutorWrapper\n**Purpose**: Wrap `ClaudeCodeExecutor` with lifecycle management\n\n**Location**: `server/src/execution/executors/claude-executor-wrapper.ts`\n\n**Responsibilities**:\n- Create and configure `ClaudeCodeExecutor` instance\n- Wire normalized output to AG-UI adapter\n- Integrate with `ExecutionLifecycleService`\n- Persist logs to `ExecutionLogsStore`\n- Emit WebSocket broadcasts for status changes\n- Handle process lifecycle (start/stop/error)\n- Support session resumption via `resumeTask()`\n\n**Interface**:\n```typescript\nclass ClaudeExecutorWrapper {\n  constructor(\n    workDir: string,\n    lifecycleService: ExecutionLifecycleService,\n    logsStore: ExecutionLogsStore,\n    projectId: string,\n    transportManager?: TransportManager\n  );\n  \n  async executeWithLifecycle(\n    executionId: string,\n    task: ExecutionTask,\n    workDir: string\n  ): Promise<void>;\n  \n  async resumeWithLifecycle(\n    executionId: string,\n    sessionId: string,\n    task: ExecutionTask,\n    workDir: string\n  ): Promise<void>;\n  \n  async cancel(executionId: string): Promise<void>;\n}\n```\n\n### Data Flow\n\n#### Execution Flow\n```\n1. ExecutionService.createExecution()\n   ↓\n2. Create ClaudeExecutorWrapper\n   ↓\n3. wrapper.executeWithLifecycle()\n   ├─→ Setup AG-UI adapter + normalized adapter\n   ├─→ Connect to TransportManager\n   ├─→ ClaudeCodeExecutor.executeTask()\n   │   ├─→ Spawn Claude process\n   │   ├─→ Setup ProtocolPeer (stdin/stdout)\n   │   └─→ Send user message via protocol\n   ├─→ normalizeOutput() stream\n   │   └─→ For each NormalizedEntry:\n   │       ├─→ Persist to ExecutionLogsStore\n   │       └─→ Convert to AG-UI via adapter\n   ├─→ Wait for process exit\n   └─→ Update execution status (completed/failed)\n```\n\n#### Session Resumption Flow\n```\n1. ExecutionService.createFollowUp()\n   ↓\n2. Extract sessionId from previous execution\n   ↓\n3. wrapper.resumeWithLifecycle(sessionId, ...)\n   ├─→ ClaudeCodeExecutor.resumeTask(sessionId)\n   │   └─→ Spawn Claude with --resume-session\n   └─→ Same output processing as executeWithLifecycle()\n```\n\n## Migration Strategy\n\n### Phase 1: Create Adapters & Integration Tests ✅ COMPLETE\n**Duration**: 2 days  \n**Risk**: Low\n\n**Tasks**:\n1. ✅ Implement `NormalizedEntryToAgUiAdapter`\n   - Map all `NormalizedEntry.type.kind` variants to AG-UI events\n   - Unit tests with mock AG-UI adapter\n   - All 16 tests passing\n\n2. ✅ Implement `ClaudeExecutorWrapper`\n   - Create executor with config\n   - Wire lifecycle hooks\n   - Integrate logs/transport/broadcasts\n   - Unit tests with mocked dependencies\n   - All 13 tests passing\n\n3. ✅ Integration tests\n   - Test normalized adapter with real AG-UI events\n   - Test wrapper with mock executor\n   - All 11 integration tests passing\n   - Full component integration validated\n\n**Deliverables**:\n- ✅ `server/src/execution/output/normalized-to-ag-ui-adapter.ts`\n- ✅ `server/src/execution/executors/claude-executor-wrapper.ts`\n- ✅ Unit test files for both components\n- ✅ Integration test suite\n- ✅ Documentation: Architecture diagrams\n\n**Success Criteria**:\n- ✅ All tests pass (40/40 tests)\n- ✅ Code review approved\n- ✅ No production impact (additive only)\n\n### Phase 2: Direct Migration to New Execution Path\n**Duration**: 2-3 days  \n**Risk**: Low (feature not actively used in production)\n\nSince this feature is not in active production use, we can skip the gradual rollout strategy and directly replace the old execution path with the new one.\n\n**Tasks**:\n\n1. **Replace ExecutionService.createExecution()**\n   - Remove manual layer stacking (SimpleProcessManager, SimpleExecutionEngine, etc.)\n   - Use `ClaudeExecutorWrapper` directly\n   - Keep same public interface\n   - Wire to existing lifecycle/logs/transport\n   \n2. **Update createFollowUp() for session resumption**\n   - Use `wrapper.resumeWithLifecycle()` with session ID\n   - Simplify worktree recreation logic\n   - Remove manual session handling\n\n3. **Update worker pool (execution-worker.ts)**\n   - Replace manual execution with `ClaudeExecutorWrapper`\n   - Keep IPC protocol unchanged for compatibility\n   - Ensure worker cancellation works correctly\n\n4. **Remove legacy code**\n   - Delete manual layer stacking from both locations\n   - Remove `ClaudeCodeOutputProcessor` (replaced by normalized adapter)\n   - Clean up ~500 lines of duplicated code\n   - Remove unused SimpleProcessManager, SimpleExecutionEngine, etc.\n\n5. **Testing & Validation**\n   - Run all existing execution tests\n   - Test execution creation\n   - Test session resumption\n   - Test cancellation\n   - Test worker pool executions\n   - Verify AG-UI frontend compatibility\n\n**Deliverables**:\n- Simplified `execution-service.ts` with direct execution\n- Simplified `execution-worker.ts` with direct execution\n- Removed legacy execution layers (~500 lines)\n- All existing tests passing\n- No breaking changes to public APIs\n\n**Success Criteria**:\n- All existing tests pass\n- Performance delta <5%\n- No critical bugs\n- Frontend continues to work correctly\n\n### Phase 3: Final Cleanup & Documentation\n**Duration**: 1-2 days  \n**Risk**: Low\n\n**Tasks**:\n\n1. **Code cleanup**\n   - Remove any remaining unused imports\n   - Clean up commented-out legacy code\n   - Ensure consistent error handling patterns\n\n2. **Database optimization (optional)**\n   - Consider adding session ID column to executions table\n   - Would enable better session tracking\n\n3. **Documentation update**\n   - Update architecture docs\n   - Add migration notes for future reference\n   - Document new execution flow\n   - Update code comments\n\n4. **Performance validation**\n   - Measure execution latency before/after\n   - Measure memory usage\n   - Document performance improvements\n\n**Deliverables**:\n- Clean codebase with no legacy execution code\n- Updated documentation\n- Performance comparison report\n- Migration retrospective\n\n**Success Criteria**:\n- Code is clean and well-documented\n- Test coverage maintained >80%\n- Team understands new architecture\n- Performance improvements documented\n\n## Testing Strategy\n\n### Unit Tests\n\n#### NormalizedEntryToAgUiAdapter ✅\n- ✅ Test each `NormalizedEntry.type.kind` mapping\n- ✅ Test message ID generation and tracking\n- ✅ Test tool call lifecycle (start → args → result → end)\n- ✅ Test error handling\n\n#### ClaudeExecutorWrapper ✅\n- ✅ Test lifecycle hooks (start/complete/error)\n- ✅ Test log persistence\n- ✅ Test AG-UI adapter integration\n- ✅ Test session resumption\n- ✅ Test cancellation\n\n### Integration Tests ✅\n\n#### Full Execution Flow ✅\n- ✅ Create execution → process output → verify AG-UI events\n- ✅ Test with mocked ClaudeCodeExecutor\n- ✅ Verify log persistence\n- ✅ Verify WebSocket broadcasts\n- ✅ All 11 integration tests passing\n\n### Acceptance Tests (Phase 2)\n- Execute real sudocode issues\n- Verify frontend receives events correctly\n- Test session resumption with follow-up\n- Test cancellation mid-execution\n- Test worker pool execution\n\n## Risk Assessment\n\n| Risk | Probability | Impact | Mitigation |\n|------|------------|--------|------------|\n| **AG-UI event incompatibility** | Low | High | Extensive integration testing validated compatibility |\n| **Performance regression** | Low | Medium | Benchmark before/after; acceptable since not in active production |\n| **Worker pool IPC issues** | Medium | Medium | Keep IPC protocol unchanged; test worker thoroughly |\n| **Session resumption bugs** | Low | Medium | Extensive testing with `resumeTask()`; well-tested in Phase 1 |\n| **Breaking frontend** | Low | High | Maintain AG-UI event compatibility; frontend integration tests |\n\n### Rollback Plan\n\n**Phase 2**: \n- If critical issues discovered: revert commits\n- Restore legacy code from git history\n- No data migration required (database schema unchanged)\n\n**Phase 3**:\n- Low risk phase (cleanup only)\n- Can defer indefinitely if needed\n\n## Success Metrics\n\n### Quantitative Metrics\n- **Code reduction**: ≥30% fewer lines in execution logic (~500 lines removed)\n- **Performance**: <5% latency increase (acceptable for non-production feature)\n- **Reliability**: ≥99% execution success rate\n- **Test coverage**: ≥80% maintained\n\n### Qualitative Metrics\n- **Maintainability**: Easier to understand and modify (single execution path)\n- **Extensibility**: Ready for multi-agent support\n- **Developer satisfaction**: Positive feedback from team\n\n### Business Metrics\n- **No user-facing regressions**\n- **Session resumption feature enabled**\n- **Foundation for future features** (approval services, multi-agent)\n\n## Timeline\n\n| Phase | Duration | Status |\n|-------|----------|--------|\n| Phase 1: Adapters & Tests | 2 days | ✅ COMPLETE |\n| Phase 2: Direct Migration | 2-3 days | 🔄 READY TO START |\n| Phase 3: Cleanup | 1-2 days | ⏳ PENDING |\n| **Total** | **~1 week** | - |\n\n## Open Questions\n\n1. **Session ID storage**: Should we add a dedicated `session_id` column to executions table?\n   - **Decision needed by**: Phase 3\n   - **Impact**: Database migration required if yes\n   - **Recommendation**: Defer to Phase 3, not critical for initial migration\n\n2. **Approval service integration**: Should we implement custom approval service now or later?\n   - **Decision needed by**: Phase 3\n   - **Impact**: Additional development time\n   - **Recommendation**: Later - not needed for basic execution\n\n3. **Performance monitoring**: What metrics should we track post-migration?\n   - **Decision needed by**: Phase 2\n   - **Impact**: Helps validate migration success\n   - **Recommendation**: Track execution latency, success rate, memory usage\n\n## References\n\n### Code Locations\n- Current execution service: `server/src/services/execution-service.ts`\n- Current worker: `server/src/workers/execution-worker.ts`\n- AG-UI integration: `server/src/execution/output/ag-ui-integration.ts`\n- Package docs: `node_modules/agent-execution-engine/README.md`\n\n### Implemented Components (Phase 1)\n- ✅ NormalizedEntryToAgUiAdapter: `server/src/execution/output/normalized-to-ag-ui-adapter.ts`\n- ✅ ClaudeExecutorWrapper: `server/src/execution/executors/claude-executor-wrapper.ts`\n- ✅ ExecutionLogsStore normalized support: `server/src/services/execution-logs-store.ts`\n- ✅ Integration tests: `server/tests/integration/execution/direct-execution-phase1.test.ts`\n\n### External Documentation\n- agent-execution-engine README: Executor pattern examples\n- Claude Code API: Stream-json protocol\n- AG-UI protocol: Event types and sequencing","priority":1,"archived":0,"archived_at":null,"created_at":"2025-11-22 04:38:22","updated_at":"2025-11-22 08:19:39","parent_id":null,"parent_uuid":null,"relationships":[],"tags":["architecture","claude-code","execution-engine","migration"]}
{"id":"s-9mtp","uuid":"0aacb002-0194-477f-b32a-ecefd3145576","title":"Multi-Agent Execution Support","file_path":"specs/multi_agent_execution_support.md","content":"# Multi-Agent Execution Support\n\n## Overview\n\nAdd comprehensive support for multiple AI coding agents (Claude Code, Codex, GitHub Copilot, Cursor) within the sudocode execution system. Users will be able to select their preferred agent on a per-execution basis, with each agent having its own configuration options and capabilities while maintaining a unified execution experience.\n\n## Background\n\nThe current sudocode system is tightly coupled to Claude Code as the only supported agent. However, the underlying **agent-execution-engine** package was designed from the ground up to support multiple CLI-based AI agents through:\n\n- **Agent Adapter Pattern**: `IAgentAdapter<TConfig>` interface for pluggable agents\n- **Agent Registry**: Centralized registry for runtime agent discovery\n- **Normalized Output Format**: Agent-agnostic `NormalizedEntry` stream that works across all agents\n- **Layered Architecture**: Process management, execution engine, resilience, and workflow orchestration layers\n\nRecent migration to the **direct execution pattern** (Phase 1 complete, Phase 2 ready) has positioned us well for multi-agent support by:\n- Eliminating code duplication between service and worker\n- Adopting protocol-level features (bidirectional communication, session resumption)\n- Implementing `NormalizedEntryToAgUiAdapter` that works for any agent outputting normalized format\n\n## Goals\n\n### Primary Goals\n\n1. **Agent Selection**: Enable users to choose from multiple agents when creating executions\n2. **Generic Executor Architecture**: Refactor `ClaudeExecutorWrapper` to support any agent adapter\n3. **Agent Registry Integration**: Integrate agent-execution-engine's registry system on the server\n4. **Initial Agent Support**: Implement adapters for Codex, GitHub Copilot, and Cursor\n5. **Configuration UI**: Provide agent-specific configuration options in the frontend\n6. **Per-Execution Agent Selection**: Allow different agents for different executions within the same project\n\n### Secondary Goals\n\n1. **Capability-Based UI**: Show/hide configuration options based on agent capabilities\n2. **Configuration Validation**: Validate agent-specific configs before execution\n3. **Graceful Degradation**: Handle unimplemented/unavailable agents gracefully\n4. **Backwards Compatibility**: Ensure existing Claude Code executions continue to work\n\n### Non-Goals (Future Work)\n\n- Per-project default agent settings\n- Global default agent preferences\n- Agent-specific configuration presets/templates\n- Dynamic form generation from agent metadata\n- Multi-agent workflows (chaining different agents)\n- Agent switching mid-execution\n- Agent performance comparison tools\n\n## User Stories\n\n### As a Developer\n\n1. **Agent Selection**\n   - I want to select my preferred agent (Claude Code, Codex, Copilot, Cursor) when creating a new execution\n   - I want to see which agents are available and which are coming soon\n   - I want to see what each agent is capable of (modes, streaming, structured output)\n\n2. **Configuration**\n   - I want to configure agent-specific settings (model, mode, API keys) appropriate to my selected agent\n   - I want invalid configurations to be caught before execution starts\n   - I want sensible defaults that work out-of-the-box for each agent\n\n3. **Execution Experience**\n   - I want the same unified execution experience (logs, terminal, status) regardless of which agent I use\n   - I want to resume/replay executions using the agent they were originally run with\n   - I want my choice of agent to be remembered in the execution history\n\n### As a System Administrator\n\n1. **Agent Management**\n   - I want to see which agents are registered and available\n   - I want agents to fail gracefully if their CLI is not installed\n   - I want clear error messages when agent execution fails\n\n## Architecture\n\n### System Overview\n\n```\n┌─────────────────────────────────────────────────────────────┐\n│                         Frontend                             │\n│  ┌────────────────────────────────────────────────────────┐ │\n│  │  AgentConfigPanel                                       │ │\n│  │  - Agent selection dropdown                             │ │\n│  │  - Agent-specific configuration forms                   │ │\n│  │  - Capability-based UI controls                         │ │\n│  └────────────────────────────────────────────────────────┘ │\n│                            ▼                                 │\n│  ┌────────────────────────────────────────────────────────┐ │\n│  │  POST /api/executions { agentType, config, ... }        │ │\n│  └────────────────────────────────────────────────────────┘ │\n└─────────────────────────────────────────────────────────────┘\n                             ▼\n┌─────────────────────────────────────────────────────────────┐\n│                      Server (Backend)                        │\n│  ┌────────────────────────────────────────────────────────┐ │\n│  │  AgentRegistryService                                   │ │\n│  │  - Maintains registry of available agents               │ │\n│  │  - Provides agent metadata and capabilities             │ │\n│  │  - GET /api/agents endpoint                             │ │\n│  └────────────────────────────────────────────────────────┘ │\n│                            ▼                                 │\n│  ┌────────────────────────────────────────────────────────┐ │\n│  │  ExecutionService                                       │ │\n│  │  - createExecution(agentType, config)                   │ │\n│  │  - Uses createExecutorForAgent() factory                │ │\n│  │  - Validates config against agent schema                │ │\n│  └────────────────────────────────────────────────────────┘ │\n│                            ▼                                 │\n│  ┌────────────────────────────────────────────────────────┐ │\n│  │  AgentExecutorWrapper<TConfig>   (Generic!)             │ │\n│  │  - Accepts IAgentAdapter<TConfig>                       │ │\n│  │  - Integrates with lifecycle, logs, transport           │ │\n│  │  - Supports any agent that implements adapter interface │ │\n│  └────────────────────────────────────────────────────────┘ │\n│                            ▼                                 │\n│  ┌────────────────────────────────────────────────────────┐ │\n│  │  Agent-Execution-Engine (Core Library)                  │ │\n│  │  ┌──────────────────────────────────────────────────┐  │ │\n│  │  │  Registered Adapters:                             │  │ │\n│  │  │  - ClaudeCodeAdapter                              │  │ │\n│  │  │  - CodexAdapter                                   │  │ │\n│  │  │  - CopilotAdapter                                 │  │ │\n│  │  │  - CursorAdapter                                  │  │ │\n│  │  └──────────────────────────────────────────────────┘  │ │\n│  │                       ▼                                  │ │\n│  │  Executor (ClaudeCodeExecutor, etc.)                    │ │\n│  │  → NormalizedEntry stream (agent-agnostic)              │ │\n│  └────────────────────────────────────────────────────────┘ │\n│                            ▼                                 │\n│  ┌────────────────────────────────────────────────────────┐ │\n│  │  NormalizedEntryToAgUiAdapter                           │ │\n│  │  - Converts to AG-UI events (works for all agents!)     │ │\n│  └────────────────────────────────────────────────────────┘ │\n└─────────────────────────────────────────────────────────────┘\n```\n\n### Key Components\n\n#### 1. Agent Registry System\n\n**Location**: `server/src/services/agent-registry.ts` (new)\n\n**Responsibilities**:\n- Initialize and maintain the `AgentRegistry` from agent-execution-engine\n- Register all available agent adapters on server startup\n- Provide API to query available agents and their metadata\n- Lookup agent adapters by type\n\n**API**:\n```typescript\ninterface AgentRegistryService {\n  initialize(): void;\n  getAvailableAgents(): AgentMetadata[];\n  getAdapter(agentType: AgentType): IAgentAdapter<any>;\n  isAgentImplemented(agentType: AgentType): boolean;\n}\n```\n\n**Endpoint**: `GET /api/agents`\n```json\n{\n  \"agents\": [\n    {\n      \"type\": \"claude-code\",\n      \"displayName\": \"Claude Code\",\n      \"description\": \"Anthropic's official CLI for Claude\",\n      \"supportedModes\": [\"structured\", \"interactive\", \"hybrid\"],\n      \"supportsStreaming\": true,\n      \"supportsStructuredOutput\": true,\n      \"implemented\": true\n    },\n    {\n      \"type\": \"codex\",\n      \"displayName\": \"OpenAI Codex\",\n      \"description\": \"OpenAI's code generation model\",\n      \"supportedModes\": [\"structured\"],\n      \"supportsStreaming\": false,\n      \"supportsStructuredOutput\": true,\n      \"implemented\": false\n    }\n    // ... more agents\n  ]\n}\n```\n\n#### 2. Generic Executor Wrapper\n\n**Location**: `server/src/execution/executors/agent-executor-wrapper.ts` (refactored from `claude-executor-wrapper.ts`)\n\n**Changes**:\n- Make class generic: `AgentExecutorWrapper<TConfig extends BaseAgentConfig>`\n- Accept `IAgentAdapter<TConfig>` in constructor\n- Use `adapter.buildProcessConfig(config)` to create process configuration\n- Remove Claude Code-specific assumptions\n- Keep all lifecycle integration (worktrees, logs, transport, broadcasts)\n\n**Before**:\n```typescript\nclass ClaudeExecutorWrapper {\n  constructor(private config: ClaudeConfig) {\n    // Hardcoded Claude Code executor\n    this.executor = new ClaudeCodeExecutor(/*...*/);\n  }\n}\n```\n\n**After**:\n```typescript\nclass AgentExecutorWrapper<TConfig extends BaseAgentConfig> {\n  constructor(\n    private adapter: IAgentAdapter<TConfig>,\n    private config: TConfig\n  ) {\n    // Use adapter to build process config\n    const processConfig = adapter.buildProcessConfig(config);\n    // Create generic executor using the adapter's executor class\n    this.executor = createExecutorFromAdapter(adapter, processConfig);\n  }\n}\n```\n\n**Factory Function**:\n```typescript\nfunction createExecutorForAgent(\n  agentType: AgentType,\n  config: any\n): AgentExecutorWrapper<any> {\n  const adapter = agentRegistry.getAdapter(agentType);\n  \n  // Validate config\n  const errors = adapter.validateConfig?.(config);\n  if (errors?.length) {\n    throw new ValidationError(errors);\n  }\n  \n  return new AgentExecutorWrapper(adapter, config);\n}\n```\n\n#### 3. Agent Adapters\n\nEach agent requires an adapter implementing `IAgentAdapter<TConfig>`:\n\n**Claude Code Adapter** (already exists in agent-execution-engine):\n- Location: `agent-execution-engine/src/agents/claude/adapter.ts`\n- Config: `ClaudeCodeConfig` with `print`, `outputFormat`, `verbose`, etc.\n- Modes: `structured`, `interactive`, `hybrid`\n- Output: Native `NormalizedEntry` stream\n\n**Codex Adapter** (new):\n- Location: `server/src/execution/adapters/codex-adapter.ts`\n- Config: API key, model, temperature, max tokens\n- Modes: `structured` only\n- Output: Convert OpenAI API responses to `NormalizedEntry`\n\n**Copilot Adapter** (new):\n- Location: `server/src/execution/adapters/copilot-adapter.ts`\n- Config: GitHub token, model variant\n- Modes: TBD (research needed)\n- Output: Convert Copilot CLI output to `NormalizedEntry`\n\n**Cursor Adapter** (new):\n- Location: `server/src/execution/adapters/cursor-adapter.ts`\n- Config: TBD (research needed)\n- Modes: TBD (research needed)\n- Output: Convert Cursor output to `NormalizedEntry`\n\n#### 4. Frontend Agent Selection\n\n**AgentConfigPanel Updates** (`frontend/src/components/executions/AgentConfigPanel.tsx`):\n\n**New UI Structure**:\n```tsx\n<AgentConfigPanel>\n  {/* NEW: Agent Selection */}\n  <AgentSelector\n    agents={availableAgents}\n    selected={selectedAgent}\n    onChange={handleAgentChange}\n  />\n  \n  {/* Existing: Mode Selection - now filtered by agent capabilities */}\n  <ModeSelector\n    modes={selectedAgent.supportedModes}\n    selected={mode}\n    onChange={handleModeChange}\n  />\n  \n  {/* Agent-specific configuration */}\n  {selectedAgent.type === 'claude-code' && (\n    <ClaudeCodeConfig config={config} onChange={handleConfigChange} />\n  )}\n  \n  {selectedAgent.type === 'codex' && (\n    <CodexConfig config={config} onChange={handleConfigChange} />\n  )}\n  \n  {/* ... other agents */}\n  \n  {/* Advanced: JSON config editor */}\n  <AdvancedConfigEditor config={config} onChange={handleConfigChange} />\n</AgentConfigPanel>\n```\n\n**State Management**:\n```typescript\ninterface ExecutionConfigState {\n  agentType: AgentType;\n  agentConfig: ClaudeCodeConfig | CodexConfig | CopilotConfig | CursorConfig;\n  mode: ExecutionMode;\n  // ... other fields\n}\n```\n\n#### 5. Configuration Storage\n\n**Database** (`types/src/schema.ts`):\n- `executions.agent_type` column (already exists)\n- `executions.config` JSON column stores agent-specific config\n- `executions.mode` stores execution mode\n\n**Config Structure in DB**:\n```json\n{\n  \"agentType\": \"claude-code\",\n  \"config\": {\n    \"print\": \"markdown\",\n    \"outputFormat\": \"stream-json\",\n    \"verbose\": false,\n    \"model\": \"claude-sonnet-4-5\"\n  },\n  \"mode\": \"structured\"\n}\n```\n\n## Implementation Phases\n\n### Phase 1: Core Architecture & Registry (Week 1)\n\n**Goal**: Establish generic executor wrapper and agent registry integration\n\n#### Tasks:\n\n1. **Update Type Definitions**\n   - File: `types/src/index.d.ts`\n   - Update `AgentType` to include: `'claude-code' | 'codex' | 'copilot' | 'cursor'`\n   - Create config types for each agent extending `BaseAgentConfig`\n   - Ensure `Execution` type properly handles multiple agent types\n\n2. **Create Agent Registry Service**\n   - File: `server/src/services/agent-registry.ts` (new)\n   - Initialize `AgentRegistry` from agent-execution-engine\n   - Register Claude Code adapter (from package)\n   - Create stub adapters for Codex, Copilot, Cursor (throw \"not implemented\" errors)\n   - Implement `getAvailableAgents()`, `getAdapter()`, `isAgentImplemented()`\n\n3. **Refactor Executor Wrapper**\n   - File: `server/src/execution/executors/claude-executor-wrapper.ts` → `agent-executor-wrapper.ts`\n   - Make class generic: `AgentExecutorWrapper<TConfig>`\n   - Accept `IAgentAdapter<TConfig>` in constructor\n   - Use `adapter.buildProcessConfig()` for process configuration\n   - Keep all lifecycle integration unchanged\n   - Create `createExecutorForAgent()` factory function\n\n4. **Update Execution Service**\n   - File: `server/src/services/executions.ts`\n   - Modify `createExecution()` to accept `agentType` parameter\n   - Use `createExecutorForAgent()` factory instead of hardcoded wrapper\n   - Add config validation using `adapter.validateConfig()`\n   - Update resume logic to instantiate correct executor based on `agent_type` from DB\n\n5. **Testing**\n   - Unit tests for `AgentRegistryService`\n   - Unit tests for generic `AgentExecutorWrapper`\n   - Integration test: Claude Code execution works with new architecture (regression test)\n   - Integration test: Factory function creates correct wrapper\n\n**Success Criteria**:\n- ✅ Existing Claude Code executions continue to work (no regression)\n- ✅ Agent registry initializes on server startup\n- ✅ Generic executor wrapper passes all tests\n- ✅ Can create executions with explicit `agentType: 'claude-code'`\n\n### Phase 2: Server API Updates (Week 1-2)\n\n**Goal**: Expose agent capabilities and handle agent-specific execution requests\n\n#### Tasks:\n\n1. **Create Agents API Endpoint**\n   - File: `server/src/routes/agents.ts` (new)\n   - Endpoint: `GET /api/agents`\n   - Returns list of available agents with metadata\n   - Includes `implemented` flag for each agent\n   - Add to router in `server/src/index.ts`\n\n2. **Update Execution API**\n   - File: `server/src/routes/executions.ts`\n   - Accept `agentType` in `POST /api/executions` request body\n   - Validate that agent is implemented before creating execution\n   - Return clear error if agent not available\n   - Store `agentType` in database\n\n3. **Error Handling**\n   - Define error types: `AgentNotFoundError`, `AgentNotImplementedError`, `AgentConfigValidationError`\n   - Return appropriate HTTP status codes (404, 501, 400)\n   - Include helpful error messages for frontend display\n\n4. **Testing**\n   - API test: `GET /api/agents` returns expected agent list\n   - API test: Create execution with `agentType: 'claude-code'` succeeds\n   - API test: Create execution with unimplemented agent returns 501\n   - API test: Create execution with invalid agent type returns 400\n\n**Success Criteria**:\n- ✅ `GET /api/agents` returns all registered agents\n- ✅ Can create Claude Code executions via API with explicit agent type\n- ✅ Attempting to create execution with unimplemented agent fails gracefully\n- ✅ All error cases handled with appropriate status codes\n\n### Phase 3: Frontend Agent Selection (Week 2)\n\n**Goal**: Enable agent selection in the UI\n\n#### Tasks:\n\n1. **Fetch Available Agents**\n   - File: `frontend/src/hooks/useAgents.ts` (new)\n   - Hook to fetch agents from `GET /api/agents`\n   - Cache results\n   - Expose loading/error states\n\n2. **Create Agent Selector Component**\n   - File: `frontend/src/components/executions/AgentSelector.tsx` (new)\n   - Dropdown to select agent\n   - Display agent name, description, and implemented status\n   - Disable unimplemented agents with \"Coming Soon\" label\n   - Show agent capabilities on hover/expand\n\n3. **Update AgentConfigPanel**\n   - File: `frontend/src/components/executions/AgentConfigPanel.tsx`\n   - Add `AgentSelector` at top of panel\n   - Track selected agent in state\n   - Filter mode dropdown by `selectedAgent.supportedModes`\n   - Conditionally show streaming toggle based on `selectedAgent.supportsStreaming`\n\n4. **Update Execution Context**\n   - File: `frontend/src/contexts/ExecutionContext.tsx`\n   - Add `agentType` to execution config state\n   - Default to `'claude-code'`\n   - Include in execution creation request\n\n5. **Update Execution Creation**\n   - File: `frontend/src/components/executions/ExecutionConfigDialog.tsx`\n   - Include `agentType` in execution creation request\n   - Display error if agent not available\n   - Show validation errors from server\n\n6. **Testing**\n   - Component test: `AgentSelector` renders available agents\n   - Component test: Unimplemented agents are disabled\n   - Component test: Selecting agent updates execution config\n   - Integration test: Can create execution with selected agent\n   - E2E test: Full execution creation flow with agent selection\n\n**Success Criteria**:\n- ✅ Agent selector dropdown appears in UI\n- ✅ Only Claude Code is enabled initially\n- ✅ Other agents show as \"Coming Soon\"\n- ✅ Selected agent persists in execution config\n- ✅ Can create Claude Code executions through new UI\n\n### Phase 4: Agent Adapter Implementations (Weeks 3-5)\n\n**Goal**: Implement adapters for Codex, Copilot, and Cursor\n\nFor each agent, follow this sub-phase structure:\n\n#### 4.1 Research Phase (Per Agent)\n\n**Tasks**:\n- Research CLI interface, installation, authentication\n- Document command structure and arguments\n- Identify input/output formats\n- Determine supported modes and capabilities\n- Document configuration options\n- Test CLI locally to understand behavior\n\n**Deliverable**: Research document per agent\n\n#### 4.2 Adapter Implementation (Per Agent)\n\n**Tasks**:\n\n1. **Create Adapter Class**\n   - File: `server/src/execution/adapters/{agent}-adapter.ts`\n   - Implement `IAgentAdapter<TConfig>` interface\n   - Define agent-specific config type\n   - Implement `buildProcessConfig()` to translate to generic `ProcessConfig`\n   - Implement `validateConfig()` for config validation\n   - Define `metadata` with capabilities\n\n2. **Create Config Builder**\n   - File: `server/src/execution/adapters/{agent}-config-builder.ts`\n   - Helper functions to build agent-specific config\n   - Sensible defaults\n\n3. **Implement Output Normalization**\n   - If agent doesn't output `NormalizedEntry` format natively:\n   - Create output parser/transformer\n   - Convert agent output to `NormalizedEntry` stream\n   - Handle errors and edge cases\n\n4. **Register Adapter**\n   - Update `server/src/services/agent-registry.ts`\n   - Replace stub with real adapter\n   - Test registration\n\n5. **Frontend Configuration UI**\n   - File: `frontend/src/components/executions/{Agent}ConfigForm.tsx` (new)\n   - Basic form for agent-specific settings\n   - API key input (if needed)\n   - Model selection (if applicable)\n   - Common settings (timeout, etc.)\n   - Integrate with `AgentConfigPanel`\n\n6. **Testing**\n   - Unit tests for adapter methods\n   - Unit tests for config validation\n   - Integration test: Create execution with agent\n   - Integration test: Execute simple task with agent\n   - E2E test: Full execution flow with agent\n\n**Success Criteria (Per Agent)**:\n- ✅ Adapter implements all required interface methods\n- ✅ Config validation works correctly\n- ✅ Can create and run executions with agent\n- ✅ Output is normalized to `NormalizedEntry` format\n- ✅ Frontend shows agent-specific config form\n- ✅ All tests pass\n\n#### Agent Implementation Order:\n\n1. **Codex** (Week 3)\n   - Simplest: API-based, well-documented\n   - Good validation of architecture\n\n2. **Copilot** (Week 4)\n   - CLI-based, similar to Claude Code\n   - Tests adapter pattern for interactive CLIs\n\n3. **Cursor** (Week 5)\n   - Most complex, may require custom integration\n   - Final validation of architecture\n\n### Phase 5: Configuration Enhancements (Week 6)\n\n**Goal**: Improve configuration UX and validation\n\n#### Tasks:\n\n1. **Capability-Based UI Controls**\n   - Update `AgentConfigPanel` to show/hide controls based on capabilities\n   - Mode dropdown: Only show modes in `supportedModes`\n   - Streaming toggle: Only show if `supportsStreaming`\n   - Model selection: Only show for agents that support models\n   - Disable \"Create Execution\" if agent not implemented\n\n2. **Advanced Configuration Editor**\n   - File: `frontend/src/components/executions/AdvancedConfigEditor.tsx` (new)\n   - JSON editor for advanced agent-specific settings\n   - Syntax highlighting\n   - Validation against schema\n   - Collapsible \"Advanced\" section\n\n3. **Configuration Validation**\n   - Client-side validation before submission\n   - Display validation errors inline\n   - Show helpful error messages\n   - Prevent submission of invalid configs\n\n4. **Configuration Defaults**\n   - Server-side: Use `adapter.getDefaultConfig()` for sensible defaults\n   - Frontend: Pre-populate forms with defaults\n   - Allow users to reset to defaults\n\n5. **Testing**\n   - Component tests for capability-based controls\n   - Component tests for config validation\n   - E2E test: Validation prevents invalid execution creation\n\n**Success Criteria**:\n- ✅ UI adapts to agent capabilities\n- ✅ Invalid configs caught before submission\n- ✅ Users can edit advanced settings via JSON\n- ✅ Default configs work out-of-the-box\n\n## Technical Considerations\n\n### Backwards Compatibility\n\n**Existing Executions**:\n- Database already has `agent_type` column\n- Existing executions may have `null` or `'claude-code'` as agent type\n- Migration: Set `agent_type = 'claude-code'` for all existing executions with `null`\n- Resume logic: Default to Claude Code if agent type missing\n\n**API Compatibility**:\n- `POST /api/executions` should accept `agentType` as optional parameter\n- Default to `'claude-code'` if not provided (backwards compatible)\n- Existing clients continue to work without changes\n\n### Security Considerations\n\n**API Key Handling**:\n- Never log API keys\n- Store encrypted in database if persistence needed\n- Transmit over HTTPS only\n- Consider using environment variables for system-wide keys\n\n**Agent CLI Validation**:\n- Validate executable path exists before execution\n- Check executable permissions\n- Sanitize user inputs passed to CLI\n- Prevent command injection via config parameters\n\n**Sandboxing**:\n- Maintain existing worktree isolation\n- Consider additional sandboxing for untrusted agents\n- Limit agent access to project files only\n\n### Performance Considerations\n\n**Agent Registry**:\n- Initialize once on server startup\n- Cache agent metadata\n- Lazy-load adapter implementations if needed\n\n**Output Normalization**:\n- Stream conversion (don't buffer entire output)\n- Handle backpressure for slow consumers\n- Optimize parsing for high-frequency output\n\n**Frontend Caching**:\n- Cache available agents list (rarely changes)\n- Cache agent metadata\n- Invalidate cache on server restart\n\n### Error Handling\n\n**Agent Not Available**:\n- Clear error message: \"Agent '{name}' requires installation of {cli-name}\"\n- Link to installation instructions\n- Disable agent selection in UI\n\n**Config Validation Failures**:\n- Show specific validation errors per field\n- Highlight invalid fields in UI\n- Provide example of valid config\n\n**Execution Failures**:\n- Distinguish agent-specific errors from system errors\n- Include agent name in error context\n- Suggest troubleshooting steps\n\n### Testing Strategy\n\n**Unit Tests**:\n- Agent adapter methods (config building, validation)\n- Agent registry service\n- Generic executor wrapper\n- Config validation logic\n\n**Integration Tests**:\n- End-to-end execution with each agent\n- Agent switching between executions\n- Config persistence and retrieval\n- Output normalization pipeline\n\n**E2E Tests**:\n- Full user flow: select agent → configure → execute → view results\n- Agent switching during session\n- Error cases (invalid config, agent unavailable)\n\n**Regression Tests**:\n- Existing Claude Code executions continue to work\n- API backwards compatibility\n- Database migrations\n\n## Migration Plan\n\n### Database Migration\n\n**Migration**: `Add_agent_type_default.sql`\n```sql\n-- Set agent_type to 'claude-code' for existing executions with NULL\nUPDATE executions \nSET agent_type = 'claude-code' \nWHERE agent_type IS NULL;\n\n-- Ensure agent_type column is NOT NULL going forward\nALTER TABLE executions \nALTER COLUMN agent_type SET DEFAULT 'claude-code';\n```\n\n### Code Migration\n\n**Phase 1**: Refactor to generic wrapper (non-breaking)\n- Create `AgentExecutorWrapper` alongside `ClaudeExecutorWrapper`\n- Update `ExecutionService` to use new wrapper for new executions\n- Keep old wrapper for resuming existing executions\n\n**Phase 2**: Deprecate old wrapper\n- Add migration to set agent_type for all executions\n- Update resume logic to use generic wrapper\n- Mark `ClaudeExecutorWrapper` as deprecated\n\n**Phase 3**: Remove old wrapper\n- Delete `ClaudeExecutorWrapper`\n- All executions use `AgentExecutorWrapper`\n\n## Rollout Plan\n\n### Stage 1: Internal Testing (Week 6)\n- Deploy to staging environment\n- Test with real API keys for each agent\n- Validate full execution flows\n- Performance testing\n- Security review\n\n### Stage 2: Beta Release (Week 7)\n- Release with Claude Code (stable) + Codex (beta)\n- Limited user group testing\n- Collect feedback on UX\n- Monitor errors and performance\n- Iterate on configuration UI\n\n### Stage 3: General Availability (Week 8)\n- Release all agents (mark experimental if needed)\n- Update documentation\n- Announce feature to users\n- Monitor adoption and issues\n\n### Stage 4: Refinement (Ongoing)\n- Add more agents based on user demand\n- Improve configuration UX based on feedback\n- Performance optimizations\n- Advanced features (presets, defaults, etc.)\n\n## Success Metrics\n\n### Functional Metrics\n- All existing Claude Code executions continue to work (100% backwards compatibility)\n- Users can successfully create executions with each implemented agent\n- Agent selection persists correctly in execution history\n- Configuration validation prevents invalid executions\n\n### Performance Metrics\n- Agent registry initialization: < 100ms\n- GET /api/agents response time: < 50ms\n- Execution creation with agent validation: < 200ms\n- Output normalization overhead: < 5% of total execution time\n\n### Quality Metrics\n- Test coverage: > 80% for new code\n- Zero regressions in existing functionality\n- All critical bugs fixed before GA release\n- Documentation completeness: 100%\n\n### Adoption Metrics\n- % of executions using non-Claude agents\n- Most popular agent (besides Claude Code)\n- Configuration error rate (should decrease over time)\n\n## Documentation Requirements\n\n### User Documentation\n\n1. **Agent Selection Guide**\n   - How to choose an agent\n   - Comparison of agent capabilities\n   - When to use which agent\n\n2. **Configuration Guide**\n   - Agent-specific configuration options\n   - How to obtain API keys\n   - Troubleshooting common issues\n\n3. **Agent Installation Guide**\n   - CLI installation instructions per agent\n   - Authentication setup\n   - Verification steps\n\n### Developer Documentation\n\n1. **Architecture Overview**\n   - Multi-agent system design\n   - Component interactions\n   - Data flow diagrams\n\n2. **Adding New Agents**\n   - Adapter implementation guide\n   - Testing requirements\n   - Registration process\n\n3. **API Documentation**\n   - GET /api/agents endpoint\n   - Updated POST /api/executions endpoint\n   - Error codes and responses\n\n## Risks and Mitigations\n\n### Risk 1: Agent CLI Not Installed\n\n**Impact**: Users can't execute with selected agent\n\n**Mitigation**:\n- Check for executable existence before showing agent as available\n- Show clear installation instructions when agent unavailable\n- Allow users to specify custom executable paths\n\n### Risk 2: Inconsistent Output Formats\n\n**Impact**: Output normalization fails for some agents\n\n**Mitigation**:\n- Thoroughly test output normalization for each agent\n- Fallback to raw output display if normalization fails\n- Add debug mode to show raw agent output\n\n### Risk 3: Breaking Changes in Agent CLIs\n\n**Impact**: Adapter stops working after agent update\n\n**Mitigation**:\n- Version-pin agent CLIs in recommendations\n- Detect CLI version and adapt behavior\n- Show warnings for unsupported versions\n- Maintain adapter compatibility matrix\n\n### Risk 4: Performance Degradation\n\n**Impact**: Multi-agent support slows down executions\n\n**Mitigation**:\n- Benchmark performance before and after changes\n- Profile hot paths (output normalization, config validation)\n- Optimize registry lookups (caching, indexing)\n- Monitor production performance metrics\n\n### Risk 5: Security Vulnerabilities\n\n**Impact**: Agent configs expose sensitive data or allow injection attacks\n\n**Mitigation**:\n- Security review of config validation logic\n- Sanitize all user inputs passed to CLI\n- Never log sensitive config fields\n- Follow secure credential storage practices\n- Regular security audits\n\n## Open Questions\n\n1. **Agent Authentication**: How should we handle API keys for each agent?\n   - Store encrypted in database per project?\n   - Use environment variables system-wide?\n   - Prompt user on each execution?\n\n2. **Agent Availability Detection**: How do we check if an agent CLI is installed?\n   - Run `{agent} --version` on startup?\n   - Check PATH for executable?\n   - Allow users to configure custom paths?\n\n3. **Output Format Compatibility**: What if an agent doesn't support structured output?\n   - Parse terminal output with heuristics?\n   - Fall back to raw output display?\n   - Require structured output capability?\n\n4. **Concurrent Multi-Agent Executions**: Should we support running multiple agents in parallel?\n   - Within same execution?\n   - Across different executions?\n   - Resource management considerations?\n\n5. **Agent-Specific Features**: How do we handle features unique to one agent?\n   - Expose in advanced config JSON?\n   - Create agent-specific UI sections?\n   - Document but don't surface in UI?\n\n## Conclusion\n\nThis spec outlines a comprehensive plan to add multi-agent support to sudocode by leveraging the existing agent-execution-engine architecture. The phased approach allows for incremental delivery, starting with core infrastructure and progressively adding agent implementations.\n\nKey success factors:\n- **Generic architecture** that supports any agent implementing the adapter interface\n- **Backwards compatibility** ensuring existing Claude Code executions continue to work\n- **Unified experience** where users get consistent execution interface regardless of agent\n- **Extensibility** making it easy to add new agents in the future\n\nBy completing this work, sudocode will evolve from a Claude Code-specific tool to a **universal AI coding agent orchestration platform**, giving users the flexibility to choose the best agent for their specific needs.","priority":1,"archived":0,"archived_at":null,"created_at":"2025-11-23 20:01:23","updated_at":"2025-11-23 20:01:23","parent_id":null,"parent_uuid":null,"relationships":[],"tags":["architecture","backend","execution","frontend","multi-agent"]}
{"id":"s-8lkf","uuid":"4d9abfb8-512c-424c-842e-1af466119d61","title":"Watcher Event System: Replace Log Parsing with Typed Callbacks","file_path":"specs/s-27p3 - Watcher Event System Replace Log Parsing with Type.md","content":"# Watcher Event System: Replace Log Parsing with Typed Callbacks\n\n## Overview\n\nReplace the fragile log message parsing system with typed event callbacks for communication between the CLI watcher and server. This improves reliability, type safety, and maintainability of the file watching and WebSocket broadcast system.\n\n## Problem Statement\n\n### Current Architecture Issues\n\nThe server currently parses CLI watcher stdout messages with regex to detect entity changes:\n\n```typescript\n// FRAGILE: Regex parsing of log messages\nconst syncMatch = message.match(\n  /\\[watch\\] Synced (spec|issue) ([A-Za-z0-9-]+) (?:to .+ )?\\((created|updated)\\)/\n);\n```\n\n**Critical Problems:**\n\n1. **Silent Failures**: If log format changes, regex doesn't match → no broadcast → UI doesn't update\n2. **No Type Safety**: Regex captures are untyped strings, easy to misuse  \n3. **Fragile Coupling**: Server depends on exact string format from CLI\n4. **Poor Debuggability**: When it fails, no indication of why\n5. **Performance Overhead**: Must query database again to get entity data\n6. **No Metadata**: Can't pass timing, source, or conflict information\n7. **No Project Context**: Events don't indicate which project they belong to (critical for multi-project servers)\n8. **Shared Database Problem**: When CLI updates DB, server's watcher can't detect changes (jsonlNeedsImport returns false)\n\n### Recent Bug Examples\n\n**Bug 1: ID Format Change**\nWhen ID format changed from `ISSUE-001` to `i-x7k9`, the regex pattern stopped matching:\n- MCP tool updates did NOT trigger UI broadcasts\n- Silent failure (no errors, just no updates)\n- Required emergency regex fix to restore functionality\n\n**Bug 2: CLI Update → No UI Update (Current)**\nWhen using CLI or MCP to update entities:\n- CLI updates database directly\n- Server's watcher detects JSONL change\n- `jsonlNeedsImport()` returns `false` (DB already synced)\n- No entity-specific logs emitted\n- Server doesn't know which entities changed\n- **UI never updates** ❌\n\nExample scenario:\n```bash\n# User runs: npx sudocode issue update ISSUE-143 --status closed\n# Expected: UI shows status updated to 'closed'\n# Actual: No UI update (database updated, but server doesn't broadcast)\n```\n\n## Solution: Typed Event Callbacks\n\n### Architecture Overview\n\nReplace stdout parsing with direct typed callbacks:\n\n```\n┌─────────────┐  onEntitySync(event) ┌──────────────┐\n│ CLI Watcher │ ──────────────────▶  │ Server       │\n│             │  EntitySyncEvent     │ Watcher      │\n└─────────────┘                      └──────────────┘\n```\n\nInstead of parsing strings, use structured data:\n\n```typescript\n// BEFORE: Parse string (fragile)\n\"[watch] Synced issue i-x7k9 to markdown (updated)\"\n\n// AFTER: Typed event (robust)\n{\n  entityType: 'issue',\n  entityId: 'i-x7k9',\n  action: 'updated',\n  filePath: '/abs/path/issues/i-x7k9.md',\n  baseDir: '/abs/path/.sudocode',  // NEW: For project identification\n  source: 'jsonl',\n  timestamp: Date,\n  entity: issueObject  // Optional: Avoids DB query\n}\n```\n\n## Multi-Project Support Design\n\n### The Challenge\n\nIn a multi-project server:\n- **Problem**: Multiple projects can have same entity ID (e.g., both have `ISSUE-143`)\n- **Question**: How does server know which project an event belongs to?\n\n### Current Architecture (Closure Scoping)\n\nEach project gets its own watcher with projectId in closure:\n\n```typescript\n// server/src/services/project-manager.ts:126-159\ncontext.watcher = startServerWatcher({\n  db,\n  baseDir: sudocodeDir,\n  onFileChange: (info) => {\n    // projectId available from closure! ✅\n    const projectId = projectId;  // From outer scope\n\n    if (info.entityType === 'issue' && info.entityId) {\n      const issue = getIssueById(db, info.entityId);\n      if (issue) {\n        broadcastIssueUpdate(projectId, info.entityId, 'updated', issue);\n      }\n    }\n  },\n});\n```\n\n**This works** because:\n- Each project has dedicated watcher instance\n- Callback has projectId in closure\n- No cross-project confusion\n\n### Design Decision: Include baseDir\n\n**✅ DECISION: Add `baseDir` to events**\n\nEvents should include `baseDir` for self-contained context:\n\n```typescript\n{\n  entityId: 'ISSUE-143',\n  baseDir: '/abs/path/to/project/.sudocode',  // ✅\n  // Server can use closure OR derive project from baseDir\n}\n```\n\n**Why baseDir?**\n1. ✅ CLI already has it (no computation needed)\n2. ✅ Server can use closure (preferred) OR derive projectId (fallback)\n3. ✅ Events are self-documenting for debugging\n4. ✅ Doesn't force CLI to understand projectId\n5. ✅ Future-proofs for multi-project CLI scenarios\n\n**Rejected Alternatives:**\n- ❌ **No project context**: Can't debug events independently\n- ❌ **Include projectId**: Breaks CLI's project-agnostic design\n- ❌ **Only filePath**: Requires parsing to find `.sudocode` dir\n\n## Type Definitions\n\n### Core Event Types\n\n```typescript\n/**\n * Event fired when an entity is synced between database and markdown\n */\nexport interface EntitySyncEvent {\n  /** Type of entity that was synced */\n  entityType: 'spec' | 'issue';\n\n  /** ID of the entity (e.g., 'i-x7k9', 's-14sh') */\n  entityId: string;\n\n  /** Action that was performed */\n  action: 'created' | 'updated' | 'deleted' | 'no-change';\n\n  /** Absolute path to the markdown file */\n  filePath: string;\n\n  /** Absolute path to the .sudocode directory (for project identification) */\n  baseDir: string;  // ✅ NEW\n\n  /** Source of the change that triggered sync */\n  source: 'markdown' | 'jsonl' | 'database';\n\n  /** Timestamp when event occurred */\n  timestamp: Date;\n\n  /** Optional: Full entity data (avoids DB query in server) */\n  entity?: Spec | Issue;\n\n  /** Optional: Duration of sync operation in milliseconds */\n  duration?: number;\n\n  /** Optional: Whether a merge conflict was resolved */\n  conflictResolved?: boolean;\n}\n\n/**\n * Event fired when a file change is detected (before sync)\n */\nexport interface FileChangeEvent {\n  /** Absolute path to the file */\n  filePath: string;\n\n  /** Absolute path to the .sudocode directory */\n  baseDir: string;  // ✅ NEW\n\n  /** Type of file system event */\n  event: 'add' | 'change' | 'unlink';\n\n  /** Detected entity type (if applicable) */\n  entityType?: 'spec' | 'issue';\n\n  /** Detected entity ID (if applicable) */\n  entityId?: string;\n\n  /** Timestamp */\n  timestamp: Date;\n}\n```\n\n### Updated Watcher Options\n\n```typescript\nexport interface WatcherOptions {\n  db: Database.Database;\n  baseDir: string;\n  debounceDelay?: number;\n  ignoreInitial?: boolean;\n  syncJSONLToMarkdown?: boolean;\n\n  // EXISTING: Keep for backward compatibility and human debugging\n  onLog?: (message: string) => void;\n  onError?: (error: Error) => void;\n\n  // NEW: Typed callbacks for machine consumption\n  /** Called when an entity is synced (after successful sync) */\n  onEntitySync?: (event: EntitySyncEvent) => void | Promise<void>;\n\n  /** Called when a file change is detected (before sync) */\n  onFileChange?: (event: FileChangeEvent) => void | Promise<void>;\n}\n```\n\n## Gap Analysis & Solutions\n\n### Gap 1: Shared Database Problem ✅ SOLUTION PROVIDED\n\n**Problem**: When CLI/MCP updates DB, server can't detect which entities changed.\n\n**Root Cause**:\n```typescript\n// cli/src/watcher.ts (current)\nif (jsonlNeedsImport(filePath)) {  // Returns false when DB already synced!\n  await importFromJSONL(db, { inputDir: baseDir });\n  // Only emits logs INSIDE this block\n  // When DB already synced, no logs = no broadcasts\n}\n```\n\n**Solution**: Emit `onEntitySync` events ALWAYS, not just when import needed.\n\n**Implementation**:\n```typescript\n// cli/src/watcher.ts (AFTER implementing Phase 1)\nconst entityType = basename === \"specs.jsonl\" ? \"spec\" : \"issue\";\n\n// Track entities BEFORE any import\nconst beforeEntities = entityType === \"spec\"\n  ? listSpecs(db).map(s => ({ id: s.id, updated_at: s.updated_at }))\n  : listIssues(db).map(i => ({ id: i.id, updated_at: i.updated_at }));\n\n// Import if needed\nif (jsonlNeedsImport(filePath)) {\n  await importFromJSONL(db, { inputDir: baseDir });\n}\n\n// Track entities AFTER (whether imported or not)\nconst afterEntities = entityType === \"spec\"\n  ? listSpecs(db).map(s => ({ id: s.id, updated_at: s.updated_at }))\n  : listIssues(db).map(i => ({ id: i.id, updated_at: i.updated_at }));\n\n// Emit events for ALL changed entities\nconst changed = detectChangedEntities(beforeEntities, afterEntities);\nfor (const entity of changed) {\n  onEntitySync?.({\n    entityType,\n    entityId: entity.id,\n    action: entity.isNew ? 'created' : 'updated',\n    filePath: entity.filePath,\n    baseDir,\n    source: 'jsonl',\n    timestamp: new Date(),\n    entity: entity.data,  // ✅ Include full entity\n  });\n}\n```\n\n**Key Points**:\n- ✅ Always track before/after state\n- ✅ Emit events even when `jsonlNeedsImport()` returns false\n- ✅ Include full entity data (avoids server DB query)\n- ✅ Solves \"CLI update → no UI update\" bug\n\n### Gap 2: Multi-Project Context ✅ SOLUTION PROVIDED\n\n**Problem**: Events don't indicate which project they belong to.\n\n**Solution**: Include `baseDir` in all events (already in type definitions above).\n\n**Server Implementation**:\n```typescript\n// server/src/services/project-manager.ts\ncontext.watcher = startServerWatcher({\n  db,\n  baseDir: sudocodeDir,\n  onFileChange: (info) => {\n    // OPTION A: Use closure (preferred)\n    const projectId = projectId;  // From outer scope ✅\n\n    // OPTION B: Derive from baseDir (fallback)\n    // const projectId = this.getProjectIdByPath(info.baseDir);\n\n    // Validate baseDir matches (optional safety check)\n    if (info.baseDir !== sudocodeDir) {\n      console.warn(`baseDir mismatch: expected ${sudocodeDir}, got ${info.baseDir}`);\n    }\n\n    // Use entity from event if available (optimization)\n    if (info.entity) {\n      broadcastIssueUpdate(projectId, info.entityId, 'updated', info.entity);\n    } else {\n      const issue = getIssueById(db, info.entityId);\n      if (issue) {\n        broadcastIssueUpdate(projectId, info.entityId, 'updated', issue);\n      }\n    }\n  },\n});\n```\n\n### Gap 3: Testing Coverage ✅ TESTS PROVIDED\n\n**Missing Tests**:\n- Multi-project scenarios\n- Shared database edge case\n- baseDir validation\n\n**Solution**: Comprehensive test suite (see Testing Strategy section below).\n\n## Implementation Plan\n\n### Phase 1: Add Callbacks (Non-Breaking) ✅ Safe\n\n**Goal**: Add new callbacks alongside existing logs, no breaking changes.\n\n**Changes**:\n\n1. **Add types** (`types/src/index.d.ts`):\n```typescript\nexport interface EntitySyncEvent { /* as defined above */ }\nexport interface FileChangeEvent { /* as defined above */ }\n```\n\n2. **Update CLI watcher** (`cli/src/watcher.ts`):\n\n```typescript\n// Add callbacks to options (already defined above)\n\n// In JSONL change handler (~line 399):\nasync function processJSONLChange(filePath: string) {\n  const entityType = basename === \"specs.jsonl\" ? \"spec\" : \"issue\";\n\n  // Track before state\n  const before = entityType === \"spec\"\n    ? listSpecs(db).map(s => ({ id: s.id, updated_at: s.updated_at }))\n    : listIssues(db).map(i => ({ id: i.id, updated_at: i.updated_at }));\n\n  // Import if needed  \n  if (jsonlNeedsImport(filePath)) {\n    await importFromJSONL(db, { inputDir: baseDir });\n    onLog(`[watch] Imported JSONL changes to database`);\n  }\n\n  // Track after state\n  const after = entityType === \"spec\"\n    ? listSpecs(db).map(s => ({ id: s.id, updated_at: s.updated_at }))\n    : listIssues(db).map(i => ({ id: i.id, updated_at: i.updated_at }));\n\n  // Detect changes\n  const beforeMap = new Map(before.map(e => [e.id, e.updated_at]));\n  const afterMap = new Map(after.map(e => [e.id, e.updated_at]));\n\n  // Emit events for changed entities\n  for (const [id, afterTime] of afterMap) {\n    const beforeTime = beforeMap.get(id);\n    const action = !beforeTime ? 'created' : beforeTime !== afterTime ? 'updated' : 'no-change';\n\n    if (action !== 'no-change') {\n      // Get full entity\n      const entity = entityType === 'spec' \n        ? getSpec(db, id)\n        : getIssue(db, id);\n\n      // Find file path\n      const filePath = entity?.file_path \n        ? path.join(baseDir, entity.file_path)\n        : path.join(baseDir, entityType === 'spec' ? 'specs' : 'issues', `${id}.md`);\n\n      // KEEP: Existing log\n      onLog(`[watch] Synced ${entityType} ${id} (${action})`);\n\n      // ADD: Typed callback\n      onEntitySync?.({\n        entityType,\n        entityId: id,\n        action,\n        filePath,\n        baseDir,\n        source: 'jsonl',\n        timestamp: new Date(),\n        entity,  // ✅ Include full entity\n      });\n    }\n  }\n}\n```\n\n3. **In Markdown sync handlers** (emit similar events after MD→DB sync)\n\n**Testing**:\n- Unit tests: Verify callbacks called with correct data\n- Integration tests: Verify existing log parsing still works\n- Ensure no breaking changes\n\n**Timeline**: 1-2 days\n\n### Phase 2: Migrate Server (Backward Compatible) ✅ Safe\n\n**Goal**: Server uses callbacks when available, falls back to parsing.\n\n**Changes**:\n\n1. Update `server/src/services/watcher.ts`:\n\n```typescript\nexport function startServerWatcher(options: ServerWatcherOptions) {\n  const { db, baseDir, onFileChange } = options;\n  let callbackFired = false;\n\n  const control = startCliWatcher({\n    db,\n    baseDir,\n\n    // NEW PATH: Use typed callback (preferred)\n    onEntitySync: (event) => {\n      callbackFired = true;\n      console.log(`[watcher] Entity synced via callback: ${event.entityType} ${event.entityId}`);\n\n      if (onFileChange) {\n        onFileChange({\n          filePath: event.filePath,\n          baseDir: event.baseDir,  // ✅ NEW\n          event: 'change',\n          entityType: event.entityType,\n          entityId: event.entityId,\n          entity: event.entity,  // ✅ Pass through\n          timestamp: event.timestamp,\n        });\n      }\n    },\n\n    // OLD PATH: Fallback to parsing\n    onLog: (message) => {\n      console.log(message);\n\n      // Only parse if callback didn't fire\n      if (!callbackFired && onFileChange && message.includes('[watch] Synced')) {\n        const syncMatch = message.match(\n          /\\[watch\\] Synced (spec|issue) ([A-Za-z0-9-]+) (?:to .+ )?\\((created|updated)\\)/\n        );\n        \n        if (syncMatch) {\n          console.warn('⚠️  Using legacy log parsing (update CLI for callbacks)');\n          const [, entityType, entityId] = syncMatch;\n          \n          onFileChange({\n            filePath: \"\",\n            baseDir,  // Use baseDir from options\n            event: 'change',\n            entityType: entityType as 'spec' | 'issue',\n            entityId,\n            timestamp: new Date(),\n          });\n        }\n      }\n\n      callbackFired = false;  // Reset for next event\n    },\n  });\n\n  return control;\n}\n```\n\n2. Update `ServerWatcherOptions` interface to match:\n\n```typescript\ninterface ServerWatcherOptions {\n  db: Database.Database;\n  baseDir: string;\n  onFileChange?: (info: {\n    filePath: string;\n    baseDir: string;  // ✅ NEW\n    event: 'add' | 'change' | 'unlink';\n    entityType?: 'spec' | 'issue';\n    entityId?: string;\n    entity?: any;  // ✅ NEW\n    timestamp: Date;\n  }) => void;\n}\n```\n\n**Testing**:\n- Test callback path works\n- Test fallback parsing works\n- Test performance improvement (should be 2x faster with callbacks)\n\n**Timeline**: 1-2 days\n\n### Phase 3: Deprecate Parsing ⚠️  Warning\n\n**Goal**: Encourage migration with deprecation warnings.\n\n**Timeline**: 2-3 release cycles\n\n### Phase 4: Remove Parsing 🔴 Breaking\n\n**Goal**: Clean up legacy code.\n\n**Timeline**: After 3+ releases with warnings\n\n## Testing Strategy\n\n### Unit Tests\n\n**CLI Watcher Tests** (`cli/tests/unit/watcher.test.ts`):\n\n```typescript\ndescribe('onEntitySync callback', () => {\n  it('should call onEntitySync when JSONL changes', async () => {\n    const events: EntitySyncEvent[] = [];\n\n    const watcher = startWatcher({\n      db,\n      baseDir,\n      onEntitySync: (event) => events.push(event),\n    });\n\n    // Modify JSONL directly\n    const issue = { id: 'i-test1', title: 'Test', updated_at: new Date().toISOString() };\n    fs.writeFileSync(issuesJsonlPath, JSON.stringify(issue));\n\n    await waitFor(() => events.length > 0);\n\n    expect(events[0]).toMatchObject({\n      entityType: 'issue',\n      entityId: 'i-test1',\n      action: 'updated',\n      source: 'jsonl',\n      baseDir,\n    });\n    expect(events[0].entity).toBeDefined();\n  });\n\n  it('should emit events even when DB already synced', async () => {\n    const events: EntitySyncEvent[] = [];\n\n    // Update DB first (simulating CLI update)\n    updateIssue(db, 'i-test1', { status: 'closed' });\n    exportToJSONL(db, { outputDir: baseDir });\n\n    const watcher = startWatcher({\n      db,\n      baseDir,\n      onEntitySync: (event) => events.push(event),\n    });\n\n    // Touch JSONL file (no actual change, DB already synced)\n    const content = fs.readFileSync(issuesJsonlPath, 'utf8');\n    fs.writeFileSync(issuesJsonlPath, content);\n\n    // Should still emit event!\n    await waitFor(() => events.length > 0);\n    expect(events[0].entityId).toBe('i-test1');\n  });\n});\n```\n\n**Server Watcher Tests** (`server/tests/integration/watcher-broadcasts.test.ts`):\n\n```typescript\ndescribe('Server watcher with typed callbacks', () => {\n  it('should broadcast via onEntitySync callback', async () => {\n    const broadcasts: any[] = [];\n    vi.spyOn(websocketModule, 'broadcastIssueUpdate')\n      .mockImplementation((...args) => broadcasts.push(args));\n\n    const projectManager = new ProjectManager(registry, { watchEnabled: true });\n    const result = await projectManager.openProject(testProjectPath);\n    const projectId = result.ok ? result.value.id : '';\n\n    // CLI updates via MCP\n    updateIssue(db, 'ISSUE-143', { status: 'closed' });\n    exportToJSONL(db, { outputDir: baseDir });\n\n    await waitFor(() => broadcasts.length > 0);\n\n    expect(broadcasts[0][0]).toBe(projectId);\n    expect(broadcasts[0][1]).toBe('ISSUE-143');\n    expect(broadcasts[0][2]).toBe('updated');\n    expect(broadcasts[0][3].status).toBe('closed');\n  });\n});\n```\n\n### Multi-Project Tests\n\n```typescript\ndescribe('Multi-project scenarios', () => {\n  it('should broadcast to correct project with same entity ID', async () => {\n    const project1 = await projectManager.openProject('/path/to/project1');\n    const project2 = await projectManager.openProject('/path/to/project2');\n\n    const broadcasts: any[] = [];\n    vi.spyOn(websocketModule, 'broadcastIssueUpdate')\n      .mockImplementation((...args) => broadcasts.push(args));\n\n    // Update ISSUE-143 in project1 only\n    updateIssue(project1.value.db, 'ISSUE-143', { status: 'closed' });\n    \n    // Should only broadcast to project1\n    expect(broadcasts).toHaveLength(1);\n    expect(broadcasts[0][0]).toBe(project1.value.id);\n  });\n\n  it('should validate baseDir matches watcher baseDir', async () => {\n    const warnings: string[] = [];\n    const warn = console.warn;\n    console.warn = (msg: string) => warnings.push(msg);\n\n    try {\n      const watcher = startServerWatcher({\n        db,\n        baseDir: '/correct/path/.sudocode',\n        onFileChange: (info) => {\n          // Handler receives event with wrong baseDir\n        },\n      });\n\n      // Emit event with mismatched baseDir\n      watcher.emit('entitySync', {\n        baseDir: '/wrong/path/.sudocode',\n        entityId: 'i-test',\n        // ...\n      });\n\n      expect(warnings.some(w => w.includes('baseDir mismatch'))).toBe(true);\n    } finally {\n      console.warn = warn;\n    }\n  });\n});\n```\n\n## Success Metrics\n\n### Reliability\n- ✅ Zero broadcast failures due to log format changes\n- ✅ 100% type safety coverage for event data\n- ✅ All entity updates reflected in UI within 2 seconds\n- ✅ CLI/MCP updates trigger UI broadcasts\n\n### Performance  \n- ✅ 50% reduction in broadcast latency (skip DB query with `entity` field)\n- ✅ 30% reduction in watcher CPU usage (no regex)\n- ✅ No performance regression on any path\n\n### Code Quality\n- ✅ Remove 100+ lines of regex parsing code\n- ✅ Increase test coverage by 20%\n- ✅ Zero TypeScript `any` types in event handling\n\n## Open Questions\n\n### 1. Should entity be included in event? ✅ RESOLVED\n**Decision**: C) Optional, with strong recommendation to include.\n\n**Rationale**: \n- Avoids server DB query (performance)\n- But allows flexibility if entity unavailable\n\n### 2. Should callbacks be async? ✅ RESOLVED\n**Decision**: B) Allow async.\n\n**Rationale**: Broadcasting may involve network I/O.\n\n### 3. Error handling strategy? ✅ RESOLVED\n**Decision**: B) Pass to `onError` callback.\n\n**Rationale**: Non-blocking, better for event-driven systems.\n\n### 4. Should we version the event format? ✅ RESOLVED\n**Decision**: A) Add version field.\n\n**Rationale**: Future-proofing for breaking changes.\n\n```typescript\nexport interface EntitySyncEvent {\n  version: 1;  // ✅ Add this\n  // ... rest of fields\n}\n```\n\n### 5. How should server resolve projectId from baseDir? ✅ RESOLVED\n**Decision**: A) Use closure as primary, B) as fallback.\n\n**Rationale**: Matches current architecture, no changes needed.\n\n## Related Work\n\n### Related Specs\n- [[s-5d2c]] Multi-Project Server Architecture\n- [[SPEC-014]] Execution Logs Design\n\n### Related Issues\n- ISSUE-143: Improve worktree recovery (discovered this bug)\n- Previous regex fix issues\n\n### References\n- `docs/watcher-refactor-design.md`\n- `docs/watcher-flow-comparison.md`\n","priority":2,"archived":0,"archived_at":null,"created_at":"2025-11-24 20:52:04","updated_at":"2025-11-24 21:29:41","parent_id":null,"parent_uuid":null,"relationships":[],"tags":[]}
{"id":"s-3v8s","uuid":"cc8a8ba0-1d0f-49a7-a993-b333b02713d0","title":"Context Injection System for Agent Prompts","file_path":"specs/s-5ti5_context_injection_system_for_agent_prompts.md","content":"# Context Injection System for Agent Prompts\n\n## Overview\n\nAdd a comprehensive context injection system to the AgentConfigPanel that allows users to mention files, specs, and issues in their prompts using `@` mentions. The system provides autocomplete search, validation, and automatic content injection for spec/issue references while letting the agent handle file fetching.\n\n## Goals\n\n1. Enable users to mention files using `@` autocomplete with file path insertion\n2. Enable users to mention specs and issues using `@` autocomplete with content injection\n3. Support multi-project environments with project-specific file search\n4. Provide a swappable search strategy interface (starting with git ls-files)\n5. Maintain backwards compatibility with existing execution API\n6. Deliver excellent UX with keyboard navigation and visual feedback\n\n## Non-Goals\n\n- Automatic file content fetching (agent handles this)\n- Complex parsing of unstructured text (only process @mentions)\n- Real-time file watching/indexing (static search is sufficient)\n- Binary file preview/handling\n\n## Architecture\n\n### High-Level Flow\n\n```\nUser types @ in prompt\n  ↓\nContext search activated (files + specs + issues)\n  ↓\nDropdown shows results grouped by type\n  ↓\nUser selects result\n  ↓\nFor files: Insert path string\nFor specs/issues: Insert [[entity-id]] reference\n  ↓\nOn submit: Process prompt\n  ↓\nResolve [[entity-id]] references → inject content\nKeep file paths as-is\n  ↓\nSend final prompt to execution API\n```\n\n### Data Model\n\n```typescript\n// Context search result (unified)\ninterface ContextSearchResult {\n  type: 'file' | 'spec' | 'issue'\n  \n  // For files\n  filePath?: string\n  fileName?: string\n  \n  // For specs/issues\n  entityId?: string      // 's-abc123' or 'i-xyz789'\n  title?: string\n  \n  // Display/insertion\n  displayText: string    // Shown in dropdown\n  secondaryText?: string // Additional context (path/description)\n  insertText: string     // What gets inserted into prompt\n  matchScore?: number    // For ranking results\n}\n\n// Prompt with references to resolve\ninterface PromptWithContext {\n  rawPrompt: string           // User's input with [[refs]]\n  resolvedPrompt: string      // After injecting spec/issue content\n  references: {\n    specs: string[]           // ['s-abc123', ...]\n    issues: string[]          // ['i-xyz789', ...]\n    files: string[]           // ['src/file.ts', ...]\n  }\n}\n```\n\n### Component Architecture\n\n```\nAgentConfigPanel\n  ├─ ContextSearchTextarea (new)\n  │   ├─ Textarea (base)\n  │   ├─ ContextSearchDropdown (new)\n  │   │   ├─ FileResultItem\n  │   │   ├─ SpecResultItem\n  │   │   └─ IssueResultItem\n  │   └─ useContextSearch hook (new)\n  └─ (existing config controls)\n```\n\n## Implementation Requirements\n\n### 1. Frontend Components\n\n#### 1.1 ContextSearchTextarea Component\n\n**Location**: `frontend/src/components/ui/context-search-textarea.tsx`\n\n**Responsibilities**:\n- Detect `@` symbol in text and extract query after it\n- Trigger search with debouncing (300ms)\n- Position dropdown near cursor\n- Handle keyboard navigation (Arrow Up/Down, Enter, Escape)\n- Insert selected result at cursor position\n- Maintain textarea auto-resize behavior\n- Support Cmd/Ctrl+Enter for submit passthrough\n\n**Key Features**:\n```typescript\ninterface ContextSearchTextareaProps {\n  value: string\n  onChange: (value: string) => void\n  onKeyDown?: (e: React.KeyboardEvent) => void\n  placeholder?: string\n  disabled?: boolean\n  className?: string\n  projectId: string  // For project-scoped search\n}\n\n// Internal state\n{\n  isSearching: boolean\n  results: ContextSearchResult[]\n  selectedIndex: number\n  dropdownPosition: { top: number; left: number }\n  showDropdown: boolean\n  currentQuery: string\n}\n```\n\n**Interaction Flow**:\n1. User types `@` → Show dropdown with empty state\n2. User types `@sr` → Search for \"sr\" across files/specs/issues\n3. Arrow keys navigate results\n4. Enter selects highlighted result\n5. Escape closes dropdown\n6. Click outside closes dropdown\n\n**Edge Cases**:\n- Multiple `@` in prompt → Use last one before cursor\n- `@` followed by space → Don't trigger search\n- Dropdown at viewport edge → Flip position\n- Empty results → Show \"No results\" message\n- Network error → Show error state with retry\n\n#### 1.2 ContextSearchDropdown Component\n\n**Location**: `frontend/src/components/ui/context-search-dropdown.tsx`\n\n**Responsibilities**:\n- Render grouped results (Files | Specs | Issues)\n- Highlight selected item\n- Show loading state\n- Handle click selection\n- Display icons/badges for result types\n\n**Structure**:\n```\n┌─────────────────────────────────┐\n│ Files (3)                       │\n├─────────────────────────────────┤\n│ 📄 AgentConfigPanel.tsx         │\n│    src/components/executions/   │\n│ 📄 execution.ts                 │\n│    src/types/                   │\n├─────────────────────────────────┤\n│ Specs (2)                       │\n├─────────────────────────────────┤\n│ 📋 Authentication System        │\n│    s-abc123                     │\n├─────────────────────────────────┤\n│ Issues (1)                      │\n├─────────────────────────────────┤\n│ 🎯 Add OAuth login              │\n│    i-xyz789                     │\n└─────────────────────────────────┘\n```\n\n**Grouping Logic**:\n- Show section headers only if results exist for that type\n- Preserve order within groups (by match score)\n- Limit: 5 files + 5 specs + 5 issues = 15 total results\n\n#### 1.3 useContextSearch Hook\n\n**Location**: `frontend/src/hooks/useContextSearch.ts`\n\n**Responsibilities**:\n- Debounced search across multiple sources\n- Merge and rank results\n- Handle loading/error states\n- Cancel in-flight requests\n\n```typescript\ninterface UseContextSearchParams {\n  query: string\n  projectId: string\n  enabled: boolean\n}\n\ninterface UseContextSearchResult {\n  results: ContextSearchResult[]\n  isLoading: boolean\n  error: Error | null\n  refetch: () => void\n}\n\nfunction useContextSearch(params: UseContextSearchParams): UseContextSearchResult {\n  // Implementation:\n  // 1. Debounce query (300ms)\n  // 2. Parallel search: files + specs + issues\n  // 3. Merge results with ranking\n  // 4. Return sorted, limited results\n}\n```\n\n**Ranking Algorithm**:\n```typescript\nfunction rankResults(results: ContextSearchResult[]): ContextSearchResult[] {\n  // Priority:\n  // 1. Exact match (name/title)\n  // 2. Prefix match\n  // 3. Word boundary match\n  // 4. Contains match\n  // 5. Within each tier, prioritize by:\n  //    - Recent usage (track in localStorage)\n  //    - Shorter paths/titles\n  //    - Alphabetical\n}\n```\n\n### 2. Backend APIs\n\n#### 2.1 File Search API\n\n**Endpoint**: `GET /api/files/search`\n\n**Query Params**:\n- `q`: Search query (required)\n- `limit`: Max results (default 20)\n- `includeDirectories`: Include dirs (default false)\n\n**Response**:\n```typescript\n{\n  success: true,\n  data: {\n    results: [\n      {\n        path: \"src/components/AgentConfigPanel.tsx\",\n        name: \"AgentConfigPanel.tsx\",\n        isFile: true,\n        matchType: \"prefix\"\n      }\n    ]\n  }\n}\n```\n\n**Implementation**:\n\n**Location**: `server/src/routes/files.ts`\n\n```typescript\nrouter.get('/files/search', async (req: Request, res: Response) => {\n  const { q: query, limit = 20, includeDirectories = false } = req.query\n  const projectId = req.headers['x-project-id']\n  \n  // Get project workspace path\n  const project = getProject(projectId)\n  const workspacePath = project.workspacePath\n  \n  // Use strategy to search files\n  const searchStrategy = getFileSearchStrategy(project)\n  const results = await searchStrategy.search(workspacePath, {\n    query: query as string,\n    limit: Number(limit),\n    includeDirectories: Boolean(includeDirectories)\n  })\n  \n  res.json({ success: true, data: { results } })\n})\n```\n\n#### 2.2 File Search Strategy Interface\n\n**Location**: `server/src/services/file-search/strategy.ts`\n\n```typescript\nexport interface FileSearchStrategy {\n  /**\n   * Search for files matching query in workspace\n   */\n  search(workspacePath: string, options: FileSearchOptions): Promise<FileSearchResult[]>\n  \n  /**\n   * Get strategy name for debugging/metrics\n   */\n  getName(): string\n}\n\nexport interface FileSearchOptions {\n  query: string\n  limit: number\n  includeDirectories: boolean\n  excludePatterns?: string[]  // Additional exclusions\n}\n\nexport interface FileSearchResult {\n  path: string           // Relative to workspace root\n  name: string           // Filename only\n  isFile: boolean        // true for files, false for dirs\n  matchType?: 'exact' | 'prefix' | 'contains'\n}\n```\n\n**Strategy Registry**:\n\n**Location**: `server/src/services/file-search/registry.ts`\n\n```typescript\ntype StrategyType = 'git-ls-files' | 'fast-glob' | 'indexed'\n\nclass FileSearchStrategyRegistry {\n  private strategies: Map<StrategyType, FileSearchStrategy>\n  private defaultStrategy: StrategyType = 'git-ls-files'\n  \n  register(type: StrategyType, strategy: FileSearchStrategy): void\n  get(type?: StrategyType): FileSearchStrategy\n  setDefault(type: StrategyType): void\n}\n\nexport const fileSearchRegistry = new FileSearchStrategyRegistry()\n```\n\n#### 2.3 Git Ls-Files Strategy (Initial Implementation)\n\n**Location**: `server/src/services/file-search/git-ls-files-strategy.ts`\n\n```typescript\nexport class GitLsFilesStrategy implements FileSearchStrategy {\n  getName(): string {\n    return 'git-ls-files'\n  }\n  \n  async search(\n    workspacePath: string, \n    options: FileSearchOptions\n  ): Promise<FileSearchResult[]> {\n    // 1. Run: git ls-files in workspacePath\n    // 2. Filter by query (fuzzy match)\n    // 3. Rank by match type\n    // 4. Apply limit\n    // 5. Return results\n    \n    const { stdout } = await execAsync('git ls-files', { cwd: workspacePath })\n    const allFiles = stdout.split('\\n').filter(Boolean)\n    \n    // Filter and rank\n    const matches = allFiles\n      .map(path => this.matchFile(path, options.query))\n      .filter(result => result !== null)\n      .sort((a, b) => this.compareMatchQuality(a, b))\n      .slice(0, options.limit)\n    \n    return matches\n  }\n  \n  private matchFile(path: string, query: string): FileSearchResult | null {\n    const name = path.split('/').pop()!\n    const lowerQuery = query.toLowerCase()\n    const lowerPath = path.toLowerCase()\n    const lowerName = name.toLowerCase()\n    \n    // Exact match (name)\n    if (lowerName === lowerQuery) {\n      return { path, name, isFile: true, matchType: 'exact' }\n    }\n    \n    // Prefix match (name starts with query)\n    if (lowerName.startsWith(lowerQuery)) {\n      return { path, name, isFile: true, matchType: 'prefix' }\n    }\n    \n    // Prefix match (path starts with query)\n    if (lowerPath.startsWith(lowerQuery)) {\n      return { path, name, isFile: true, matchType: 'prefix' }\n    }\n    \n    // Contains match (anywhere in path)\n    if (lowerPath.includes(lowerQuery)) {\n      return { path, name, isFile: true, matchType: 'contains' }\n    }\n    \n    return null\n  }\n  \n  private compareMatchQuality(a: FileSearchResult, b: FileSearchResult): number {\n    const matchOrder = { exact: 0, prefix: 1, contains: 2 }\n    const aOrder = matchOrder[a.matchType!]\n    const bOrder = matchOrder[b.matchType!]\n    \n    if (aOrder !== bOrder) return aOrder - bOrder\n    \n    // Same match type → shorter path wins\n    if (a.path.length !== b.path.length) {\n      return a.path.length - b.path.length\n    }\n    \n    // Same length → alphabetical\n    return a.path.localeCompare(b.path)\n  }\n}\n\n// Register as default\nfileSearchRegistry.register('git-ls-files', new GitLsFilesStrategy())\n```\n\n**Performance Considerations**:\n- Cache `git ls-files` output for 5 seconds (per project)\n- Invalidate cache on file system events (future enhancement)\n- For large repos (>10k files), consider indexing strategy\n\n#### 2.4 Context Resolution API\n\n**Endpoint**: `POST /api/prompts/resolve`\n\n**Purpose**: Resolve [[entity-id]] references in prompt before execution\n\n**Request**:\n```typescript\n{\n  prompt: \"Implement [[s-abc123]] and fix [[i-xyz789]]\",\n  projectId: \"project-uuid\"\n}\n```\n\n**Response**:\n```typescript\n{\n  success: true,\n  data: {\n    resolvedPrompt: \"Implement <spec content> and fix <issue content>\",\n    references: {\n      specs: [\"s-abc123\"],\n      issues: [\"i-xyz789\"],\n      files: []\n    },\n    errors: []  // Array of unresolvable references\n  }\n}\n```\n\n**Implementation**:\n\n**Location**: `server/src/routes/prompts.ts`\n\n```typescript\nrouter.post('/prompts/resolve', async (req: Request, res: Response) => {\n  const { prompt, projectId } = req.body\n  \n  const result = await promptResolver.resolve(prompt, projectId)\n  \n  res.json({ success: true, data: result })\n})\n```\n\n**Prompt Resolver Service**:\n\n**Location**: `server/src/services/prompt-resolver.ts`\n\n```typescript\nexport class PromptResolver {\n  /**\n   * Resolve all [[entity-id]] references in prompt\n   */\n  async resolve(prompt: string, projectId: string): Promise<PromptResolutionResult> {\n    // 1. Extract all [[entity-id]] patterns\n    const references = this.extractReferences(prompt)\n    \n    // 2. Fetch content for specs and issues\n    const project = getProject(projectId)\n    const specContents = await this.fetchSpecs(references.specs, project)\n    const issueContents = await this.fetchIssues(references.issues, project)\n    \n    // 3. Replace [[entity-id]] with content\n    let resolvedPrompt = prompt\n    const errors: string[] = []\n    \n    for (const specId of references.specs) {\n      const content = specContents.get(specId)\n      if (content) {\n        resolvedPrompt = resolvedPrompt.replace(\n          new RegExp(`\\\\[\\\\[${specId}\\\\]\\\\]`, 'g'),\n          this.formatSpecContent(content)\n        )\n      } else {\n        errors.push(`Spec not found: ${specId}`)\n      }\n    }\n    \n    for (const issueId of references.issues) {\n      const content = issueContents.get(issueId)\n      if (content) {\n        resolvedPrompt = resolvedPrompt.replace(\n          new RegExp(`\\\\[\\\\[${issueId}\\\\]\\\\]`, 'g'),\n          this.formatIssueContent(content)\n        )\n      } else {\n        errors.push(`Issue not found: ${issueId}`)\n      }\n    }\n    \n    return {\n      resolvedPrompt,\n      references,\n      errors\n    }\n  }\n  \n  private extractReferences(prompt: string): {\n    specs: string[]\n    issues: string[]\n    files: string[]\n  } {\n    // Regex: [[s-xxxxx]] or [[i-xxxxx]]\n    const specPattern = /\\[\\[(s-[a-z0-9]+)\\]\\]/g\n    const issuePattern = /\\[\\[(i-[a-z0-9]+)\\]\\]/g\n    const filePattern = /@([^\\s]+)/g\n    \n    const specs = [...prompt.matchAll(specPattern)].map(m => m[1])\n    const issues = [...prompt.matchAll(issuePattern)].map(m => m[1])\n    const files = [...prompt.matchAll(filePattern)].map(m => m[1])\n    \n    return {\n      specs: [...new Set(specs)],  // Deduplicate\n      issues: [...new Set(issues)],\n      files: [...new Set(files)]\n    }\n  }\n  \n  private async fetchSpecs(\n    specIds: string[], \n    project: Project\n  ): Promise<Map<string, Spec>> {\n    const specs = new Map<string, Spec>()\n    \n    for (const specId of specIds) {\n      try {\n        const spec = project.specsService.getSpec(specId)\n        if (spec) specs.set(specId, spec)\n      } catch (error) {\n        console.warn(`Failed to fetch spec ${specId}:`, error)\n      }\n    }\n    \n    return specs\n  }\n  \n  private async fetchIssues(\n    issueIds: string[], \n    project: Project\n  ): Promise<Map<string, Issue>> {\n    const issues = new Map<string, Issue>()\n    \n    for (const issueId of issueIds) {\n      try {\n        const issue = project.issuesService.getIssue(issueId)\n        if (issue) issues.set(issueId, issue)\n      } catch (error) {\n        console.warn(`Failed to fetch issue ${issueId}:`, error)\n      }\n    }\n    \n    return issues\n  }\n  \n  private formatSpecContent(spec: Spec): string {\n    return `\n## Spec: ${spec.title} (${spec.id})\n\n${spec.description}\n\n${spec.tags?.length ? `Tags: ${spec.tags.join(', ')}` : ''}\n`.trim()\n  }\n  \n  private formatIssueContent(issue: Issue): string {\n    return `\n## Issue: ${issue.title} (${issue.id})\n\n${issue.description}\n\nStatus: ${issue.status}\n${issue.tags?.length ? `Tags: ${issue.tags.join(', ')}` : ''}\n`.trim()\n  }\n}\n\nexport const promptResolver = new PromptResolver()\n```\n\n### 3. Integration Points\n\n#### 3.1 AgentConfigPanel Integration\n\n**Location**: `frontend/src/components/executions/AgentConfigPanel.tsx`\n\n**Changes**:\n\n```typescript\n// Replace line 481-498 (current Textarea)\n<ContextSearchTextarea\n  ref={textareaRef}\n  value={prompt}\n  onChange={(value) => setPrompt(value)}\n  onKeyDown={handleKeyDown}\n  placeholder={\n    promptPlaceholder ||\n    (loading\n      ? 'Loading prompt...'\n      : isFollowUp\n        ? 'Enter feedback to continue the execution... Use @ to mention files, specs, or issues.'\n        : 'Enter prompt for the agent... Use @ to mention files, specs, or issues.')\n  }\n  disabled={loading}\n  className=\"max-h-[300px] min-h-0 resize-none overflow-y-auto border-none bg-muted/80 py-2 text-sm shadow-none transition-[height] duration-100 focus-visible:ring-0 focus-visible:ring-offset-0\"\n  style={{ height: 'auto' }}\n  projectId={/* Get from context or prop */}\n/>\n```\n\n#### 3.2 Execution Creation Flow\n\n**Current Flow**:\n```\nhandleStart() \n  → onStart(config, prompt, agentType)\n    → executionsApi.create(issueId, { config, prompt, agentType })\n```\n\n**New Flow**:\n```\nhandleStart()\n  → Resolve prompt references (if any)\n    → POST /api/prompts/resolve { prompt, projectId }\n      → Get resolvedPrompt\n  → onStart(config, resolvedPrompt, agentType)\n    → executionsApi.create(issueId, { config, prompt: resolvedPrompt, agentType })\n```\n\n**Implementation**:\n\n```typescript\nconst handleStart = async () => {\n  try {\n    // Resolve references before creating execution\n    let finalPrompt = prompt\n    \n    // Check if prompt contains references\n    if (prompt.includes('[[')) {\n      const resolved = await promptsApi.resolve({\n        prompt,\n        projectId: currentProjectId!\n      })\n      \n      if (resolved.errors.length > 0) {\n        // Show error toast\n        toast.error(`Could not resolve: ${resolved.errors.join(', ')}`)\n        return\n      }\n      \n      finalPrompt = resolved.resolvedPrompt\n    }\n    \n    // Save config to localStorage\n    if (isValidExecutionConfig(config)) {\n      try {\n        localStorage.setItem(LAST_EXECUTION_CONFIG_KEY, JSON.stringify(config))\n        localStorage.setItem(LAST_AGENT_TYPE_KEY, selectedAgentType)\n      } catch (error) {\n        console.warn('Failed to save execution config to localStorage:', error)\n      }\n    }\n    \n    onStart(config, finalPrompt, selectedAgentType)\n    setPrompt('') // Clear the prompt after submission\n  } catch (error) {\n    console.error('Failed to resolve prompt:', error)\n    toast.error('Failed to prepare prompt. Please try again.')\n  }\n}\n```\n\n### 4. Multi-Project Support\n\n#### 4.1 Project Context\n\nAll search operations are scoped to the current project:\n\n```typescript\n// Frontend: Get projectId from context\nimport { useProject } from '@/contexts/ProjectContext'\n\nfunction AgentConfigPanel() {\n  const { currentProject } = useProject()\n  \n  return (\n    <ContextSearchTextarea\n      projectId={currentProject.id}\n      // ...\n    />\n  )\n}\n```\n\n#### 4.2 Backend Project Resolution\n\n```typescript\n// All API endpoints use X-Project-ID header\nconst projectId = req.headers['x-project-id']\nconst project = getProject(projectId)\n\n// File search is scoped to project workspace\nconst workspacePath = project.workspacePath\nconst results = await fileSearchStrategy.search(workspacePath, options)\n```\n\n#### 4.3 Workspace Path Handling\n\nEach project has a configured workspace path:\n\n```typescript\ninterface Project {\n  id: string\n  workspacePath: string  // Absolute path to project root\n  // ...\n}\n\n// File search operates within this workspace\n// All returned paths are relative to workspacePath\n```\n\n### 5. API Updates\n\n#### 5.1 New Routes\n\n**File**: `server/src/routes/files.ts`\n```typescript\nrouter.get('/files/search', handleFileSearch)\n```\n\n**File**: `server/src/routes/prompts.ts`\n```typescript\nrouter.post('/prompts/resolve', handlePromptResolve)\n```\n\n**File**: `server/src/index.ts`\n```typescript\nimport { createFilesRouter } from './routes/files.js'\nimport { createPromptsRouter } from './routes/prompts.js'\n\napp.use('/api', requireProject(), createFilesRouter())\napp.use('/api', requireProject(), createPromptsRouter())\n```\n\n#### 5.2 Frontend API Client\n\n**File**: `frontend/src/lib/api.ts`\n\n```typescript\nexport const filesApi = {\n  search: (query: string, options?: { limit?: number }) =>\n    get<{ results: FileSearchResult[] }>(\n      `/files/search?q=${encodeURIComponent(query)}&limit=${options?.limit || 20}`\n    ).then(res => res.results),\n}\n\nexport const promptsApi = {\n  resolve: (request: { prompt: string; projectId: string }) =>\n    post<PromptResolutionResult>('/prompts/resolve', request),\n}\n```\n\n### 6. Testing Strategy\n\n#### 6.1 Unit Tests\n\n**Frontend**:\n- `ContextSearchTextarea.test.tsx`\n  - @ detection and query extraction\n  - Keyboard navigation\n  - Result insertion at cursor\n  - Edge cases (multiple @, at viewport edge)\n  \n- `useContextSearch.test.ts`\n  - Debouncing behavior\n  - Result merging and ranking\n  - Error handling\n  - Request cancellation\n\n**Backend**:\n- `GitLsFilesStrategy.test.ts`\n  - File matching logic\n  - Ranking algorithm\n  - Edge cases (empty repo, no git)\n  \n- `PromptResolver.test.ts`\n  - Reference extraction\n  - Content injection\n  - Error handling (missing refs)\n  - Multiple references\n\n#### 6.2 Integration Tests\n\n- End-to-end prompt resolution flow\n- Multi-project file search isolation\n- Execution creation with resolved prompt\n\n#### 6.3 Manual Test Cases\n\n1. **Basic file mention**\n   - Type `@src` → See file results\n   - Select file → Path inserted\n   - Submit → Execution created\n\n2. **Spec mention**\n   - Type `@Auth` → See specs with \"Auth\" in title\n   - Select spec → `[[s-abc123]]` inserted\n   - Submit → Spec content injected into prompt\n\n3. **Issue mention**\n   - Type `@Add` → See issues with \"Add\" in title\n   - Select issue → `[[i-xyz789]]` inserted\n   - Submit → Issue content injected into prompt\n\n4. **Mixed mentions**\n   - Type: `Fix [[i-xyz]] in @src/auth.ts per [[s-abc]]`\n   - Submit → Both spec and issue content injected, file path kept\n\n5. **Multi-project**\n   - Switch projects → Search returns different files\n   - References resolve to correct project's specs/issues\n\n6. **Error cases**\n   - Invalid reference → Error message shown\n   - Network error → Retry option\n   - Empty search → \"No results\" message\n\n### 7. Future Enhancements\n\n#### Phase 2: Advanced Search\n- Fuzzy matching with fuse.js\n- Search result caching\n- Recent mentions tracking\n- Keyboard shortcuts (Cmd+K to open search)\n\n#### Phase 3: Rich Previews\n- Hover over mention → Show preview popup\n- File preview with syntax highlighting\n- Spec/issue preview with metadata\n- Click to open in editor\n\n#### Phase 4: Smart Context\n- Auto-suggest related specs for issue\n- Auto-suggest related files for spec\n- Context relevance scoring\n- Learn from user patterns\n\n#### Phase 5: Performance\n- Indexed file search strategy\n- Incremental file watching\n- Search result streaming\n- Virtual scrolling for large result sets\n\n## Success Criteria\n\n1. **Functionality**\n   - ✅ Users can mention files with @ autocomplete\n   - ✅ Users can mention specs with @ autocomplete\n   - ✅ Users can mention issues with @ autocomplete\n   - ✅ Spec/issue content is injected into prompt\n   - ✅ File paths are passed to agent as-is\n   - ✅ Multi-project support works correctly\n\n2. **Performance**\n   - ✅ Search results appear within 500ms\n   - ✅ No UI blocking during search\n   - ✅ Handles repos with 10k+ files\n\n3. **UX**\n   - ✅ Keyboard navigation feels natural\n   - ✅ Dropdown positioning is correct\n   - ✅ Error states are clear\n   - ✅ Loading states are visible\n\n4. **Reliability**\n   - ✅ All tests passing\n   - ✅ No crashes on edge cases\n   - ✅ Graceful degradation on errors\n\n## Open Questions\n\n1. Should we support multiline in dropdown (show wrapped text)?\n   - **Decision Needed**: Truncate with ellipsis vs wrap\n\n2. Should we cache git ls-files output across requests?\n   - **Proposal**: Yes, 5 second TTL per project\n\n3. How to handle very large spec/issue content?\n   - **Proposal**: Truncate at 5000 chars with warning\n\n4. Should @ mentions be syntax highlighted in the textarea?\n   - **Proposal**: Yes, subtle background color for [[refs]]\n\n5. Should we support range selection for files (e.g., @file.ts:10-20)?\n   - **Proposal**: Phase 2 enhancement\n\n## Dependencies\n\n- Frontend: React hooks, shadcn/ui components\n- Backend: git CLI, existing specs/issues services\n- Testing: Vitest, React Testing Library\n\n## Timeline Estimate\n\n- Week 1: Backend file search + strategy interface\n- Week 2: Frontend ContextSearchTextarea component\n- Week 3: Prompt resolver + integration\n- Week 4: Testing + polish\n- Week 5: Spec/issue search integration\n- Week 6: Bug fixes + documentation\n\n## References\n\n- Vibe-kanban FileSearchTextarea: `/references/vibe-kanban/frontend/src/components/ui/file-search-textarea.tsx`\n- Current AgentConfigPanel: `/frontend/src/components/executions/AgentConfigPanel.tsx`\n- Execution API: `/server/src/routes/executions.ts`","priority":1,"archived":0,"archived_at":null,"created_at":"2025-11-26 23:00:25","updated_at":"2025-11-26 23:00:25","parent_id":null,"parent_uuid":null,"relationships":[],"tags":["agent-prompts","context-injection","feature","ui"]}
{"id":"s-1yug","uuid":"cc2b5928-e0bb-474c-91c5-00d94c3224de","title":"Git Diff Viewer for Agent Trajectory UI","file_path":"specs/s-1yug_git_diff_viewer_for_agent_trajectory_ui.md","content":"# Git Diff Viewer for Agent Trajectory UI\n\n## Problem Statement\n\nThe agent execution trajectory monitor UI currently displays tool calls (Edit, Write) in a compact text format. Users cannot easily visualize what code changes were made during execution, making it difficult to:\n- Understand what the agent modified\n- Review code changes at a glance\n- Spot potential issues in agent-generated code\n- Learn from the agent's editing patterns\n\n## Requirements\n\n### Functional Requirements\n\n1. **Diff Viewing for Edit Tool Calls**\n   - Display inline diffs showing code changes\n   - Parse Edit tool args format: `{path, changes: [{type, diff}]}`\n   - Show syntax-highlighted before/after code\n   - Render diff format (lines starting with `-` for deletions, `+` for additions)\n\n2. **Diff Viewing for Write Tool Calls**\n   - Display new file content\n   - Show all content as additions (green highlighting)\n   - Include syntax highlighting based on file extension\n\n3. **UI Integration**\n   - Inline expansion below tool calls in trajectory\n   - Follow terminal-style aesthetic of ClaudeCodeTrajectory\n   - Use `∟` continuation character for consistency\n   - \"Show diff\" / \"Hide diff\" toggle buttons\n\n4. **Display Controls**\n   - Default collapsed view showing first 10-15 lines\n   - \"Expand full diff\" button for files exceeding line limit\n   - Graceful degradation for large files (500+ lines)\n\n5. **Syntax Highlighting**\n   - Detect language from file extension\n   - Support common languages: TypeScript, JavaScript, Python, JSON, YAML, CSS, HTML, etc.\n   - Use existing highlight.js infrastructure\n   - Fallback to plaintext for unknown extensions\n\n6. **Theme Support**\n   - Match light/dark theme from ThemeContext\n   - Terminal-friendly colors (subtle backgrounds for additions/deletions)\n   - Automatic theme switching\n\n### Non-Functional Requirements\n\n1. **Performance**\n   - Lazy render: only display diff when expanded\n   - Disable syntax highlighting for very large files (500+ lines)\n   - No performance regression with multiple diffs in trajectory\n\n2. **Reusability**\n   - Generic DiffViewer component for future agent types\n   - Adapter pattern for different tool arg formats\n\n3. **Error Handling**\n   - Graceful fallback for malformed JSON args\n   - Error messages for missing file paths\n   - Don't break trajectory rendering on diff errors\n\n4. **Accessibility**\n   - Keyboard navigation support\n   - Screen reader friendly\n\n## Technical Constraints\n\n1. Use already-installed `@git-diff-view/react` library (v0.0.22)\n2. Integrate with existing ClaudeCodeTrajectory component\n3. Follow existing terminal-style UI patterns\n4. Use existing theming infrastructure (ThemeContext)\n5. Maintain bundle size (library adds ~50KB)\n\n## Example Tool Args Formats\n\n### Edit Tool\n```json\n{\n  \"path\": \"frontend/src/components/issues/IssuePanel.tsx\",\n  \"changes\": [{\n    \"type\": \"edit\",\n    \"diff\": \"- import { useState, useEffect, useRef } from 'react'\\n+ import { useState, useEffect, useRef, useMemo } from 'react'\"\n  }]\n}\n```\n\n### Write Tool\n```json\n{\n  \"file_path\": \"src/newFile.ts\",\n  \"content\": \"export const foo = 'bar'\\n\"\n}\n```\n\n## Visual Design\n\nTerminal-style rendering:\n```\n⏺ Edit (frontend/src/components/Example.tsx)          0.45s\n  ∟ File edited successfully\n  ∟ > Show changes\n     ┌────────────────────────────────────┐\n     │ frontend/src/components/Example.tsx│\n     │  1 | import { useState } from 'react'│\n     │  2 | -const value = 10;              │ (red bg)\n     │  3 | +const value = 20;              │ (green bg)\n     │  4 | +console.log(value);            │ (green bg)\n     │  5 | return <div>{value}</div>       │\n     └────────────────────────────────────┘\n     > Expand full diff (45 lines)\n     > Hide changes\n```\n\n## Success Criteria\n\n- [ ] Diffs display inline for Edit and Write tool calls\n- [ ] Syntax highlighting works for TS, JS, Python, JSON\n- [ ] Theme switching works correctly\n- [ ] Expand/collapse works for diffs >15 lines\n- [ ] Error handling gracefully degrades\n- [ ] Terminal aesthetic matches ClaudeCodeTrajectory\n- [ ] No performance regression\n- [ ] Generic component reusable for other agents\n\n## Out of Scope\n\n- Split view mode (unified view only)\n- Inline commenting on diff lines\n- Copy diff to clipboard\n- Download as .patch file\n- Adapter logic for non-Claude agents (future work)","priority":2,"archived":1,"archived_at":"2025-11-27T08:02:10.684Z","created_at":"2025-11-27 02:20:10","updated_at":"2025-11-27 08:02:10","parent_id":null,"parent_uuid":null,"relationships":[],"tags":["diff-viewer","frontend","trajectory","ui"]}
{"id":"s-4mgr","uuid":"8c8bc6ab-41e3-42a9-a63f-c8d170bd7bbc","title":"Worktree Sync: Integrate Agent Execution Changes","file_path":"specs/s-4mgr_worktree_sync_integrate_agent_execution_changes.md","content":"# Worktree Sync: Integrate Agent Execution Changes\n\n## Overview\n\nEnable users to sync changes from agent execution worktrees back to their local working tree. This allows users to review agent-generated code in isolation (worktree) and then selectively integrate those changes into their main development environment.\n\n## Problem Statement\n\nCurrently, agent executions run in isolated git worktrees with their own branches. While this provides excellent isolation during execution, there's no built-in way to:\n\n1. **Preview changes** made by the agent before integrating them\n1. **Detect merge conflicts** between worktree changes and local changes\n1. **Integrate worktree changes** into the local tree in a controlled manner\n1. **Choose integration strategy** (squash all changes vs. preserve individual commits)\n\nUsers must manually use git commands to merge worktree branches, which is error-prone and doesn't handle sudocode-specific concerns (JSONL merge conflicts, isolated database state, etc.).\n\n## Requirements\n\n### Functional Requirements\n\n#### FR1: Conflict Detection\n\n- **FR1.1** Detect file-level merge conflicts between worktree branch and local branch\n- **FR1.2** Detect JSONL merge conflicts in `.sudocode/issues.jsonl` and `.sudocode/specs.jsonl`\n- **FR1.3** Check branch compatibility (worktree and local share compatible base)\n- **FR1.4** Provide detailed conflict report with file paths and conflict types\n\n#### FR2: Sync Preview\n\n- **FR2.1** Show diff between worktree current state and local HEAD (regardless of execution status)\n- **FR2.2** Display list of files changed in worktree\n- **FR2.3** Show commit history from worktree (for preserve-commits mode)\n- **FR2.4** Calculate and display merge base commit\n- **FR2.5** Preview resulting JSONL after merge (with conflict resolution applied)\n- **FR2.6** Include uncommitted JSONL changes in preview\n\n#### FR3: Squash Sync Mode\n\n- **FR3.1** Combine all worktree changes into a single commit\n- **FR3.2** Apply squashed commit to current local branch\n- **FR3.3** Use automatic JSONL merge resolution (existing UUID-based deduplication)\n- **FR3.4** Include uncommitted JSONL changes from worktree in sync\n- **FR3.5** Allow user to provide custom commit message\n- **FR3.6** Default commit message includes execution ID and issue reference\n\n#### FR4: Preserve Commits Sync Mode\n\n- **FR4.1** Cherry-pick all commits from worktree branch to local branch\n- **FR4.2** Preserve commit messages, authors, and timestamps\n- **FR4.3** Stop on first merge conflict and allow user intervention\n- **FR4.4** Use automatic JSONL merge resolution for each commit\n- **FR4.5** Include uncommitted JSONL changes from worktree as final commit\n- **FR4.6** Support resuming after manual conflict resolution\n\n#### FR5: JSONL Conflict Resolution\n\n- **FR5.1** Automatically resolve JSONL conflicts using existing merge-resolver logic\n- **FR5.2** UUID-based deduplication for issues and specs\n- **FR5.3** Timestamp-based prioritization for same UUID conflicts\n- **FR5.4** Metadata merging (relationships, tags, feedback)\n\n#### FR6: Code Conflict Detection & Handling\n\n- **FR6.1** Detect merge conflicts in regular code files (non-JSONL)\n- **FR6.2** Report conflicting files with line-level conflict information\n- **FR6.3** Provide options: abort sync or manual resolution in IDE\n- **FR6.4** For manual resolution: pause sync, offer \"Open in IDE\" button, allow user to resolve and resume\n- **FR6.5** Track conflict resolution state across sync retries\n\n#### FR7: UI Integration\n\n- **FR7.1** Add \"Sync Worktree to Local\" action button on execution view (available for all execution states)\n- **FR7.2** Display sync preview dialog with change summary\n- **FR7.3** Show conflict warnings before sync\n- **FR7.4** Provide mode selector (squash vs. preserve commits)\n- **FR7.5** Show sync progress and status updates\n- **FR7.6** Display sync result summary (files changed, conflicts resolved)\n- **FR7.7** Add \"Open Worktree in IDE\" button to allow users to inspect/modify worktree changes before syncing\n- **FR7.8** Offer worktree cleanup option after successful sync (for manual cleanup mode only)\n\n#### FR8: Safety & Validation\n\n- **FR8.1** Validate local working tree is clean before sync (no uncommitted changes)\n- **FR8.2** Validate worktree still exists and is accessible\n- **FR8.3** Create safety branch/tag before sync for rollback\n- **FR8.4** Allow sync from any execution state (running, paused, stopped, cancelled, completed) - snapshot current worktree state\n- **FR8.5** Validate branch compatibility before proceeding\n\n### Non-Functional Requirements\n\n#### NFR1: Performance\n\n- Preview generation should complete in < 2 seconds for typical changes\n- Conflict detection should complete in < 3 seconds for typical changes\n\n#### NFR2: Data Integrity\n\n- JSONL merge must never lose data (use merge-resolver guarantees)\n- All git operations must be atomic (rollback on failure)\n- Database state must remain consistent with JSONL after sync\n\n#### NFR3: Usability\n\n- Clear error messages for all failure scenarios\n- Conflict reports should be actionable (show what user needs to do)\n- Default to safest option (squash mode with preview)\n\n## Implementation Strategy\n\n### Architecture Overview\n\n```\n┌─────────────────────────────────────────────────────────────────┐\n│                         Frontend (React)                        │\n│  - ExecutionView with \"Sync\" button                            │\n│  - SyncPreviewDialog (shows diff, conflicts, mode selector)    │\n│  - SyncProgressDialog (shows real-time sync status)            │\n└────────────────────┬────────────────────────────────────────────┘\n                     │ HTTP API\n┌────────────────────▼────────────────────────────────────────────┐\n│                    Server (Express Routes)                      │\n│  POST /executions/:id/sync/preview                             │\n│  POST /executions/:id/sync/squash                              │\n│  POST /executions/:id/sync/preserve                            │\n│  GET  /executions/:id/sync/status                              │\n└────────────────────┬────────────────────────────────────────────┘\n                     │\n┌────────────────────▼────────────────────────────────────────────┐\n│                  WorktreeSync Service                           │\n│  - previewSync()    - detectConflicts()                        │\n│  - squashSync()     - preserveCommitsSync()                    │\n│  - resolveJSONLConflicts()                                     │\n│  - detectCodeConflicts()                                       │\n└────────────────────┬────────────────────────────────────────────┘\n                     │\n        ┌────────────┴──────────────┐\n        │                           │\n┌───────▼────────┐       ┌──────────▼──────────┐\n│  GitSyncCli    │       │  ConflictDetector   │\n│  - getMergeBase│       │  - checkMerge       │\n│  - getDiff     │       │  - parseConflicts   │\n│  - squashMerge │       │  - classifyConflict │\n│  - cherryPick  │       │  - suggestResolution│\n└────────────────┘       └─────────────────────┘\n```\n\n### Component Design\n\n#### 1\\. GitSyncCli (New: `server/src/execution/worktree/git-sync-cli.ts`)\n\nExtends existing `git-cli.ts` with sync-specific git operations:\n\n```typescript\nexport class GitSyncCli {\n  /**\n   * Find common ancestor between two branches\n   */\n  getMergeBase(branch1: string, branch2: string): string;\n  \n  /**\n   * Get diff between two commits\n   * Returns: { files: string[], additions: number, deletions: number }\n   */\n  getDiff(fromCommit: string, toCommit: string): DiffResult;\n  \n  /**\n   * Check if merge would conflict\n   * Returns: { hasConflicts: boolean, conflictingFiles: string[] }\n   */\n  checkMergeConflicts(sourceBranch: string, targetBranch: string): ConflictCheckResult;\n  \n  /**\n   * Perform squash merge\n   */\n  squashMerge(sourceBranch: string, targetBranch: string, message: string): void;\n  \n  /**\n   * Cherry-pick range of commits\n   */\n  cherryPickRange(startCommit: string, endCommit: string): CherryPickResult;\n  \n  /**\n   * Get list of commits between two refs\n   */\n  getCommitList(baseRef: string, headRef: string): Commit[];\n  \n  /**\n   * Check if working tree is clean\n   */\n  isWorkingTreeClean(): boolean;\n  \n  /**\n   * Create safety tag for rollback\n   */\n  createSafetyTag(tagName: string, ref: string): void;\n}\n```\n\n**Implementation Notes:**\n\n- Use `git merge-tree` for conflict detection without modifying working tree\n- Use `git diff --name-status` for file listing\n- Use `execSync` with proper error handling\n- Parse git output using regex patterns (similar to existing `worktreeList()`)\n\n#### 2\\. ConflictDetector (New: `server/src/execution/worktree/conflict-detector.ts`)\n\nDetects and classifies merge conflicts:\n\n```typescript\nexport interface ConflictReport {\n  hasConflicts: boolean;\n  codeConflicts: CodeConflict[];\n  jsonlConflicts: JSONLConflict[];\n  totalFiles: number;\n  summary: string;\n}\n\nexport interface CodeConflict {\n  filePath: string;\n  conflictType: 'content' | 'delete' | 'rename' | 'mode';\n  description: string;\n  canAutoResolve: boolean;\n  resolutionStrategy?: string;\n}\n\nexport interface JSONLConflict {\n  filePath: string;\n  entityType: 'issue' | 'spec';\n  conflictCount: number;\n  canAutoResolve: boolean; // Always true for JSONL\n}\n\nexport class ConflictDetector {\n  /**\n   * Detect all conflicts between branches\n   */\n  detectConflicts(\n    repoPath: string,\n    sourceBranch: string,\n    targetBranch: string\n  ): ConflictReport;\n  \n  /**\n   * Check if file has git conflict markers\n   */\n  private hasConflictMarkers(content: string): boolean;\n  \n  /**\n   * Parse git merge-tree output\n   */\n  private parseMergeTreeOutput(output: string): ConflictInfo[];\n  \n  /**\n   * Classify conflict type\n   */\n  private classifyConflict(conflict: ConflictInfo): CodeConflict | JSONLConflict;\n}\n```\n\n**Conflict Detection Strategy:**\n\n1. **Use** `git merge-tree` **for dry-run merge:**\n\n```bash\ngit merge-tree $(git merge-base branch1 branch2) branch1 branch2\n```\n\n- No working tree modification\n- Returns merge result with conflict markers\n- Parse output to identify conflicting files\n\n1. **Classify conflicts:**\n\n- JSONL files (`.sudocode/*.jsonl`) → JSONLConflict (auto-resolvable)\n- Other files → CodeConflict (needs inspection)\n\n1. **For code conflicts, detect type:**\n\n- Content conflict: Both branches modified same lines\n- Delete conflict: One deleted, one modified\n- Rename conflict: Both renamed same file differently\n- Mode conflict: File mode changed differently\n\n1. **Auto-resolution capabilities:**\n\n- JSONL: Always auto-resolve using merge-resolver\n- Code: Limited auto-resolution (e.g., non-overlapping changes)\n- Most code conflicts require manual resolution\n\n#### 3\\. WorktreeSync Service (New: `server/src/services/worktree-sync-service.ts`)\n\nOrchestrates the sync workflow:\n\n```typescript\nexport interface SyncPreviewResult {\n  canSync: boolean;\n  conflicts: ConflictReport;\n  diff: DiffSummary;\n  commits: Commit[];\n  mergeBase: string;\n  uncommittedJSONLChanges: boolean;\n  executionStatus: ExecutionStatus; // Warn if running/paused\n  warnings: string[];\n}\n\nexport interface SyncResult {\n  success: boolean;\n  finalCommit?: string;\n  filesChanged: number;\n  conflictsResolved: number;\n  uncommittedJSONLIncluded: boolean;\n  error?: string;\n  cleanupOffered?: boolean; // True if cleanup mode is 'manual'\n}\n\nexport class WorktreeSyncService {\n  /**\n   * Preview sync without making changes\n   */\n  async previewSync(executionId: string): Promise<SyncPreviewResult>;\n  \n  /**\n   * Perform squash sync\n   */\n  async squashSync(\n    executionId: string,\n    commitMessage?: string\n  ): Promise<SyncResult>;\n  \n  /**\n   * Perform preserve-commits sync\n   */\n  async preserveCommitsSync(executionId: string): Promise<SyncResult>;\n  \n  /**\n   * Validate preconditions for sync\n   */\n  private async validateSyncPreconditions(execution: Execution): Promise<void>;\n  \n  /**\n   * Resolve JSONL conflicts using merge-resolver\n   */\n  private async resolveJSONLConflicts(\n    repoPath: string,\n    jsonlFiles: string[]\n  ): Promise<void>;\n  \n  /**\n   * Create safety snapshot before sync\n   */\n  private async createSafetySnapshot(\n    repoPath: string,\n    executionId: string\n  ): Promise<string>;\n}\n```\n\n**Sync Workflow (Squash Mode):**\n\n```\n1. Load execution from database\n2. Validate preconditions:\n   - Worktree still exists\n   - Local working tree is clean\n   - Worktree branch exists\n   - (Execution can be in any state - just snapshot current worktree state)\n3. Create safety tag: `sudocode-sync-before-{execution-id}`\n4. Get current worktree HEAD commit (may include uncommitted JSONL changes)\n5. Detect conflicts using ConflictDetector\n6. If code conflicts exist:\n   - Pause sync, notify user, offer \"Open in IDE\" to resolve\n   - Return error if user aborts\n7. Checkout local target branch\n8. Perform git merge --squash worktree-branch\n9. Resolve JSONL conflicts:\n   - Extract issues.jsonl and specs.jsonl (including uncommitted changes)\n   - Run merge-resolver on each\n   - Stage resolved files\n10. Create commit with message\n11. Sync worktree JSONL/DB to local:\n    - Copy resolved JSONL to .sudocode/\n    - Re-import to local database\n12. Offer worktree cleanup (if cleanup mode is 'manual')\n13. Return success result\n```\n\n**Sync Workflow (Preserve Commits Mode):**\n\n```\n1-6. Same as squash mode\n7. Get commit list from merge-base to worktree HEAD\n8. For each commit in order:\n   a. Cherry-pick commit\n   b. If JSONL conflicts:\n      - Resolve using merge-resolver\n      - Continue cherry-pick\n   c. If code conflicts:\n      - Pause and report to user\n      - Offer \"Open in IDE\" for manual resolution\n      - Wait for user to resolve and confirm\n      - Resume cherry-pick on user command\n9. If worktree has uncommitted JSONL changes:\n   - Create final commit with those changes\n10. Sync final state (same as squash #11)\n11. Offer worktree cleanup (if cleanup mode is 'manual')\n12. Return success result\n```\n\n#### 4\\. API Routes (Add to `server/src/routes/executions.ts`)\n\n```typescript\n/**\n * Preview sync changes and detect conflicts\n * GET /api/executions/:id/sync/preview\n */\nrouter.get('/:id/sync/preview', async (req, res) => {\n  const { id } = req.params;\n  const result = await worktreeSyncService.previewSync(id);\n  res.json(result);\n});\n\n/**\n * Perform squash sync\n * POST /api/executions/:id/sync/squash\n * Body: { commitMessage?: string }\n */\nrouter.post('/:id/sync/squash', async (req, res) => {\n  const { id } = req.params;\n  const { commitMessage } = req.body;\n  const result = await worktreeSyncService.squashSync(id, commitMessage);\n  res.json(result);\n});\n\n/**\n * Perform preserve-commits sync\n * POST /api/executions/:id/sync/preserve\n */\nrouter.post('/:id/sync/preserve', async (req, res) => {\n  const { id } = req.params;\n  const result = await worktreeSyncService.preserveCommitsSync(id);\n  res.json(result);\n});\n```\n\n#### 5\\. Frontend Components\n\n**a. Add Sync and IDE Buttons to ExecutionView**\n\nLocation: `frontend/src/components/executions/ExecutionView.tsx`\n\n```typescript\n// Add sync and IDE buttons next to other execution actions\n// Available for all execution states (not just completed)\n{execution.worktree_path && (\n  <>\n    <Button\n      onClick={handleOpenInIDE}\n      variant=\"secondary\"\n    >\n      Open Worktree in IDE\n    </Button>\n    <Button\n      onClick={handleSyncClick}\n    >\n      Sync Worktree to Local\n    </Button>\n  </>\n)}\n```\n\n**b. SyncPreviewDialog (New component)**\n\n```typescript\ninterface SyncPreviewDialogProps {\n  execution: Execution;\n  preview: SyncPreviewResult;\n  onConfirm: (mode: 'squash' | 'preserve', message?: string) => void;\n  onCancel: () => void;\n  onOpenIDE: () => void;\n}\n\n// Shows:\n// - Execution status indicator (if running/paused, warn that state may change)\n// - Diff summary (files changed, +/- lines)\n// - Conflict warnings (if any) with \"Open in IDE\" button\n// - Uncommitted JSONL changes indicator\n// - Mode selector (squash vs preserve)\n// - Commit message input (for squash)\n// - Confirm/Cancel buttons\n```\n\n**c. SyncProgressDialog (New component)**\n\n```typescript\ninterface SyncProgressDialogProps {\n  syncStatus: SyncResult | null;\n  onClose: () => void;\n  onCleanupWorktree?: () => void;\n  showCleanupOption: boolean;\n}\n\n// Shows:\n// - Progress indicator\n// - Status messages (cherry-picking commits, resolving conflicts, etc.)\n// - Conflict resolution prompt with \"Open in IDE\" button (if conflicts detected)\n// - Success/error summary\n// - Files changed count\n// - Worktree cleanup option (if cleanup mode is 'manual' and sync succeeded)\n```\n\n### Implementation Phases\n\n#### Phase 1: Git Operations & Conflict Detection (Foundation)\n\n- Implement `GitSyncCli` with all git operations\n- Implement `ConflictDetector` for dry-run conflict detection\n- Add unit tests for git operations\n- Add integration tests for conflict detection scenarios\n\n#### Phase 2: Squash Sync (Core Feature)\n\n- Implement `WorktreeSyncService.previewSync()`\n- Implement `WorktreeSyncService.squashSync()`\n- Integrate with existing merge-resolver for JSONL\n- Add API routes for preview and squash\n- Add tests for squash sync workflow\n\n#### Phase 3: UI Integration (User-Facing)\n\n- Add \"Sync Worktree to Local\" button to ExecutionView\n- Create `SyncPreviewDialog` component\n- Create `SyncProgressDialog` component\n- Add sync state management to execution context\n- Add user-facing error handling and messaging\n\n#### Phase 4: Preserve Commits Sync (Advanced Feature)\n\n- Implement `WorktreeSyncService.preserveCommitsSync()`\n- Add cherry-pick logic with conflict handling\n- Add pause/resume functionality for manual conflict resolution\n- Add API route for preserve sync\n- Update UI to support mode selection\n\n#### Phase 5: Code Conflict Resolution (Future Enhancement)\n\n- Add conflict resolution strategies for common code patterns\n- Implement semi-automatic conflict resolution\n- Add conflict resolution UI (inline diff editor)\n- Support manual conflict resolution workflow\n- Add rollback/undo functionality\n\n## Edge Cases & Considerations\n\n### 1\\. Worktree No Longer Exists\n\n- **Scenario:** User deleted worktree directory manually\n- **Handling:** Check worktree existence in preview, show error, disable sync\n- **Recovery:** No sync possible, user must re-run execution\n\n### 2\\. Local Working Tree Dirty\n\n- **Scenario:** User has uncommitted changes in local tree\n- **Handling:** Block sync, show warning, suggest stash or commit\n- **Recovery:** User cleans working tree, retries sync\n\n### 3\\. Diverged Branches (No Common Base)\n\n- **Scenario:** Worktree branch and local branch have completely different histories\n- **Handling:** Detect in preview, show error, explain incompatibility\n- **Recovery:** User must manually reconcile or abandon sync\n\n### 4\\. Execution In Progress\n\n- **Scenario:** User wants to sync while agent is still executing (running/paused state)\n- **Handling:** Allow sync of current worktree state, warn user that execution may continue making changes after sync\n- **Impact:** Synced state may not reflect final execution result; user may need to sync again after completion\n\n### 5\\. JSONL Conflicts with UUID Collisions\n\n- **Scenario:** Worktree and local both have different entities with same ID hash\n- **Handling:** Merge-resolver renames duplicates with `.1`, `.2` suffixes\n- **Impact:** Users may need to manually reconcile entity references\n\n### 6\\. Binary File Conflicts\n\n- **Scenario:** Agent modified images/binaries that also changed locally\n- **Handling:** Git shows binary conflict, cannot auto-resolve\n- **Recovery:** Manual resolution required (choose ours/theirs or manual merge)\n\n### 7\\. Database State Inconsistency\n\n- **Scenario:** JSONL sync succeeds but database import fails\n- **Handling:** Rollback git changes, report error, maintain consistency\n- **Recovery:** Fix database issue, retry sync\n\n### 8\\. Partial Sync Failure (Preserve Mode)\n\n- **Scenario:** Cherry-pick succeeds for some commits, fails on later commit\n- **Handling:** Leave partial changes, report failure point, offer rollback\n- **Recovery:** User resolves conflict, continues cherry-pick, or rolls back\n\n## Security Considerations\n\n1. **Path Traversal:** Validate all file paths are within repo boundaries\n1. **Command Injection:** Sanitize all git command arguments (use existing execSync wrapper)\n1. **Data Loss Prevention:** Always create safety tags before destructive operations\n1. **Access Control:** Validate user has permission to modify target branch\n1. **Rollback Safety:** Ensure rollback is always possible (safety tags + clean state validation)\n\n## Testing Strategy\n\n### Unit Tests\n\n- Git operations (getMergeBase, getDiff, etc.)\n- Conflict detection logic\n- JSONL merge resolution\n- Validation checks\n\n### Integration Tests\n\n- Full squash sync workflow\n- Full preserve-commits sync workflow\n- Conflict detection scenarios\n- JSONL conflict resolution\n- Database sync after merge\n\n### E2E Tests\n\n- User creates execution, makes changes, syncs back (squash)\n- User creates execution, makes changes, syncs back (preserve)\n- User encounters conflict, resolves, completes sync\n- User cancels sync, no changes applied\n\n### Manual Testing Scenarios\n\n- Real-world agent execution with complex changes\n- Multiple JSONL conflicts (issues + specs)\n- Code conflicts requiring manual resolution\n- Large diffs (100+ files)\n- Binary file modifications\n\n## Design Decisions\n\n### 1\\. Syncing from Any Execution State\n\n**Decision:** Allow syncing from executions in any state (running, paused, stopped, cancelled, completed, blocked).\n\n**Rationale:** Users may want to preview or integrate partial work from an in-progress execution. The sync operation captures the current state of the worktree at the time of sync request.\n\n**Implications:**\n\n- Sync takes a snapshot of current worktree HEAD commit\n- For running/paused executions, warn user that execution may continue making changes\n- User can sync again after execution completes to get final state\n\n### 2\\. Worktree Cleanup After Sync\n\n**Decision:** Use configured cleanup mode from execution settings. For manual cleanup mode, offer cleanup option after successful sync.\n\n**Rationale:** Respects existing user preferences while providing explicit control for manual cleanup scenarios.\n\n**Behavior:**\n\n- **Auto cleanup:** Automatically clean up worktree after sync (follows existing execution cleanup config)\n- **Manual cleanup:** Show \"Clean up worktree?\" prompt after successful sync\n- **Never cleanup:** Keep worktree intact (allows follow-up executions)\n\n### 3\\. Selective File Sync\n\n**Decision:** Not supported in initial implementation. Sync all changes or none.\n\n**Rationale:** Simplifies implementation and UX. Users who need fine-grained control can:\n\n- Use \"Open Worktree in IDE\" to make selective changes before syncing\n- Manually use git commands for advanced workflows\n\n**Future Enhancement:** May add selective file sync in Phase 5+ based on user feedback.\n\n### 4\\. Uncommitted JSONL Changes\n\n**Decision:** Include uncommitted JSONL changes from worktree in sync.\n\n**Rationale:** Worktree may have uncommitted spec/issue updates that represent important work state. These should be preserved during sync.\n\n**Implementation:** Before sync, check for uncommitted changes in `.sudocode/*.jsonl`, include them in merge resolution.\n\n### 5\\. Bi-directional Sync (Local → Worktree)\n\n**Decision:** Not implemented in this version, but design is future-proofed to support it.\n\n**Rationale:** Current use case is primarily worktree→local (integrating agent work). Local→worktree (updating agent context) is a different workflow that requires additional UX design.\n\n**Future-Proofing:**\n\n- `WorktreeSyncService` interface designed to be symmetric (can add `syncToWorktree()` method)\n- API routes structured to support bidirectional operations (`/sync/to-worktree` endpoint can be added)\n- Conflict detection logic is branch-agnostic (works for either direction)\n\n**Future Implementation Notes:**\n\n- When implemented, local→worktree sync would allow users to:\n  - Push hotfixes to running executions\n  - Update specs/issues that agent is working on\n  - Share local work with paused execution for agent to continue\n- Would need careful handling of running executions (notify/pause agent during sync)\n\n### 6\\. Manual Code Conflict Resolution UX\n\n**Decision:** Pause sync, notify user of conflicts, provide \"Open in IDE\" button for manual resolution.\n\n**Rationale:**\n\n- Most code conflicts require developer judgment and context\n- IDE provides familiar, powerful tools for conflict resolution\n- Simpler than building custom conflict resolution UI\n\n**Workflow:**\n\n1. Conflict detected during sync\n1. Sync pauses, shows conflict report with file list\n1. User clicks \"Open in IDE\" button\n1. System opens worktree in configured IDE with conflict markers visible\n1. User resolves conflicts in IDE, saves files\n1. User returns to sync dialog, clicks \"Continue\"\n1. System validates conflicts are resolved, continues sync\n\n**Future Enhancement:** In-app conflict visualization and resolution (Phase 5) for users who prefer not to context-switch to IDE.\n\n## Success Metrics\n\n- **Adoption:** % of completed executions that get synced\n- **Success Rate:** % of sync attempts that complete without error\n- **Conflict Rate:** % of syncs that encounter conflicts (target: < 20%)\n- **Auto-Resolution Rate:** % of conflicts resolved automatically (target: > 80% for JSONL)\n- **User Satisfaction:** Feedback from users on sync experience\n\n## Future Enhancements\n\n1. **Bi-directional Sync (Local → Worktree):** Push changes from local tree to worktree\n\n- Use cases: Update running execution context, share hotfixes with agent\n- API: `POST /executions/:id/sync/to-worktree`\n- Requires coordination with running agent processes\n\n1. **Smart Conflict Resolution:** ML-based suggestions for code conflict resolution\n1. **Partial File Sync:** Select specific files/changes to sync\n1. **Sync Templates:** Pre-configured sync strategies for common patterns\n1. **Batch Sync:** Sync multiple executions at once\n1. **Sync History:** Track all syncs performed, allow rollback to previous state\n1. **Async Sync:** Long-running syncs don't block UI\n1. **Conflict Visualization:** Visual diff tool for reviewing conflicts (in-app alternative to IDE)\n1. **Auto-sync:** Optional auto-sync on execution completion\n1. **IDE Integration Protocol:** Standardized way to open specific files at conflict locations across different IDEs","priority":1,"archived":0,"archived_at":null,"created_at":"2025-11-28 20:27:12","updated_at":"2025-11-28 20:49:51","parent_id":null,"parent_uuid":null,"relationships":[],"tags":["agent-execution","feature","git","sync","worktree"]}
{"id":"s-6u9w","uuid":"99956c8a-3d04-4edb-8d6f-c295c167f75a","title":"Worktree Management Page","file_path":"specs/s-6u9w_worktree_management_page.md","content":"# Overview\n\nA dedicated page at `/worktrees` that provides centralized management of git worktrees created for agent executions, enabling users to view, sync, and manage multiple worktrees efficiently.\n\n## User Requirements\n\n### Workflow Context\n- Worktrees exist as standalone entities but are interacted with through executions\n- Users can create standalone worktrees and bind issue executions to them\n- Users can create new worktrees through new executions\n- Users need visibility into all worktrees to enable reuse across multiple executions\n\n### Core Features (MVP)\n1. **List all worktrees** with status visibility\n2. **Quick actions**: Sync to local, Delete worktree, Open in IDE\n3. **Detailed change preview**: View commits, file changes, conflicts inline\n4. **Search and filtering**: Find worktrees by execution ID, branch name, issue\n5. **Issue association**: Clear visibility of which issue each worktree relates to\n6. **Worktree reusability**: See all existing worktrees to identify candidates for new executions\n\n## Technical Architecture\n\n### Data Model\n\n**Foundation Principle**: Worktrees ARE Executions\n- Query executions where `worktree_path IS NOT NULL`\n- Reuse existing `Execution` type from `types/src/schema.ts`\n- No new database schema changes required\n\n**Key Execution Fields**:\n```typescript\n{\n  id: string                    // Execution identifier\n  issue_id: string              // Associated issue\n  worktree_path: string         // File system path to worktree\n  branch_name: string           // Git branch for this worktree\n  target_branch: string         // Base branch (where changes will merge)\n  status: ExecutionStatus       // running | paused | completed | failed\n  files_changed: string[]       // List of modified files\n  before_commit: string         // HEAD before execution\n  after_commit: string          // Latest commit in worktree\n  created_at: Date\n  updated_at: Date\n}\n```\n\n### Backend API\n\n**New Endpoint**:\n```\nGET /api/executions/worktrees\n```\n\n**Response**:\n```typescript\n{\n  success: boolean\n  data: Execution[]  // Executions filtered by worktree_path != null\n}\n```\n\n**Implementation** (server/src/routes/executions.ts):\n- Use existing ExecutionService.listAllExecutions()\n- Filter results where worktree_path is not null\n- Return as standard execution array\n\n**Reused Endpoints**:\n- `GET /api/executions/:id/sync/preview` - Preview sync changes\n- `POST /api/executions/:id/sync/squash` - Perform squash sync\n- `POST /api/executions/:id/sync/preserve` - Perform preserve-commits sync\n- `DELETE /api/executions/:id/worktree` - Delete worktree\n\n### Frontend Architecture\n\n#### Page Structure (follows IssuesPage pattern)\n\n**Route**: `/worktrees`\n\n**Layout**:\n```\n┌─────────────────────────────────────────────────────────┐\n│ Header (Title, Search, Filters, Sort)                  │\n├─────────────────────────────────────────────────────────┤\n│ ┌──────────────────────┬──────────────────────────────┐ │\n│ │ WorktreeList (66%)   │ WorktreeDetailPanel (34%)    │ │\n│ │                      │                              │ │\n│ │ Grid of Cards:       │ Selected Worktree Details:   │ │\n│ │ - WorktreeCard       │ - Overview                   │ │\n│ │ - WorktreeCard       │ - Commits                    │ │\n│ │ - WorktreeCard       │ - Files Changed              │ │\n│ │ ...                  │ - Conflicts                  │ │\n│ │                      │ - Action Buttons             │ │\n│ └──────────────────────┴──────────────────────────────┘ │\n└─────────────────────────────────────────────────────────┘\n```\n\n**Resizable Panels**:\n- Uses `react-resizable-panels`\n- Panel sizes persist to localStorage\n- Collapsible right panel\n\n**State Management**:\n- URL hash for selected worktree (#execution-id)\n- localStorage for sort/filter preferences (key: `sudocode:worktrees:sortOption`)\n- React Query for data fetching and caching\n\n#### Component Hierarchy\n\n```\nWorktreesPage\n├── Header\n│   ├── Title with count badge\n│   ├── Project info (repo name, branch)\n│   ├── Search input\n│   ├── Sort dropdown (newest, last-updated, status)\n│   └── Filter dropdown (all, active, completed, with-conflicts)\n├── PanelGroup\n│   ├── Panel (Left - List View)\n│   │   └── WorktreeList\n│   │       └── WorktreeCard[] (grid layout)\n│   ├── PanelResizeHandle\n│   └── Panel (Right - Detail View)\n│       └── WorktreeDetailPanel\n│           ├── Overview section\n│           ├── Commits section\n│           ├── Files changed section\n│           ├── Conflicts section\n│           └── Action bar\n└── Dialogs (from useExecutionSync)\n    ├── SyncPreviewDialog\n    ├── SyncProgressDialog\n    └── DeleteWorktreeDialog\n```\n\n#### Component Specifications\n\n**WorktreeCard** (frontend/src/components/worktrees/WorktreeCard.tsx):\n- Displays per worktree:\n  - Execution ID (truncated, copyable tooltip)\n  - Branch name with GitBranch icon\n  - Status badge (colored by status)\n  - Issue reference (clickable → navigate to `/issues/:id`)\n  - File count badge (from files_changed.length)\n  - Conflict indicator (red badge if conflicts detected)\n  - Last updated timestamp (relative time)\n- Hover actions:\n  - View Details (navigate to execution detail)\n  - Sync to Local (trigger sync preview)\n  - Open in IDE (copy path to clipboard)\n  - Delete (confirmation dialog)\n- Visual states: default, hover, selected\n\n**WorktreeList** (frontend/src/components/worktrees/WorktreeList.tsx):\n- Grid layout: `md:grid-cols-2 lg:grid-cols-3`\n- Loading state: Skeleton cards\n- Empty state: \"No worktrees found. Create an execution with worktree mode to get started.\"\n- Maps filtered/sorted worktrees to WorktreeCard\n- Click handler to update URL hash and select worktree\n\n**WorktreeDetailPanel** (frontend/src/components/worktrees/WorktreeDetailPanel.tsx):\n\n**Overview Section**:\n- Execution ID (copyable)\n- Issue link (navigate to issue)\n- Branch name\n- Status badge\n- Created/Updated timestamps\n- Worktree path (copyable)\n\n**Commits Section**:\n- Fetches via `executionsApi.syncPreview(executionId)`\n- Displays commit list from preview result:\n  - SHA (short form, copyable)\n  - Commit message\n  - Author\n  - Date (relative time)\n- Shows merge base reference\n- Link to view full execution details\n\n**Files Changed Section**:\n- From sync preview `diff.files` array\n- File list showing:\n  - File path\n  - +/- line counts\n  - Change type (modified, added, deleted)\n- Summary: Total additions/deletions\n\n**Conflicts Section**:\n- Displayed only if conflicts detected\n- Code conflicts:\n  - File path\n  - Conflict type (content, delete, rename, mode)\n  - \"Requires manual resolution\" indicator\n- JSONL conflicts:\n  - File path\n  - \"Auto-resolvable\" indicator\n- Total conflict count badge\n\n**Action Bar**:\n- Primary button: \"Sync to Local\" → calls `fetchSyncPreview(executionId)`\n- Secondary button: \"Open in IDE\" → calls `openWorktreeInIDE(execution)`\n- Danger button: \"Delete Worktree\" → shows DeleteWorktreeDialog\n- Tertiary link: \"View Full Details\" → navigate to `/executions/:id`\n\n**WorktreesPage** (frontend/src/pages/WorktreesPage.tsx):\n\n**Header**:\n- Title: \"Worktrees\" with count badge\n- Project context: Repository name, current branch (from useRepositoryInfo)\n- Search input: Filter by execution ID, branch name, issue ID\n- Sort dropdown:\n  - Newest first (created_at DESC)\n  - Last updated (updated_at DESC)\n  - Status (running → paused → completed → failed)\n- Filter dropdown:\n  - All worktrees\n  - Active only (status = running or paused)\n  - Completed only (status = completed)\n  - With conflicts (requires sync preview check)\n\n**State Management**:\n```typescript\nconst [selectedWorktree, setSelectedWorktree] = useState<Execution | undefined>()\nconst [filterText, setFilterText] = useState('')\nconst [sortOption, setSortOption] = useState<SortOption>('newest')\nconst [statusFilter, setStatusFilter] = useState<'all' | 'active' | 'completed'>('all')\n```\n\n**URL Hash Selection**:\n- Parse `location.hash` on mount → select initial worktree\n- Update hash when worktree selected\n- Listen to hash changes for browser back/forward\n\n**Filtering Logic**:\n```typescript\nconst filtered = useMemo(() => {\n  return worktrees.filter(wt => \n    (filterText === '' || \n     wt.id.includes(filterText) ||\n     wt.branch_name.includes(filterText) ||\n     wt.issue_id.includes(filterText)) &&\n    (statusFilter === 'all' || \n     statusFilter === 'active' && ['running', 'paused'].includes(wt.status) ||\n     statusFilter === 'completed' && wt.status === 'completed')\n  )\n}, [worktrees, filterText, statusFilter])\n```\n\n**Sorting Logic**:\n```typescript\nconst sorted = useMemo(() => {\n  const items = [...filtered]\n  switch (sortOption) {\n    case 'newest':\n      return items.sort((a, b) => new Date(b.created_at) - new Date(a.created_at))\n    case 'last-updated':\n      return items.sort((a, b) => new Date(b.updated_at) - new Date(a.updated_at))\n    case 'status':\n      const statusOrder = { running: 0, paused: 1, completed: 2, failed: 3 }\n      return items.sort((a, b) => statusOrder[a.status] - statusOrder[b.status])\n  }\n}, [filtered, sortOption])\n```\n\n#### Data Hook\n\n**useWorktrees** (frontend/src/hooks/useWorktrees.ts):\n\nPattern: Follow useIssues.ts structure\n\n```typescript\nexport function useWorktrees() {\n  const queryClient = useQueryClient()\n  const { currentProjectId } = useProject()\n  \n  const queryKey = ['worktrees', currentProjectId]\n  \n  const query = useQuery({\n    queryKey,\n    queryFn: () => executionsApi.listWorktrees(),\n    enabled: !!currentProjectId\n  })\n  \n  // Optional: WebSocket subscription for real-time updates\n  const { connected, subscribe, addMessageHandler } = useWebSocketContext()\n  \n  useEffect(() => {\n    const handleMessage = (message: WebSocketMessage) => {\n      if (message.type === 'execution_updated' || \n          message.type === 'execution_completed') {\n        queryClient.invalidateQueries({ queryKey: ['worktrees', currentProjectId] })\n      }\n    }\n    \n    addMessageHandler('useWorktrees', handleMessage)\n    if (connected) subscribe('execution')\n    \n    return () => {\n      removeMessageHandler('useWorktrees')\n      unsubscribe('execution')\n    }\n  }, [connected])\n  \n  return {\n    worktrees: query.data ?? [],\n    isLoading: query.isLoading,\n    isError: query.isError,\n    error: query.error\n  }\n}\n```\n\n### Component Reuse Strategy\n\n**100% Reuse (No modifications needed)**:\n1. `useExecutionSync` hook - All sync state management\n2. `SyncPreviewDialog` - Preview changes before sync\n3. `SyncProgressDialog` - Show sync progress and results\n4. `DeleteWorktreeDialog` - Delete confirmation\n5. All UI primitives from shadcn/ui:\n   - Badge, Button, Card, Input, Select\n   - Tooltip, AlertDialog\n   - PanelGroup, Panel, PanelResizeHandle\n\n**Pattern Reuse**:\n- Page structure from `IssuesPage.tsx`\n- Data hook pattern from `useIssues.ts`\n- Status badges from `ExecutionView.tsx`\n\n### Navigation Integration\n\n**App.tsx** modification:\n```typescript\n<Route\n  path=\"worktrees\"\n  element={\n    <ProtectedRoute>\n      <WorktreesPage />\n    </ProtectedRoute>\n  }\n/>\n```\n\n**Sidebar.tsx** modification:\n```typescript\nconst navItems = [\n  { path: '/issues', label: 'Issues', icon: ListTodo },\n  { path: '/specs', label: 'Specs', icon: FileText },\n  { path: '/worktrees', label: 'Worktrees', icon: GitBranch }, // NEW\n]\n```\n\n## User Workflows\n\n### View All Worktrees\n1. User clicks \"Worktrees\" in sidebar\n2. Page loads, fetches all executions with worktree_path\n3. Displays grid of worktree cards\n4. User can search/filter/sort as needed\n\n### Inspect Worktree Details\n1. User clicks on a worktree card\n2. URL hash updates to `#execution-id`\n3. Detail panel loads sync preview\n4. Shows commits, files, conflicts\n5. User can see all changes before syncing\n\n### Sync Worktree to Local\n1. User clicks \"Sync to Local\" in detail panel\n2. `fetchSyncPreview()` called → opens SyncPreviewDialog\n3. User reviews changes, conflicts, warnings\n4. User selects sync mode (squash or preserve)\n5. User optionally customizes commit message\n6. User clicks \"Sync\" → opens SyncProgressDialog\n7. Backend performs sync with conflict resolution\n8. Success: Shows summary with option to delete worktree\n9. Failure: Shows error with recovery options\n\n### Open Worktree in IDE\n1. User clicks \"Open in IDE\"\n2. Worktree path copied to clipboard\n3. Toast notification: \"Path copied to clipboard\"\n4. User manually opens path in IDE\n\n### Delete Worktree\n1. User clicks \"Delete Worktree\"\n2. DeleteWorktreeDialog appears with confirmation\n3. User confirms deletion\n4. Backend deletes worktree and branch\n5. Worktree removed from list\n6. If worktree was selected, detail panel shows empty state\n\n### Reuse Existing Worktree\n1. User views worktree list\n2. User identifies worktree with desired context\n3. User can see worktree path, branch, and current state\n4. User creates new execution targeting that worktree (future feature)\n\n## Implementation Phases\n\n### Phase 1: Data Layer (30 min)\n- Add `GET /executions/worktrees` backend endpoint\n- Add `executionsApi.listWorktrees()` to API client\n- Create `useWorktrees` hook with React Query\n\n### Phase 2: Components (2-2.5 hours)\n- Create WorktreeCard component\n- Create WorktreeList component\n- Create WorktreeDetailPanel component\n- Create WorktreesPage component\n- Wire up useExecutionSync for all sync operations\n\n### Phase 3: Navigation (15 min)\n- Add /worktrees route to App.tsx\n- Add Worktrees nav item to Sidebar.tsx\n- Test navigation and URL hash selection\n\n### Phase 4: Polish (30-45 min)\n- Add loading states (skeleton cards)\n- Add empty states (no worktrees, no selection)\n- Error handling (failed to load, sync errors)\n- Test all actions\n- Verify responsive layout\n\n**Total Implementation Time: 3.5-4 hours**\n\n## Success Criteria\n\n- [ ] User can navigate to /worktrees\n- [ ] User can see all worktrees in a grid layout\n- [ ] User can search/filter worktrees by execution ID, branch, issue\n- [ ] User can sort worktrees by date, status\n- [ ] User can select a worktree to see details\n- [ ] User can see commits, file changes, and conflicts for selected worktree\n- [ ] User can preview sync changes before executing\n- [ ] User can sync worktree to local (squash or preserve modes)\n- [ ] User can delete worktree with confirmation\n- [ ] User can open worktree path in IDE (via clipboard)\n- [ ] User can identify which issue a worktree relates to\n- [ ] User can view full execution details for any worktree\n- [ ] User can navigate via URL hash (shareable links, browser back/forward)\n- [ ] Page handles loading, empty, and error states gracefully\n\n## Future Enhancements (Post-MVP)\n\n- Real-time WebSocket updates for worktree status changes\n- Batch operations (select multiple worktrees, bulk sync/delete)\n- Inline sync preview in card hover (without opening full dialog)\n- Advanced filters (by base branch, file count range, conflict status)\n- Worktree health checks (verify directory still exists on disk)\n- Auto-cleanup policies (delete worktrees older than X days)\n- Disk usage statistics and warnings\n- Branch divergence visualization\n- Quick actions: Create PR from worktree\n- Execution binding: Attach new execution to existing worktree\n\n## Technical Dependencies\n\n**Frontend**:\n- React 18+\n- React Router v6 (for routing)\n- TanStack Query v4 (for data fetching)\n- react-resizable-panels (for layout)\n- lucide-react (for icons)\n- shadcn/ui components\n- Tailwind CSS\n\n**Backend**:\n- Existing ExecutionService\n- Existing WorktreeSyncService\n- Existing worktree endpoints\n\n**No new dependencies required**","priority":1,"archived":0,"archived_at":null,"created_at":"2025-11-30 02:08:36","updated_at":"2025-11-30 02:08:36","parent_id":null,"parent_uuid":null,"relationships":[],"tags":["execution","frontend","ui","worktree"]}
{"id":"s-65lm","uuid":"c5a5a0dc-3dfa-4aca-9ae9-0474c5e05834","title":"Executions Page - Multi-Execution Monitoring","file_path":"specs/s-65lm_executions_page_multi_execution_monitoring.md","content":"# Executions Page - Multi-Execution Monitoring\n\n## Overview\n\nBuild an \"Executions Page\" that allows users to monitor and interact with multiple executions simultaneously through a grid-based layout with an intelligent sidebar for execution management.\n\n## User Requirements\n\n### Core Features\n1. **Grid of Multiple Execution Views**: Display multiple executions in a configurable grid layout, each with its own execution monitor and agent config panel\n2. **Sidebar with Execution List**: Show all executions with metadata (issue, branch, status, timestamp) and checkbox-based visibility controls\n3. **Rapid Context Switching**: Allow users to quickly toggle which executions are displayed and interact with different agent config panels\n4. **Configurable Grid Layouts**: Support 2-column, 3-column, and 4-column grid layouts based on user preference\n\n### User Workflow\n- Users can view a list of all executions in the sidebar\n- Check/uncheck executions to show/hide them in the grid\n- Monitor multiple executions simultaneously with real-time updates\n- Submit follow-ups to any execution directly from its grid tile\n- Change grid density (2/3/4 columns) based on screen size and preference\n\n## Architecture\n\n### Component Structure\n\n#### ExecutionsPage (Main Container)\n- **Location**: `/frontend/src/pages/ExecutionsPage.tsx`\n- **Layout**: PanelGroup with resizable sidebar + grid area (following IssuesPage pattern)\n- **State Management**:\n  - `gridLayout`: '2col' | '3col' | '4col' (persisted to localStorage)\n  - `visibleExecutionIds`: Set<string> (sessionStorage, resets on reload)\n  - `searchText`: string (optional filter)\n  - `statusFilter`: ExecutionStatus | 'all'\n- **Header Controls**: Grid layout toggle, filters, search\n- **Persistence**: Layout preferences saved to localStorage, panel sizes saved\n\n#### ExecutionsSidebar\n- **Location**: `/frontend/src/components/executions/ExecutionsSidebar.tsx`\n- **Features**:\n  - List of all executions with metadata display\n  - Checkbox for each execution to toggle visibility in grid\n  - Status badges with color coding (running=blue, completed=green, failed=red)\n  - Relative timestamps (\"3m ago\")\n  - Real-time WebSocket updates for status changes\n  - Collapsible (60px collapsed, 280-320px expanded)\n\n#### ExecutionsGrid\n- **Location**: `/frontend/src/components/executions/ExecutionsGrid.tsx`\n- **Implementation**: CSS Grid with dynamic column count\n  - 2-column: `grid-template-columns: repeat(2, 1fr)`\n  - 3-column: `grid-template-columns: repeat(3, 1fr)` (default)\n  - 4-column: `grid-template-columns: repeat(4, 1fr)`\n- **Responsive Behavior**:\n  - < 1024px: Force 1 column\n  - 1024-1440px: Max 2 columns\n  - 1440+px: Allow all layouts\n- **Empty State**: \"Check executions in sidebar to display\"\n\n#### ExecutionGridTile\n- **Location**: `/frontend/src/components/executions/ExecutionGridTile.tsx`\n- **Structure**:\n  - Sticky Header: Execution ID, status badge, quick actions\n  - Scrollable Middle: ExecutionMonitor (compact mode)\n  - Sticky Footer: AgentConfigPanel (follow-up mode)\n- **Integration**:\n  - Reuses `ExecutionMonitor` with `compact={true}` prop\n  - Reuses `AgentConfigPanel` with `isFollowUp={true}` for follow-ups\n  - Focus indicators (2px border) when active\n\n### Backend API\n\n#### New Endpoint: GET /api/executions\n- **Purpose**: List all executions across all issues with filtering and pagination\n- **Query Parameters**:\n  - `limit?: number` (default: 50)\n  - `offset?: number` (default: 0)\n  - `status?: ExecutionStatus | ExecutionStatus[]`\n  - `issueId?: string`\n  - `sortBy?: 'created_at' | 'updated_at'` (default: 'created_at')\n  - `order?: 'asc' | 'desc'` (default: 'desc')\n- **Response**:\n  ```typescript\n  {\n    executions: Execution[]\n    total: number\n    hasMore: boolean\n  }\n  ```\n- **Location**: `/server/src/routes/executions.ts`\n\n#### Frontend API Client\n- **Location**: `/frontend/src/lib/api.ts`\n- **Method**: `executionsApi.listAll(params?)`\n- **React Query Hook**: `useExecutions()` for data fetching with caching\n\n### Data Flow\n\n#### Initial Load\n1. ExecutionsPage mounts\n2. Fetch executions via `executionsApi.listAll()`\n3. Display all in sidebar (none checked initially)\n4. Grid shows empty state\n\n#### Show/Hide Executions\n1. User checks execution in sidebar\n2. Add `execution.id` to `visibleExecutionIds` Set\n3. Grid re-renders with new ExecutionGridTile\n4. ExecutionMonitor connects to SSE stream (if execution is running)\n5. AgentConfigPanel ready for follow-up submission\n\n#### Real-time Updates\n1. WebSocket receives `execution_status_changed` event\n2. Update execution in sidebar (status badge changes)\n3. If execution visible in grid → ExecutionMonitor updates via SSE\n\n#### Follow-up Submission\n1. User submits prompt in AgentConfigPanel\n2. Call `executionsApi.createFollowUp(executionId, { feedback })`\n3. New execution created\n4. WebSocket broadcasts `execution_created`\n5. Sidebar adds new execution to list\n6. User can check it to show in grid\n\n### WebSocket Integration\n- Subscribe to 'execution' entity type on page mount\n- Handle events:\n  - `execution_created`: Add to sidebar list\n  - `execution_updated`: Update execution metadata\n  - `execution_status_changed`: Update status badges\n  - `execution_deleted`: Remove from sidebar and grid\n- Unsubscribe on page unmount\n\n## Implementation Phases\n\n### Phase 1: Backend (1.5 hours)\n1. Add GET /api/executions endpoint to `/server/src/routes/executions.ts`\n2. Implement ExecutionService.listAll() method with filtering/pagination\n3. Test endpoint with various filters and pagination\n\n### Phase 2: Frontend Components (3 hours)\n1. Create ExecutionGridTile component\n   - Sticky header/footer with scrollable ExecutionMonitor\n   - Test with single execution\n2. Create ExecutionsGrid component\n   - CSS Grid with dynamic columns (2/3/4)\n   - Empty state handling\n3. Create ExecutionsSidebar component\n   - Execution list with checkboxes\n   - Metadata display (issue, branch, status, time)\n   - WebSocket subscription for updates\n4. Create ExecutionsPage component\n   - PanelGroup layout\n   - State management\n   - Grid layout controls\n\n### Phase 3: Integration (1.5 hours)\n1. Add route `/executions` to `/frontend/src/App.tsx`\n2. Add navigation link to MainLayout\n3. Add `executionsApi.listAll()` to API client\n4. Create `useExecutions()` React Query hook\n5. WebSocket integration for real-time updates\n6. Polish: empty states, loading states, error handling\n\n### Phase 4: Testing & Refinement (2 hours)\n1. Manual testing with multiple executions\n2. Test grid layout switches\n3. Test WebSocket real-time updates\n4. Test follow-up submissions\n5. Bug fixes and edge cases\n6. Responsive behavior testing\n\n**Total Estimated Time: 7 hours**\n\n## Success Criteria\n\nMVP is successful if:\n- ✅ Users can view multiple executions simultaneously in a grid\n- ✅ Users can show/hide executions via sidebar checkboxes\n- ✅ Users can interact with agent config panels for each execution\n- ✅ Grid layout can be changed between 2/3/4 columns\n- ✅ Real-time updates work via WebSocket\n- ✅ No performance issues with 10 concurrent executions\n- ✅ Implementation completed in 6-8 hours\n\n## Deferred Features (Future Versions)\n\n### v1.1 Enhancements\n- Keyboard shortcuts (Tab to cycle, Cmd+K quick switcher)\n- Search/filter in sidebar\n- Sort options (newest, status, priority)\n- Drag-and-drop to reorder grid tiles\n\n### v1.2 Performance\n- Virtualization for sidebar (when 100+ executions)\n- Smart SSE connection management (limit to 5 concurrent streams)\n- Memory optimization with ring buffers\n\n### v1.3 Advanced UX\n- Custom grid layouts (adjustable tile sizes)\n- Execution comparison view\n- Execution grouping/workspaces\n- Pin favorite executions\n\n## Testing Checklist\n\n### Manual Testing\n- [ ] Create 3 executions on different issues\n- [ ] Check all 3 in sidebar → verify grid shows 3 tiles\n- [ ] Uncheck 1 → verify it disappears from grid\n- [ ] Submit follow-up from one tile → verify new execution appears in sidebar\n- [ ] Change grid layout (2/3/4 col) → verify tiles reflow correctly\n- [ ] Reload page → verify grid layout preference persists\n- [ ] Cancel a running execution → verify status updates in sidebar and grid\n- [ ] Test on mobile (< 1024px) → verify forces 1 column\n\n### Edge Cases\n- [ ] Empty state when no executions exist\n- [ ] Empty state when executions exist but none checked\n- [ ] Handle execution deletion (remove from sidebar and grid)\n- [ ] Handle execution error states\n- [ ] Handle SSE disconnection and reconnection\n\n## Technical Constraints\n\n- Reuse ExecutionMonitor component (no modifications needed)\n- Reuse AgentConfigPanel component (no modifications needed)\n- Follow IssuesPage PanelGroup pattern for layout consistency\n- Use existing WebSocket infrastructure\n- No virtualization in MVP (defer to v1.2 if needed)\n- Grid layout preference persists via localStorage\n- Visible executions reset on page reload (sessionStorage)\n\n## Files Affected\n\n### New Files (4)\n1. `/frontend/src/pages/ExecutionsPage.tsx` (~350 lines)\n2. `/frontend/src/components/executions/ExecutionGridTile.tsx` (~200 lines)\n3. `/frontend/src/components/executions/ExecutionsGrid.tsx` (~80 lines)\n4. `/frontend/src/components/executions/ExecutionsSidebar.tsx` (~250 lines)\n\n### Modified Files (3)\n1. `/frontend/src/App.tsx` - Add route (~8 lines)\n2. `/frontend/src/lib/api.ts` - Add listAll method (~15 lines)\n3. `/server/src/routes/executions.ts` - Add GET /executions endpoint (~60 lines)\n\n### Reference Files (No Changes)\n1. `/frontend/src/pages/IssuesPage.tsx` - PanelGroup layout pattern\n2. `/frontend/src/components/executions/ExecutionMonitor.tsx` - Compact mode\n3. `/frontend/src/components/executions/AgentConfigPanel.tsx` - Follow-up mode\n4. `/frontend/src/components/executions/ExecutionView.tsx` - Structure reference","priority":1,"archived":0,"archived_at":null,"created_at":"2025-11-30 10:55:34","updated_at":"2025-11-30 10:55:34","parent_id":null,"parent_uuid":null,"relationships":[],"tags":["executions","feature","monitoring","ui"]}
{"id":"s-6h0o","uuid":"f6ea3c72-123d-4220-9c6b-8fa8989918da","title":"Execution Code Changes Extraction","file_path":"specs/s-6h0o_execution_code_changes_extraction.md","content":"# Execution Code Changes Extraction\n\n## Overview\n\nAdd functionality to extract and display code changes (file lists + diff statistics) from executions. This allows users to see what files were modified during an agent execution and view statistics about the changes.\n\n## Requirements\n\n### Functional Requirements\n\n1. **Data to Extract**\n   - List of changed files with paths\n   - Diff statistics per file (lines added/deleted)\n   - File status indicators (A=Added, M=Modified, D=Deleted, R=Renamed)\n   - Summary statistics (total files, total additions, total deletions)\n\n2. **Capture Timing**\n   - Capture when execution completes (status: 'completed')\n   - Capture when execution is stopped/cancelled (status: 'stopped')\n   - Do NOT capture for failed executions (inconsistent state)\n\n3. **Execution Modes Support**\n   - **Worktree mode**: Track changes in isolated worktree\n   - **Local mode**: Track changes in main repository working tree\n\n4. **Commit Scenarios**\n   - **Committed changes**: Agent commits changes during execution\n   - **Uncommitted changes**: Agent makes changes without committing (auto-commit disabled)\n   - Handle both scenarios transparently\n\n### Non-Functional Requirements\n\n1. **Minimal Storage**: Store only commit SHAs (80 bytes per execution), not full diffs\n2. **Recalculatable**: Changes can be re-computed at any time from git history\n3. **Fast UI**: Changes available within 50-200ms for typical executions\n4. **Clear Errors**: Show explicit error messages when changes unavailable\n5. **Simplicity**: Leverage existing git infrastructure, minimal new code\n\n## Design Approach\n\n### Core Strategy\n\n**On-demand calculation with commit SHA tracking**:\n- Store `before_commit` and `after_commit` SHAs in database (existing fields)\n- Calculate changes on-demand when UI requests them via new API endpoint\n- Use existing git CLI infrastructure for diff operations\n- Support both committed and uncommitted changes\n\n### Why This Approach?\n\n- ✅ Minimal storage overhead (just 2 commit SHAs)\n- ✅ Recalculatable anytime (not locked into initial calculation)\n- ✅ Simple implementation (reuse existing git utilities)\n- ✅ Works after worktree deletion (for committed changes)\n- ✅ No lifecycle complexity (just capture commits)\n\n## Architecture\n\n### Database Schema\n\n**No schema changes required** - use existing fields:\n```sql\nexecutions table:\n  - before_commit TEXT    -- Existing field\n  - after_commit TEXT     -- Existing field\n```\n\n### New Components\n\n1. **ExecutionChangesService** (`/server/src/services/execution-changes-service.ts`)\n   - Calculate diff statistics from commit SHAs\n   - Handle 3 diff scenarios (committed/uncommitted/none)\n   - Parse git numstat output\n   - Validate execution status and commit availability\n\n2. **API Endpoint** (`GET /api/executions/:executionId/changes`)\n   - Expose changes calculation to frontend\n   - Return structured diff data or unavailable reason\n\n3. **CodeChangesPanel** (`/frontend/src/components/executions/CodeChangesPanel.tsx`)\n   - UI component to display file changes\n   - Show file list with +/- statistics\n   - Badge for uncommitted changes\n   - Error states for unavailable changes\n\n4. **useExecutionChanges** (`/frontend/src/hooks/useExecutionChanges.ts`)\n   - React hook to fetch execution changes\n   - Handle loading/error states\n\n### Commit Capture Strategy\n\n#### before_commit Capture\n\n**Worktree mode**: Already captured during worktree creation (no changes needed)\n\n**Local mode**: Capture at execution creation\n```typescript\n// In ExecutionService.createExecution()\nif (mode === 'local') {\n  const beforeCommit = execSync('git rev-parse HEAD', { cwd: repoPath }).trim();\n  await updateExecution(db, executionId, { before_commit: beforeCommit });\n}\n```\n\n#### after_commit Capture\n\n**All modes**: Capture at execution completion/stop\n```typescript\n// In AgentExecutorWrapper.handleSuccess() and cancel()\nconst repoPath = execution.worktree_path || this.repoPath;\nconst afterCommit = execSync('git rev-parse HEAD', { cwd: repoPath }).trim();\nawait updateExecution(db, executionId, { after_commit: afterCommit });\n```\n\n### 3-Scenario Diff Strategy\n\nThe system automatically detects which scenario applies:\n\n#### Scenario A: Committed Changes\n**Condition**: `after_commit` exists and differs from `before_commit`\n\n**Git Command**:\n```bash\ngit diff --numstat --name-status --find-renames <before>..<after>\n```\n\n**Characteristics**:\n- Standard commit-to-commit diff\n- Works even after worktree deletion (git objects persist)\n- Most reliable scenario\n\n#### Scenario B: Uncommitted Changes\n**Condition**: `after_commit` is null OR equals `before_commit`\n\n**Git Command**:\n```bash\n# In worktree mode: use worktree_path if it exists\n# In local mode: use main repo path\ngit diff --numstat --name-status --find-renames HEAD\n```\n\n**Characteristics**:\n- Captures working tree changes relative to HEAD\n- Critical for executions without auto-commit enabled\n- Only works if worktree/working tree still exists\n- Set `uncommitted: true` in response\n\n#### Scenario C: No Changes\n**Condition**: No commits AND no working tree changes\n\n**Response**: Empty files array with zero summary stats\n\n### API Interface\n\n#### Request\n```\nGET /api/executions/:executionId/changes\n```\n\n#### Success Response (Committed Changes)\n```json\n{\n  \"success\": true,\n  \"data\": {\n    \"available\": true,\n    \"uncommitted\": false,\n    \"commitRange\": {\n      \"before\": \"abc123...\",\n      \"after\": \"def456...\"\n    },\n    \"changes\": {\n      \"files\": [\n        {\n          \"path\": \"frontend/src/App.tsx\",\n          \"additions\": 5,\n          \"deletions\": 2,\n          \"status\": \"M\"\n        },\n        {\n          \"path\": \"server/src/new-file.ts\",\n          \"additions\": 20,\n          \"deletions\": 0,\n          \"status\": \"A\"\n        }\n      ],\n      \"summary\": {\n        \"totalFiles\": 2,\n        \"totalAdditions\": 25,\n        \"totalDeletions\": 2\n      }\n    }\n  }\n}\n```\n\n#### Success Response (Uncommitted Changes)\n```json\n{\n  \"success\": true,\n  \"data\": {\n    \"available\": true,\n    \"uncommitted\": true,\n    \"commitRange\": null,\n    \"changes\": {\n      \"files\": [...],\n      \"summary\": {...}\n    }\n  }\n}\n```\n\n#### Error Response (Unavailable)\n```json\n{\n  \"success\": true,\n  \"data\": {\n    \"available\": false,\n    \"reason\": \"worktree_deleted_with_uncommitted_changes\"\n  }\n}\n```\n\n**Unavailability Reasons**:\n- `missing_commits`: before_commit not captured\n- `commits_not_found`: Commits garbage collected\n- `incomplete_execution`: Execution status not completed/stopped\n- `git_error`: Git command failed\n- `worktree_deleted_with_uncommitted_changes`: Uncommitted changes lost\n\n## Edge Cases\n\n| Scenario | Handling |\n|----------|----------|\n| Uncommitted changes (no auto-commit) | Use `git diff HEAD` to capture working tree changes, set `uncommitted: true` |\n| Uncommitted + worktree deleted | Return `available: false, reason: 'worktree_deleted_with_uncommitted_changes'` |\n| Committed changes + worktree deleted | Git objects persist in main repo - diff still works |\n| Commits garbage collected | Return `available: false, reason: 'commits_not_found'` |\n| Execution failed early | Return `available: false, reason: 'incomplete_execution'` |\n| Local mode (no isolation) | Capture before_commit at creation, check uncommitted or committed changes |\n| after_commit == before_commit | Treat as uncommitted changes, use `git diff HEAD` |\n| Binary files | Git numstat shows `-` for binary, parse as 0 changes |\n| Empty diff | Return empty files array with 0 summary stats |\n| Large diffs (1000+ files) | Return all files (UI can paginate if needed) |\n| Missing before commit | Return `available: false, reason: 'missing_commits'` |\n\n## UI Design\n\n### Display Location\nIntegrate `CodeChangesPanel` into `ExecutionView` for completed/stopped executions.\n\n### Component Features\n- File list with status badges (A/M/D/R)\n- Per-file statistics (+5 -2 format)\n- Summary header (X files changed, +Y -Z)\n- \"Uncommitted Changes\" badge when applicable\n- Warning message for uncommitted changes\n- Error state for unavailable changes with reason\n\n### Optional Caching\nSimple in-memory cache with 5-minute TTL for performance optimization (can be added later if needed).\n\n## Performance Characteristics\n\n### Computation Time\n- Git diff command: 50-200ms for typical changes (10-100 files)\n- Large diffs (1000+ files): 500ms-2s\n- On-demand calculation: Acceptable for UI\n- With cache: <1ms for repeated requests\n\n### Storage Impact\n- Per execution: 80 bytes (2 commit SHAs)\n- No permanent diff storage: Zero overhead\n- Cache memory: ~5KB per execution × active requests only\n\n### Network Impact\n- API response: 2-10KB for typical changes (50 files)\n- Large diffs: 50KB (500 files)\n- Gzip compression: ~5x reduction\n\n## Implementation Files\n\n### Backend (New)\n- `/server/src/services/execution-changes-service.ts` - Core diff calculation service\n- `/server/tests/unit/services/execution-changes-service.test.ts` - Unit tests\n- `/server/tests/integration/execution-changes.test.ts` - Integration tests\n\n### Backend (Modified)\n- `/server/src/services/execution-service.ts` - Add before_commit capture for local mode\n- `/server/src/execution/executors/agent-executor-wrapper.ts` - Add after_commit capture\n- `/server/src/routes/executions.ts` - Add changes API endpoint\n\n### Frontend (New)\n- `/frontend/src/hooks/useExecutionChanges.ts` - React hook\n- `/frontend/src/components/executions/CodeChangesPanel.tsx` - UI component\n- `/frontend/tests/components/executions/CodeChangesPanel.test.tsx` - Component tests\n\n### Frontend (Modified)\n- `/frontend/src/lib/api.ts` - Add getChanges() API client method\n- `/frontend/src/components/executions/ExecutionView.tsx` - Integrate CodeChangesPanel\n\n## Testing Strategy\n\n### Unit Tests\n- Parse numstat output correctly\n- Handle binary files (- -)\n- Detect file status (A/M/D/R)\n- Calculate summary statistics\n- Return unavailable when commits missing\n- Return unavailable when status not completed/stopped\n- Handle git command errors gracefully\n- Detect uncommitted changes (after_commit == before_commit)\n- Use git diff HEAD for uncommitted changes\n- Handle worktree deleted with uncommitted changes\n\n### Integration Tests\n- End-to-end: create execution → complete → get changes (committed)\n- End-to-end: create execution → complete → get changes (uncommitted)\n- Worktree mode with real git operations\n- Local mode with real git operations\n- Cancelled execution captures changes\n- Changes calculated after worktree cleanup (committed changes)\n- Uncommitted changes not available after worktree cleanup\n\n### Frontend Tests\n- Display file list correctly\n- Show summary statistics\n- Handle unavailable state with error message\n- Handle loading state\n- Handle fetch errors\n- Display uncommitted badge when appropriate\n\n## Migration & Rollout\n\n### Backward Compatibility\n- Old executions: May have null `before_commit` or `after_commit`\n- Handling: Return `available: false, reason: 'missing_commits'`\n- No database migration needed: Additive-only changes\n\n### Rollout Strategy\n1. Deploy backend changes (commit capture + API endpoint)\n2. Monitor that commits are being captured correctly\n3. Deploy frontend changes (UI components)\n4. Verify in production with real executions\n\n## Success Criteria\n\n1. ✅ Users can view code changes for completed executions\n2. ✅ Changes display within 200ms for typical executions\n3. ✅ Both committed and uncommitted changes are tracked\n4. ✅ Clear error messages when changes unavailable\n5. ✅ Works for both worktree and local mode executions\n6. ✅ No storage bloat (only commit SHAs stored)\n7. ✅ Changes recalculatable at any time\n\n## Estimated Effort\n\n**5-7 hours** total implementation time","priority":2,"archived":0,"archived_at":null,"created_at":"2025-11-30 10:59:23","updated_at":"2025-11-30 10:59:23","parent_id":null,"parent_uuid":null,"relationships":[],"tags":["executions","feature","git","ui"]}
{"id":"s-2s2l","uuid":"98c9a2dc-9607-40cf-9d46-46396d3f38d0","title":"IDE Opening for Execution Worktrees","file_path":"specs/s-2s2l_ide_opening_for_execution_worktrees.md","content":"# IDE Opening for Execution Worktrees\n\n## Overview\n\nEnable users to open execution worktrees directly in their configured IDE from the web UI, replacing the current clipboard-copy workflow with seamless IDE integration.\n\n## Background\n\n**Current State:**\n\n- When users want to inspect or modify execution worktrees, they must:\n  1. Click \"Open in IDE\" button\n  1. Path is copied to clipboard with alert dialog\n  1. Manually open their IDE and navigate to the path\n- This creates friction and interrupts the workflow\n\n**Desired State:**\n\n- Single click opens the worktree directly in the user's preferred IDE\n- Supports multiple popular editors (VS Code, Cursor, Windsurf, IntelliJ, Zed, Xcode, custom)\n- Per-user configuration (not project-wide)\n- Local IDE opening only (no remote SSH in initial version)\n\n## Requirements\n\n### Functional Requirements\n\n**FR1: IDE Opening**\n\n- Users can open execution worktrees in their configured IDE with a single click\n- System spawns the IDE process with the worktree path as an argument\n- Works for any execution that has a valid worktree\n\n**FR2: Multiple Editor Support**\n\n- Support popular editors:\n  - VS Code (`code` command)\n  - Cursor (`cursor` command)\n  - Windsurf (`windsurf` command)\n  - IntelliJ IDEA (`idea` command)\n  - Zed (`zed` command)\n  - Xcode (`xed` command)\n  - Custom command (user-specified)\n\n**FR3: Per-User Configuration**\n\n- Each user can configure their preferred editor\n- Configuration stored in `.sudocode/config.local.json` (gitignored)\n- Default: VS Code if available, otherwise first available editor\n- Falls back gracefully if configured editor not available\n\n**FR4: Editor Availability Detection**\n\n- System detects which editors are installed/available\n- Settings UI shows only available editors\n- Helpful error messages when configured editor is unavailable\n\n**FR5: User Feedback**\n\n- Toast notifications for success/failure\n- Clear error messages with actionable guidance\n- Replace current alert() dialogs with modern toast notifications\n\n### Non-Functional Requirements\n\n**NFR1: Security**\n\n- All command execution happens server-side\n- Frontend cannot inject arbitrary commands\n- Command validation and sanitization\n\n**NFR2: Cross-Platform Compatibility**\n\n- Works on macOS, Linux, and Windows\n- Platform-specific command resolution using Node.js `which` package\n\n**NFR3: Performance**\n\n- Editor availability checks cached (5-minute TTL)\n- Non-blocking editor spawning (detached processes)\n- No impact on execution performance\n\n**NFR4: Extensibility**\n\n- Architecture supports future enhancements:\n  - Remote SSH editor support\n  - File-specific opening (not just worktree root)\n  - Multi-file opening\n  - Editor-specific arguments\n\n## Design\n\n### Architecture\n\nBased on vibe-kanban's clean implementation pattern:\n\n```\nFrontend (ExecutionView)\n    ↓ HTTP POST /api/executions/:id/open-in-ide\nAPI Routes (executions.ts)\n    ↓\nEditorService\n├── getCommand() - Map editor type to command string\n├── checkAvailability() - Use 'which' to verify installation\n└── spawnEditor() - Launch detached process\n    ↓\nNode.js child_process.spawn() + which package\n```\n\n### Implementation Approach (from vibe-kanban)\n\n**Command Resolution Pattern:**\n\n```typescript\nclass EditorService {\n  // Simple string mapping (vibe-kanban's approach)\n  getCommand(editorType: EditorType): string {\n    const commands = {\n      'vs-code': 'code',\n      'cursor': 'cursor',\n      'windsurf': 'windsurf',\n      'intellij': 'idea',\n      'zed': 'zed',\n      'xcode': 'xed'\n    }\n    return commands[editorType] || 'code'\n  }\n\n  // Availability check using which\n  async checkAvailability(command: string): Promise<boolean> {\n    try {\n      await which(command)\n      return true\n    } catch {\n      return false\n    }\n  }\n\n  // Non-blocking spawn (vibe-kanban's approach)\n  async spawnEditor(path: string, command: string): Promise<void> {\n    spawn(command, [path], {\n      detached: true,\n      stdio: 'ignore'\n    })\n  }\n}\n```\n\n**Key Simplifications for Phase 1:**\n\n- Use `which` npm package instead of complex PATH refresh (simpler than vibe-kanban's Rust version)\n- Direct command mapping without CommandBuilder abstraction\n- Node.js handles cross-platform differences automatically\n\n**Future Enhancement (Phase 2+):**\n\n- Could add PATH refresh logic like vibe-kanban if needed (spawning login shell)\n- For now, simple `which` lookup is sufficient\n\n### Data Model\n\n**EditorType Enum:**\n\n```typescript\nenum EditorType {\n  VS_CODE = 'vs-code',\n  CURSOR = 'cursor',\n  WINDSURF = 'windsurf',\n  INTELLIJ = 'intellij',\n  ZED = 'zed',\n  XCODE = 'xcode',\n  CUSTOM = 'custom'\n}\n```\n\n**EditorConfig Interface:**\n\n```typescript\ninterface EditorConfig {\n  editorType: EditorType\n  customCommand?: string  // Required if editorType === 'custom'\n}\n```\n\n**Configuration File (**`.sudocode/config.local.json`**):**\n\n```json\n{\n  \"editor\": {\n    \"editorType\": \"vs-code\",\n    \"customCommand\": null\n  }\n}\n```\n\n### API Design\n\n**Endpoint 1: Open Worktree in IDE**\n\n```\nPOST /api/executions/:executionId/open-in-ide\n\nRequest:\n{\n  editorType?: string  // Optional override for this execution\n}\n\nResponse:\n{\n  success: boolean\n  message?: string\n  error?: {\n    code: 'EDITOR_NOT_FOUND' | 'WORKTREE_MISSING' | 'SPAWN_FAILED'\n    details: string\n  }\n}\n```\n\n**Endpoint 2: Get Editor Configuration (Phase 2)**\n\n```\nGET /api/config/editor\n\nResponse:\n{\n  editorType: string\n  customCommand?: string\n}\n```\n\n**Endpoint 3: Update Editor Configuration (Phase 2)**\n\n```\nPUT /api/config/editor\n\nRequest:\n{\n  editorType: string\n  customCommand?: string\n}\n\nResponse:\n{\n  success: boolean\n  config: EditorConfig\n}\n```\n\n**Endpoint 4: Check Editor Availability (Phase 2)**\n\n```\nGET /api/config/editor/available\n\nResponse:\n{\n  available: {\n    'vs-code': boolean,\n    'cursor': boolean,\n    'windsurf': boolean,\n    'intellij': boolean,\n    'zed': boolean,\n    'xcode': boolean\n  },\n  current: EditorConfig\n}\n```\n\n### Component Design\n\n**EditorService (Backend)**\n\n```typescript\nclass EditorService {\n  /**\n   * Load editor configuration from .sudocode/config.local.json\n   * Falls back to default (VS Code) if file doesn't exist\n   */\n  loadConfig(): EditorConfig\n  \n  /**\n   * Get command name for editor type\n   * Examples: 'vs-code' → 'code', 'cursor' → 'cursor'\n   * Based on vibe-kanban's simple string mapping\n   */\n  getCommand(editorType: EditorType): string\n  \n  /**\n   * Check if editor command is available using 'which' package\n   * Simpler than vibe-kanban's PATH refresh approach\n   */\n  async checkAvailability(command: string): Promise<boolean>\n  \n  /**\n   * Spawn editor process with worktree path\n   * Detached mode for non-blocking execution (vibe-kanban pattern)\n   * Returns immediately after spawn\n   */\n  async spawnEditor(path: string, config: EditorConfig): Promise<void>\n  \n  /**\n   * Check availability of all supported editors (Phase 2)\n   */\n  async checkAllAvailability(): Promise<Record<EditorType, boolean>>\n}\n```\n\n**useExecutionSync Hook (Frontend)**\n\n```typescript\n// Update existing openWorktreeInIDE function\nconst openWorktreeInIDE = useCallback(async (execution: Execution) => {\n  if (!execution.worktree_path) {\n    toast.error('No worktree path available')\n    return\n  }\n\n  try {\n    await executionsApi.openInIde(execution.id)\n    toast.success('Opening worktree in IDE...')\n  } catch (error) {\n    const message = error instanceof Error ? error.message : 'Failed to open IDE'\n    toast.error(message)\n  }\n}, [])\n```\n\n### Error Handling\n\n**Error Types (based on vibe-kanban's pattern):**\n\n```typescript\nclass EditorOpenError extends Error {\n  code: 'EDITOR_NOT_FOUND' | 'WORKTREE_MISSING' | 'SPAWN_FAILED'\n  editorType: EditorType\n  details?: string\n}\n```\n\n**Error Messages:**\n\n1. **EDITOR\\_NOT\\_FOUND**: Configured editor command not in PATH\n\n- Message: \"Editor not found. Please install \\[editor name\\] or configure a different editor in Settings.\"\n\n1. **WORKTREE\\_MISSING**: Execution has no worktree path\n\n- Message: \"No worktree available for this execution.\"\n\n1. **SPAWN\\_FAILED**: Process launch failed\n\n- Message: \"Failed to launch editor. Check that \\[editor name\\] is properly installed.\"\n\n**Fallback Strategy:**\n\n- Log detailed error server-side\n- Return user-friendly error message to frontend\n- Toast notification with error and guidance\n- No fallback to clipboard copy (clean separation of concerns)\n\n### User Experience Flow\n\n**Basic Flow (Phase 1):**\n\n1. User completes execution (has worktree)\n1. User clicks \"Open in IDE\" button in ExecutionView\n1. Frontend calls `POST /api/executions/:id/open-in-ide`\n1. Backend loads editor config (default: VS Code)\n1. Backend spawns editor process: `code /path/to/worktree` (detached)\n1. Toast shows \"Opening worktree in IDE...\"\n1. IDE launches with worktree open\n\n**Configuration Flow (Phase 2):**\n\n1. User navigates to Settings page\n1. System checks which editors are available\n1. User sees dropdown with available editors (checkmarks)\n1. User selects preferred editor\n1. User clicks \"Save\"\n1. Configuration saved to `.sudocode/config.local.json`\n1. Toast shows \"Editor configuration saved\"\n\n**Error Flow:**\n\n1. User clicks \"Open in IDE\"\n1. Backend attempts to spawn editor\n1. Editor not found (not in PATH)\n1. Error response returned\n1. Toast shows: \"VS Code not found. Please install VS Code or configure a different editor in Settings.\"\n\n## Implementation Phases\n\n### Phase 1: Basic IDE Opening (MVP)\n\n**Goal:** Replace clipboard copy with actual IDE opening\n\n**Scope:**\n\n- Backend EditorService with all editor type support\n- API endpoint for opening worktrees\n- Frontend hook integration\n- Toast notifications\n- Default to VS Code, fall back gracefully\n\n**Implementation Details:**\n\n- Use vibe-kanban's simple command mapping approach\n- Use Node.js `which` package for availability checking\n- Use `child_process.spawn()` with detached mode (vibe-kanban pattern)\n- Install `which` npm package: `npm install which @types/which`\n\n**Timeline:** 2-3 days\n\n**Success Criteria:**\n\n- ✓ Clicking \"Open in IDE\" launches VS Code with worktree\n- ✓ Error handling for editor not installed\n- ✓ Toast notifications replace alert dialogs\n- ✓ No regression in worktree functionality\n\n### Phase 2: Configuration UI\n\n**Goal:** Allow users to configure preferred editor\n\n**Scope:**\n\n- Settings page with editor selector\n- Editor availability detection\n- Configuration API endpoints\n- Editor icons in UI\n- Per-user configuration persistence\n\n**Timeline:** 3-5 days\n\n**Success Criteria:**\n\n- ✓ Settings page shows available editors\n- ✓ User can select and save preferred editor\n- ✓ Configuration persists across sessions\n- ✓ Each editor type works when installed\n- ✓ Custom command support\n\n### Phase 3: File-Specific Opening (Future)\n\n**Goal:** Open specific files that changed during execution\n\n**Scope:** Deferred - focusing on worktree root first\n\n**Future Requirements:**\n\n- Track changed files during execution\n- API to retrieve changed files list\n- UI to select files to open\n- Pass file paths to editor command\n\n## Technical Considerations\n\n### Command Resolution Strategy\n\n**Editor → Command Mapping (vibe-kanban approach):**\n\n```typescript\nconst EDITOR_COMMANDS: Record<EditorType, string> = {\n  'vs-code': 'code',\n  'cursor': 'cursor',\n  'windsurf': 'windsurf',\n  'intellij': 'idea',\n  'zed': 'zed',\n  'xcode': 'xed'\n}\n```\n\n**Availability Detection:**\n\n```typescript\nimport which from 'which'\n\nasync function checkAvailability(command: string): Promise<boolean> {\n  try {\n    await which(command)\n    return true\n  } catch {\n    return false\n  }\n}\n```\n\n### Process Spawning Strategy\n\n**Detached Mode (vibe-kanban pattern):**\n\n```typescript\nimport { spawn } from 'child_process'\n\nfunction spawnEditor(command: string, worktreePath: string): void {\n  spawn(command, [worktreePath], {\n    detached: true,      // Don't wait for process to exit\n    stdio: 'ignore',     // Ignore stdout/stderr\n    cwd: worktreePath    // Set working directory\n  })\n}\n```\n\n**Benefits:**\n\n- Server doesn't block waiting for editor to close\n- Editor runs as independent process\n- API responds immediately\n\n### Configuration Management\n\n**File Location:** `.sudocode/config.local.json`\n\n**Why Local Config:**\n\n- Per-user preferences (different developers prefer different editors)\n- Gitignored (doesn't pollute repository)\n- Follows existing sudocode configuration patterns\n- Can provide `.sudocode/config.local.json.example` for teams\n\n**Default Behavior:**\n\n- If file doesn't exist, default to VS Code\n- If VS Code not available, check other editors in priority order\n- If no editors available, return helpful error\n\n### Security Considerations\n\n**Command Injection Prevention:**\n\n- All commands hardcoded in EditorService (vibe-kanban approach)\n- Only allow predefined editor types\n- Custom commands validated (no shell metacharacters)\n- Paths sanitized and validated\n\n**Server-Side Execution:**\n\n- Frontend cannot execute arbitrary commands\n- All spawning happens server-side with validation\n- Request validation and sanitization\n\n### Dependencies\n\n**New NPM Packages:**\n\n- `which` - Cross-platform command resolution\n- `@types/which` - TypeScript types\n\n**Installation:**\n\n```bash\nnpm install which @types/which\n```\n\n## Success Metrics\n\n**Phase 1:**\n\n- Users stop manually opening IDEs for worktree inspection\n- Reduction in time to start editing worktree code\n- Positive user feedback on workflow improvement\n\n**Phase 2:**\n\n- Multiple editor types being used\n- Users successfully configure custom editors\n- Zero support requests about editor configuration\n\n## Reference Implementation\n\nBased on vibe-kanban's implementation:\n\n- `/references/vibe-kanban/crates/services/src/services/config/editor/mod.rs` - Core patterns\n  - Lines 83-97: Simple command mapping\n  - Lines 127-129: Availability checking\n  - Lines 160-171: Non-blocking spawn pattern\n- `/references/vibe-kanban/crates/utils/src/shell.rs` - Command resolution\n  - Lines 32-53: Multi-stage executable resolution (simplified for Node.js)\n  - Lines 95-101: Using `which` crate\n\n**Key Adaptations:**\n\n- Rust → TypeScript translation\n- Use Node.js `which` package instead of Rust `which` crate\n- Simplify PATH refresh (not needed initially with `which` package)\n- Adapt to sudocode's configuration patterns\n- Integrate with existing execution infrastructure\n\n## Open Questions\n\nNone - requirements clarified with user:\n\n- ✓ Editor support: Multiple editors (not just VS Code)\n- ✓ Remote support: Local only (no SSH)\n- ✓ Target: Worktree root first, file-specific later\n- ✓ Configuration: `.sudocode/config.local.json` (gitignored)\n- ✓ Implementation approach: Use vibe-kanban's patterns\n\n## Dependencies\n\n**Technical:**\n\n- Node.js `child_process` module (built-in)\n- Node.js `path` module (built-in)\n- `which` npm package (new dependency)\n- Existing execution/worktree infrastructure\n\n**External:**\n\n- Users must have editor installed and in PATH\n- Editors must support command-line launching with directory argument\n\n## Future Enhancements\n\nNot in current scope, but architecture supports:\n\n1. **Remote SSH Support**\n\n- Generate `vscode://vscode-remote/ssh-remote+user@host/path` URLs\n- Support remote development workflows\n\n1. **File-Specific Opening**\n\n- Open specific files that changed during execution\n- Pass line/column numbers for precise navigation\n\n1. **Multi-File Opening**\n\n- Open multiple changed files simultaneously\n- Editor-specific multi-file arguments\n\n1. **Editor Arguments**\n\n- Custom flags per editor (e.g., `--new-window`, `--goto`)\n- User-configurable argument templates\n\n1. **PATH Refresh Enhancement**\n\n- Add vibe-kanban's login shell PATH refresh if simple `which` proves insufficient\n- Would help in GUI environments with limited PATH\n\n1. **Keyboard Shortcuts**\n\n- Hotkeys to open IDE from execution view\n- Quick actions menu integration\n\n1. **Integration with Follow-Ups**\n\n- \"Open in IDE and create follow-up\" workflow\n- Automatic follow-up after manual edits","priority":1,"archived":0,"archived_at":null,"created_at":"2025-11-30 11:04:27","updated_at":"2025-11-30 11:10:42","parent_id":null,"parent_uuid":null,"relationships":[],"tags":["developer-experience","feature","ide-integration","worktree"]}
